{"Procedure":{"Name":"ADAPTIVEREG","ProductGroup":"SAS/STAT","ProcedureHelp":{"#cdata":"Syntax: PROC ADAPTIVEREG <options> ; \n    BY variables ; \n    CLASS variables </ options> ; \n    FREQ variable ; \n    MODEL dependent <(options)> = <effects></ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword <(keyword-options )> <=name>> \u2026<keyword <(keyword-options )> <=name>> ; \n    PARTITION <options> ; \n    SCORE <DATA=SAS-data-set> <OUT=SAS-data-set><keyword <=name>>\u2026<keyword <=name>> ; \n    WEIGHT variable ; \n\n[SAS/STAT 12.1 Experimental Procedure]\n\nThe ADAPTIVEREG procedure fits multivariate adaptive regression splines as defined by Friedman (1991b). \nThe method is a nonparametric regression technique that combines both regression splines and model \nselection methods. It does not assume parametric model forms and does not require specification of \nknot values for constructing regression spline terms. Instead, it constructs spline basis functions \nin an adaptive way by automatically selecting appropriate knot values for different variables and \nobtains reduced models by applying model selection techniques.\n\nThe main features of the ADAPTIVEREG procedure are as follows: \n\n\u2022 supports classification variables with ordering options \n\u2022 enables you to force effects in the final model or restrict variables in linear forms \n\u2022 supports options for fast forward selection \n\u2022 supports data with response variables that are distributed in the exponential family \n\u2022 supports partitioning of data into training, validation, and testing roles \n\u2022 provides leave-one-out and k-fold cross validation \n\u2022 produces a graphical representation of the selection process, model fit, functional components, \n  and fit diagnostics \n\u2022 produces an output data set that contains predicted values and residuals \n\u2022 produces an output data set that contains the design matrix of formed basis functions \n\u2022 supports multiple SCORE statements"},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"Syntax: DATA=SAS-data-set\n      \nSpecifies the SAS data set to be read by PROC ADAPTIVEREG. If you do not specify the DATA= \noption, PROC ADAPTIVEREG uses the most recently created SAS data set."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"DETAILS=","ProcedureOptionHelp":{"#cdata":"Syntax: DETAILS<=(detail-options)> \n      \nRequests detailed model fitting information. You can specify the following detail-options: \n\nBASES -- displays the \u201cBases Information\u201d table. \nBWDSUMMARY -- displays the \u201cBackward Selection Summary\u201d table. \nFWDSUMMARY -- displays the \u201cForward Selection Summary\u201d table. \nFWDPARAMS -- displays the \u201cForward Selection Parameter Estimates\u201d table. \n\nIf you do not specify a detail-option, PROC ADAPTIVEREG produces all the preceding tables by default."},"ProcedureOptionType":"S|V","SubOptionsKeywords":"BASES|BWDSUMMARY|FWDSUMMARY|FWDPARAMS"},{"ProcedureOptionName":"NAMELEN=","ProcedureOptionHelp":{"#cdata":"Syntax: NAMELEN=number \n      \nSpecifies the length to which long effect names are shortened. The default and minimum value is 20."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NLOPTIONS","ProcedureOptionHelp":{"#cdata":"Syntax: NLOPTIONS(options) \n      \nSpecifies options for the nonlinear optimization methods if you are applying the multivariate adaptive \nregression splines algorithm to generalized linear models. You can specify the following options: \n\nABSCONV=r | ABSTOL=r \n  specifies an absolute function convergence criterion by which minimization stops. The default value \n  of r is the negative square root of the largest double-precision value, which serves only as a \n  protection against overflows. \nABSFCONV=r | ABSFTOL=r \n  specifies an absolute function difference convergence criterion. The default value is r=0. \nABSGCONV=r | ABSGTOL=r \n  specifies an absolute gradient convergence criterion. This criterion is not used by the NMSIMP \n  technique. The default value is r = 1E\u20135. \nFCONV=r | FTOL=r \n  specifies a relative function convergence criterion. \nGCONV=r | GTOL=r \n  specifies a relative gradient convergence criterion. This criterion is not used by the NMSIMP \n  technique. The default value is r = 1E\u20138. \nHESSIAN=hessian-options\n  specifies the Hessian matrix type used in the optimization of likelihood functions, if the Newton-Raphson technique is used. You can specify the following hessian-options: \n\n  EXPECTED -- requests that the Hessian matrix in optimization be computed as the negative of the expected information matrix. \n  OBSERVED -- requests that the Hessian matrix in optimization be computed as the negative of the observed information matrix. \n  For many specified distribution families and link functions, the observed information matrix is equal to the expected information matrix. \n\nThe default is HESSIAN=EXPECTED. \nMAXFUNC=n | MAXFU=n \n  specifies the maximum number of function calls in the optimization process. The default values are as follows, \n  depending on the optimization technique: \n\n    \u2022 TRUREG, NRRIDG, and NEWRAP: 125 \n    \u2022 QUANEW and DBLDOG: 500 \n    \u2022 CONGRA: 1000 \n    \u2022 NMSIMP: 3000 \n\nThe optimization can terminate only after completing a full iteration. Therefore, the number of function calls \nthat are actually performed can exceed the number that is specified by this option. You can select the optimization \ntechnique by specifying the TECHNIQUE= option. \n\nMAXITER=n | MAXIT=n \n  specifies the maximum number of iterations in the optimization process. The default values are as follows, \n  depending on the optimization technique: \n\n    \u2022 TRUREG, NRRIDG, and NEWRAP: 50 \n    \u2022 QUANEW and DBLDOG: 200 \n    \u2022 CONGRA: 400 \n    \u2022 NMSIMP: 1000 \n    \nThese default values also apply when n is specified as a missing value. You can select the \noptimization technique by specifying the TECHNIQUE= option. \n\nMAXTIME=r\n  specifies an upper limit of r seconds of CPU time for the optimization process. The default \n  value is the largest floating-point double representation of your computer. The time that \n  is specified by the MAXTIME= option is checked only once at the end of each iteration. \n  Therefore, the actual running time can be longer than the time specified by this option. \nMINITER=n | MINIT=n \n  specifies the minimum number of iterations. The default value is 0. If you request more \n  iterations than are actually needed for convergence to a stationary point, the optimization \n  algorithms can behave strangely. For example, the effect of rounding errors can prevent the \n  algorithm from continuing for the required number of iterations. \nTECHNIQUE=keyword\n  specifies the optimization technique to obtain maximum likelihood estimates for nonnormal \n  distributions. You can choose from the following techniques by specifying the appropriate keyword: \n\n    CONGRA -- performs a conjugate-gradient optimization. \n    DBLDOG -- performs a version of double-dogleg optimization. \n    NEWRAP -- performs a Newton-Raphson optimization that combines a line-search algorithm with ridging. \n    NMSIMP -- performs a Nelder-Mead simplex optimization. \n    NONE --   performs no optimization. \n    NRRIDG -- performs a Newton-Raphson optimization with ridging. \n    QUANEW -- performs a dual quasi-Newton optimization. \n    TRUREG -- performs a trust-region optimization. \n\nThe default is TECHNIQUE=NEWRAP."},"ProcedureOptionType":"S","SubOptionsKeywords":null},{"ProcedureOptionName":"NOTHREADS","ProcedureOptionHelp":{"#cdata":"Forces single-threaded execution of the analytic computations. This overrides the SAS system \noption THREADS | NOTHREADS. Specifying this option is equivalent to specifying the THREADS=1\noption."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"OUTDESIGN=","ProcedureOptionHelp":{"#cdata":"Syntax: OUTDESIGN<(options)>=SAS-data-set\n      \nCreates a data set that contains the design matrix of constructed basis functions. The design \nmatrix column names consist of a prefix followed by an index. The default naming prefix is _X. \nThe default output is the design matrix of basis functions after backward selection. \n\nYou can specify the following options in parentheses to control the content of the OUTDESIGN= data set: \n\n  BACKWARDMODEL |BACKWARD \n    produces the design matrix for the selected model after the backward selection. \n  FORWARDMODEL |FORWARD \n    produces the design matrix for the selected model after the forward selection. \n  PREFIX=prefix\n    requests that the design matrix column names consist of a prefix followed by an index. \n  STARTMODEL \n    produces the design matrix for the initial model specified in the MODEL statement."},"ProcedureOptionType":"S|V","SubOptionsKeywords":"BACKWARDMODEL|BACKWARD|FORWARDMODEL|FORWARD|PREFIX=|STARTMODEL"},{"ProcedureOptionName":"PLOTS=","ProcedureOptionHelp":{"#cdata":"Syntax: PLOTS <(global-plot-options)> <= plot-request <(options)>> \nPLOTS <(global-plot-options)> <= (plot-request <(options)> <... plot-request <(options)>>)> \n\nControls the plots produced through ODS Graphics. When you specify only one plot-request, \nyou can omit the parentheses around the plot-request.\n\nYou can specify the following global-plot-option, which applies to all plots that the \nADAPTIVEREG procedure generates: \n\nUNPACK |UNPACKPANEL \n  suppresses paneling. By default, multiple plots can appear in some output panels. \n  \nSpecify UNPACK to get each plot individually. You can also specify UNPACK as a suboption \nwith COMPONENTS and DIAGNOSTICS."},"ProcedureOptionType":"S|V","ProcedureOptionValues":{"@Value1":"ALL","@Value2":"COMPONENTS","@Value3":"DIAGNOSTICS","@Value4":"FIT","@Value5":"NONE","@Value6":"SELECTION"},"ProcedureOptionToolTips":{"@ToolTip1":"Requests that all default plots be produced.","@ToolTip2":"Syntax: COMPONENTS <(component-options)>                                   Plots a panel of functional components of the fitted model. You can specify the following component-options:     COMMONAXES -- specifies that the functional component plots use a common vertical axis except for contour      plots. This enables you to visually judge relative effect size.         UNPACK |UNPACKPANEL -- displays the component plots individually.","@ToolTip3":"Syntax: DIAGNOSTICS <(UNPACK |UNPACKPANEL)>>                                 Produces a summary panel of fit diagnostics that consists of the following:     \u2022 residuals versus the predicted values    \u2022 a histogram of the residuals    \u2022 a normal quantile plot of the residuals    \u2022 a residual-fit (RF) plot that consists of side-by-side quantile plots of the centered fit and the residuals    \u2022 response values versus the predicted values   You can request the five plots in this panel as individual plots by specifying the UNPACK suboption.  The fit diagnostics panel is not produced for dependent variable with nonnormal distributions.","@ToolTip4":"FIT <(NODATA |NOOBS)>                                  Produces a plot of the predicted values against the variables that form the selected model.  By default, a scatter plot of the input data is overlaid. You can suppress the scatter plot  by specifying the NODATA | NOOBS option.   The plot is not produced if the number of variables in the selected model exceeds two. The  plot is not produced for dependent variables with nonnormal distributions.","@ToolTip5":"Suppresses all plots.","@ToolTip6":"Syntax: SELECTION <(selection-panel-options)>                                 Plots a panel of model fit criteria. The panel consists of two plots. The upper plot shows  the progression of the model lack-of-fit criterion as the selection process proceeds. The  lower plot shows the progression of the model validation criterion as the selection process  proceeds. By default, the selection panel shows the progression for the backward selection  process. You can specify the following selection-panel-options:     BACKWARDMODEL |BACKWARD      displays the progression of model fit criteria for the backward selection process.    FORWARDMODEL |FORWARD      displays the progression of model fit criteria for the forward selection process."},"SubOptionsKeywords":"UNPACK|UNPACKPANEL|NODATA|NOOBS|BACKWARDMODEL|BACKWARD|FORWARDMODEL|FORWARD"},{"ProcedureOptionName":"SEED=","ProcedureOptionHelp":{"#cdata":"Syntax: SEED=number\n      \nSpecifies an integer used to start the pseudorandom number generator for random cross validation \nand random partitioning of data for training, testing, and validation. If you do not specify a \nseed, or if you specify a value less than or equal to 0, the seed is generated from the time of \nday, which is read from the computer\u2019s clock."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SINGULAR=|EPSILON=","ProcedureOptionHelp":{"#cdata":"[Syntax: SINGULAR=number | EPSILON=number \n      \nSets the tolerance for testing singularity of the matrix that is formed from the design matrix X. \nRoughly, the test requires that a pivot be at least this number times the original diagonal value. \nBy default, number is 10\u2077 times the machine epsilon. The default number is approximately 10\u2079 on \nmost machines."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"TESTDATA=","ProcedureOptionHelp":{"#cdata":"Syntax: TESTDATA=SAS-data-set\n      \nNames a SAS data set that contains test data. This data set must contain all the variables \nspecified in the MODEL statement. Furthermore, when a BY statement is used and the TESTDATA=data \nset contains any of the BY variables, then the TESTDATA= data set must also contain all the BY \nvariables sorted in the order of the BY variables. In this case, only the test data for a \nspecific BY group are used with the corresponding BY group in the analysis data. If the \nTESTDATA= data set contains none of the BY variables, then the entire TESTDATA = data set \nis used with each BY group of the analysis data. \n\nIf you specify a TESTDATA= data set, then you cannot also specify a PARTITION statement to \nreserve observations for testing."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"THREADS=","ProcedureOptionHelp":{"#cdata":"Syntax: THREADS=n \n      \nSpecifies the number of threads for analytic computations and overrides the SAS system \noption THREADS | NOTHREADS. If you do not specify the THREADS= option or if you specify \nTHREADS=0, the number of threads is determined based on the data size and the number of \nCPUs on the host on which the analytic computations execute. If the specified number of \nthreads is more than the number of actual CPUs, PROC ADAPTIVEREG by default sets the \nvalue to the number of actual CPUs."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"VALDATA=","ProcedureOptionHelp":{"#cdata":"Syntax: VALDATA=SAS-data-set\n      \nNames a SAS data set that contains validation data. This data set must contain all the \nvariables specified in the MODEL statement. Furthermore, when a BY statement is used and \nthe VALDATA= data set contains any of the BY variables, then the VALDATA= data set must \nalso contain all the BY variables sorted in the order of the BY variables. In this case, \nonly the validation data for a specific BY group are used with the corresponding BY group \nin the analysis data. If the VALDATA= data set contains none of the BY variables, then \nthe entire VALDATA = data set is used with each BY group of the analysis data. \n\nIf you specify a VALDATA= data set, then you cannot also specify a PARTITION statement \nto reserve observations for validation."},"ProcedureOptionType":"DV"}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"BY","StatementHelp":{"#cdata":"[Syntax: BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>; ]\n      \nYou can specify a BY statement with PROC ADAPTIVEREG to obtain separate analyses of observations \nin groups that are defined by the BY variables. When a BY statement appears, the procedure expects \nthe input data set to be sorted in order of the BY variables. If you specify more than one BY \nstatement, only the last one specified is used. \n\nIf your input data set is not sorted in ascending order, use one of the following alternatives: \n\n\u2022 Sort the data by using the SORT procedure with a similar BY statement. \n\n\u2022 Specify the NOTSORTED or DESCENDING option in the BY statement for the ADAPTIVEREG procedure. \n  The NOTSORTED option does not mean that the data are unsorted but rather that the data are \n  arranged in groups (according to values of the BY variables) and that these groups are not \n  necessarily in alphabetical or increasing numeric order. \n\n\u2022 Create an index on the BY variables by using the DATASETS procedure (in Base SAS software)."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING","StatementOptionHelp":{"#cdata":"Specifies that the observations are sorted in descending order by the variable that immediately \nfollows the word DESCENDING in the BY statement."},"StatementOptionType":"S"},{"StatementOptionName":"NOTSORTED","StatementOptionHelp":{"#cdata":"The NOTSORTED option does not mean that the data are unsorted but rather that the data are \narranged in groups (according to values of the BY variables) and that these groups are not \nnecessarily in alphabetical or increasing numeric order."},"StatementOptionType":"S"}]}},{"StatementName":"CLASS","StatementHelp":{"#cdata":"Syntax: CLASS variables </ options> ; \n      \nThe CLASS statement names the classification variables to be used in the analysis. Typical class \nvariables are Treatment, Sex, Race, Group, and Replication. If the CLASS statement is used, it \nmust appear before the MODEL statement. \n\nClassification variables can be either character or numeric. Class levels are determined from \nthe formatted values of the variables. Thus, you can use formats to group values into levels."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING|DESC","StatementOptionHelp":{"#cdata":"Reverses the sort order of the classification variable. If you specify both the DESCENDING \nand ORDER= options, PROC ADAPTIVEREG orders the categories according to the ORDER= option \nand then reverses that order."},"StatementOptionType":"S"},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"Specifies the sort order for the categories of categorical variables. This ordering determines \nwhich parameters in the model correspond to each level in the data. When the default ORDER=FORMATTED \nis in effect for numeric variables for which you have supplied no explicit format, the levels are \nordered by their internal values. \n\nFor the FORMATTED and INTERNAL values, the sort order is machine-dependent. If you specify \nthe ORDER= option in the MODEL statement and the ORDER= option in the CLASS statement, the \nformer takes precedence."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"FREQDATA","@Value5":"FREQFORMATTED","@Value6":"FREQINTERNAL","@Value7":"INTERNAL"},"StatementOptionToolTips":{"@ToolTip1":"Order of appearance in the input data set","@ToolTip2":"External formatted value, except for numeric variables with no explicit format, which are sorted by their unformatted (internal) value","@ToolTip3":"Descending frequency count; levels with the most observations come first in the order","@ToolTip4":"Order of descending frequency count, and within counts by order of appearance in the input data set when counts are tied","@ToolTip5":"Order of descending frequency count, and within counts by formatted value (as above) when counts are tied","@ToolTip6":"Order of descending frequency count, and within counts by unformatted value when counts are tied","@ToolTip7":"Unformatted value"}}]}},{"StatementName":"FREQ","StatementHelp":{"#cdata":"Syntax:  FREQ variable ; \n\nThe FREQ statement names a variable that provides frequencies for each observation in the \nDATA= data set. Specifically, if n is the value of the FREQ variable for a given observation, \nthen that observation is used n times. \n\nThe analysis produced using a FREQ statement reflects the expanded number of observations. \nYou can produce the same analysis without the FREQ statement by first creating a new data \nset that contains the expanded number of observations. For example, if the value of the \nFREQ variable is 5 for the first observation, the first five observations in the new data \nset are identical. Each observation in the old data set is replicated ni times in the new data \nset, where ni is the value of the FREQ variable for that observation. \n\nIf the value of the FREQ variable is missing or is less than 1, the observation is not used \nin the analysis. If the value is not an integer, only the integer portion is used."},"StatementOptions":null},{"StatementName":"MODEL","StatementHelp":{"#cdata":"Syntax: MODEL dependent <(options)>=<effects> </ options> ; \n  MODEL events/trials = <effects> </ options> ; \n      \nThe MODEL statement names the response variable and the explanatory effects, including covariates, \nmain effects, interactions, and nested effects. If you omit the explanatory effects, the procedure \nfits an intercept-only model. You must specify exactly one MODEL statement. \n\nYou can specify two forms of the MODEL statement. The first form, referred to as single-trial syntax, \nis applicable to binary, ordinal, and nominal response data. The second form, referred to as events/trials \nsyntax, is restricted to binary response data. You use the single-trial syntax when each observation in \nthe DATA= data set contains information about only a single trial, such as a single subject in an experiment. \nWhen each observation contains information about multiple binary response trials, such as the counts of \nthe number of observed subjects and the number of subjects who respond, then you can use the events/trials syntax. \n\nIn the events/trials syntax, you specify two variables that contain count data for a binomial experiment. \nThese two variables are separated by a slash. The value of the first variable, events, is the number of \npositive responses (or events). The value of the second variable, trials, is the number of trials. The \nvalues of both events and (trials\u2013events) must be nonnegative and the value of trials must be positive \nfor the response to be valid. \n\nIn the single-trial syntax, you specify one variable (on the left side of the equal sign) as the response \nvariable. This variable can be character or numeric. You can specify variable options specific to the \nresponse variable immediately after the response variable with parentheses around them. \n\nFor both forms of the MODEL statement, explanatory effects follow the equal sign. Variables can be either \ncontinuous or classification variables. Classification variables can be character or numeric, and they \nmust be declared in the CLASS statement. When an effect is a classification variable, the procedure \ninserts a set of coded columns into the design matrix instead of directly entering a single column that \ncontains the values of the variable."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADDITIVE","StatementOptionHelp":{"#cdata":"Requests an additive model for which only main effects are included in the fitted model. \nIf you do not specify the ADDITIVE option, PROC ADAPTIVEREG fits a model that has both \nmain effects and two-way interaction terms."},"StatementOptionType":"S"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"Syntax: ALPHA=number \n          \nSpecifies the parameter that controls the number of knots considered for each variable.\n\nThe value of should be greater than 0 and less than 1. The default is ALPHA=0.05."},"StatementOptionType":"V"},{"StatementOptionName":"CVMETHOD=","StatementOptionHelp":{"#cdata":"Syntax: CVMETHOD=RANDOM <(n)> \nCVMETHOD=INDEX (variable) \n\nSpecifies the method for subdividing the training data into n parts when you request n-fold \ncross validation when you do backward selection. CVMETHOD=RANDOM assigns each training observation \nrandomly to one of the n parts. CVMETHOD=INDEX(variable) assigns observations to parts based on the \nformatted value of the named variable. This input data set variable is treated as a classification \nvariable, and the number of parts n is the number of distinct levels of this variable. By optionally \nnaming this variable in a CLASS statement, you can use the ORDER= option in the CLASS statement to \ncontrol how this variable is levelized. \n\nThe value of n defaults to 5 with CVMETHOD=RANDOM."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"RANDOM(n)","@Value2":"INDEX(variable)"},"StatementOptionToolTips":{"@ToolTip1":"Assigns each training observation randomly to one of the n parts.","@ToolTip2":"Assigns observations to parts based on the formatted value of the named variable."}},{"StatementOptionName":"DFPERBASIS=|D=","StatementOptionHelp":{"#cdata":"Syntax: DFPERBASIS=d | DF=d \nSpecifies the degrees of freedom (d) that are \u201ccharged\u201d for each basis function that is used in the \nlack-of-fit function for backward selection. Larger values of d lead to fewer spline knots and thus \nsmoother function estimates. The default is DFPERBASIS=2."},"StatementOptionType":"V"},{"StatementOptionName":"DIST=","StatementOptionHelp":{"#cdata":"Syntax DIST=distribution-id\n          \nSpecifies the distribution family used in the model. \n\nIf you do not specify a distribution-id, the ADAPTIVEREG procedure defaults to the normal distribution \nfor continuous response variables and to the binary distribution for classification or character variables, \nunless the events/trial syntax is used in the MODEL statement. If you choose the events/trial syntax, the \nADAPTIVEREG procedure defaults to the binomial distribution."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BINOMIAL","@Value2":"GAMMA|GAM|G","@Value3":"GAUSSIAN|NORMAL|N|NOR","@Value4":"IGAUSSIAN","@Value5":"NEGBIN","@Value6":"POISSON"},"StatementOptionToolTips":{"@ToolTip1":"Binomial distribution","@ToolTip2":"Gamma distribution","@ToolTip3":"Gaussian distribution","@ToolTip4":"Inverse Gaussian distribution","@ToolTip5":"Negative binomial distribution","@ToolTip6":"Poisson distribution"}},{"StatementOptionName":"FAST","StatementOptionHelp":{"#cdata":"Syntax: FAST<(fast-options)> \n          \nImproves the speed of the modeling. Because of the computation complexity in the original multivariate \nadaptive regression splines algorithm, Friedman (1993) proposes modifications to improve the speed by \ntuning several parameters. See the section Fast Algorithm for more information about the improvement \nof the multivariate adaptive regression splines algorithm. You can specify the following fast-options: \n\n  BETA=beta\n    specifies the \u201caging\u201d factor in the priority queue of candidate parent bases. Larger values of beta \n    result in low-improvement parents rising fast into top list of candidates. The default value is BETA=1. \n    \n  H=h\n  specifies the parameter that controls how often the improvement is recomputed for a parent basis over \n  all candidate variables. Larger values of h cause fewer computations of improvement. The default value is H=1. \n  \n  K=k\n  specifies the number of top candidates in the priority queue of parent bases for selecting new bases. \n  Larger values of k cause more parent bases to be considered. The default is to use all eligible parent \n  bases at every iteration."},"StatementOptionType":"S","SubOptionsKeywords":"BETA=|H=|K="},{"StatementOptionName":"FORWARDONLY","StatementOptionHelp":{"#cdata":"Skips the backward selection step after forward selection is finished."},"StatementOptionType":"S"},{"StatementOptionName":"KEEP=","StatementOptionHelp":{"#cdata":"Syntax: KEEP=effects\n          \nSpecifies a list of variables to be included in the final model."},"StatementOptionType":"V"},{"StatementOptionName":"LINEAR=","StatementOptionHelp":{"#cdata":"Syntax: LINEAR=effects\n          \nSpecifies a list of variables to be considered without nonparametric transformation. They should \nappear in the linear form if they are selected. "},"StatementOptionType":"V"},{"StatementOptionName":"LINK=","StatementOptionHelp":{"#cdata":"Specifies the link function in the model. Not all link functions are available for all distribution families."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CLOGLOG","@Value2":"IDENTITY","@Value3":"LOG","@Value4":"LOGIT","@Value5":"POWERMINUS2","@Value6":"PROBIT","@Value7":"RECIPROCAL"},"StatementOptionToolTips":{"@ToolTip1":"Complemetary log-log link function","@ToolTip2":"Identity link function","@ToolTip3":"Log link function","@ToolTip4":"Logit link function","@ToolTip5":"Power with exponent -2 link function","@ToolTip6":"Probit link function","@ToolTip7":"Reciprocal link function"}},{"StatementOptionName":"MAXBASIS=","StatementOptionHelp":{"#cdata":"Syntax: MAXBASIS=number \n          \nSpecifies the maximum number of basis functions that can be used in the final model. The default \nvalue is the larger value between 21 and one plus two times the number of nonintercept effects \nspecified in the MODEL statement."},"StatementOptionType":"V"},{"StatementOptionName":"MAXORDER=","StatementOptionHelp":{"#cdata":"Syntax: MAXORDER=number \n          \nSpecifies the maximum interaction levels for effects that could potentially enter the model. \n\nThe default value is MAXORDER=2."},"StatementOptionType":"V"},{"StatementOptionName":"NOMISS","StatementOptionHelp":{"#cdata":"Excludes all observations with missing values from the model fitting. By default, the ADAPTIVEREG \nprocedure takes the missingness into account when an explanatory variable has missing values."},"StatementOptionType":"S"},{"StatementOptionName":"OFFSET=","StatementOptionHelp":{"#cdata":"Syntax: OFFSET=variable \n          \nSpecifies an offset for the linear predictor. An offset plays the role of a predictor \nwhose coefficient is known to be 1. For example, you can use an offset in a Poisson \nmodel when counts have been obtained in time intervals of different lengths. With a \nlog link function, you can model the counts as Poisson variables with the logarithm \nof the time interval as the offset variable. The offset variable cannot appear in the \nCLASS statement or elsewhere in the MODEL statement."},"StatementOptionType":"V"},{"StatementOptionName":"VARPENALTY=","StatementOptionHelp":{"#cdata":"Syntax: VARPENALTY= \u03b3\n          \nSpecifies the incremental penalty \u03b3 for increasing the number of variables in the adaptive regression model. \nTo discourage a model with too many variables, at each iteration of the forward selection the model improvement \nis reduced by a factor of (1 - \u03b3) for any new variable that is introduced. \n\nFor highly collinear designs, the VARPENALTY= option helps PROC ADAPTIVEREG produce models that are nearly \nequivalent in terms of residual sum of squares but have fewer independent variables. Friedman (1991b) suggests \nthe following values for \u03b3: \n\n  0.0 -- no penalty (default value) \n  0.05 -- moderate penalty \n  0.1 -- heavy penalty \n\nThe best value depends on the specific situation. Some experimenting with different values is usually \nrequired. You should use this option with care."},"StatementOptionType":"V"},{"StatementOptionName":"NOPRINT","StatementOptionHelp":{"#cdata":"Suppresses the normal display of regression results."},"StatementOptionType":"S"},{"StatementOptionName":"OUTSEB","StatementOptionHelp":{"#cdata":"Outputs the standard errors of the parameter estimates to the OUTEST= data set."},"StatementOptionType":"S"},{"StatementOptionName":"OUTSTB","StatementOptionHelp":{"#cdata":"Outputs the standardized parameter estimates as well as the usual estimates to the OUTEST= data set\nwhen the RIDGE= or PCOMIT= option is specified. "},"StatementOptionType":"S"},{"StatementOptionName":"OUTVIF","StatementOptionHelp":{"#cdata":"Outputs the variance inflation factors (VIF) to the OUTEST= data set when the RIDGE= \nor PCOMIT= option is specified."},"StatementOptionType":"S"},{"StatementOptionName":"P","StatementOptionHelp":{"#cdata":"Calculates predicted values from the input data and the estimated model."},"StatementOptionType":"S"},{"StatementOptionName":"PARTIAL","StatementOptionHelp":{"#cdata":"Requests partial regression leverage plots for each regressor."},"StatementOptionType":"S"},{"StatementOptionName":"PARTIALDATA","StatementOptionHelp":{"#cdata":"Requests partial regression leverage data for each regressor."},"StatementOptionType":"S"},{"StatementOptionName":"PC","StatementOptionHelp":{"#cdata":"Outputs Amemiya\u2019s prediction criterion for each model selected to the OUTEST= data set."},"StatementOptionType":"S"},{"StatementOptionName":"PCOMIT=","StatementOptionHelp":{"#cdata":"[Syntax: PCOMIT=list] \n          \nRequests an IPC analysis for each value m in the list."},"StatementOptionType":"V"},{"StatementOptionName":"PCORR1","StatementOptionHelp":{"#cdata":"Displays the squared partial correlation coefficients computed using Type I sum of squares (SS)."},"StatementOptionType":"S"},{"StatementOptionName":"PCORR2","StatementOptionHelp":{"#cdata":"Displays the squared partial correlation coefficients computed using Type II sums of squares."},"StatementOptionType":"S"},{"StatementOptionName":"PRESS","StatementOptionHelp":{"#cdata":"Outputs the PRESS statistic to the OUTEST= data set. The values of this statistic are saved in the variable _PRESS_."},"StatementOptionType":"S"},{"StatementOptionName":"R","StatementOptionHelp":{"#cdata":"Requests an analysis of the residuals."},"StatementOptionType":"S"},{"StatementOptionName":"RIDGE=","StatementOptionHelp":{"#cdata":"[Syntax: RIDGE=list] \n          \nRequests a ridge regression analysis and specifies the values of the ridge constant k."},"StatementOptionType":"V"},{"StatementOptionName":"RMSE","StatementOptionHelp":{"#cdata":"Displays the root mean square error for each model selected."},"StatementOptionType":"S"},{"StatementOptionName":"RSQUARE","StatementOptionHelp":{"#cdata":"Has the same effect as the EDF option."},"StatementOptionType":"S"},{"StatementOptionName":"SBC","StatementOptionHelp":{"#cdata":"Outputs the SBC statistic for each model selected to the OUTEST= data set."},"StatementOptionType":"S"},{"StatementOptionName":"SCORR1","StatementOptionHelp":{"#cdata":"[Syntax: SCORR1 <( < TESTS> <SEQTESTS> ) >] \n          \nDisplays the squared semipartial correlation coefficients computed using Type I sums of squares."},"StatementOptionType":"S"},{"StatementOptionName":"PARTIALR2","StatementOptionHelp":{"#cdata":"[Syntax: PARTIALR2 <( < TESTS> <SEQTESTS> ) >] \n          \nDisplays the squared semipartial correlation coefficients computed using Type I sums of squares."},"StatementOptionType":"S"},{"StatementOptionName":"SCORR2","StatementOptionHelp":{"#cdata":"[Syntax: SCORR2 <( TESTS )>] \n          \nDisplays the squared semipartial correlation coefficients computed using Type II sums of squares."},"StatementOptionType":"S"},{"StatementOptionName":"SEQB","StatementOptionHelp":{"#cdata":"Produces a sequence of parameter estimates as each variable is entered into the model."},"StatementOptionType":"S"},{"StatementOptionName":"SIGMA=","StatementOptionHelp":{"#cdata":"[Syntax: SIGMA=n] \n          \nSpecifies the true standard deviation of the error term to be used in computing the CP and BIC statistics."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=n] \n          \nTunes the mechanism used to check for singularities."},"StatementOptionType":"V"},{"StatementOptionName":"SLENTRY=|SLE=","StatementOptionHelp":{"#cdata":"[Syntax: SLENTRY=value] \n          \nSpecifies the significance level for entry into the model used in the FORWARD and STEPWISE methods. \nThe defaults are 0.50 for FORWARD and 0.15 for STEPWISE."},"StatementOptionType":"V"},{"StatementOptionName":"SLSTAY=|SLS=","StatementOptionHelp":{"#cdata":"[Syntax: SLSTAY=value] \n          \nSpecifies the significance level for staying in the model for the BACKWARD and STEPWISE methods. \nThe defaults are 0.10 for BACKWARD and 0.15 for STEPWISE."},"StatementOptionType":"V"},{"StatementOptionName":"SP","StatementOptionHelp":{"#cdata":"outputs the Sp statistic for each model selected to the OUTEST= data set."},"StatementOptionType":"S"},{"StatementOptionName":"SPEC","StatementOptionHelp":{"#cdata":"Performs a test that the first and second moments of the model are correctly specified."},"StatementOptionType":"S"},{"StatementOptionName":"SS1","StatementOptionHelp":{"#cdata":"Displays the sequential sums of squares (Type I SS) along with the parameter estimates for each term in the model."},"StatementOptionType":"S"},{"StatementOptionName":"SS2","StatementOptionHelp":{"#cdata":"Displays the partial sums of squares (Type II SS) along with the parameter estimates for each term in the model."},"StatementOptionType":"S"},{"StatementOptionName":"SSE","StatementOptionHelp":{"#cdata":"Computes the error sum of squares for each model selected."},"StatementOptionType":"S"},{"StatementOptionName":"START=","StatementOptionHelp":{"#cdata":"[Syntax: START=s] \n          \nIs used to begin the comparing-and-switching process in the MAXR, MINR, and STEPWISE methods for a \nmodel containing the first s independent variables in the MODEL statement, where s is the START value."},"StatementOptionType":"V"},{"StatementOptionName":"STB","StatementOptionHelp":{"#cdata":"Produces standardized regression coefficients."},"StatementOptionType":"S"},{"StatementOptionName":"STOP=","StatementOptionHelp":{"#cdata":"[Syntax: STOP=s] \n          \nCauses PROC REG to stop when it has found the \"best\" s-variable model, where s is the STOP value."},"StatementOptionType":"V"},{"StatementOptionName":"TOL","StatementOptionHelp":{"#cdata":"Produces tolerance values for the estimates."},"StatementOptionType":"S"},{"StatementOptionName":"VIF","StatementOptionHelp":{"#cdata":"Produces variance inflation factors with the parameter estimates. Variance inflation is the \nreciprocal of tolerance."},"StatementOptionType":"S"},{"StatementOptionName":"WHITE","StatementOptionHelp":{"#cdata":"See the HCC option."},"StatementOptionType":"S"},{"StatementOptionName":"XPX","StatementOptionHelp":{"#cdata":"Displays the X'X crossproducts matrix for the model."},"StatementOptionType":"S"}]}},{"StatementName":"OUTPUT","StatementHelp":{"#cdata":"Syntax: OUTPUT <OUT=SAS-data-set>< keyword=names> <...keyword=names> ;\n      \nThe OUTPUT statement creates a new SAS data set that saves diagnostic measures calculated after \nfitting the model."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nGives the name of the new data set. By default, the procedure uses the DATAn convention \nto name the new data set."},"StatementOptionType":"DV"},{"StatementOptionName":"COOKD=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nCook\u2019s D influence statistic"},"StatementOptionType":"V"},{"StatementOptionName":"COVRATIO=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nStandard influence of observation on covariance of betas"},"StatementOptionType":"V"},{"StatementOptionName":"DFFITS=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nStandard influence of observation on predicted value"},"StatementOptionType":"V"},{"StatementOptionName":"H=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nLeverage"},"StatementOptionType":"V"},{"StatementOptionName":"LCL=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nLower bound of a 100(1 - \u03b1)% confidence interval for an individual prediction."},"StatementOptionType":"V"},{"StatementOptionName":"LCLM=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nLower bound of a 100(1 - \u03b1)% confidence interval for the expected value (mean) of the \ndependent variable."},"StatementOptionType":"V"},{"StatementOptionName":"PREDICTED=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nPredicted values"},"StatementOptionType":"V"},{"StatementOptionName":"PRESS=","StatementOptionHelp":{"#cdata":"[keyword] \n          \ni-th residual divided by (1-h), where h is the leverage, and where the model \nhas been refit without the i-th observation."},"StatementOptionType":"V"},{"StatementOptionName":"RESIDUAL=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nResiduals, calculated as ACTUAL minus PREDICTED."},"StatementOptionType":"V"},{"StatementOptionName":"RSTUDENT=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nA studentized residual with the current observation deleted."},"StatementOptionType":"V"},{"StatementOptionName":"STDI=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nStandard error of the individual predicted value."},"StatementOptionType":"V"},{"StatementOptionName":"STDP=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nStandard error of the mean predicted value."},"StatementOptionType":"V"},{"StatementOptionName":"STDR","StatementOptionHelp":{"#cdata":"[keyword] \n          \nStandard error of the residual."},"StatementOptionType":"V"},{"StatementOptionName":"STUDENT=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nStudentized residuals, which are the residuals divided by their standard errors."},"StatementOptionType":"V"},{"StatementOptionName":"UCL=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nUpper bound of a 100(1 - \u03b1)% confidence interval for an individual prediction."},"StatementOptionType":"V"},{"StatementOptionName":"UCLM=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nUpper bound of a 100(1 - \u03b1)% confidence interval for the expected value (mean) \nof the dependent variable."},"StatementOptionType":"V"}]}},{"StatementName":"PARTITION","StatementHelp":{"#cdata":"Syntax: PARTITION <options> ; \n\nThe PARTITION statement specifies how observations in the input data set are logically partitioned \ninto disjoint subsets for model training, validation, and testing. Either you can designate a variable \nin the input data set and a set of formatted values of that variable to determine the role of each \nobservation, or you can specify proportions to use for random assignment of observations for each role. \n\nAn alternative to using a PARTITION statement is to provide a variable named _ROLE_ in the input \ndata set to define roles of observations in the input data. If you specify a PARTITION statement, \nthen the _ROLE_ variable is ignored if it is present in the input data set. If you do not specify \na PARTITION statement and the input data do not contain a variable named _ROLE_, then all observations \nin the input data set are assigned to model training."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ROLEVAR=|ROLE=","StatementOptionHelp":{"#cdata":"Syntax: ROLEVAR=variable (<TEST='value'> <TRAIN='value'> <VALIDATE='value'>)\nROLE=variable (<TEST='value'> <TRAIN='value'> <VALIDATE='value'>) \n \nNames the variable in the input data set whose values are used to assign roles to each observation. \nThe formatted values of this variable that are used to assign observations roles are specified in \nthe TEST=, TRAIN=, and VALIDATE= suboptions. If you do not specify the TRAIN= suboption, then all \nobservations whose role is not determined by the TEST= or VALIDATE= suboptions are assigned to \ntraining. If you specify a TESTDATA= data set in the PROC ADAPTIVEREG statement, then you cannot \nalso specify the TEST= suboption in the PARTITION statement. If you specify a VALDATA= data set \nin the PROC ADAPTIVEREG statement, then you cannot also specify the VALIDATE= suboption in the \nPARTITION statement."},"StatementOptionType":"V"},{"StatementOptionName":"FRACTION","StatementOptionHelp":{"#cdata":"Syntax: FRACTION(<fraction> <VALIDATE=fraction>) \n          \nRandomly assigns training and validation roles to the observations in the input data according \nto the proportions that are specified by the fraction values in the TEST= and VALIDATE= suboptions. \nIf you specify both the TEST= and VALIDATE= suboptions, then the sum of the specified fractions \nmust be less than 1 and the remaining fraction of the observations are assigned to the training \nrole. If you specify a TESTDATA= data set in the PROC ADAPTIVEREG statement, then you cannot \nalso specify the TEST= suboption in the PARTITION statement. If you specify a VALDATA= data \nset in the PROC ADAPTIVEREG statement, then you cannot also specify the VALIDATE= suboption \nin the PARTITION statement."},"StatementOptionType":"S","SubOptionsKeywords":"TEST=|VALIDATE="}]}},{"StatementName":"SCORE","StatementHelp":{"#cdata":"Syntax: SCORE <DATA=SAS-data-set> <OUT=SAS-data-set><keyword <=name>>\u2026<keyword <=name>> ; \n\nThe SCORE statement creates a new SAS data set to contain predicted values and optionally residuals \nfor data in a new data set that you name. If you do not specify a DATA= data set, then the input data \nare scored. If you want to predict multiple data sets, you can specify multiple SCORE statements. If \nyou want to create a SAS data set in a permanent library, you must specify a two-level name.  \n\nWhen you specify a BY statement, the DATA= data set must either contain all the BY variables sorted \nin the order of the BY variables or contain none of the BY variables. If the DATA= data set contains \nall the BY variables, then the model that is selected for a given BY group is used to score just the \nmatching observations in that data set. If the DATA= set contains none of the BY variables, then the \nentire data set is scored for each BY group. \n\nAll observations in the DATA= data set are retained in the output data set. All the variables in the \ninput data set are included in the output data set, along with variables that contain predicted values \nand optionally residuals."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DATA=","StatementOptionHelp":{"#cdata":"Syntax: DATA=SAS data set \n          \nNames the data set to be scored. If you omit this option, then the input data set that is named \nin the DATA= option in the PROC ADAPTIVEREG statement is scored."},"StatementOptionType":"DV"},{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"Syntax: OUT=SAS data set \n          \nSpecifies the name of the new output data set. By default, PROC ADAPTIVEREG uses the DATAn \nconvention to name the new data set. "},"StatementOptionType":"V"},{"StatementOptionName":"PREDICTED|PRED|P","StatementOptionHelp":{"#cdata":"Syntax: PREDICTED <=name>\n          \nIncludes predicted values in the output data set. The prefix for the default name is Pred. "},"StatementOptionType":"S"},{"StatementOptionName":"RESIDUAL|RESID|R","StatementOptionHelp":{"#cdata":"Syntax: RESIDUAL <=name> \n          \nIncludes residuals (which are calculated as ACTUAL \u2013 PREDICTED), in the output data set. \nThe prefix for the default name is Resid."},"StatementOptionType":"S"}]}},{"StatementName":"WEIGHT","StatementHelp":{"#cdata":"Syntax: WEIGHT variable ; \n\nWhen you specify a WEIGHT statement, each observation in the input data set is weighted \nby the value of variable. The value of variable can be nonintegral. Observations that have \na negative, zero, or missing value for the WEIGHT variable are not used in model fitting."},"StatementOptions":null}]}}}