{"Procedure":{"Name":"GENMOD","#comment":{},"ProductGroup":"SAS/STAT","ProcedureHelp":{"#cdata":"Syntax: PROC GENMOD <options> ; \n    ASSESS | ASSESSMENT VAR=(effect) | LINK </ options> ; \n    BAYES <options> ; \n    BY variables ; \n    CLASS variable <(options)><variable <(options)>> </ options> ; \n    CONTRAST \u2019label\u2019 contrast-specification </ options> ; \n    DEVIANCE variable = expression ; \n    EFFECTPLOT <plot-type <(plot-definition-options)>> </ options> ; \n    ESTIMATE \u2019label\u2019 effect values <,...effect values> </ options> ; \n    EXACT <\u2019label\u2019> <INTERCEPT> <effects> </ options> ; \n    EXACTOPTIONS options ; \n    FREQ | FREQUENCY variable ; \n    FWDLINK variable = expression ; \n    INVLINK variable = expression ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect <'label'> values <divisor=> <, ...<'label'> values <divisor=>> < / options> ; \n    MODEL response = <effects > </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name...keyword=name> ; \n    Programming statements ; \n    REPEATED SUBJECT=subject-effect </ options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    STRATA variable <(option)>  <variable <(option)>> </ options> ; \n    WEIGHT | SCWGT variable ; \n    VARIANCE variable = expression ; \n    ZEROMODEL <effects > </ options> ; \n\nThe GENMOD procedure fits generalized linear models, as defined by Nelder and Wedderburn \n(1972). The class of generalized linear models is an extension of traditional linear models \nthat allows the mean of a population to depend on a linear predictor through a nonlinear \nlink function and allows the response probability distribution to be any member of an \nexponential family of distributions. Many widely used statistical models are generalized \nlinear models. These include classical linear models with normal errors, logistic and probit \nmodels for binary data, and log-linear models for multinomial data. Many other useful \nstatistical models can be formulated as generalized linear models by the selection of an \nappropriate link function and response probability distribution."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"[Syntax: DATA=SAS-data-set] \n      \nSpecifies the SAS data set containing the data to be analyzed. If you omit\nthe DATA= option, the procedure uses the most recently created SAS data set."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"DESCENDING|DESCEND|DESC","ProcedureOptionHelp":{"#cdata":"Specifies that the levels of the response variable for the ordinal multinomial model and the binomial\nmodel with single variable response syntax be sorted in the reverse of the default order."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NAMELEN=","ProcedureOptionHelp":{"#cdata":"[Syntax: NAMELEN=n] \n      \nSpecifies the length of effect names in tables and output data sets to be n \ncharacters long, where n is a value between 20 and 200 characters. The default \nlength is 20 characters."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"ORDER=","ProcedureOptionHelp":{"#cdata":"Specifies the sorting order for the levels of all classification variables (specified in the CLASS statement). \nThis ordering determines which parameters in the model correspond to each level in the data."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"ProcedureOptionToolTips":{"@ToolTip1":"Orders values according to their order in the input data set.","@ToolTip2":"Orders values by their ascending formatted values. This order depends on your operating environment.","@ToolTip3":"Orders values by descending frequency count so that levels with the most observations are listed first.","@ToolTip4":"Orders values by their unformatted values, which yields the same order as PROC SORT. This order depends on your operating environment."}},{"ProcedureOptionName":"PLOTS=","ProcedureOptionHelp":{"#cdata":"Specifies plots to be created using ODS Graphics.\n      \nSyntax: \n(1) PLOTS <(global-plot-options)> = plot-request <(options)>\n(2) PLOTS <(global-plot-options)> = (plot-request <(options)> <...plot-request <(options)> > )\n\nThe following global plot options are available:\n\nCLUSTERLABEL \ndisplays formatted levels of the SUBJECT= effect instead of plot symbols. \n\nUNPACK \ndisplays multiple plots individually. The default is to display related multiple plots in a panel."},"ProcedureOptionType":"S|V","ProcedureOptionValues":{"@Value1":"ALL","@Value2":"COOKSD","@Value3":"DFBETA","@Value4":"DFBETAS","@Value5":"LEVERAGE","@Value6":"PREDICTED<(CLM)>","@Value7":"RESCHI<(options)>","@Value8":"RESDEV<(options)>","@Value9":"RESLIK<(options)>","@Value10":"RESRAW<(options)>","@Value11":"STDRESCHI<(options)>","@Value12":"STDRESDEV<(options)>","@Value13":"CLEVERAGE","@Value14":"CLUSTERCOOKSD","@Value15":"CLUSTERDFIT","@Value16":"DFBETAC","@Value17":"DFBETACS"},"ProcedureOptionToolTips":{"@ToolTip1":"Produces all available plots.","@ToolTip2":"Plots the Cook\u2019s distance statistic as a function of observation number.","@ToolTip3":"Plots the \u03b2 deletion statistic as a function of observation number for each regression  parameter in the model.","@ToolTip4":"Plots the standardized \u03b2 deletion statistic as a function of observation number for each  regression parameter in the model.","@ToolTip5":"Plots the leverage as a function of observation number.","@ToolTip6":"Plots predicted values with confidence limits as a function of observation number. The CLM option includes confidence limits in the predicted value plot.","@ToolTip7":"Plots Pearson residuals.The RESCHI plot request has the following options:   INDEX  plots as a function of observation number.   XBETA  plots as a function of linear predictor.","@ToolTip8":"Plots deviance residuals. The RESDEV plot request has the following options:   INDEX  plots as a function of observation number.   XBETA  plots as a function of linear predictor.","@ToolTip9":"Plots likelihood residuals. The RESLIK plot request has the following options:   INDEX  plots as a function of observation number.   XBETA  plots as a function of linear predictor.","@ToolTip10":"Plots raw residuals. The RESRAW plot request has the following options:   INDEX  plots as a function of observation number.   XBETA  plots as a function of linear predictor.","@ToolTip11":"Plots standardized Pearson residuals. The STDRESCHI plot request has the following options:   INDEX  plots as a function of observation number.   XBETA  plots as a function of linear predictor.","@ToolTip12":"Plots standardized deviance residuals. The STDRESDEV plot request has the following options:   INDEX  plots as a function of observation number.   XBETA  plots as a function of linear predictor.","@ToolTip13":"Plots the cluster leverage as a function of ordered cluster.","@ToolTip14":"Plots the cluster Cook\u2019s distance statistic as a function of ordered cluster.","@ToolTip15":"Plots the studentized cluster Cook\u2019s distance statistic as a function of ordered cluster.","@ToolTip16":"Plots the cluster deletion statistic as a function of ordered cluster for each regression  parameter in the model.","@ToolTip17":"Plots the standardized cluster deletion statistic as a function of ordered cluster for each  regression parameter in the model."},"SubOptionsKeywords":"INDEX|XBETA|CLM|CLUSTERLABEL|UNPACKPANEL|UNPACK"},{"ProcedureOptionName":"RORDER=","ProcedureOptionHelp":{"#cdata":"Specifies the sorting order for the levels of the response variable."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"ProcedureOptionToolTips":{"@ToolTip1":"Orders values according to their order in the input data set.","@ToolTip2":"Orders values by their ascending formatted values. This order depends on your operating environment.","@ToolTip3":"Orders values by descending frequency count so that levels with the most observations are listed first.","@ToolTip4":"Orders values by their unformatted values, which yields the same order as PROC SORT. This order depends    on your operating environment."}}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"ASSESS|ASSESSMENT","StatementHelp":{"#cdata":"Syntax: ASSESS VAR=(effect) | LINK </ options> ; \n  | ASSESSMENT VAR=(effect) | LINK </ options> ;\n      \nThe ASSESS statement computes and plots, using ODS Graphics, model-checking statistics \nbased on aggregates of residuals. \n\nThe types of aggregates available are cumulative residuals, moving sums of residuals, and \nloess smoothed residuals. If you do not specify which aggregate to use, the assessments are \nbased on cumulative sums. PROC GENMOD uses ODS Graphics for graphical displays. \n\nYou must specify either LINK or VAR= in order to create an analysis."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"LINK","StatementOptionHelp":{"#cdata":"Requests the assessment of the link function by performing the analysis with respect \nto the linear predictor."},"StatementOptionType":"RV"},{"StatementOptionName":"VAR=","StatementOptionHelp":{"#cdata":"[Syntax: VAR=(effect)] \n          \nSpecifies that the functional form of a covariate be checked by performing the\nanalysis with respect to the variable identified by the effect. The effect must \nbe specified in the MODEL statement and must contain only continuous variables \nvariables not listed in a CLASS statement)."},"StatementOptionType":"RV"},{"StatementOptionName":"CRPANEL","StatementOptionHelp":{"#cdata":"Requests that a plot with four panels showing just a few of the paths from the default aggregate plot\nto make it easier to compare simulated and observed paths."},"StatementOptionType":"S"},{"StatementOptionName":"LOESS|LOWESS","StatementOptionHelp":{"#cdata":"[Syntax: LOESS<(number)> | LOWESS<(number)>] \n          \nRequests model assessment based on loess smoothed residuals with optional number \nthe fraction of data used; number must be between zero and one."},"StatementOptionType":"S"},{"StatementOptionName":"NPATHS=|NPATH=|PATHS=|PATH=","StatementOptionHelp":{"#cdata":"[Syntax: NPATHS=number] \n          \nSpecifies the number of simulated paths to plot in the default aggregate residuals \nplot. The default value of number is 20."},"StatementOptionType":"V"},{"StatementOptionName":"RESAMPLE=|RESAMPLES=","StatementOptionHelp":{"#cdata":"[Syntax: RESAMPLE<=number>] \n          \nSpecifies that a p-value be computed based on 1,000 simulated paths, or number paths, \nif number is specified."},"StatementOptionType":"S|V"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"Specifies a seed (number) for the normal random number generator used in creating simulated \nrealizations of aggregates of residuals for plots and estimating p-values. Specifying a seed \nenables you to produce identical graphs and p-values from one run of the procedure to the next \nrun. If a seed is not specified, or if number is negative or zero, a random number seed is \nderived from the time of day."},"StatementOptionType":"V"},{"StatementOptionName":"WINDOW","StatementOptionHelp":{"#cdata":"[Syntax: WINDOW<(number)>] \n          \nRequests assessment based on a moving sum window of width number. If number is  \nnot specified, a value of one-half of the range of the x-coordinate is used."},"StatementOptionType":"S"}]}},{"StatementName":"BAYES","StatementHelp":{"#cdata":"Syntax: BAYES <options> ; \n      \nThe BAYES statement requests a Bayesian analysis of the regression model by using \nGibbs sampling. The Bayesian posterior samples (also known as the chain) for the \nregression parameters are not tabulated. The Bayesian posterior samples (also known \nas the chain) for the regression parameters can be output to a SAS data set."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"COEFFPRIOR=|COEFF=|CPRIOR=","StatementOptionHelp":{"#cdata":"Specifies the prior distribution for the regression coefficients."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JEFFREYS","@Value2":"NORMAL","@Value3":"UNIFORM"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: JEFFREYS<(option)>               Jeffreys\u2019 prior is specified by COEFFPRIOR=JEFFREYS, which can be followed by the following  option in parentheses:    CONDITIONAL    specifies that the Jeffreys\u2019 prior, conditional on the current Markov chain value of the generalized   linear model precision parameter \u03c4, is proportional to |tauI(\u03b2)|^(1/2).","@ToolTip2":"Syntax: NORMAL<(options)>                                      The normal prior is specified by COEFFPRIOR=NORMAL, which can be followed by one of the following options enclosed in parentheses:    CONDITIONAL    specifies that the normal prior, conditional on the current Markov chain value of the generalized    linear model precision parameter \u03c4, is N(\u00b5,\u03c4\u207b\u00b9Z), where \u00b5 and Z are the mean and covariance   of the normal prior specified by other normal options.    INPUT=SAS-data-set    specifies a SAS data set containing the mean and covariance information of the normal prior.   The data set must have a _TYPE_ variable to represent the type of each observation and a variable   for each regression coefficient.    RELVAR<=c>   Specifies the normal prior N(0, cJ), where J is a diagonal matrix with diagonal elements equal to the   variances of the corresponding ML estimator. By default, C=10\u2076.    VAR<=c>   Specifies the normal prior N(0,cI), where I is the identity matrix.","@ToolTip3":"Specifies the noninformative and improper prior of a constant."}},{"StatementOptionName":"DIAGNOSTICS=","StatementOptionHelp":{"#cdata":"Controls the number of diagnostics produced."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"NONE","@Value3":"<(keyword-list)>"},"StatementOptionToolTips":{"@ToolTip1":"Requests all diagnostics","@ToolTip2":"Requests no diagnostics","@ToolTip3":"If you want some but not all of the diagnostics, or if you want to change certain settings of these diagnostics, specify a subset of the following keywords:   AUTOCORR<(LAGS= numeric-list)> -- Computes the autocorrelations of lags given by LAGS= list for each parameter.   ESS -- Computes Carlin\u2019s estimate of the effective sample size, the correlation time, and the efficiency of the chain for each parameter.  GELMAN<(gelman-options)> -- Computes the Gelman and Rubin convergence diagnostics, with the following gelman-options:       NCHAIN | N=number -- Specifies the number of parallel chains used to compute the diagnostic, and must be  \u2265  2. Default: NCHAIN=3.         ALPHA=value -- Specifies the significance level for the upper bound. The default is ALPHA=0.05, resulting in a 97.5% bound.    GEWEKE<(geweke-options)>-- Computes the Geweke spectral density diagnostics, which are essentially a two-sample t test between the first f1 portion and the last f2 portion of the chain. The default is f1=0.1 and f2=0.5. The geweke-options are:       FRAC1=value -- Specifies the fraction f1 for the first window.     FRAC2=value -- Specifies the fraction f2 for the second window.   HEIDELBERGER<(heidel-options)> -- Computes the Heidelberger and Welch diagnostic for each variable. The heidel-options are:       SALPHA=value -- Specifies the \u03b1 level for the stationarity test.     HALPHA=value -- Specifies the \u03b1 level for the halfwidth test.      EPS=value -- Specifies a positive number \u03b5 such that if the halfwidth is less than \u03b5 times the sample mean     of the retained iterates, the halfwidth test is passed.       MCERROR | MCSE --Computes an estimate of the Monte Carlo standard error for each parameter.  RAFTERY<(raftery-options)> -- Computes Raftery and Lewis diagnostics that evaluate accuracy of the estimated quantile of a chain.  raftery-options are:      QUANTILE= | Q=value -- Specifies the order (a value between 0 and 1) of the quantile of interest. The default is 0.025.     ACCURACY= | R=value -- Specifies a small positive number as the margin of error for measuring the accuracy of estimation     of the quantile. The default is 0.005.     PROBABILITY= | S=value -- Specifies the probability of attaining the accuracy of the estimation of the quantile. The default is 0.95.     EPSILON= | EPS=value -- Specifies the tolerance level (a small positive number) for the stationary test. The default is 0.001."},"SubOptionsKeywords":"\n            EPSILON=|EPS=|PROBABILITY=|S=|ACCURACY=|R=|QUANTILE=|Q=|\n            RAFTERY|MCERROR|MCSE|EPS=|HALPHA=|SALPHA=|HEIDELBERGER|\n            FRAC1|FRAC2|GEWEKE|ALPHA|NCHAIN|GELMAN|ESS|AUTOCORR|LAGS=\n          "},{"StatementOptionName":"DISPERSIONPRIOR=|DPRIOR=","StatementOptionHelp":{"#cdata":"Specifies that Gibbs sampling be performed on the generalized linear model dispersion parameter and the \nprior distribution for the dispersion parameter, if there is a dispersion parameter in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"GAMMA","@Value2":"IGAMMA","@Value3":"IMPROPER"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: GAMMA<(options)>               Specifies that Gibbs sampling be performed on the generalized linear model dispersion parameter and the gamma prior distribution for the dispersion parameter, if one exists in the model. A gamma prior G(a,b) is specified by DISPERSIONPRIOR=GAMMA, which can be followed by one of the following gamma-options enclosed in parentheses:      RELSHAPE<=c>     specifies independent G(c \u03a6-hat,c) distribution, where \u03a6-hat is the MLE of the dispersion parameter.      With this choice of hyperparameters, the mean of the prior distribution is \u03a6-hat and the variance is \u03a6-hat/c.     By default, c=10\u207b\u2074.       SHAPE=\u03b1 and ISCALE=b      specify the G(a,b) prior.           SHAPE=c      specifies the G(c,c) prior.       ISCALE=c      specifies the G(c,c) prior.","@ToolTip2":"Syntax: IGAMMA<(options)>                                      Specifies that Gibbs sampling be performed on the generalized linear model dispersion parameter and the inverse gamma prior distribution for the dispersion parameter, if one exists in the model. An inverse gamma prior IG(a,b) is specified by DISPERSIONPRIOR=IGAMMA, which can be followed by one of the following inverse gamma-options enclosed in parentheses. The hyperparameters a and b are the shape and scale parameters of the inverse gamma distribution, respectively. The default is IG(2.001,0.001).       RELSHAPE<=c>     specifies independent IG((c+\u03a6-hat)/\u03a6-hat,c) distribution, where p-hat is the MLE of the dispersion     parameter. With this choice of hyperparameters, the mean of the prior distribution is \u03a6-hat. By default,     c=10\u207b\u2074.       SHAPE=\u03b1 and SCALE=b      specify the IG(a,b) prior.       SHAPE=c      specifies the IG(c,c) prior.       SCALE=c      specifies the IG(c,c) prior.","@ToolTip3":"Specifies that Gibbs sampling be performed on the generalized linear model dispersion parameter                                    and the improper prior distribution for the dispersion parameter, if one exists in the model."},"SubOptionsKeywords":"RELSHAPE|SHAPE=|SCALE=|ISCALE="},{"StatementOptionName":"INITIAL=","StatementOptionHelp":{"#cdata":"[Syntax: INITIAL=SAS-data-set] \n          \nSpecifies the SAS data set that contains the initial values of the Markov chains. \nThe INITIAL= data set must contain all the variables of the model. You can specify\nmultiple rows as the initial values of the parallel chains for the Gelman-Rubin \nstatistics, but posterior summaries, diagnostics, and plots are computed only for \nthe first chain. If the data set also contains the variable _SEED_, the value of \nthe _SEED_ variable is used as the seed of the random number generator for the \ncorresponding chain."},"StatementOptionType":"DV"},{"StatementOptionName":"INITIALMLE","StatementOptionHelp":{"#cdata":"Specifies that maximum likelihood estimates of the model parameters be used as initial \nvalues of the Markov chain. If this option is not specified, estimates of the mode of \nthe posterior distribution obtained by optimization are used as initial values."},"StatementOptionType":"S"},{"StatementOptionName":"METROPOLIS=","StatementOptionHelp":{"#cdata":"Specifies whether to use a Metropolis step to generate Gibbs samples for posterior distributions \nthat are not log concave. The default value is METROPOLIS=YES."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"YES","@Value2":"NO"},"StatementOptionToolTips":{"@ToolTip1":"Specifies to use a Metropolis step to generate Gibbs samples for posterior distributions  that are not log concave.","@ToolTip2":"Specifies not to use a Metropolis step to generate Gibbs samples for posterior distributions  that are not log concave."}},{"StatementOptionName":"NBI=","StatementOptionHelp":{"#cdata":"[Syntax: NBI=number] \n          \nSpecifies the number of burn-in iterations before the chains are saved. The default \nis 2000."},"StatementOptionType":"V"},{"StatementOptionName":"NMC=","StatementOptionHelp":{"#cdata":"[Syntax: NMC=number] \n          \nSpecifies the number of iterations after the burn-in. The default is 10000."},"StatementOptionType":"V"},{"StatementOptionName":"OUTPOST=|OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUTPOST=SAS-data-set] \n          \nNames the SAS data set that contains the posterior samples."},"StatementOptionType":"DV"},{"StatementOptionName":"PRECISIONPRIOR=|PPRIOR=","StatementOptionHelp":{"#cdata":"Specifies that Gibbs sampling be performed on the generalized linear model precision \nparameter and the prior distribution for the precision parameter, if there is a precision \nparameter in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"GAMMA","@Value2":"IMPROPER"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: GAMMA<(options)>               Specifies that Gibbs sampling be performed on the generalized linear model precision parameter and the gamma prior distribution for the precision parameter, if one exists in the model. A gamma prior G(a,b) is specified by DISPERSIONPRIOR=GAMMA, which can be followed by one of the following gamma-options enclosed in parentheses:      RELSHAPE<=c>     specifies independent G(c \u03c4-hat,c) distribution, where \u03c4-hat is the MLE of the dispersion parameter.      With this choice of hyperparameters, the mean of the prior distribution is \u03c4-hat and the variance is \u03c4-hat/c.     By default, c=10\u207b\u2074.       SHAPE=\u03b1 and ISCALE=b      specify the G(a,b) prior.           SHAPE=c      specifies the G(c,c) prior.       ISCALE=c      specifies the G(c,c) prior.","@ToolTip2":"Specifies that Gibbs sampling be performed on the generalized linear model precision parameter and the improper prior distribution for the precision parameter, if one exists in the model."}},{"StatementOptionName":"SCALEPRIOR=","StatementOptionHelp":{"#cdata":"Specifies that Gibbs sampling be performed on the generalized linear model scale parameter and the prior distribution\nfor the scale parameter, if there is a precision parameter in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"GAMMA","@Value2":"IMPROPER"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: GAMMA<(options)>               Specifies that Gibbs sampling be performed on the generalized linear model scale parameter and the gamma prior distribution for the scale parameter, if one exists in the model. A gamma prior G(a,b) is specified by DISPERSIONPRIOR=GAMMA, which can be followed by one of the following gamma-options  enclosed in parentheses:      RELSHAPE<=c>     specifies independent G(c \u03c3-hat,c) distribution, where \u03c3-hat is the MLE of the dispersion parameter.      With this choice of hyperparameters, the mean of the prior distribution is \u03c3-hat and the variance is \u03c3-hat/c.     By default, c=10\u207b\u2074.       SHAPE=\u03b1 and ISCALE=b      specify the G(a,b) prior.           SHAPE=c      specifies the G(c,c) prior.       ISCALE=c      specifies the G(c,c) prior.","@ToolTip2":"Specifies that Gibbs sampling be performed on the generalized linear model scale parameter and the improper prior distribution for the scale parameter, if one exists in the model."}},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Controls the display of diagnostic plots. \n          \nSyntax:\n(1) PLOTS<(global-plot-options)>= plot-request \n(2) PLOTS<(global-plot-options)>= (plot-request < ...plot-request>) \n\nThe global plot options are as follows: \n\n    FRINGE \n    creates a fringe plot on the X axis of the density plot.\n\n    GROUPBY=TYPE | PARAMETER\n    specifies that the plots be grouped by type or parameter.\n\n    LAGS=n \n    specifies that autocorrelations be plotted up to lag n. If this option is not specified, autocorrelations are plotted up to lag 50. \n\n    SMOOTH \n    displays a fitted penalized \u03b2-spline curve for each trace plot. \n\n    UNPACKPANEL | UNPACK \n    specifies that all paneled plots be unpacked, meaning that each plot in a panel is displayed separately. \n\nThe plot requests include the following: \n\n    ALL \n    specifies all types of plots. PLOTS=ALL is equivalent to specifying PLOTS=(TRACE AUTOCORR DENSITY). \n\n    AUTOCORR \n    displays the autocorrelation function plots for the parameters. \n\n    DENSITY \n    displays the kernel density plots for the parameters. \n\n    NONE \n    suppresses all diagnostic plots. \n\n    TRACE \n    displays the trace plots for the parameters"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"AUTOCORR","@Value3":"DENSITY","@Value4":"NONE","@Value5":"TRACE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies all types of plots.","@ToolTip2":"Displays the autocorrelation function plots for the parameters.","@ToolTip3":"Displays the kernel density plots for the parameters.","@ToolTip4":"Suppresses all diagnostic plots.","@ToolTip5":"Displays the trace plots for the parameters."},"SubOptionsKeywords":"FRINGE|GROUPBY=|LAGS=|SMOOTH|UNPACK|UNPACKPANEL"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies an integer seed in the range 1 to 2\u00b3\u00b9-1 for the random number \ngenerator in the simulation."},"StatementOptionType":"V"},{"StatementOptionName":"STATISTICS=|STATS=","StatementOptionHelp":{"#cdata":"Controls the number of posterior statistics produced.\n          \nSyntax: STATISTICS <(global-options)> = ALL | NONE | keyword | (keyword-list) \n\nThe global-options include the following: \n\nALPHA=numeric-list \ncontrols the probabilities of the credible intervals. The ALPHA= values must be between 0 and 1.\n\nPERCENT=numeric-list \nrequests the percentile points of the posterior samples. The PERCENT= values must be between 0 and 100.\nThe default is PERCENT=25, 50, 75, which yield the 25th, 50th, and 75th percentile points, respectively,\nfor each parameter."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"NONE","@Value3":"CORR","@Value4":"COV","@Value5":"SUMMARY","@Value6":"INTERVAL","@Value7":"(CORR COV SUMMARY INTERVAL)"},"StatementOptionToolTips":{"@ToolTip1":"Requests all posterior statistics. Equivalent to specifying STATISTICS=(CORR COV SUMMARY INTERVAL).","@ToolTip2":"Requests no posterior statistics","@ToolTip3":"Requests the posterior correlation matrix.","@ToolTip4":"Requests the posterior covariance matrix.","@ToolTip5":"Requests the means, standard deviations, and percentile points for the posterior samples.  The default is to produce the 25th, 50th, and 75th percentile points, but you can use the global PERCENT= option to request specific percentile points.","@ToolTip6":"Requests equal-tail credible intervals and HPD intervals. The defult is to produce the 95% equal-tail credible intervals and 95% HPD intervals, but you can use the global ALPHA= option to request intervals of any probabilities.","@ToolTip7":"If you want some but not all of the posterior statistics, specify a subset of the following keywords: CORR COV SUMMARY INTERVAL"},"SubOptionsKeywords":"ALPHA=|PERCENT="},{"StatementOptionName":"THINNING=|THIN=","StatementOptionHelp":{"#cdata":"[Syntax:THINNING=number] \n          \nControls the thinning of the Markov chain."},"StatementOptionType":"V"}]}},{"StatementName":"BY","StatementHelp":{"#cdata":"Syntax: BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>; \n      \nYou can specify a BY statement with PROC GENMOD to obtain separate analyses on \nobservations in groups defined by the BY variables. When a BY statement appears, \nthe procedure expects the input data set to be sorted in order of the BY variables."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING","StatementOptionHelp":{"#cdata":"Specifies that the observations are sorted in descending order by the variable that \nimmediately follows the word DESCENDING in the BY statement."},"StatementOptionType":"S"},{"StatementOptionName":"NOTSORTED","StatementOptionHelp":{"#cdata":"Specifies that observations are not necessarily sorted in alphabetic or numeric order."},"StatementOptionType":"S"}]}},{"StatementName":"CLASS","StatementHelp":{"#cdata":"Syntax: CLASS variable<(options)>...<variable<(options)>></options> ; \n      \nThe CLASS statement names the classification variables to be used in the analysis. The \nCLASS statement must precede the MODEL statement. You can specify various v-options for \neach variable by enclosing them in parentheses after the variable name. You can also \nspecify global v-options for the CLASS statement by placing them after a slash (/). \nGlobal v-options are applied to all the variables specified in the CLASS statement. \nIf you specify more than one CLASS statement, the global v-options specified in any \none CLASS statement apply to all CLASS statements. However, individual CLASS variable \nv-options override the global v-options."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING|DESC","StatementOptionHelp":{"#cdata":"Reverses the sorting order of the classification variable."},"StatementOptionType":"S"},{"StatementOptionName":"TRUNCATE=","StatementOptionHelp":{"#cdata":"[Syntax: TRUNCATE<=n>] \n          \nSpecifies the length n of CLASS variable values to use in determining CLASS variable \nlevels. If you specify TRUNCATE without the length n, the first 16 characters of the \nformatted values are used."},"StatementOptionType":"S|V"},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"Specifies the sorting order for the levels of classification variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"StatementOptionToolTips":{"@ToolTip1":"Orders values according to their order in the input data set.","@ToolTip2":"Orders values by their ascending formatted values. This order depends on your operating environment.","@ToolTip3":"Orders values by descending frequency count so that levels with the most observations are listed first.","@ToolTip4":"Orders values by their unformatted values, which yields the same order as PROC SORT. This order  depends on your operating environment."}},{"StatementOptionName":"MISSING","StatementOptionHelp":{"#cdata":"Allows missing value (\u2019.\u2019 for a numeric variable and blank for a character variable) \nas a valid value for the CLASS variable."},"StatementOptionType":"S"},{"StatementOptionName":"PARAM=","StatementOptionHelp":{"#cdata":"Specifies the parameterization method for the classification variable or variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EFFECT","@Value2":"GLM","@Value3":"ORDINAL|THERMOMETER","@Value4":"POLYNOMIAL|POLY","@Value5":"REFERENCE|REF","@Value6":"ORTHEFFECT","@Value7":"ORTHORDINAL|ORTHOTHERM","@Value8":"ORTHPOLY","@Value9":"ORTHREF"},"StatementOptionToolTips":{"@ToolTip1":"Specifies effect coding.","@ToolTip2":"Specifies less-than-full-rank, reference-cell coding; this option can be used  only as a global option.","@ToolTip3":"Specifies the cumulative parameterization for an ordinal CLASS variable.","@ToolTip4":"Specifies polynomial coding.","@ToolTip5":"Specifies reference-cell coding.","@ToolTip6":"Orthogonalizes PARAM=EFFECT.","@ToolTip7":"Orthogonalizes PARAM=ORDINAL.","@ToolTip8":"Orthogonalizes PARAM=POLYNOMIAL.","@ToolTip9":"Orthogonalizes PARAM=REFERENCE."}},{"StatementOptionName":"REF=","StatementOptionHelp":{"#cdata":"Specifies the reference level for PARAM=EFFECT, PARAM=REFERENCE, and their orthogonalizations."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"<level>","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"Specifies the level of the variable to use as the reference level. Replace <level>  with an actual value.","@ToolTip2":"Designates the first ordered level as reference.","@ToolTip3":"Designates the last ordered level as reference."}}]}},{"StatementName":"CONTRAST","StatementHelp":{"#cdata":"Syntax: CONTRAST \u2019label\u2019 contrast-specification / <options> ; \n      \nThe CONTRAST statement provides a means of obtaining a test of a specified hypothesis \nconcerning the model parameters. This is accomplished by specifying a matrix L for testing \nthe hypothesis L'\u03b2=0. You must be familiar with the details of the model parameterization \nthat PROC GENMOD uses. \n\nThere is no limit to the number of CONTRAST statements that you can specify, but they must \nappear after the MODEL statement and after the ZEROMODEL statement for zero-inflated Poisson \nmodels. Statistics for multiple CONTRAST statements are displayed in a single table. \n\nThe elements of the CONTRAST statement are as follows: \n\nlabel \nidentifies the contrast on the output. A label is required for every contrast specified. \nLabels can be up to 20 characters and must be enclosed in single quotes. \n\ncontrast-specification \nidentifies the effects and their coefficients from which the L matrix is formed. The \ncontrast-specification can be specified in two different ways. The first method applies \nto all models except the zero-inflated Poisson (ZIP) distribution, and the syntax is: \n\n  effect values <,...effect values> \n\nThe second method of specifying a contrast applies only to ZIP models, and the syntax is: \n\n  effect values <,...effect values> @zero effect values <,...effect values>"},"StatementOptions":{"StatementOption":[{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"SINGULAR=|EPSILON=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking."},"StatementOptionType":"V"},{"StatementOptionName":"WALD","StatementOptionHelp":{"#cdata":"Requests that a Wald chi-square statistic be computed for the contrast rather than \nthe default likelihood ratio or score statistic."},"StatementOptionType":"S"}]}},{"StatementName":"DEVIANCE","StatementHelp":{"#cdata":"Syntax: DEVIANCE variable = expression ;\n      \nYou can specify a probability distribution other than those available in PROC GENMOD \nby using the DEVIANCE and VARIANCE statements. You do not need to specify the DEVIANCE \nor VARIANCE statement if you use the DIST= MODEL statement option to specify a probability \ndistribution. The variable identifies the deviance contribution from a single observation \nto the procedure, and it must be a valid SAS variable name that does not appear in the \ninput data set. The expression can be any arithmetic expression supported by the DATA \nstep language, and it is used to define the functional dependence of the deviance on the\nmean and the response. You use the automatic variables _MEAN_ and _RESP_ to represent the \nmean and response in the expression. \n\nAlternatively, the deviance function can be defined using programming statements and \nassigned to a variable, which is then listed as the expression. This form is convenient \nfor using complex statements such as IF-THEN/ELSE clauses. \n\nThe DEVIANCE statement is ignored unless the VARIANCE statement is also specified."},"StatementOptions":null},{"StatementName":"EFFECTPLOT","StatementHelp":{"#cdata":"Syntax: EFFECTPLOT <plot-type <(plot-definition-options)>> </ options> ; \n      \nThe EFFECTPLOT statement produces a display of the fitted model and provides options \nfor changing and enhancing the displays."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"BOX","StatementOptionHelp":{"#cdata":"Displays a box plot of continuous response data at each level of a CLASS effect, with \npredicted values superimposed and connected by a line. This is an alternative to the \nINTERACTION plot-type."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X="},{"StatementOptionName":"CONTOUR","StatementOptionHelp":{"#cdata":"Displays a contour plot of predicted values against two continuous covariates."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X=|Y="},{"StatementOptionName":"FIT","StatementOptionHelp":{"#cdata":"Displays a curve of predicted values versus a continuous variable."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X="},{"StatementOptionName":"INTERACTION","StatementOptionHelp":{"#cdata":"Displays a curve of predicted values versus a continuous variable grouped by the levels \nof a CLASS effect."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|SLICEBY=|X="},{"StatementOptionName":"SLICEFIT","StatementOptionHelp":{"#cdata":"[Syntax: ]"},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|SLICEBY=|X="},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=value] \n          \nSpecifies the significance level, 0 \u2265 value \u2265 1, for producing 100(1-value/2)% \nprediction and confidence limits. By default, value=0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT <contopt> <classopt> <variable1=varopt <variable2=varopt...>> \n\nwhere contopt= MEAN | MIN | MAX | MIDRANGE \nclassopt= ALL | REF \nvaropt= contopts | number-list |  classopts | \u2019class-level\u2019...\u2019class-level\u2019] \n\nSpecifies values at which to fix continuous and class variables when they are not used \nin X=, Y=, SLICEBY=, or PLOTBY= effects. The contopt keyword fixes continuous variables \nat their mean, minimum, maximum, or midrange; the default is to use the mean. The classopt \nkeyword either fixes a CLASS variable at its reference (last) level or indicates that all \nlevels of the CLASS variable should be processed; the default is to use the reference level. \nThe varopt values enable you to specify contopt and classopt keywords, or to specify lists \nof numbers or class levels. You can specify a CLASS variable only once in the AT specification, \nbut you can specify a continuous variable multiple times."},"StatementOptionType":"S"},{"StatementOptionName":"ATLEN=","StatementOptionHelp":{"#cdata":"[Syntax: ATLEN=n] \n          \nSpecifies the maximum length (1 < n < 256) of the levels of the AT variables that are displayed \nin footnotes and headers. By default, up to 256 characters of the CLASS levels are displayed, \nand the continuous AT levels are displayed with a BEST format that has a width greater than \nor equal to 5, which distinguishes each level. Caution:If the levels of your AT variables are \nnot unique when the first n characters are displayed, then the levels are combined in the plots \nbut not in the underlying computations. Also, at most n characters for continuous AT variables \nare displayed."},"StatementOptionType":"V"},{"StatementOptionName":"ATORDER=","StatementOptionHelp":{"#cdata":"Uses the AT values for continuous variables in ascending or descending order as specified. \nBy default, values are used in the order of their first appearance in the AT option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ASCENDING","@Value2":"DESCENDING"},"StatementOptionToolTips":{"@ToolTip1":"Uses the AT values for continuous variables in ascending order","@ToolTip2":"Uses the AT values for continuous variables in descending order"}},{"StatementOptionName":"CLI","StatementOptionHelp":{"#cdata":"Displays normal (Wald) prediction limits. This option is available only for normal \ndistributions with identity links. If your model is from a Bayesian analysis, then \nsampling-based intervals are computed."},"StatementOptionType":"S"},{"StatementOptionName":"CLM","StatementOptionHelp":{"#cdata":"Displays confidence limits. These are computed as the normal (Wald) confidence limits \nfor the linear predictor, and if the ILINK option is specified, the limits are also \nback-transformed by the inverse link function. If your model is from a Bayesian analysis, \nthen sampling-based intervals are computed."},"StatementOptionType":"S"},{"StatementOptionName":"CLUSTER","StatementOptionHelp":{"#cdata":"Syntax: CLUSTER<=percent> \n          \nModifies the BOX and INTERACTION plot-types by displaying the levels of the SLICEBY= effect in \na side-by-side fashion. You can specify percent as a percentage of half the distance between X \nlevels. The percent value must be between 0.1 and 1; the default percent depends on the number \nof X levels, the number of SLICEBY levels, and the number of PLOTBY levels for INTERACTION \nplot-types. Default clustering can be removed by specifying the NOCLUSTER option."},"StatementOptionType":"S|V"},{"StatementOptionName":"CONNECT","StatementOptionHelp":{"#cdata":"Modifies the BOX and INTERACTION plot-types by connecting the predicted values with a line. \nDefault connecting lines can be removed by specifying the NOCONNECT option."},"StatementOptionType":"S"},{"StatementOptionName":"EXTEND=","StatementOptionHelp":{"#cdata":"Extends continuous covariate axes by value x \u00bdrange in both directions, where range \nis the range of the X axis."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"<value>"},"StatementOptionToolTips":{"@ToolTip1":"Displays curves to the range of the data within the appropriate SLICEBY=, PLOTBY=, and AT level.","@ToolTip2":"Replace <value> with an actual value."}},{"StatementOptionName":"GRIDSIZE=","StatementOptionHelp":{"#cdata":"[Syntax: GRIDSIZE=n] \n          \nSpecifies the resolution of curves by computing the predicted values at n equally spaced \nx-values and specifies the resolution of surfaces by computing the predicted values on an \nnxn grid of points. Default values are n=200 for curves and bands, n=50 for surfaces, and \nn=2 for lines. If results of a Bayesian or bootstrap analysis are being displayed, then \nthe defaults are n=500000/B, where B is the number of samples, the upper limit is equal \nto the usual defaults, and the lower limit equal to 20."},"StatementOptionType":"V"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Displays the fit on the scale of the inverse link function. In particular, the results \nare displayed on the probability scale for logistic regression. By default, a procedure \ndisplays the fit on either the link or inverse link scale."},"StatementOptionType":"S"},{"StatementOptionName":"INDIVIDUAL","StatementOptionHelp":{"#cdata":"Displays individual probabilities for polytomous response models with cumulative links \non the scale of the inverse link function. This option is not available when the LINK \noption is specified, and confidence limits are not available with this option."},"StatementOptionType":"S"},{"StatementOptionName":"LIMITS","StatementOptionHelp":{"#cdata":"Invokes the CLI and CLM options."},"StatementOptionType":"S"},{"StatementOptionName":"LINK","StatementOptionHelp":{"#cdata":"Displays the fit on the scale of the link function; that is, the linear predictor. \nNote that probabilities or observed proportions near 0 and 1 are transformed to . \nBy default, a procedure displays the fit on either the link or inverse link scale."},"StatementOptionType":"S"},{"StatementOptionName":"MOFF","StatementOptionHelp":{"#cdata":"Moves the offset for a Poisson regression model to the response side of the equation. \nIf the ILINK option is also in effect, then the rate is displayed on the Y axis, while \nthe LINK option displays the log of the rate on the Y axis. Without this option, the \npredicted values are computed and displayed only for the observations."},"StatementOptionType":"S"},{"StatementOptionName":"NCOLS=","StatementOptionHelp":{"#cdata":"[Syntax: NCOLS=n] \n          \nSpecifies the maximum number of columns in a paneled plot. This option is not available \nwith the BOX plot-type. \n\nThe default choice of NROWS= and NCOLS= is based on the number of PLOTBY= and AT levels. \nIf there is only one plot being displayed in a panel, then NROWS=1 and NCOLS=1 and the \nplots are produced as if you specified only the UNPACK option. If only two plots are \ndisplayed in a panel, then NROWS=1 and NCOLS=2. For all other cases, a 2x2, 2x3, or 3x3 \npanel is chosen based on how much of the last panel is used, with ties going to the larger \npanels. For example, if 14 plots are being created, then this requires either four 2x2 \npanels with 50% of the last panel filled, three 2x3 panels with 33% of the last panel \nfilled, or two 3x3 panels with 55% of the last panel filled; in this case, the 3x3 panels \nare chosen. \n\nIf you specify both of the NROWS= and NCOLS= options, then those are the values used. However, \nif you only specify one of the options but have fewer plots, then the panel size is reduced; \nfor example, if you specify NROWS=6 but only have four plots, then a plot with four rows and \none column is produced."},"StatementOptionType":"V"},{"StatementOptionName":"NOCLI","StatementOptionHelp":{"#cdata":"Suppresses the prediction limits."},"StatementOptionType":"S"},{"StatementOptionName":"NOCLM","StatementOptionHelp":{"#cdata":"Suppresses the confidence limits."},"StatementOptionType":"S"},{"StatementOptionName":"NOLIMITS","StatementOptionHelp":{"#cdata":"Invokes the NOCLI and NOCLM options."},"StatementOptionType":"S"},{"StatementOptionName":"NOOBS","StatementOptionHelp":{"#cdata":"Suppresses the display of observations and overrides the specification of the OBS= option."},"StatementOptionType":"S"},{"StatementOptionName":"NROWS=","StatementOptionHelp":{"#cdata":"[Syntax: NROWS=n] \n          \nSpecifies the maximum number of rows in a paneled plot. This option is not available \nwith the BOX plot-type. See the NCOLS= option for more details."},"StatementOptionType":"V"},{"StatementOptionName":"OBS","StatementOptionHelp":{"#cdata":"[Syntax: OBS<(options)>] \n          \nDisplays observations on the effect plots. An input data set is required; hence the OBS option \nis not available with PROC PLM. The OBS option is overridden by the NOOBS option. When the ILINK \noption is specified with binary response variables, then either the observed proportions or a coded \nvalue of the response is displayed. For polytomous response variables, the observed values are overlaid \nonto the fitted curves unless the LOCATION= option is specified. Whether observations are displayed by \ndefault or not depends upon the procedure. If the PLOTBY= option is specified, then the observations \ndisplayed on each plot are from the corresponding PLOTBY= level for classification effects; for \ncontinuous effects, all observations are displayed on every plot. \n\nThe following options are available: \n\n  BYAT -- subsets the observations by AT level and by the PLOTBY= level. \n\n  CDISPLAY=NONE | OUTLINE | GRADIENT | OUTLINEGRADIENT \n  controls the display of observations on contour plots. \n\n  CGRADIENT=RESIDUAL | DEPENDENT \n  specifies what the gradient-shading of the observed values on the CONTOUR plot-type represents. \n\n  DEPTH=depth (you can specify 1 \u2264 depth \u2264 100. By default, DEPTH=1)\n  specifies the number of overlapping observations that can be distinguished by adjusting their transparency.\n\n  DISTANCE \n  displays observations on FIT plot-types with a color-gradient that indicates how far the \n  observation is from the AT and PLOTBY= level. \n\n  FITATCLASS --  computes fitted values only for class levels that are observed in the data set.  \n\n  FRINGE -- displays observations in a fringe (rug) plot at the bottom of the plot.  \n\n  JITTER<(FACTOR=factor SEED=seed X=x-jitter Y=y-jitter)> --  shifts (jitters) the observations. \n  \n  LABEL<=OBS> --  labels markers with their observation number. \n\n  LOCATION= BOTTOM | CURVE | FIRST | MAX | MIDDLE | MIN | SPREAD | TOP<=factor>\n  specifies where the observed values for polytomous response models are displayed when the SLICEBY= variable is the response."},"StatementOptionType":"S","SubOptionsKeywords":"BYAT|CDISPLAY=|CGRADIENT=|DEPTH=|DISTANCE|FITATCLASS|FRINGE|JITTER|FACTOR=|SEED=|X=|Y=|LABEL|LABEL=|LOCATION="},{"StatementOptionName":"PLOTBY=","StatementOptionHelp":{"#cdata":"[Syntax: PLOTBY<(panel-type)>=effect<=numeric-list>] \n          \nSpecifies a variable or CLASS effect at whose levels the predicted values are computed \nand the plots are displayed. You can specify the response variable as the effect for \npolytomous response models. The panel-type argument specifies the method in which the \nplots are grouped for the display. The following panel-types are available. \n\n  COLUMNS \n  specifies that the columns within each panel correspond to different levels of the PLOTBY= \n  effect and hence the rows correspond to different AT levels. \n\n  PACK \n  specifies that plots be displayed in the panels as they are produced with no control over \n  the placement of the PLOTBY= and AT levels. \n\n  PANELS | LEVELS \n  specifies that each level of the PLOTBY= effect begin a new panel of plots and the AT \n  levels define the plots within the panels. \n\n  ROWS \n  specifies that the rows within each panel correspond to different levels of the PLOTBY= \n  effect and hence the columns correspond to different AT levels. \n\nThis option is ignored with the BOX plot-type; box plots are always displayed in an unpacked \nfashion, grouped by the PLOTBY= and AT levels. If you specify a continuous variable as the \neffect, then you can either specify a numeric-list of values at which to display that variable \nor, by default, five equally spaced values from the minimum variable value to its maximum are \ndisplayed."},"StatementOptionType":"S|V","SubOptionsKeywords":"COLUMNS|PACK|PANELS|LEVELS|ROWS"},{"StatementOptionName":"PLOTBYLEN=","StatementOptionHelp":{"#cdata":"[Syntax: PLOTBYLEN=n] \n          \nSpecifies the maximum length (1 \u2264 n \u2264 256) of the levels of the PLOTBY= variables, which are displayed \nin footnotes and headers. By default, up to 256 characters of the CLASS levels are displayed. \n\nCaution:If the levels of your PLOTBY= variables are not unique when the first n characters \nare displayed, then the levels are combined in the plots but not in the underlying computations."},"StatementOptionType":"V"},{"StatementOptionName":"POLYBAR","StatementOptionHelp":{"#cdata":"Displays polytomous response data as a stacked histogram with bar heights defined \nby the individual predicted value. Your response variable must be the SLICEBY= \nvariable, and the INDIVIDUAL and ILINK options must be in effect; otherwise, the \noption is ignored. Confidence limits are ignored."},"StatementOptionType":"S"},{"StatementOptionName":"PREDLABEL=","StatementOptionHelp":{"#cdata":"[Syntax: PREDLABEL=label] \n          \nSpecifies a label to be displayed on the Y axis. The default Y axis label is determined \nby your model. For the CONTOUR plot-type, this option changes the title to \"label for Y.\""},"StatementOptionType":"V"},{"StatementOptionName":"SHOWCLEGEND","StatementOptionHelp":{"#cdata":"Displays the gradient-legend for the CONTOUR plot-type. This option has no effect \nwhen the OBS(CGRADIENT=RESIDUAL) option is also specified."},"StatementOptionType":"S"},{"StatementOptionName":"SLICEBY=","StatementOptionHelp":{"#cdata":"[Syntax: SLICEBY=NONE | effect<=numeric-list>] \n          \nDisplays the fitted values at the different levels of the specified variable or CLASS effect."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"NONE","@Value2":"effect<=numeric-list>"},"StatementOptionToolTips":{"@ToolTip1":"Preventing the INTERACTION plot-type from slicing by a second class covariate. Note  that the SLICEBY=NONE option is not available for the SLICEFIT plot-type, since that  is the same as the FIT plot-type.","@ToolTip2":"You can specify the response variable as the effect for polytomous response models. Use   this option to modify SLICEFIT and INTERACTION plot-types. If you specify a continuous  variable as the effect, then you can either specify a numeric-list of values at which  to display that variable or, by default, five equally spaced values from the minimum  variable value to its maximum are displayed."}},{"StatementOptionName":"SMOOTH","StatementOptionHelp":{"#cdata":"Overlays a loess smooth on the FIT plot-type for models that have only one continuous \npredictor. This option is not available for binary or polytomous response models."},"StatementOptionType":"S"},{"StatementOptionName":"UNPACK","StatementOptionHelp":{"#cdata":"Suppresses paneling. By default, multiple plots can appear in some output panels. \nSpecify UNPACK to display each plot separately.]"},"StatementOptionType":"S"},{"StatementOptionName":"X=","StatementOptionHelp":{"#cdata":"[Syntax: X=effect] \n          \nSpecifies values to display on the X axis. For BOX and INTERACTION plot-types, effect \ncan be a CLASS effect in the MODEL statement. For FIT, SLICEFIT, and CONTOUR plot-types, \neffect can be any continuous variable in the model."},"StatementOptionType":"V"},{"StatementOptionName":"Y=","StatementOptionHelp":{"#cdata":"[Syntax: Y=args] \n          \nSpecifies values to display on the Y axis for the CONTOUR plot-type. The Y= argument \ncan be any continuous variable in the model."},"StatementOptionType":"V"},{"StatementOptionName":"YRANGE=","StatementOptionHelp":{"#cdata":"Displays the predicted values on the Y axis in the range [min,max]. \n          \nBy default, when the Y axis displays predicted probabilities, the entire Y axis, [0,1], \nis displayed. This option is useful if your predicted probabilities are all contained \nin some subset of this range. This option is not available with the CONTOUR plot-type. "},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CLIP","@Value2":"<(<min><,max>)>"},"StatementOptionToolTips":{"@ToolTip1":"Has the same effect as specifying the minimum predicted value as min and the maximum predicted value as max.","@ToolTip2":"Replace min and max with actual values."}}],"#comment":{}}},{"StatementName":"ESTIMATE","StatementHelp":{"#cdata":"Syntax: ESTIMATE \u2019label\u2019 effect values <,...effect values> </options> ;\n      \nThe ESTIMATE statement is similar to a CONTRAST statement, except only one-row \nL' matrices are permitted."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a confidence interval be constructed with confidence level 1-number. \nThe value of number must be between 0 and 1; the default value is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=|EPSILON=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking."},"StatementOptionType":"V"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests that exp(L'\u03b2), its standard error, and its confidence limits be computed. \nIf you specify the EXP option, standard errors and confidence intervals are computed \nusing the delta method."},"StatementOptionType":"S"}]}},{"StatementName":"EXACT","StatementHelp":{"#cdata":"Syntax: EXACT <\u2019label\u2019> <INTERCEPT> <effects> </ options> ; \n      \nThe EXACT statement performs exact tests of the parameters for the specified effects \nand optionally estimates the parameters and outputs the exact conditional distributions. \nYou can specify the keyword INTERCEPT and any effects in the MODEL statement. Inference \non the parameters of the specified effects is performed by conditioning on the sufficient \nstatistics of all the other model parameters (possibly including the intercept). \n\nYou can specify several EXACT statements, but they must follow the MODEL statement. \nEach statement can optionally include an identifying label. If several EXACT statements \nare specified, any statement without a label is assigned a label of the form \"Exact,\" \nwhere n indicates the nth EXACT statement. The label is included in the headers of the \ndisplayed exact analysis tables."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSpecifies the level of significance \u03b1 for 100(1-\u03b1)% confidence limits for the parameters \nor odds ratios. The value of number must be between 0 and 1. By default, number is equal \nto the value of the ALPHA= option in the MODEL statement, or 0.05 if that option is not \nspecified."},"StatementOptionType":"V"},{"StatementOptionName":"CLTYPE=","StatementOptionHelp":{"#cdata":"Requests either the exact or mid-p confidence intervals for the parameter estimates. \nBy default, the exact intervals are produced."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EXACT","@Value2":"MIDP"},"StatementOptionToolTips":{"@ToolTip1":"Requests the exact confidence intervals for the parameter estimates.","@ToolTip2":"Requests either the mid-p confidence intervals for the parameter estimates."}},{"StatementOptionName":"ESTIMATE=","StatementOptionHelp":{"#cdata":"Estimates the individual parameters (conditioned on all other parameters) for the \neffects specified in the EXACT statement. For each parameter, a point estimate, \na standard error, a confidence interval, and a p-value for a two-sided test that \nthe parameter is zero are displayed. Note that the two-sided p-value is twice the \none-sided p-value."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"PARM","@Value2":"ODDS","@Value3":"BOTH"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the parameters be estimated. This is the default.","@ToolTip2":"Specifies that the odds ratios be estimated. If you have classification variables,  then you must also specify the PARAM=REF option in the CLASS statement.","@ToolTip3":"Specifies that both the parameters and odds ratios be estimated."}},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"Performs the joint test that all of the parameters are simultaneously equal to zero, \nperforms individual hypothesis tests for the parameter of each continuous variable, \nand performs joint tests for the parameters of each classification variable. The \njoint test is indicated in the \"Conditional Exact Tests\" table by the label \"Joint.\""},"StatementOptionType":"S"},{"StatementOptionName":"JOINTONLY","StatementOptionHelp":{"#cdata":"Performs only the joint test of the parameters. The test is indicated in the \"Conditional \nExact Tests\" table by the label \"Joint.\" When this option is specified, individual tests \nfor the parameters of each continuous variable and joint tests for the parameters of the \nclassification variables are not performed."},"StatementOptionType":"S"},{"StatementOptionName":"MIDPFACTOR=","StatementOptionHelp":{"#cdata":"[Syntax: MIDPFACTOR=\u03b41 | (\u03b41, \u03b42)] \n          \nSets the tie factors used to produce the mid-p hypothesis statistics and the mid-p confidence \nintervals. \u03b41 modifies both the hypothesis tests and confidence intervals, while \u03b42 affects \nonly the hypothesis tests. By default, \u03b41=0.5 and \u03b42=1.0."},"StatementOptionType":"V"},{"StatementOptionName":"ONESIDED","StatementOptionHelp":{"#cdata":"Requests one-sided confidence intervals and p-values for the individual parameter \nestimates and odds ratios. The one-sided p-value is the smaller of the left- and \nright-tail probabilities for the observed sufficient statistic of the parameter \nunder the null hypothesis that the parameter is zero. The two-sided p-values \n(default) are twice the one-sided p-values."},"StatementOptionType":"S"},{"StatementOptionName":"OUTDIST=","StatementOptionHelp":{"#cdata":"[Syntax: OUTDIST=SAS-data-set] \n          \nNames the SAS data set that contains the exact conditional distributions. This data set \ncontains all of the exact conditional distributions that are required to process the \ncorresponding EXACT statement. This data set contains the possible sufficient statistics \nfor the parameters of the effects specified in the EXACT statement, the counts, and, when \nhypothesis tests are performed on the parameters, the probability of occurrence and the \nscore value for each sufficient statistic. When you request an OUTDIST= data set, the \nobserved sufficient statistics are displayed in the \"Sufficient Statistics\" table."},"StatementOptionType":"DV"}]}},{"StatementName":"EXACTOPTIONS","StatementHelp":{"#cdata":"Syntax: EXACTOPTIONS options ;\n      \nThe EXACTOPTIONS statement specifies options that apply to every EXACT statement \nin the program."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ABSFCONV=","StatementOptionHelp":{"#cdata":"[Syntax: ABSFCONV=value] \n          \nSpecifies the absolute function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ADDTOBS","StatementOptionHelp":{"#cdata":"Adds the observed sufficient statistic to the sampled exact distribution if the statistic \nwas not sampled. This option has no effect unless the METHOD=NETWORKMC option is specified \nand the ESTIMATE option is specified in the EXACT statement. If the observed statistic has \nnot been sampled, then the parameter estimate does not exist; by specifying this option, you \ncan produce (biased) estimates."},"StatementOptionType":"S"},{"StatementOptionName":"BUILDSUBSETS","StatementOptionHelp":{"#cdata":"Builds every distribution for sampling. By default, some exact distributions are \ncreated by taking a subset of a previously generated exact distribution. When \nthe METHOD=NETWORKMC option is invoked, this subsetting behavior has the effect \nof using fewer than the desired n samples; see the N= option for more details. \nUse the BUILDSUBSETS option to suppress this subsetting."},"StatementOptionType":"S"},{"StatementOptionName":"EPSILON=","StatementOptionHelp":{"#cdata":"[Syntax: EPSILON=value] \n          \nControls how the partial sums \u2211 yixi (where i=1 to j) are compared. value must be \nbetween 0 and 1; by default, value=1E\u20138."},"StatementOptionType":"V"},{"StatementOptionName":"FCONV=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV=value] \n          \nSpecifies the relative function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"MAXTIME=","StatementOptionHelp":{"#cdata":"[Syntax: MAXTIME=seconds] \n          \nSpecifies the maximum clock time (in seconds) that PROC GENMOD can use to calculate \nthe exact distributions. If the limit is exceeded, the procedure halts all computations \nand prints a note to the LOG. The default maximum clock time is seven days."},"StatementOptionType":"V"},{"StatementOptionName":"METHOD=","StatementOptionHelp":{"#cdata":"Specifies which exact conditional algorithm to use for every EXACT statement specified."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DIRECT","@Value2":"NETWORK","@Value3":"NETWORKMC"},"StatementOptionToolTips":{"@ToolTip1":"Invokes the multivariate shift algorithm of Hirji, Mehta, and Patel (1987). This method  directly builds the exact distribution, but it can require an excessive amount of memory  in its intermediate stages. METHOD=DIRECT is invoked by default when you are conditioning  out at most the intercept.","@ToolTip2":"Invokes an algorithm described in Mehta, Patel, and Senchaudhuri (1992). This method builds  a network for each parameter that you are conditioning out, combines the networks, then uses  the multivariate shift algorithm to create the exact distribution. The NETWORK method can be  faster and require less memory than the DIRECT method. The NETWORK method is invoked by default  for most analyses.","@ToolTip3":"Invokes the hybrid network and Monte Carlo algorithm of Mehta, Patel, and Senchaudhuri (1992).  This method creates a network, then samples from that network; this method does not reject  any of the samples at the cost of using a large amount of memory to create the network.  METHOD=NETWORKMC is most useful for producing parameter estimates for problems that are  too large for the DIRECT and NETWORK methods to handle and for which asymptotic methods  are invalid\u2014for example, for sparse data on a large grid."}},{"StatementOptionName":"N=","StatementOptionHelp":{"#cdata":"[Syntax: N=n] \n          \nSpecifies the number of Monte Carlo samples to take when the METHOD=NETWORKMC option \nis specified. By default, n=100,000."},"StatementOptionType":"V"},{"StatementOptionName":"NOLOGSCALE","StatementOptionHelp":{"#cdata":"Specifies that computations for the exact conditional models be computed by using \nnormal scaling. Log scaling can handle numerically larger problems than normal \nscaling; however, computations in the log scale are slower than computations in \nnormal scale."},"StatementOptionType":"S"},{"StatementOptionName":"ONDISK","StatementOptionHelp":{"#cdata":"Uses disk space instead of random access memory to build the exact conditional \ndistribution. Use this option to handle larger problems at the cost of slower processing."},"StatementOptionType":"S"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=seed] \n          \nSpecifies the initial seed for the random number generator used to take the Monte Carlo \nsamples when the METHOD=NETWORKMC option is specified. The value of the SEED= option must \nbe an integer. If you do not specify a seed, or if you specify a value less than or equal \nto zero, then PROC GENMOD uses the time of day from the computer\u2019s clock to generate an \ninitial seed."},"StatementOptionType":"V"},{"StatementOptionName":"STATUSN=","StatementOptionHelp":{"#cdata":"[Syntax: STATUSN=number] \n          \nPrints a status line in the SAS log after every number of Monte Carlo samples when the \nMETHOD=NETWORKMC option is specified. The number of samples taken and the current exact \np-value for testing the significance of the model are displayed. You can use this status \nline to track the progress of the computation of the exact conditional distributions."},"StatementOptionType":"V"},{"StatementOptionName":"STATUSTIME=","StatementOptionHelp":{"#cdata":"[Syntax: STATUSTIME=seconds] \n          \nSpecifies the time interval (in seconds) for printing a status line in the LOG. \nYou can use this status line to track the progress of the computation of the exact \nconditional distributions. The time interval you specify is approximate; the actual \ntime interval varies. By default, no status reports are produced."},"StatementOptionType":"V"},{"StatementOptionName":"XCONV=","StatementOptionHelp":{"#cdata":"[Syntax: XCONV=value] \n          \nSpecifies the relative parameter convergence criterion."},"StatementOptionType":"V"}]}},{"StatementName":"FREQ|FREQUENCY","StatementHelp":{"#cdata":"Syntax: FREQ | FREQUENCY variable;\n      \nThe variable in the FREQ statement identifies a variable in the input data set \ncontaining the frequency of occurrence of each observation. PROC GENMOD treats \neach observation as if it appears n times, where n is the value of the FREQ variable \nfor the observation. If it is not an integer, the frequency value is truncated to \nan integer. If it is less than 1 or missing, the observation is not used. In the \ncase of models fit with generalized estimating equations (GEEs), the frequencies \napply to the subject/cluster and therefore must be the same for all observations \nwithin each subject."},"StatementOptions":null},{"StatementName":"FWDLINK","StatementHelp":{"#cdata":"Syntax: FWDLINK variable = expression ;\n      \nYou can define a link function other than a built-in link function by using the \nFWDLINK statement. If you use the MODEL statement option LINK= to specify a link \nfunction, you do not need to use the FWDLINK statement. The variable identifies \nthe link function to the procedure. The expression can be any arithmetic expression \nsupported by the DATA step language, and it is used to define the functional \ndependence on the mean."},"StatementOptions":null},{"StatementName":"INVLINK","StatementHelp":{"#cdata":"Syntax: INVLINK variable = expression ; \n      \nIf you define a link function in the FWDLINK statement, then you must define the \ninverse link function by using the INVLINK statement. If you use the MODEL statement \noption LINK= to specify a link function, you do not need to use the INVLINK statement. \nThe variable identifies the inverse link function to the procedure. The expression \ncan be any arithmetic expression supported by the DATA step language, and it is used \nto define the functional dependence on the linear predictor."},"StatementOptions":null},{"StatementName":"LSMEANS","StatementHelp":{"#cdata":"Syntax: LSMEANS <model-effects> </ options> ; \n      \nThe LSMEANS statement computes and compares least squares means (LS-means) of fixed \neffects. LS-means are predicted population margins\u2014that is, they estimate the marginal \nmeans over a balanced population. In a sense, LS-means are to unbalanced designs as \nclass and subclass arithmetic means are to balanced designs."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the LSMEANS effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the LSMEANS statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the LSMEANS \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="}]}},{"StatementName":"LSMESTIMATE","StatementHelp":{"#cdata":"Syntax: LSMESTIMATE model-effect <'label'> values <divisor=> \n  <, ...<'label'> values <divisor=>>\n  < / options> ; \n  \nThe LSMESTIMATE statement provides a mechanism for obtaining custom hypothesis \ntests among least squares means."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the \nLS-mean estimates. The adjusted quantities are produced in addition to the unadjusted \np-values and confidence limits. Adjusted confidence limits are produced if the CL or \nALPHA= option is in effect."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means with \nconfidence level 1-number. The value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates used in computing LS-means. By default, all \ncovariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that the procedure compute separate margins for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F tests with the JOINT option. \n\nThe category-options indicate how response variable levels are treated in constructing \nthe estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row LSESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row LSESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. \nThe confidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L coefficients of the estimable function be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ELSM","StatementOptionHelp":{"#cdata":"Requests that the K matrix coefficients be displayed. These are the coefficients \nthat apply to the LS-means. This option is useful to ensure that you assigned the \ncoefficients correctly to the LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the least squares means estimate. When you model data \nwith the logit link function and the estimate represents a log odds ratio, the \nEXP option produces an odds ratio. If you specify the CL or ALPHA= option, the \n(adjusted) confidence limits for the estimate are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the \nmean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004). \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to \nthose found in the OM-data-set. This adjustment is reasonable when you want your \ninferences to apply to a population that is not necessarily balanced but has the \nmargins observed in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip3":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip4":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|HIST|NOHIST|\n            NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the ESTIMATE statement."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant.\n\nYou can specify the following step-down-options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential subsets \n    of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60.\n\n    ORDER=PVALUE \n    ORDER=ROWS \n    specifies the order in which the step-down tests are performed. ORDER=PVALUE is the default, with LS-mean\n    estimates being declared significant only if all LS-mean estimates with smaller (unadjusted) p-values are\n    significant. If you specify ORDER=ROWS, then significances are evaluated in the order in which they are specified. \n\n    REPORT \n    specifies that a report on the step-down adjustment be displayed, including a listing of the sequential \n    subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically consistent \n    sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, \n    sequential subsets are computed ignoring logical constraints. The TYPE=FREE results are more conservative \n    than those for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. Default: TYPE=FREE."},"StatementOptionType":"S"},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nLSMESTIMATE statement. The rules for specifying the value-list are very similar to those  \nfor specifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"MODEL","StatementHelp":{"#cdata":"Syntax: MODEL response = <effects> < /options> ; \n  | MODEL events/trials = <effects> < /options> ; \n\nThe MODEL statement specifies the response, or dependent variable, and the effects, \nor explanatory variables. If you omit the explanatory variables, the procedure fits \nan intercept-only model. An intercept term is included in the model by default. The \nintercept can be removed with the NOINT option. \n\nYou can specify the response in the form of a single variable or in the form of a \nratio of two variables denoted events/trials. The first form is applicable to all \nresponses. The second form is applicable only to summarized binomial response data. \nWhen each observation in the input data set contains the number of events (for example, \nsuccesses) and the number of trials from a set of binomial trials, use the events/trials \nsyntax. \n\nIn the events/trials model syntax, you specify two variables that contain the event \nand trial counts. These two variables are separated by a slash (/). The values of both \nevents and (trialsevents) must be nonnegative, and the value of the trials variable must \nbe greater than 0 for an observation to be valid. The variable events or trials can take \nnoninteger values."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"AGGREGATE=","StatementOptionHelp":{"#cdata":"[Syntax: AGGREGATE= (variable-list) | AGGREGATE= variable | AGGREGATE] \n          \nSpecifies the subpopulations on which the Pearson chi-square and the deviance \nare calculated. Specifying the AGGREGATE option is equivalent to specifying the \nAGGREGATE= option with a variable list that includes all explanatory variables \nin the MODEL statement."},"StatementOptionType":"S|V"},{"StatementOptionName":"ALPHA=|ALPH=|A=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSets the confidence coefficient for parameter confidence intervals to 1-number. \nThe value of number must be between 0 and 1. The default value of number is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"CICONV=","StatementOptionHelp":{"#cdata":"[Syntax: CICONV=number] \n          \nSets the convergence criterion for profile likelihood confidence intervals."},"StatementOptionType":"V"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that confidence limits for predicted values be displayed (see the OBSTATS option)."},"StatementOptionType":"S"},{"StatementOptionName":"CODING=","StatementOptionHelp":{"#cdata":"Specifies that effect coding be used for all classification variables in the model. \nThis is the same as specifying PARAM=EFFECT as a CLASS statement option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EFFECT","@Value2":"FULLRANK"},"StatementOptionToolTips":{"@ToolTip1":"CODING=EFFECT","@ToolTip2":"CODING=FULLRANK"}},{"StatementOptionName":"CONVERGE=","StatementOptionHelp":{"#cdata":"[Syntax: CONVERGE=number] \n          \nSets the convergence criterion. The value of number must be between 0 and 1."},"StatementOptionType":"V"},{"StatementOptionName":"CONVH=","StatementOptionHelp":{"#cdata":"[Syntax: CONVH=number] \n          \nSets the relative Hessian convergence criterion. The value of number must be between 0 and 1."},"StatementOptionType":"V"},{"StatementOptionName":"CORRB","StatementOptionHelp":{"#cdata":"Requests that the parameter estimate correlation matrix be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"COVB","StatementOptionHelp":{"#cdata":"Requests that the parameter estimate covariance matrix be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"DIAGNOSTICS|INFLUENCE","StatementOptionHelp":{"#cdata":"Requests that case deletion diagnostic statistics be displayed (see the OBSTATS option)."},"StatementOptionType":"S"},{"StatementOptionName":"DIST=|D=|ERROR=|ERR=","StatementOptionHelp":{"#cdata":"Specifies the built-in probability distribution to use in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BINOMIAL","@Value2":"GAMMA","@Value3":"GEOMETRIC","@Value4":"IGAUSSIAN","@Value5":"MULTINOMIAL","@Value6":"NEGBIN","@Value7":"NORMAL","@Value8":"POISSON","@Value9":"ZIP"},"StatementOptionToolTips":{"@ToolTip1":"Binomial distribution","@ToolTip2":"Gamma distribution","@ToolTip3":"Geometric distribution","@ToolTip4":"Inverse Gaussian distribution","@ToolTip5":"Multinomial distribution","@ToolTip6":"Negative binomial distribution","@ToolTip7":"Normal distribution","@ToolTip8":"Poisson distribution"}},{"StatementOptionName":"EXACTMAX","StatementOptionHelp":{"#cdata":"Syntax: EXACTMAX<=variable> \n\nNames a variable used for performing an exact Poisson regression. For each observation, \nthe integer part of the EXACTMAX value should be nonnegative and at least as large as \nthe response value. If the EXACTMAX option is specified without a variable, then default \nvalues are computed."},"StatementOptionType":"S|V"},{"StatementOptionName":"EXPECTED","StatementOptionHelp":{"#cdata":"Requests that the expected Fisher information matrix be used to compute parameter estimate \ncovariances and the associated statistics."},"StatementOptionType":"S"},{"StatementOptionName":"INITIAL=","StatementOptionHelp":{"#cdata":"[Syntax: INITIAL=numbers] \n          \nSets initial values for parameter estimates in the model."},"StatementOptionType":"V"},{"StatementOptionName":"INTERCEPT=","StatementOptionHelp":{"#cdata":"[Syntax: INTERCEPT=number] \n          \nInitializes the intercept term to number for parameter estimation."},"StatementOptionType":"V"},{"StatementOptionName":"ITPRINT","StatementOptionHelp":{"#cdata":"Displays the iteration history for all iterative processes: parameter estimation, fitting \nconstrained models for contrasts and Type 3 analyses, and profile likelihood confidence \nintervals."},"StatementOptionType":"S"},{"StatementOptionName":"LINK=","StatementOptionHelp":{"#cdata":"Specifies the link function to use in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CUMCLL","@Value2":"CUMLOGIT","@Value3":"CUMPROBIT","@Value4":"CLOGLOG","@Value5":"IDENTITY","@Value6":"LOG","@Value7":"LOGIT","@Value8":"PROBIT","@Value9":"POWER(number)"},"StatementOptionToolTips":{"@ToolTip1":"Cumulative complementary log-log function","@ToolTip2":"Cumulative logit function","@ToolTip3":"Cumulative probit function","@ToolTip4":"Complementary log-log function","@ToolTip5":"Identity function","@ToolTip6":"Log function","@ToolTip7":"Logit function","@ToolTip8":"Probit function","@ToolTip9":"Power with \u03bb=number function"}},{"StatementOptionName":"LRCI","StatementOptionHelp":{"#cdata":"Requests that two-sided confidence intervals for all model parameters be computed based on \nthe profile likelihood function."},"StatementOptionType":"S"},{"StatementOptionName":"MAXITER=|MAXIT=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER=number] \n          \nSets the maximum allowable number of iterations for all iterative computation processes \nin PROC GENMOD. By default, MAXITER=50."},"StatementOptionType":"V"},{"StatementOptionName":"NOINT","StatementOptionHelp":{"#cdata":"Requests that no intercept term be included in the model. An intercept is included unless \nthis option is specified."},"StatementOptionType":"S"},{"StatementOptionName":"NOSCALE","StatementOptionHelp":{"#cdata":"Holds the scale parameter fixed. Otherwise, for the normal, inverse Gaussian, and gamma \ndistributions, the scale parameter is estimated by maximum likelihood. If you omit the \nSCALE= option, the scale parameter is fixed at the value 1."},"StatementOptionType":"S"},{"StatementOptionName":"OBSTATS","StatementOptionHelp":{"#cdata":"Specifies that an additional table of statistics be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"OFFSET=","StatementOptionHelp":{"#cdata":"[Syntax: OFFSET=variable] \n          \nSpecifies a variable in the input data set to be used as an offset variable."},"StatementOptionType":"V"},{"StatementOptionName":"PREDICTED|PRED|P","StatementOptionHelp":{"#cdata":"Requests that predicted values, the linear predictor, its standard error, and the Hessian \nweight be displayed (see the OBSTATS option)."},"StatementOptionType":"S"},{"StatementOptionName":"RESIDUALS|R","StatementOptionHelp":{"#cdata":"Requests that residuals and standardized residuals be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"SCALE=","StatementOptionHelp":{"#cdata":"Sets the value used for the scale parameter where the NOSCALE option is used."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"<number>","@Value2":"PEARSON|P","@Value3":"DEVIANCE|D"},"StatementOptionToolTips":{"@ToolTip1":"Replace number with an actual scale parameter value.","@ToolTip2":"Fixes the scale parameter at the value 1 in the estimation procedure. After the parameter estimates are  determined, the exponential family dispersion parameter is assumed to be given by Pearson\u2019s chi-square statistic divided by the degrees of freedom.","@ToolTip3":"Fixes the scale parameter at a value of 1 in the estimation procedure. After the parameter estimates are  determined, the exponential family dispersion parameter is assumed to be given by the deviance divided by the degrees of freedom."}},{"StatementOptionName":"DSCALE","StatementOptionHelp":{"#cdata":"Same as specifying SCALE=DEVIANCE or SCALE=D. This fixes the scale parameter at a value \nof 1 in the estimation procedure."},"StatementOptionType":"S"},{"StatementOptionName":"SCORING=","StatementOptionHelp":{"#cdata":"[Syntax: SCORING=number] \n          \nRequests that on iterations up to number, the Hessian matrix be computed using \nthe Fisher scoring method."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nSets the tolerance for testing singularity of the information matrix and the \ncrossproducts matrix."},"StatementOptionType":"V"},{"StatementOptionName":"TYPE1","StatementOptionHelp":{"#cdata":"Requests that a Type 1, or sequential, analysis be performed."},"StatementOptionType":"S"},{"StatementOptionName":"TYPE3","StatementOptionHelp":{"#cdata":"Requests that statistics for Type 3 contrasts be computed for each effect specified in the \nMODEL statement."},"StatementOptionType":"S"},{"StatementOptionName":"WALD","StatementOptionHelp":{"#cdata":"Requests Wald statistics for Type 3 contrasts. You must also specify the TYPE3 option in \norder to compute Type 3 Wald statistics."},"StatementOptionType":"S"},{"StatementOptionName":"WALDCI","StatementOptionHelp":{"#cdata":"Requests that two-sided Wald confidence intervals for all model parameters be computed based \non the asymptotic normality of the parameter estimators."},"StatementOptionType":"S"},{"StatementOptionName":"XVARS","StatementOptionHelp":{"#cdata":"Requests that the regression variables be included in the OBSTATS table."},"StatementOptionType":"S"}]}},{"StatementName":"OUTPUT","StatementHelp":{"#cdata":"Syntax: OUTPUT <OUT=SAS-data-set> <keyword=name ...keyword=name> ; \n      \nThe OUTPUT statement creates a new SAS data set that contains all the variables \nin the input data set and, optionally, the estimated linear predictors (XBETA) \nand their standard error estimates, the weights for the Hessian matrix, predicted \nvalues of the mean, confidence limits for predicted values, residuals, and case \ndeletion diagnostics. Residuals and diagnostic statistics are not computed for \nmultinomial models."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nSpecifies the output data set. If you omit the OUT=option, the output data \nset is created and given a default name that uses the DATA convention."},"StatementOptionType":"RV|DV"},{"StatementOptionName":"DFBETA=|DBETA=","StatementOptionHelp":{"#cdata":"Represents the effect of deleting an observation on parameter estimates."},"StatementOptionType":"V"},{"StatementOptionName":"DFBETAS=|DBETAS=","StatementOptionHelp":{"#cdata":"Represents the effect of deleting an observation on standardized parameter estimates."},"StatementOptionType":"V"},{"StatementOptionName":"DOBS=|COOKD=|COOKSD=","StatementOptionHelp":{"#cdata":"Represents the Cook distance type statistic to measure the influence of deleting a single observation \non the overall model fit."},"StatementOptionType":"V"},{"StatementOptionName":"HESSWGT=","StatementOptionHelp":{"#cdata":"Represents the diagonal element of the weight matrix used in computing the Hessian matrix."},"StatementOptionType":"V"},{"StatementOptionName":"LEVERAGE=|H=","StatementOptionHelp":{"#cdata":"Represents the leverage of a single observation."},"StatementOptionType":"V"},{"StatementOptionName":"LOWER=|L=","StatementOptionHelp":{"#cdata":"Represents the lower confidence limit for the predicted value of the mean, or the lower \nconfidence limit for the probability that the response is less than or equal to the value \nof Level or Value."},"StatementOptionType":"V"},{"StatementOptionName":"PREDICTED=|PRED=|PROB=|P=","StatementOptionHelp":{"#cdata":"Represents the predicted value of the mean of the response or the predicted probability \nthat the response variable is less than or equal to the value of Level or Value if the \nmultinomial model for ordinal data is used."},"StatementOptionType":"V"},{"StatementOptionName":"PZERO=","StatementOptionHelp":{"#cdata":"Represents the zero-inflation probability for zero-inflated models."},"StatementOptionType":"V"},{"StatementOptionName":"RESCHI=","StatementOptionHelp":{"#cdata":"Represents the Pearson (chi) residual for identifying observations that are poorly accounted for \nby the model."},"StatementOptionType":"V"},{"StatementOptionName":"RESDEV=","StatementOptionHelp":{"#cdata":"Represents the deviance residual for identifying poorly fitted observations."},"StatementOptionType":"V"},{"StatementOptionName":"RESLIK=","StatementOptionHelp":{"#cdata":"Represents the likelihood residual for identifying poorly fitted observations."},"StatementOptionType":"V"},{"StatementOptionName":"RESRAW=","StatementOptionHelp":{"#cdata":"Represents the raw residual for identifying poorly fitted observations."},"StatementOptionType":"V"},{"StatementOptionName":"STDRESCHI=","StatementOptionHelp":{"#cdata":"Represents the standardized Pearson (chi) residual for identifying observations that are poorly \naccounted for by the model."},"StatementOptionType":"V"},{"StatementOptionName":"STDRESDEV=","StatementOptionHelp":{"#cdata":"Represents the standardized deviance residual for identifying poorly fitted observations."},"StatementOptionType":"V"},{"StatementOptionName":"STDXBETA=","StatementOptionHelp":{"#cdata":"Represents the standard error estimate of XBETA (see the XBETA keyword)."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER=|U=","StatementOptionHelp":{"#cdata":"Represents the upper confidence limit for the predicted value of the mean, or the upper \nconfidence limit for the probability that the response is less than or equal to the value \nof Level or Value."},"StatementOptionType":"V"},{"StatementOptionName":"XBETA=","StatementOptionHelp":{"#cdata":"Represents the estimate of the linear predictor x'iB for observation i, or aj + x'iB,\nwhere j is the corresponding ordered value of the response variable for the multinomial \nmodel with ordinal data."},"StatementOptionType":"V"},{"StatementOptionName":"CH=|CLUSTERH=|CLEVERAGE=","StatementOptionHelp":{"#cdata":"[Requires REPEATED statement] \n          \nRepresents the leverage of a cluster."},"StatementOptionType":"V"},{"StatementOptionName":"CLUSTER","StatementOptionHelp":{"#cdata":"[Requires REPEATED statement] \n          \nRepresents the numerical cluster index, in order of sorted clusters."},"StatementOptionType":"V"},{"StatementOptionName":"DCLS=|CLUSTERCOOKD=|CLUSTERCOOKSD=","StatementOptionHelp":{"#cdata":"[Requires REPEATED statement] \n          \nRepresents the Cook distance type statistic to measure the influence of deleting \nan entire cluster on the overall model fit."},"StatementOptionType":"V"},{"StatementOptionName":"DFBETAC=|DBETAC=","StatementOptionHelp":{"#cdata":"[Requires REPEATED statement] \n          \nRepresents the effect of deleting an entire cluster on parameter estimates."},"StatementOptionType":"V"},{"StatementOptionName":"DFBETACS=|DBETACS=","StatementOptionHelp":{"#cdata":"[Requires REPEATED statement] \n          \nRepresents the effect of deleting an entire cluster on normalized parameter estimates."},"StatementOptionType":"V"},{"StatementOptionName":"MCLS=|CLUSTERDFIT=","StatementOptionHelp":{"#cdata":"[Requires REPEATED statement] \n          \nRepresents the studentized Cook distance type statistic to measure the influence \nof deleting an entire cluster on the overall model fit."},"StatementOptionType":"V"}]}},{"StatementName":"REPEATED","StatementHelp":{"#cdata":"Syntax: REPEATED SUBJECT= subject-effect </ options> ; \n\nThe REPEATED statement specifies the covariance structure of multivariate responses \nfor GEE model fitting in the GENMOD procedure."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"SUBJECT=","StatementOptionHelp":{"#cdata":"[Syntax: SUBJECT=subject-effect] \n          \nIdentifies subjects in the input data set."},"StatementOptionType":"RV"},{"StatementOptionName":"ALPHAINIT=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHAINIT=numbers] \n          \nSpecifies initial values for log odds ratio regression parameters if the LOGOR= option \nis specified for binary data."},"StatementOptionType":"V"},{"StatementOptionName":"CONVERGE=","StatementOptionHelp":{"#cdata":"[Syntax: CONVERGE=number] \n          \nSpecifies the convergence criterion for GEE parameter estimation."},"StatementOptionType":"V"},{"StatementOptionName":"CORRW","StatementOptionHelp":{"#cdata":"Displays the estimated regression parameter correlation matrix. Both model-based and empirical \ncorrelations are displayed."},"StatementOptionType":"S"},{"StatementOptionName":"COVB","StatementOptionHelp":{"#cdata":"Displays the estimated regression parameter covariance matrix. Both model-based and empirical \ncovariances are displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ECORRB","StatementOptionHelp":{"#cdata":"Displays the estimated regression parameter empirical correlation matrix."},"StatementOptionType":"S"},{"StatementOptionName":"ECOVB","StatementOptionHelp":{"#cdata":"Displays the estimated regression parameter empirical covariance matrix."},"StatementOptionType":"S"},{"StatementOptionName":"INTERCEPT=","StatementOptionHelp":{"#cdata":"[Syntax: INTERCEPT=number] \n          \nSpecifies either an initial or a fixed value of the intercept regression parameter \nin the GEE model."},"StatementOptionType":"V"},{"StatementOptionName":"INITIAL=","StatementOptionHelp":{"#cdata":"[Syntax: INITIAL=numbers] \n          \nSpecifies initial values of the regression parameters estimation, other than the \nintercept parameter, for GEE estimation."},"StatementOptionType":"V"},{"StatementOptionName":"LOGOR=","StatementOptionHelp":{"#cdata":"Specifies the regression structure of the log odds ratio used to model the association of the responses \nfrom subjects for binary data."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EXCH","@Value2":"FULLCLUST","@Value3":"LOGORVAR(variable)","@Value4":"NESTK","@Value5":"NEST1","@Value6":"ZFULL","@Value7":"ZREP","@Value8":"ZREP(matrix)"},"StatementOptionToolTips":{"@ToolTip1":"Exchangeable","@ToolTip2":"Fully parameterized clusters","@ToolTip3":"Indicator variable for specifying block effects","@ToolTip4":"k-nested","@ToolTip5":"1-nested","@ToolTip6":"Fully specified z-matrix specified in ZDATA= data set","@ToolTip7":"Single cluster specification for replicated z-matrix specified in ZDATA= data set","@ToolTip8":"Single cluster specification for replicated z-matrix"}},{"StatementOptionName":"MAXITER=|MAXIT=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER=number] \n          \nSpecifies the maximum number of iterations allowed in the iterative GEE estimation \nprocess. The default number is 50."},"StatementOptionType":"V"},{"StatementOptionName":"MCORRB","StatementOptionHelp":{"#cdata":"Displays the estimated regression parameter model-based correlation matrix."},"StatementOptionType":"S"},{"StatementOptionName":"MCOVB","StatementOptionHelp":{"#cdata":"Displays the estimated regression parameter model-based covariance matrix."},"StatementOptionType":"S"},{"StatementOptionName":"MODELSE","StatementOptionHelp":{"#cdata":"Displays an analysis of parameter estimates table that uses model-based standard errors for inference."},"StatementOptionType":"S"},{"StatementOptionName":"PRINTMLE","StatementOptionHelp":{"#cdata":"Displays an analysis of maximum likelihood parameter estimates table. The maximum likelihood \nestimates are not displayed unless this option is specified."},"StatementOptionType":"S"},{"StatementOptionName":"RUPDATE=","StatementOptionHelp":{"#cdata":"[Syntax: RUPDATE=number] \n          \nSpecifies the number of iterations between updates of the working correlation matrix."},"StatementOptionType":"V"},{"StatementOptionName":"SORTED","StatementOptionHelp":{"#cdata":"Specifies that the input data are grouped by subject and sorted within subject."},"StatementOptionType":"S"},{"StatementOptionName":"SUBCLUSTER=|SUBCLUST=","StatementOptionHelp":{"#cdata":"[Syntax: SUBCLUSTER=variable] \n          \nSpecifies a variable defining subclusters for the 1-nested or k-nested log odds \nratio association modeling structures."},"StatementOptionType":"V"},{"StatementOptionName":"TYPE=|CORR=","StatementOptionHelp":{"#cdata":"Specifies the structure of the working correlation matrix used to model the correlation of the \nresponses from subjects."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"AR","@Value2":"EXCH","@Value3":"IND","@Value4":"MDEP(number)","@Value5":"UNSTR","@Value6":"USER","@Value7":"FIXED (matrix)"},"StatementOptionToolTips":{"@ToolTip1":"Autoregressive(1)","@ToolTip2":"Exchangeable","@ToolTip3":"Independent","@ToolTip4":"m-dependent with m=number","@ToolTip5":"Unstructured","@ToolTip6":"Fixed, user-specified correlation matrix","@ToolTip7":"Fixed, user-specified correlation matrix"}},{"StatementOptionName":"V6CORR","StatementOptionHelp":{"#cdata":"Specifies that the SAS \u2018Version 6\u2019 method of computing the normalized Pearson chi-square be used for \nworking correlation estimation and for model-based covariance matrix scale factor."},"StatementOptionType":"S"},{"StatementOptionName":"WITHINSUBJECT=|WITHIN=","StatementOptionHelp":{"#cdata":"[Syntax: WITHINSUBJECT= | WITHIN=within subject-effect] \n          \nDefines an effect specifying the order of measurements within subjects."},"StatementOptionType":"V"},{"StatementOptionName":"YPAIR=","StatementOptionHelp":{"#cdata":"[Syntax: YPAIR=variable-list] \n          \nSpecifies the variables in the ZDATA= data set corresponding to pairs of responses \nfor log odds ratio association modeling."},"StatementOptionType":"V"},{"StatementOptionName":"ZDATA=","StatementOptionHelp":{"#cdata":"[Syntax: ZDATA=SAS-data-set] \n          \nSpecifies a SAS data set containing either the full z-matrix for log odds ratio \nassociation modeling or the z-matrix for a single complete cluster to be replicated \nfor all clusters."},"StatementOptionType":"DV"},{"StatementOptionName":"ZROW=","StatementOptionHelp":{"#cdata":"[Syntax: ZROW=variable-list] \n          \nSpecifies the variables in the ZDATA= data set corresponding to rows of the \nz-matrix for log odds ratio association modeling."},"StatementOptionType":"V"}]}},{"StatementName":"SLICE","StatementHelp":{"#cdata":"Syntax: SLICE model-effect </ options> ; \n      \nThe SLICE statement provides a general mechanism for performing a partitioned analysis \nof the LS-means for an interaction. This analysis is also known as an analysis of simple \neffects. \n\nThe SLICE statement uses the same options as the LSMEANS statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the SLICE model-effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified SLICE effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the SLICE effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the SLICE statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this SLICE statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the SLICE \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="},{"StatementOptionName":"SLICEBY=","StatementOptionHelp":{"#cdata":"Determines how to construct the partition of the least squares means for the model-effect.\n          \nSyntax: \nSLICEBY <=> slice-specification \nSIMPLE <=> slice-specification \nSLICEBY(slice-specification <, slice-specification <, >>) \nSIMPLE(slice-specification <, slice-specification <, >>) \n\nA slice-specification consists of an effect name followed by an optional list of formatted \nvalues. For example, the following statements creates partitions of the A*B interaction effect \nfor all levels of variable A: \n\n  class a b;\n  model y = a b a*b;\n  slice a*b / sliceby=a;"},"StatementOptionType":"S|V"},{"StatementOptionName":"NOF","StatementOptionHelp":{"#cdata":"Suppresses the F test for testing the mutual equality of the estimable functions \nin the partition."},"StatementOptionType":"S"}]}},{"StatementName":"STORE|ITEMSTORE","StatementHelp":{"#cdata":"Syntax: STORE <OUT=>item-store-name </ LABEL='label'> ; \n      \nThe STORE statement requests that the procedure save the context and results of the \nstatistical analysis. The resulting item store is a binary file format that cannot \nbe modified. The contents of the item store can be processed with the PLM procedure. \n\nThe item-store-name is a usual one- or two-level SAS name, like the names that are used \nfor SAS data sets. If you specify a one-level name, then the item store resides in the \nWORK library and is deleted at the end of the SAS session. Since item stores usually are \nused to perform postprocessing tasks, typical usage specifies a two-level name of the form \nlibname.membername. \n\nIf an item store by the same name as specified in the STORE statement already exists, \nthe existing store is replaced."},"StatementOptions":{"StatementOption":{"StatementOptionName":"LABEL=","StatementOptionHelp":{"#cdata":"[Syntax: LABEL='label'] \n          \nAdds a custom label. When the PLM procedure processes an item store, the label appears \nin the PROC PLM output along with other identifying information."},"StatementOptionType":"V"}}},{"StatementName":"STRATA|STRATUM","StatementHelp":{"#cdata":"Syntax: STRATA variable <( list )> < ...variable <( list )>> < /option> ;\n      \nThe proportional hazards assumption might not be realistic for all data. If so, it might still be \nreasonable to perform a stratified analysis. The STRATA statement names the variables that determine \nthe stratification. Strata are formed according to the nonmissing values of the STRATA variables \nunless the MISSING option is specified. In the STRATA statement, variable is a variable with values \nthat are used to determine the strata levels, and list is an optional list of values for a numeric \nvariable. Multiple variables can appear in the STRATA statement."},"StatementOptions":{"StatementOption":{"StatementOptionName":"MISSING","StatementOptionHelp":{"#cdata":"Treats missing values (\u2018.\u2019,\u2018.A\u2019,...,\u2018.Z\u2019 for numeric variables and blanks for character variables) \nas valid STRATA variable values."},"StatementOptionType":"S"}}},{"StatementName":"VARIANCE","StatementHelp":{"#cdata":"Syntax: VARIANCE variable = expression ; \n    \nYou can specify a probability distribution other than the built-in distributions \nby using the VARIANCE and DEVIANCE statements. The variable name variable identifies \nthe variance function to the procedure. The expression is used to define the functional \ndependence on the mean, and it can be any arithmetic expression supported by the DATA \nstep language. You use the automatic variable _MEAN_ to represent the mean in the \nexpression."},"StatementOptions":null},{"StatementName":"WEIGHT|SCWGT","StatementHelp":{"#cdata":"Syntax: WEIGHT | SCWGT variable;\n      \nThe WEIGHT statement identifies a variable in the input data set to be used as the \nexponential family dispersion parameter weight for each observation. The exponential \nfamily dispersion parameter is divided by the WEIGHT variable value for each observation. \nThis is true regardless of whether the parameter is estimated by the procedure or specified \nin the MODEL statement with the SCALE= option. It is also true for distributions such as \nthe Poisson and binomial that are not usually defined to have a dispersion parameter. For \nthese distributions, a WEIGHT variable weights the overdispersion parameter, which has the \ndefault value of 1. \n\nThe WEIGHT variable does not have to be an integer; if it is less than or equal to 0 or \nif it is missing, the corresponding observation is not used."},"StatementOptions":null},{"StatementName":"ZEROMODEL","StatementHelp":{"#cdata":"Syntax: ZEROMODEL effects < /options> ;\n      \nThe ZEROMODEL statement enables you to perform zero-inflated Poisson regression or \nzero-inflated negative binomial regression when those respective distributions are \nspecified by the DIST= option in the MODEL statement. The effects in the ZEROMODEL \nstatement consist of explanatory variables or combinations of variables for the\nzero-inflation probability regression model in a zero-inflated model."},"StatementOptions":{"StatementOption":{"StatementOptionName":"LINK=","StatementOptionHelp":{"#cdata":"Specifies the link function to use in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CLOGLOG","@Value2":"LOGIT","@Value3":"PROBIT"},"StatementOptionToolTips":{"@ToolTip1":"Specifies to use the complementary log-log link function in the model.","@ToolTip2":"Specifies to use the logit link function in the model.","@ToolTip3":"Specifies to use the probit link function in the model."}}}},{"StatementName":"IF","StatementHelp":{"#cdata":"Executes a SAS statement for observations that meet specific conditions. \n\nSyntax: \n(1) IF expression THEN statement; \n    <ELSE statement;> \n(2) IF condition;"},"StatementOptions":{"StatementOption":[{"StatementOptionName":"THEN","StatementOptionHelp":{"#cdata":"If the conditions that are specified in the IF clause are met, the IF-THEN statement executes a SAS \nstatement for observations that are read from a SAS data set, for records in an external file, or \nfor computed values."},"StatementOptionType":"S"},{"StatementOptionName":"DO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"WHEN","StatementOptionHelp":{"#cdata":"WHEN statement in an IF-THEN-WHEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"OUTPUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"GO TO|GOTO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct. \n          \nSyntax: ... GO TO label; | ... GOTO label;\n      \nJumps to a new statement."},"StatementOptionType":"S"},{"StatementOptionName":"PUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"STOP","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct. \n          \nStops execution of the current DATA step."},"StatementOptionType":"S"},{"StatementOptionName":"SET","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct.\n          \nSyntax: SET <SAS-data-set(s) <(data-set-options(s) )>>; \n      \nReads an observation from one or more SAS data sets."},"StatementOptionType":"S"},{"StatementOptionName":"NOT","StatementOptionType":"S"},{"StatementOptionName":"OR","StatementOptionType":"S"},{"StatementOptionName":"AND","StatementOptionType":"S"}],"#comment":{}}},{"StatementName":"ELSE","StatementHelp":{"#cdata":"If the condition in an IF-THEN statement is false and an ELSE statement is present, \nthen the ELSE action is carried out."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"THEN","StatementOptionHelp":{"#cdata":"If the conditions that are specified in the IF clause are met, the IF-THEN statement executes a SAS \nstatement for observations that are read from a SAS data set, for records in an external file, or \nfor computed values."},"StatementOptionType":"S"},{"StatementOptionName":"IF","StatementOptionHelp":{"#cdata":"Executes a SAS statement for observations that meet specific conditions."},"StatementOptionType":"S"},{"StatementOptionName":"DO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN-ELSE construct."},"StatementOptionType":"S"},{"StatementOptionName":"OUTPUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN-ELSE construct."},"StatementOptionType":"S"},{"StatementOptionName":"NOT","StatementOptionType":"S"},{"StatementOptionName":"OR","StatementOptionType":"S"},{"StatementOptionName":"AND","StatementOptionType":"S"}],"#comment":{}}}],"#comment":{}}}}