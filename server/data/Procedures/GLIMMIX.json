{"Procedure":{"Name":"GLIMMIX","#comment":{},"ProductGroup":"SAS/STAT","ProcedureHelp":{"#cdata":"Syntax: PROC GLIMMIX <options> ; \n    BY variables ; \n    CLASS variable <(REF= option)> \u2026<variable <(REF= option)>> </ global-options>;  \n    CODE <options>; \n    CONTRAST 'label' contrast-specification <, contrast-specification> <, ...> </ options> ; \n    COVTEST <'label'> <test-specification> </ options> ; \n    EFFECT effect-specification ; \n    ESTIMATE 'label' contrast-specification <(divisor=n)>\n      <, 'label' contrast-specification <(divisor=n)>> <, ...> </ options> ; \n    FREQ variable ; \n    ID variables ; \n    LSMEANS fixed-effects </ options> ; \n    LSMESTIMATE fixed-effect <'label'> values <divisor=>\n      <, <'label'> values <divisor=n>> <, ...> </ options> ; \n    MODEL response<(response variable options)> = <fixed-effects> </ model-options> ; \n    MODEL events/trials = <fixed-effects> </ model-options> ; \n    NLOPTIONS <options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword<(keyword-options)> <=name>>...\n      <keyword<(keyword-options)> <=name>> </ options> ; \n    PARMS (value-list) ...</ options> ; \n    RANDOM random-effects </ options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    WEIGHT variable ; \n    Programming statements ;  \n\nThe GLIMMIX procedure fits statistical models to data with correlations or nonconstant variability \nand where the response is not necessarily normally distributed. These models are known as generalized \nlinear mixed models (GLMM). \n\nGLMMs, like linear mixed models, assume normal (Gaussian) random effects. Conditional on these random \neffects, data can have any distribution in the exponential family. The exponential family comprises many \nof the elementary discrete and continuous distributions. The binary, binomial, Poisson, and negative \nbinomial distributions, for example, are discrete members of this family. The normal, beta, gamma, and \nchi-square distributions are representatives of the continuous distributions in this family. In the absence \nof random effects, the GLIMMIX procedure fits generalized linear models (fit by the GENMOD procedure)."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"ABSPCONV=","ProcedureOptionHelp":{"#cdata":"[Syntax: ABSPCONV=r] \n      \n Specifies an absolute parameter estimate convergence criterion for doubly iterative \n estimation methods."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"ASYCORR","ProcedureOptionHelp":{"#cdata":"Produces the asymptotic correlation matrix of the covariance parameter estimates."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"ASYCOV","ProcedureOptionHelp":{"#cdata":"Requests that the asymptotic covariance matrix of the covariance parameter estimates be displayed."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"CHOLESKY|CHOL","ProcedureOptionHelp":{"#cdata":"Requests that the mixed model equations be constructed and solved by using the Cholesky \nroot of the G matrix. This option applies only to estimation methods that involve mixed \nmodel equations."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"[Syntax: DATA=SAS-data-set] \n      \nNames the SAS data set to be used by PROC GLIMMIX. The default is the most recently \ncreated data set."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"EMPIRICAL=","ProcedureOptionHelp":{"#cdata":"Requests that the covariance matrix of the parameter estimates be computed as one of the asymptotically \nconsistent estimators, known as sandwich or empirical estimators."},"ProcedureOptionType":"S|V","ProcedureOptionValues":{"@Value1":"CLASSICAL|HCO","@Value2":"DF|HC1","@Value3":"MBN","@Value4":"ROOT|HC2","@Value5":"FIRORES|HC3","@Value6":"FIROEEQ"},"ProcedureOptionToolTips":{"@ToolTip1":"Computes the classical sandwich estimator.","@ToolTip2":"Applies a simple, multiplicative correction factor to the classical estimator.","@ToolTip3":"Adjusts the likelihood-based sandwich estimator further if you fit a mixed model by maximum likelihood with Laplace or quadrature approximation (METHOD=LAPLACE, METHOD=QUAD).  Syntax: MBN<(mbn-options)>  The valid mbn-options are as follows:     DF   a sample size adjustment is applied when the DF suboption is in effect.     NODF   The NODF suboption suppresses this component of the adjustment.     R=   The lower bound of the design effect parameter 0 \u2264r \u2264 1 can be specified with the R= option.     D=   The magnitude of Morel's \u03b4 parameter is partly determined with the D= option (d \u2265 1)","@ToolTip4":"Based on the residual approximation in Kauermann and Carroll (2001)","@ToolTip5":"Based on Taylor series approximations applied to residuals and estimating equations. For uncorrelated  data, the EMPIRICAL=FIRORES estimator can be motivated as a jackknife estimator.","@ToolTip6":"Syntax: FIROEEQ<(r)>                                 Based on approximating an unbiased estimating equation (Fay and Graubard 2001). The optional  number 0 \u2264 r \u2264 1 is chosen to provide an upper bound on the correction factor. The default  value for r is 0.75."}},{"ProcedureOptionName":"EXPHESSIAN","ProcedureOptionHelp":{"#cdata":"Requests that the expected Hessian matrix be used in computing the covariance matrix of the nonprofiled \nparameters."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"FDIGITS=","ProcedureOptionHelp":{"#cdata":"[Syntax: FDIGITS=r] \n      \nSpecifies the number of accurate digits in evaluations of the objective function. \nFractional values are allowed."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"GRADIENT","ProcedureOptionHelp":{"#cdata":"Displays the gradient of the objective function with respect to the parameter estimates in the \"Covariance \nParameter Estimates\" table and/or the \"Parameter Estimates\" table."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"HESSIAN|HESS|H","ProcedureOptionHelp":{"#cdata":"Displays the Hessian matrix of the optimization."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"INFOCRIT=|IC=","ProcedureOptionHelp":{"#cdata":"Determines the computation of information criteria in the \"Fit Statistics\" table."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"NONE","@Value2":"PQ","@Value3":"Q"},"ProcedureOptionToolTips":{"@ToolTip1":"Criteria are suppressed in the 'Fit Statistics' table. This is the default for models based on  pseudo-likelihoods.","@ToolTip2":"Requests that the penalties include the number of fixed-effects parameters, when estimation in  models with random  effects is based on a residual (restricted) likelihood.","@ToolTip3":"The default for linear mixed models with normal errors, and the resulting information criteria  are identical to the IC option in the MIXED procedure."}},{"ProcedureOptionName":"INITGLM|STARTGLM","ProcedureOptionHelp":{"#cdata":"Requests that the estimates from a generalized linear model fit (a model without random effects) be \nused as the starting values for the generalized linear mixed model."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"INITITER=","ProcedureOptionHelp":{"#cdata":"[Syntax: INITITER=number] \n      \nSpecifies the maximum number of iterations used when a generalized linear model \nis fit initially to derive starting values for the fixed effects; see the INITGLM \noption."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"ITDETAILS","ProcedureOptionHelp":{"#cdata":"Adds parameter estimates and gradients to the \"Iteration History\" table."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"LIST","ProcedureOptionHelp":{"#cdata":"Requests that the model program and variable lists be displayed. This is a debugging feature and \nis not normally needed."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"MAXLMMUPDATE=|MAXOPT=","ProcedureOptionHelp":{"#cdata":"[Syntax: MAXLMMUPDATE=number] \n      \nSpecifies the maximum number of optimizations for doubly iterative estimation \nmethods based on linearizations."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"METHOD=","ProcedureOptionHelp":{"#cdata":"Specifies the estimation method in a generalized linear mixed model (GLMM). The default is METHOD=RSPL. \nEstimation methods ending in \"PL\" are pseudo-likelihood techniques. The first letter of the METHOD= \nidentifier determines whether estimation is based on a residual likelihood (\"R\") or a maximum \nlikelihood (\"M\"). The second letter identifies the expansion locus for the underlying approximation \n(\"S\" for vector of random effects solutions and \"M\" for mean of random effects."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"RSPL","@Value2":"MSPL","@Value3":"RMPL","@Value4":"MMPL","@Value5":"LAPLACE","@Value6":"QUAD<(quad-options)>"},"ProcedureOptionToolTips":{"@ToolTip1":"A pseudo-likelihood estimation method based on a residual likelihood, with vector of random effects  solutions as the expansion locus for the underlying approximation.","@ToolTip2":"A pseudo-likelihood estimation method based on a maximum likelihood, with vector of random effects  solutions as the expansion locus for the underlying approximation.","@ToolTip3":"A pseudo-likelihood estimation method based on a residual likelihood, with mean of random effects  as the expansion locus for the underlying approximation.","@ToolTip4":"A pseudo-likelihood estimation method based on a maximum likelihood, with mean of random effects  as the expansion locus for the underlying approximation.","@ToolTip5":"Approximates the marginal likelihood by using Laplace's method.","@ToolTip6":"Approximates the marginal log likelihood with an adaptive Gauss-Hermite quadrature.                                 You can specify the following quad-options for METHOD=QUAD in parentheses:    EBDETAILS      reports details about the empirical Bayes suboptimization process should this suboptimization fail.   EBSSFRAC=r      specifies the step-shortening fraction to be used while computing empirical Bayes estimates of the random effects.  EBSSTOL=r      specifies the objective function tolerance for determining the cessation of step shortening while computing      empirical Bayes estimates of the random effects, r > 0.  EBSTEPS=n      specifies the maximum number of Newton steps for computing empirical Bayes estimates of random effects, n > 0.  EBSUBSTEPS=n      specifies the maximum number of step shortenings for computing empirical Bayes estimates of random effects.  EBTOL=r      specifies the convergence tolerance for empirical Bayes estimation, n >= 0.  FASTQUAD | FQ       requests the multilevel adaptive quadrature algorithm proposed by Pinheiro and Chao (2006).   INITPL=number      requests that adaptive quadrature commence after performing up to number pseudo-likelihood updates.   QCHECK      performs an adaptive recalculation of the objective function (\u20132 log likelihood) at the solution.  QFAC=r      determines the step size for the quadrature point sequence.  QMAX=n      specifies an upper bound for the number of quadrature points. The default is n=31.   QMIN=n      specifies a lower bound for the number of quadrature points.  QPOINTS=n      determines the number of quadrature points in each dimension of the integral.  QTOL=r    specifies a relative tolerance criterion for the successive evaluation of log likelihoods for different    numbers of quadrature points."},"SubOptionsKeywords":"EBDETAILS|EBSSFRAC=|EBSSTOL=|EBSTEPS=|EBSUBSTEPS=|EBTOL=|FASTQUAD|FQ|INITPL=|QCHECK|QFAC=|QMAX=|QMIN=|QPOINTS=|QTOL="},{"ProcedureOptionName":"NAMELEN=","ProcedureOptionHelp":{"#cdata":"[Syntax: NAMELEN=number] \n      \nSpecifies the length to which long effect names are shortened. The default and \nminimum value is 20."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NOBOUND","ProcedureOptionHelp":{"#cdata":"Requests the removal of boundary constraints on covariance and scale parameters in mixed models."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOBSDETAIL","ProcedureOptionHelp":{"#cdata":"Adds detailed information to the \"Number of Observations\" table to reflect how many observations were \nexcluded from the analysis and for which reason."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOCLPRINT=","ProcedureOptionHelp":{"#cdata":"[Syntax: NOCLPRINT<=number>] \n      \nSuppresses the display of the \"Class Level Information\" table, if you do not specify \nnumber. If you specify number, only levels with totals that are less than number are \nlisted in the table."},"ProcedureOptionType":"S|V"},{"ProcedureOptionName":"NOFIT","ProcedureOptionHelp":{"#cdata":"Suppresses fitting of the model. When the NOFIT option is in effect, PROC GLIMMIX produces the \n\"Model Information,\" \"Class Level Information,\" \"Number of Observations,\" and \"Dimensions\" tables."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOINITGLM","ProcedureOptionHelp":{"#cdata":"Requests that the starting values for the fixed effects not be obtained by first fitting a \ngeneralized linear model."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOITPRINT","ProcedureOptionHelp":{"#cdata":"Suppresses the display of the \"Iteration History\" table."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOPROFILE","ProcedureOptionHelp":{"#cdata":"Includes the scale parameter (\u03a6) into the optimization for models that have such a parameter."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOREML","ProcedureOptionHelp":{"#cdata":"Determines the denominator for the computation of the scale parameter in a GLM for normal data and \nfor overdispersion parameters."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"ODDSRATIO|OR","ProcedureOptionHelp":{"#cdata":"Requests that odds ratios be added to the output when applicable."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"ORDER=","ProcedureOptionHelp":{"#cdata":"Specifies the order in which to sort the levels of the classification variables (which are \nspecified in the CLASS statement). This ordering determines which parameters in the model \ncorrespond to each level in the data, so the ORDER= option can be useful when you use \nCONTRAST or ESTIMATE statements."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"ProcedureOptionToolTips":{"@ToolTip1":"Levels sorted by the order of appearance in the input data set.","@ToolTip2":"Levels sorted by the external formatted value, except for numeric variables with no explicit  format, which are sorted by their unformatted (internal) value.","@ToolTip3":"Levels sorted by the descending frequency count; levels with the most observations come first  in the order.","@ToolTip4":"Levels sorted by the unformatted value."}},{"ProcedureOptionName":"OUTDESIGN","ProcedureOptionHelp":{"#cdata":"[Syntax: OUTDESIGN<(options)><=SAS-data-set>] \n      \nCreates a data set that contains the contents of the X and Z matrix.\n\nYou can specify the following options in parentheses to control the contents of the OUTDESIGN data set: \n\n NAMES \n  produces tables associating columns in the OUTDESIGN data set with fixed-effects parameter estimates and random-effects solutions. \n NOMISS \n  excludes from the OUTDESIGN data set observations that were not used in the analysis. \n NOVAR \n    excludes from the OUTDESIGN data set variables from the input data set. \n X<=prefix> \n  saves the contents of the X matrix. The optional prefix is used to name the columns. The default naming prefix is \"_X\". \n Z<=prefix> \n  saves the contents of the Z matrix. The optional prefix is used to name the columns. The default naming prefix is \"_Z\"."},"ProcedureOptionType":"S|V","SubOptionsKeywords":"NAMES|NOMISS|NOVAR|X|X=|Z|Z="},{"ProcedureOptionName":"PCONV=","ProcedureOptionHelp":{"#cdata":"[Syntax: PCONV=r] \n      \nSpecifies the parameter estimate convergence criterion for doubly iterative \nestimation methods."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"PLOTS=","ProcedureOptionHelp":{"#cdata":"Controls the plots produced through ODS Graphics. Specify the PLOTS=NONE option in order to \nprevent these plots from being produced when ODS Graphics is enabled.\n\nSyntax:\n(1) PLOTS <(global-plot-options)> <= plot-request <(options)>> \n(2) PLOTS <(global-plot-options)> <= (plot-request <(options)> <... plot-request <(options)>>)> \n\nThe global-plot-options supported by the GLIMMIX procedure are as follows: \n\n  OBSNO \n  uses the data set observation number to identify observations in tooltips, provided that the \n  observation number can be determined. Otherwise, the number displayed in tooltips is the index \n  of the observation as it is used in the analysis within the BY group. \n\n  UNPACKPANEL | UNPACK \n  breaks a graphic that is otherwise paneled into individual component plots."},"ProcedureOptionType":"S|V","ProcedureOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"MEANPLOT","@Value7":"NONE","@Value8":"ODDSRATIO","@Value9":"RESIDUALPANEL","@Value10":"STUDENTPANEL","@Value11":"PEARSONPANEL"},"ProcedureOptionToolTips":{"@ToolTip1":"Produces all appropriate plots.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared against  an average least squares mean.","@ToolTip3":"[Syntax: BOXPLOT<(boxplot-options)>]                                  Requests box plots for the effects in your model that consist of classification  effects only. The available boxplot-options are as follows:       BLOCK | BLOCKLEGEND -- displays levels of up to four classification variables of the box plot effect by using block legends instead of axis tick values.     BLUP | CONDITIONAL -- constructs box plots from conditional residuals\u2014that is, residuals that use the estimated BLUPs of random effects.     FIXED -- produces box plots for all fixed effects (MODEL statement) consisting entirely of classification variables.     GROUP -- produces box plots for all GROUP= effects in RANDOM statements consisting entirely of classification variables.      ILINK | NONLINEAR -- computes the residual on the scale of the data (the inverse linked scale).      NOBLUP | MARGINAL -- constructs box plots from marginal residuals.     NOILINK | LINEAR -- computes the residual on the linked scale.      NPANELPOS=number -- specifies the number of box positions on the graphic and provides the capability to break a box plot into multiple graphics.      OBSERVED -- adds box plots of the observed data for the selected effects.      PEARSON -- constructs box plots from Pearson residuals rather than from the default residuals.      PSEUDO -- adds box plots of the pseudo-data for the selected effects.       RANDOM -- produces box plots for all effects in RANDOM statements that consist entirely of classification variables.       RAW -- constructs box plots from raw residuals (observed minus predicted).      STUDENT -- constructs box plots from studentized residuals rather than from the default residuals.      SUBJECT -- produces box plots for all SUBJECT= effects in RANDOM statements consisting entirely of classification variables.      USEINDEX -- uses as the horizontal axis label the index of the effect level, rather than the formatted value(s).","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"[Syntax: DIFFPLOT<(diffplot-options)>]                                  Requests a display of all pairwise least squares mean differences and their  significance. You can specify the following diffplot-options.       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES      suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"[Syntax: MEANPLOT<(meanplot-options)>]                                  Requests a display of the least squares means of effects specified in LSMEANS statements.  The following meanplot-options control the display of the least squares means.       ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip7":"Requests that no plots be produced","@ToolTip8":"[Syntax: ODDSRATIO<(oddsratioplot-options)>]                                  Requests a display of odds ratios and their confidence limits when the link function  permits the computation of odds ratios. The available oddsratioplot-options are as follows:      LOGBASE=2|E|10      log-scales the odds ratio axis.       NPANELPOS=n      provides the capability to break an odds ratio plot into multiple graphics having at      most n odds ratios per graphic.       ORDER=ASCENDING|DESCENDING      displays the odds ratios in sorted order. By default the odds ratios are displayed in the order in which      they appear in the \"Odds Ratio Estimates\" table.       RANGE=(<min> <,max>) | CLIP      specifies the range of odds ratios to display.       STATS      adds the numeric values of the odds ratio and its confidence limits to the graphic.","@ToolTip9":"[Syntax: RESIDUALPANEL<(residualplot-options)>]                                  Requests a paneled display constructed from raw residuals. The residualplot-options  take on the following values:       BLUP | CONDITIONAL      uses the predictors of the random effects in computing the residual.       ILINK | NONLINEAR      computes the residual on the inverse linked scale (the data scale).       NOBLUP | MARGINAL      does not use the predictors of the random effects in computing the residual.       NOILINK | LINEAR      computes the residual on the linked scale.       UNPACK      produces separate plots from the elements of the panel.","@ToolTip10":"[Syntax: STUDENTPANEL<(residualplot-options)>]                                  Requests a paneled display constructed from studentized residuals. The residualplot-options  take on the following values:       BLUP | CONDITIONAL      uses the predictors of the random effects in computing the residual.       ILINK | NONLINEAR      computes the residual on the inverse linked scale (the data scale).       NOBLUP | MARGINAL      does not use the predictors of the random effects in computing the residual.       NOILINK | LINEAR      computes the residual on the linked scale.       UNPACK      produces separate plots from the elements of the panel.","@ToolTip11":"[Syntax: PEARSONPANEL<(residualplot-options)>]                                  Requests a paneled display constructed from Pearson residuals. The residualplot-options  take on the following values:       BLUP | CONDITIONAL      uses the predictors of the random effects in computing the residual.       ILINK | NONLINEAR      computes the residual on the inverse linked scale (the data scale).       NOBLUP | MARGINAL      does not use the predictors of the random effects in computing the residual.       NOILINK | LINEAR      computes the residual on the linked scale.       UNPACK      produces separate plots from the elements of the panel."},"SubOptionsKeywords":"\n        |OBSNO|UNPACKPANEL|UNPACK|ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|CONNECT|SLICEBY=|PLOTBY=|\n        |BLUP|CONDITIONAL|ILINK|NONLINEAR|NOBLUP|MARGINAL|NOILINK|LINEAR|UNPACK|LOGBASE|NPANELPOS|ORDER=|ASCENDING|DESCENDING|\n        |STATS|RANGE|CLIP|OBSERVED|PSEUDO|PEARSON|RANDOM|RAW|STUDENT|SUBJECT|USEINDEX|\n      "},{"ProcedureOptionName":"PROFILE","ProcedureOptionHelp":{"#cdata":"Requests that scale parameters be profiled from the optimization, if possible. This is the default \nfor generalized linear mixed models. In generalized linear models with normally distributed data, \nyou can use the PROFILE option to request profiling of the residual variance."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"SCOREMOD","ProcedureOptionHelp":{"#cdata":"requests that the Hessian matrix in GLMMs be based on a modified scoring algorithm, provided that \nPROC GLIMMIX is in scoring mode when the Hessian is evaluated."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"SCORING=","ProcedureOptionHelp":{"#cdata":"[Syntax: SCORING=number] \n      \nRequests that Fisher scoring be used in association with the estimation method \nup to iteration number."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SINGCHOL=","ProcedureOptionHelp":{"#cdata":"[Syntax: SINGCHOL=number] \n      \nTunes the singularity criterion in Cholesky decompositions. The default is 1E4 times \nthe machine epsilon; this product is approximately 1E-12 on most computers."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SINGRES=","ProcedureOptionHelp":{"#cdata":"[Syntax: SINGRES=number] \n      \nSets the tolerance for which the residual variance is considered to be zero. \nThe default is 1E4 times the machine epsilon; this product is approximately \n1E-12 on most computers."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SINGULAR=","ProcedureOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n      \nTunes the general singularity criterion applied by the GLIMMIX procedure \nin divisions and inversions. The default is 1E4 times the machine epsilon; \nthis product is approximately 1E-12 on most computers."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SUBGRADIENT|SUBGRAD","ProcedureOptionHelp":{"#cdata":"[Syntax: SUBGRADIENT<=SAS-data-set>] \n      \nCreates a data set with information about the gradient of the objective function. The contents and organization \nof the SUBGRADIENT= data set depend on the type of model.\n\n  o GLMM Mode\n    If the GLIMMIX procedure operates in GLMM mode, the SUBGRADIENT= data set contains as many observations \n    as there are usable subjects in the analysis.\n  o GLM Mode\n    When you fit a generalized linear model (GLM) or a GLM with overdispersion, the SUBGRADIENT= data set contains \n    the observation-wise gradients of the negative log-likelihood function with respect to the parameter estimates."},"ProcedureOptionType":"S|V"}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"BY","StatementHelp":{"#cdata":"Syntax: BY variables; \n\nYou can specify a BY statement with PROC GLIMMIX to obtain separate analyses of observations in groups that \nare defined by the BY variables. When a BY statement appears, the procedure expects the input data set to be \nsorted in order of the BY variables. If you specify more than one BY statement, only the last one specified is used. \n\nIf your input data set is not sorted in ascending order, use one of the following alternatives: \n\n  \u2022 Sort the data by using the SORT procedure with a similar BY statement. \n  \u2022 Specify the NOTSORTED or DESCENDING option in the BY statement for the BCHOICE procedure. The NOTSORTED \n    option does not mean that the data are unsorted but rather that the data are arranged in groups (according to values \n    of the BY variables) and that these groups are not necessarily in alphabetical or increasing numeric order. \n  \u2022 Create an index on the BY variables by using the DATASETS procedure (in Base SAS software)."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING","StatementOptionHelp":{"#cdata":"Specifies that the observations are sorted in descending order by the variable that \nimmediately follows the word DESCENDING in the BY statement."},"StatementOptionType":"S"},{"StatementOptionName":"NOTSORTED","StatementOptionHelp":{"#cdata":"Specifies that observations are not necessarily sorted in alphabetic or numeric order."},"StatementOptionType":"S"}]}},{"StatementName":"CLASS","StatementHelp":{"#cdata":"Syntax: CLASS variable <(REF= option)> \u2026<variable <(REF= option)>> </ global-options>; \n\nThe CLASS statement names the classification variables to be used in the model. Typical classification \nvariables are Treatment, Sex, Race, Group, and Replication. If you use the CLASS statement, it must \nappear before the MODEL statement. \n\nClassification variables can be either character or numeric. By default, class levels are determined \nfrom the entire set of formatted values of the CLASS variables."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"REF=","StatementOptionHelp":{"#cdata":"Syntax: REF='level' | FIRST | LAST \n\nSpecifies a level of the classification variable to be put at the end of the list of levels. This level \nthus corresponds to the reference level in the usual interpretation of the estimates with PROC GLIMMIX's \nsingular parameterization. \n\nYou can specify the following REF= option to indicate how the levels of an individual classification \nvariable are to be ordered by enclosing it in parentheses after the variable name: \n\n REF='level' | FIRST | LAST \n  specifies a level of the classification variable to be put at the end of the list of levels."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"'<level>'","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"The level of the variable to use as the reference level. Specify the formatted value of the variable  if a format is assigned. Replace <level> with an actual value.","@ToolTip2":"Designates the first ordered level as reference.","@ToolTip3":"Designates the last ordered level as reference."}},{"StatementOptionName":"TRUNCATE","StatementOptionHelp":{"#cdata":"Specifies that class levels be determined by using only up to the first 16 characters of the formatted \nvalues of CLASS variables. When formatted values are longer than 16 characters, you can use this option \nto revert to the levels as determined in releases prior to SAS 9."},"StatementOptionType":"S|V"}]}},{"StatementName":"CODE","StatementHelp":{"#cdata":"Syntax: CODE <option(s)> ; \n\nThe CODE statement writes SAS DATA step code for computing predicted values of the fitted model either \nto a file or to a catalog entry. This code can then be included in a DATA step to score new data."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CATALOG=|CAT=","StatementOptionHelp":{"#cdata":"Syntax: CATALOG=library.catalog.entry.type\n Syntax: CAT=library.catalog.entry.type \n  \nSpecifies where to write the generated code in the form of library.catalog.entry.type. The compound\nname can have from one to four levels. The default library is determined by the USER= SAS system\noption, which by default is WORK. The default entry is SASCODE, and the default type is SOURCE."},"StatementOptionType":"V"},{"StatementOptionName":"DUMMIES","StatementOptionHelp":{"#cdata":"Specifies to keep dummy variables that represent the CLASS levels in the data set. The default\nis NODUMMIES, which specifies that dummy variables not be retained."},"StatementOptionType":"S"},{"StatementOptionName":"NODUMMIES","StatementOptionHelp":{"#cdata":"Specifies that dummy variables not be retained."},"StatementOptionType":"S"},{"StatementOptionName":"ERROR","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"S"},{"StatementOptionName":"NOERROR","StatementOptionHelp":{"#cdata":"The default is NOERROR, which specifies that the error function not be generated."},"StatementOptionType":"S"},{"StatementOptionName":"FILE=","StatementOptionHelp":{"#cdata":"Syntax: FILE= filename \n          \nNames the external file that saves the generated code. When enclosed in a quoted string (for example,\nFILE=\"c:nmydirnscorecode.sas\"), this option specifies the path for writing the code to an external\nfile. You can also specify unquoted SAS filenames of no more than eight characters for filename. If\nthe filename is assigned as a fileref in a Base SAS FILENAME statement, the file specified in the\nFILENAME statement is opened. The special filerefs LOG and PRINT are always assigned. If the\nspecified filename is not an assigned fileref, the specified value for filename is concatenated with a .txt\nextension before the file is opened. For example, if FOO is not an assigned fileref, FILE=FOO causes\nFOO.txt to be opened. If filename has more than eight characters, an error message is printed."},"StatementOptionType":"V"},{"StatementOptionName":"FORMAT=","StatementOptionHelp":{"#cdata":"Syntax: FORMAT=format \n         \nSpecifies the format for the regression coefficients and other numerical values that do not have a format\nfrom the input data set. The default format is BEST20."},"StatementOptionType":"V"},{"StatementOptionName":"GROUP=","StatementOptionHelp":{"#cdata":"Syntax: GROUP=group-name \n         \nSpecifies the group identifier for group processing. The group-name should be a valid SAS name of no\nmore than 16 characters. It is used to construct array names and statement labels in the generated code."},"StatementOptionType":"V"},{"StatementOptionName":"IMPUTE","StatementOptionHelp":{"#cdata":"Imputes the predicted values according to an intercept-only model for observations with missing or\ninvalid covariate values. For a continuous response, the predicted value is the mean of the response\nvariable; for a categorical response, the predicted values are the proportions of the response categories.\nWhen the IMPUTE option is specified, the scoring code also creates a variable named _WARN_ that\ncontains one or more single-character codes that indicate problems in computing predicted values. The\ncharacter codes used in _WARN_ go in the following positions:\n\nCode Column Meaning\nM     1     Missing covariate value\nU     2     Unrecognized covariate category"},"StatementOptionType":"S"},{"StatementOptionName":"LINESIZE=|LS=","StatementOptionHelp":{"#cdata":"Syntax: LINESIZE=value |  LS=value \n         \nSpecifies the line size for the generated code. The default is 72. The permissible range is 64 to 254."},"StatementOptionType":"V"},{"StatementOptionName":"LOOKUP=","StatementOptionHelp":{"#cdata":"Syntax: LOOKUP=lookup-method \n          \nSpecifies the algorithm for looking up CLASS levels. The default is LOOKUP=AUTO."},"StatementOptionValues":{"@Value1":"AUTO","@Value2":"BINARY","@Value3":"LINEAR","@Value4":"SELECT"},"StatementOptionToolTips":{"@ToolTip1":"Selects the LINEAR algorithm if a CLASS variable has fewer than five categories; otherwise, the BINARY algorithm is used. This is the default.","@ToolTip2":"Uses a binary search. This method is fast, but might produce incorrect results and the normalized category values might contain characters that collate in different orders in ASCII and EBCDIC, if you generate the code on an ASCII machine and execute the code on an EBCDIC machine or vice versa.","@ToolTip3":"Uses a linear search with IF statements that have categories in the order of the class levels. This method is slow if there are many categories.","@ToolTip4":"Uses a SELECT statement."},"StatementOptionType":"V"},{"StatementOptionName":"RESIDUAL","StatementOptionHelp":{"#cdata":"Specifies to generate code to compute residual values. If you request code for residuals and\nthen score a data set that does not contain target values, the residuals will have missing values. The\ndefault is NORESIDUAL, which specifies that the code for residuals not be generated."},"StatementOptionType":"S"},{"StatementOptionName":"NORESIDUAL","StatementOptionHelp":{"#cdata":"The default is NORESIDUAL, which specifies that the code for residuals not be generated."},"StatementOptionType":"S"}]}},{"StatementName":"CONTRAST","StatementHelp":{"#cdata":"Syntax: CONTRAST 'label' contrast-specification <, contrast-specification> <, ...> < / options> ;\n\nThe CONTRAST statement provides a mechanism for obtaining custom hypothesis tests. \nIt is patterned after the CONTRAST statement in PROC MIXED and enables you to select \nan appropriate inference space (McLean, Sanders, and Stroup 1991). The GLIMMIX procedure \ngives you greater flexibility in entering contrast coefficients for random effects, \nhowever, because it permits the usual value-oriented positional syntax for entering \ncontrast coefficients, as well as a level-oriented syntax that simplifies entering \ncoefficients for interaction terms and is designed to work with constructed effects \nthat are defined through the experimental EFFECT statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"BYCATEGORY|BYCAT","StatementOptionHelp":{"#cdata":"Requests that in models for nominal data (generalized logit models) the contrasts not be combined across \nresponse categories but reported separately for each category."},"StatementOptionType":"S"},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed for all contrasts in addition to any F tests."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the denominator degrees of freedom for the F test."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the contrast be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"GROUP","StatementOptionHelp":{"#cdata":"[Syntax: GROUP coeffs] \n          \nSets up random-effect contrasts between different groups when a GROUP= variable \nappears in the RANDOM statement."},"StatementOptionType":"S"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking."},"StatementOptionType":"V"},{"StatementOptionName":"SUBJECT","StatementOptionHelp":{"#cdata":"[Syntax: SUBJECT coeffs] \n          \nSets up random-effect contrasts between different subjects when a SUBJECT= \nvariable appears in the RANDOM statement."},"StatementOptionType":"S"}]}},{"StatementName":"COVTEST","StatementHelp":{"#cdata":"Syntax: COVTEST <'label'> <test-specification> </ options> ; \n      \nThe COVTEST statement provides a mechanism to obtain statistical inferences for the \ncovariance parameters."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"GLM|INDEP","StatementOptionHelp":{"#cdata":"[test-specification keyword] \n          \nTests the model against a null model of complete independence."},"StatementOptionType":"RS"},{"StatementOptionName":"DIAGG","StatementOptionHelp":{"#cdata":"[test-specification keyword] \n          \nTests for a diagonal G matrix by constraining off-diagonal elements in G to zero. \nThe R-side structure is not modified."},"StatementOptionType":"RS"},{"StatementOptionName":"DIAGR|CINDEP","StatementOptionHelp":{"#cdata":"[test-specification keyword] \n          \nTests for conditional independence by reducing the R-side covariance structure \nto diagonal form. The G-side structure is not modified."},"StatementOptionType":"RS"},{"StatementOptionName":"HOMOGENEITY","StatementOptionHelp":{"#cdata":"[test-specification keyword] \n          \nTests homogeneity of covariance parameters across groups by imposing equality \nconstraints."},"StatementOptionType":"RS"},{"StatementOptionName":"START|INITIAL","StatementOptionHelp":{"#cdata":"[test-specification keyword] \n          \nCompares the final estimates to the starting values of the covariance parameter \nestimates."},"StatementOptionType":"RS"},{"StatementOptionName":"ZEROG","StatementOptionHelp":{"#cdata":"[test-specification keyword] \n          \nTests whether the G matrix can be reduced to a zero matrix. This eliminates all \nG-side random effects from the model."},"StatementOptionType":"RS"},{"StatementOptionName":"TESTDATA=|TDATA=","StatementOptionHelp":{"#cdata":"[test-specification keyword] \n          \nReads in covariance parameter values from a SAS data set."},"StatementOptionType":"RV"},{"StatementOptionName":"GENERAL|CONTRAST","StatementOptionHelp":{"#cdata":"[test-specification][Syntax: GENERAL coefficients <,coefficients> <,...> ]\n            \nProvides a general facility to test linear combinations of covariance parameters."},"StatementOptionType":"RV"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"[Syntax: CL<(suboptions)>]\n          \nRequests confidence limits or bounds for the covariance parameter estimates. These limits are displayed \nas extra columns in the \"Covariance Parameter Estimates\" table.\n\nThe following suboptions determine the computation of confidence bounds and intervals.\n\nALPHA=number \n  determines the confidence level for constructing confidence   limits for the covariance parameters.\nLOWERBOUND | LOWER  \n  requests lower confidence bounds. \nTYPE=method \n  determines how the GLIMMIX procedure constructs confidence limits   for covariance parameters.\nUPPERBOUND | UPPER  \n  requests upper confidence bounds. \n\nIf you do not specify any suboptions, the default is to compute two-sided Wald confidence intervals with \nconfidence level 1 - alpha = 0.95."},"StatementOptionType":"V","SubOptionsKeywords":"ALPHA=|LOWERBOUND|LOWER|TYPE=|UPPERBOUND|UPPER"},{"StatementOptionName":"CLASSICAL","StatementOptionHelp":{"#cdata":"Requests that the p-value of the likelihood ratio test be computed by the classical method."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=value-list] \n          \nEnables you to supply degrees of freedom for the computation of p-values from \nchi-square mixtures."},"StatementOptionType":"V"},{"StatementOptionName":"ESTIMATES|EST","StatementOptionHelp":{"#cdata":"Displays the estimates of the covariance parameters under the null hypothesis."},"StatementOptionType":"S"},{"StatementOptionName":"MAXITER=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER=number] \n          \nLimits the number of iterations when you are refitting the model under the \nnull hypothesis to number iterations."},"StatementOptionType":"V"},{"StatementOptionName":"PARMS","StatementOptionHelp":{"#cdata":"Displays the values of the covariance parameters under the null hypothesis."},"StatementOptionType":"S"},{"StatementOptionName":"RESTART","StatementOptionHelp":{"#cdata":"Specifies that starting values for the covariance parameters for the null model are obtained by the \nsame mechanism as starting values for the full models."},"StatementOptionType":"S"},{"StatementOptionName":"TOLERANCE=","StatementOptionHelp":{"#cdata":"[Syntax: TOLERANCE=r] \n          \nValues within tolerance r >=0 of the boundary of the parameter space are considered \non the boundary when PROC GLIMMIX examines estimates of nuisance parameters under \nHo and determines whether mixture weights and degrees of freedom can be obtained."},"StatementOptionType":"V"},{"StatementOptionName":"WALD","StatementOptionHelp":{"#cdata":"Produces Wald Z tests for the covariance parameters based on the estimates\nand asymptotic standard errors in the \"Covariance Parameter Estimates\" table."},"StatementOptionType":"S"},{"StatementOptionName":"WGHT=","StatementOptionHelp":{"#cdata":"[Syntax: WGHT=value-list] \n          \nEnables you to supply weights for the computation of p-values from \nchi-square mixtures."},"StatementOptionType":"V"}],"#comment":{}}},{"StatementName":"EFFECT","StatementHelp":{"#cdata":"Syntax: EFFECT effect-name = effect-type (var-list < / effect-options >) ; \n\nThe name of the effect is specified after the EFFECT keyword. This name can appear \nin only one EFFECT statement and cannot be the name of a variable in the input data \nset. The effect-type is specified after an equal sign, followed by a list of variables \nwithin parentheses which are used in constructing the effect. Effect-options that are \nspecific to an effect-type can be specified after a slash (/) following the variable list. \n\nThe EFFECT statement enables you to construct special collections of columns for design \nmatrices. These collections are referred to as constructed effects to distinguish them \nfrom the usual model effects formed from continuous or classification variables."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"EFFECT-NAME=","StatementOptionHelp":{"#cdata":"Replace 'EFFECT-NAME' with the name of the effect, specified after the EFFECT keyword. \nThis name can appear in only one EFFECT statement and cannot be the name of a \nvariable in the input data set."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"COLLECTION","@Value2":"LAG","@Value3":"MULTIMEMBER|MM","@Value4":"POLYNOMIAL|POLY","@Value5":"SPLINE"},"StatementOptionToolTips":{"@ToolTip1":"Is a collection effect that defines one or more variables as a single effect with  multiple degrees of freedom. The variables in a collection are considered as a  unit for estimation and inference.  Option(s) available (specified after a slash (/) following the variable list):   DETAILS  Displays the constituents of the collection effect","@ToolTip2":"Is a classification effect in which the level that is used for a given period  corresponds to the level in the preceding period.   Options available (specified after a slash (/) following the variable list):    DESIGNROLE=    Names a variable that controls to which lag design an observation is assigned     DETAILS    Displays the lag design of the lag effect     NLAG=    Specifies the number of periods in the lag     PERIOD=    Names the variable that defines the period     WITHIN=    Names the variable or variables that define the group within which each period is defined","@ToolTip3":"Is a multimember classification effect whose levels are determined by one or  more variables that appear in a CLASS statement.   Options available (specified after a slash (/) following the variable list):     NOEFFECT    Specifies that observations with all missing levels for the multimember variables should    have zero values in the corresponding design matrix columns     WEIGHT=    Specifies the weight variable for the contributions of each of the classification effects","@ToolTip4":"Is a multivariate polynomial effect in the specified numeric variables.                                      Options available (specified after a slash (/) following the variable list):     DEGREE=    Specifies the degree of the polynomial     MDEGREE=    Specifies the maximum degree of any variable in a term of the polynomial     STANDARDIZE=    Specifies centering and scaling suboptions for the variables that define the polynomial","@ToolTip5":"Is a regression spline effect whose columns are univariate spline expansions of  one or more variables. A spline expansion replaces the original variable with  an expanded or larger set of new variables.   Options available (specified after a slash (/) following the variable list):     BASIS=    Specifies the type of basis (B-spline basis or truncated power function basis) for the spline expansion     DEGREE=    Specifies the degree of the spline transformation     KNOTMETHOD=    Specifies how to construct the knots for spline effects"},"SubOptionsKeywords":"DETAILS|DESIGNROLE=|NLAG=|WITHIN=|NOEFFECT|WEIGHT=|DEGREE=|MDEGREE=|STANDARDIZE=|BASIS=|KNOTMETHOD="},{"StatementOptionName":"PERIOD=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only]\n          \n[Syntax: PERIOD=variable] \n          \nSpecifies the period variable of the LAG design. The number of periods is the number \nof unique formatted values of the PERIOD= variable, and the ordering of the period is \nformed by sorting these formatted values in ascending order. You must specify a PERIOD= \nvariable."},"StatementOptionType":"V"},{"StatementOptionName":"WITHIN=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: WITHIN=(variables) | WITHIN=variable] \n\nSpecifies a variable (or a list of variables within parentheses) that defines the \nsubject grouping of the lag design. If there is only one WITHIN= variable, then the \nparentheses are not required. Each subject is defined by the unique set of formatted \nvalues of the variables in the WITHIN= list. The subjects are sorted in ascending \nlexicographic order. You must specify a WITHIN= variable."},"StatementOptionType":"V"},{"StatementOptionName":"DESIGNROLE=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: DESIGNROLE=variable] \n\nSpecifies a numeric variable that is used to subset observations into a fitting group \nin which the value of the DESIGNROW= variable is nonzero and a second group in which \nthe value of the specified variable is zero. The observations in the fitting group are \nused to form the LAG design matrix that is used in fitting the model. The LAG design \nthat corresponds to the non-fitting group is used when scoring observations in the \ninput data set that do not belong to the fitting group. This option is useful when \nyou want to obtain predicted values in an output data set for observations that are \nnot used in fitting the model. If you do not specify a DESIGNROLE= variable, then all \nobservations are assigned to the fitting group."},"StatementOptionType":"V"},{"StatementOptionName":"DETAILS","StatementOptionHelp":{"#cdata":"[For the LAG | COLLECTION | MULTIMEMBER | POLYNOMIAL |SPLINE effect-type] \n          \nRequests a table that shows the (1) lag design matrix of the lag effect, or (2) constituents \nof the collection effect, or (3) levels of the multimember effect, or (4) details of the specified \npolynomial, or (5) knot locations and the knots associated with each spline basis function."},"StatementOptionType":"S"},{"StatementOptionName":"NLAG=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: NLAG= n] \n\nSpecifies the number of lags. By default NLAG=1."},"StatementOptionType":"V"},{"StatementOptionName":"NOEFFECT","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \nSpecifies that, for observations with all missing levels of the multimember variables, \nthe values in the corresponding design matrix columns be set to zero."},"StatementOptionType":"S"},{"StatementOptionName":"STDIZE","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \nSpecifies that for each observation, the entries in the design matrix that corresponds \nto the multimember effect be scaled to have a sum of one."},"StatementOptionType":"S"},{"StatementOptionName":"WEIGHT=","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \n[Syntax: WEIGHT=wght-list] \n\nSpecifies numeric variables used to weigh the contributions of each of the classification \neffects that define the constructed multimember effect. The number of variables in wght-list \nmust match the number of classification variables that define the effect."},"StatementOptionType":"V"},{"StatementOptionName":"DEGREE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL and SPLINE effect-type only] \n          \n[Syntax: DEGREE=n] \n\nSpecifies the (1) degree of the polynomial, or (2) degree of the spline transformation. \nThe degree must be a positive integer. The n degree is typically a small integer, such as \n1, 2, or 3. The default for polynomial effect is DEGREE=1, and DEGREE=3 for spline \ntransformation."},"StatementOptionType":"V"},{"StatementOptionName":"LABELSTYLE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: LABELSTYLE=(style-opts) | LABELSTYLE=style-opt] \n\nSpecifies how the terms in the polynomial are labeled. By default, powers are shown \nwith ^ as the exponentiation operator and * as the multiplication operator."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EXPAND","@Value2":"EXPONENT","@Value3":"INCLUDENAME","@Value4":"PRODUCTSYMBOL="},"StatementOptionToolTips":{"@ToolTip1":"Specifies that each variable with an exponent greater than 1 be written as products of that variable.","@ToolTip2":"Syntax: EXPONENT <=quoted string>                                      Specifies that each variable with an exponent greater than 1 be written using exponential  notation. By default, the symbol ^ is used as the exponentiation operator. If you supply the  optional quoted string after an equal sign, then that string is used as the exponentiation  operator.","@ToolTip3":"Specifies that the name of the effect followed by an underscore be used as a prefix  for term labels.","@ToolTip4":"Syntax: PRODUCTSYMBOL=NONE | quoted string                                      Specifies that the supplied string be used as the product symbol."}},{"StatementOptionName":"MDEGREE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: MDEGREE=n] \n\nSpecifies the maximum degree of any variable in a term of the polynomial. This degree \nmust be a positive integer. The default is the degree of the specified polynomial."},"StatementOptionType":"V"},{"StatementOptionName":"NOSEPARATE","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \nSpecifies that the polynomial be treated as a single effect with multiple degrees \nof freedom. The effect name that you specify is used as the constructed effect name, \nand the labels of the terms are used as labels of the corresponding parameters."},"StatementOptionType":"S"},{"StatementOptionName":"STANDARDIZE","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: STANDARDIZE <(centerscale-opts)> <= standardize-opt>] \n\nSpecifies that the variables that define the polynomial be standardized. By default, \nthe standardized variables receive prefix \"s_\" in the variable names. \n\nYou can use the following centerscale-opts to specify how the center and scale are estimated: \n\n  METHOD=MOMENTS \n  specifies that the center be estimated by the variable mean and the scale be estimated by the standard deviation. \n\n  METHOD=RANGE \n  specifies that the center be estimated by the midpoint of the variable range and the scale be estimated as half the variable range.\n\n  METHOD=WMOMENTS \n  is the same as METHOD=MOMENTS except that weighted means and weighted standard deviations are used. \n\n  PREFIX=NONE | quoted-string \n  specifies the prefix that is appended to standardized variables when forming the term labels."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"CENTER","@Value2":"CENTERSCALE","@Value3":"NONE","@Value4":"SCALE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that variables be centered but not scaled.","@ToolTip2":"Specifies that variables be centered and scaled. This is the default if you do not  specify a standardization-opt.","@ToolTip3":"Specifies that no standardization be performed.","@ToolTip4":"Specifies that variables be scaled but not centered."}},{"StatementOptionName":"BASIS=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies a basis for the spline expansion."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BSPLINE","@Value2":"TPF"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a B-spline basis for the spline expansion.","@ToolTip2":"Syntax: TPF(options)                                      Specifies a truncated power function basis for the spline expansion.   You can modify the number of columns when you request BASIS=TPF with the following options:     NOINT    excludes the intercept column.     NOPOWERS    excludes the intercept and polynomial columns."}},{"StatementOptionName":"DATABOUNDARY","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only]\n          \nSpecifies that the extremes of the data be used as boundary knots when building a B-spline basis."},"StatementOptionType":"S"},{"StatementOptionName":"KNOTMAX=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only]\n          \n[Syntax: KNOTMAX=value] \n\nSpecifies that, for each variable in the EFFECT statement, the right-side boundary \nknots be equally spaced starting at the maximum of the variable and ending at the \nspecified value. This option is ignored for variables whose maximum value is greater \nthan the specified value or if the DATABOUNDARY option is also specified."},"StatementOptionType":"V"},{"StatementOptionName":"KNOTMETHOD=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies how to construct the knots for spline effects."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EQUAL","@Value2":"LIST","@Value3":"LISTWITHBOUNDARY","@Value4":"MULTISCALE","@Value5":"PERCENTILES","@Value6":"RANGEFRACTIONS"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: EQUAL<(n)>               Specifies that n equally spaced knots be positioned between the extremes of the data.  The default is n=3. For a B-spline basis, any needed boundary knots continue to be  equally spaced unless the DATABOUNDARY option has also been specified. KNOTMETHOD=EQUAL  is the default if no knot-method is specified.","@ToolTip2":"Syntax: LIST(number-list)                                      Specifies the list of internal knots to be used in forming the spline basis columns.  For a B-spline basis, the data extremes are used as boundary knots.","@ToolTip3":"Syntax: LISTWITHBOUNDARY(number-list)                                      Specifies the list of all knots that are used in forming the spline basis columns.","@ToolTip4":"Syntax: MULTISCALE<(multiscale-options)>                                      Specifies that multiple B-spline bases be generated, corresponding to sets with an  increasing number of internal knots.   You can control which scales are included with the following multiscale-options:     STARTSCALE=n    specifies the start scale, where n is a positive integer. The default is STARTSCALE=0.     ENDSCALE=n    specifies the end scale, where n is a positive integer. The default is ENDSCALE=7.","@ToolTip5":"Syntax: PERCENTILES(n)                                      Requests that internal knots be placed at n equally spaced percentiles of the variable  or variables named in the EFFECT statement.","@ToolTip6":"Syntax: RANGEFRACTIONS(fraction-list)                                      Requests that internal knots be placed at each fraction of the ranges of the variables  in the EFFECT statement."}},{"StatementOptionName":"KNOTMIN=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \n[Syntax: KNOTMIN=value] \n\nSpecifies that for each variable in the EFFECT statement, the left-side boundary knots be \nequally spaced starting at the specified value and ending at the minimum of the variable. \nThis option is ignored for variables whose minimum value is less than the specified value \nor if the DATABOUNDARY option is also specified."},"StatementOptionType":"V"},{"StatementOptionName":"SEPARATE","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies that when multiple variables are specified in the EFFECT statement, \nthe spline basis for each variable be treated as a separate effect. The names \nof these separated effects are formed by appending an underscore followed by \nthe name of the variable to the name that you specify in the EFFECT statement."},"StatementOptionType":"S"},{"StatementOptionName":"SPLIT","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies that each individual column in the design matrix that corresponds to the spline \neffect be treated as a separate effect that can enter or leave the model independently. \nNames for these split effects are generated by appending the variable name and an index \nfor each column to the name that you specify in the EFFECT statement."},"StatementOptionType":"S"}]}},{"StatementName":"ESTIMATE","StatementHelp":{"#cdata":"Syntax: ESTIMATE 'label' contrast-specification <(divisor=n)>\n    <, 'label' contrast-specification <(divisor=n)> > <, ...>  < / options> ; \n\nThe ESTIMATE statement provides a mechanism for obtaining custom hypothesis tests."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence limits are adjusted\nfor multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the final effect listed in the ESTIMATE statement from the 'Type III Tests of Fixed Effects' table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the estimates."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE<(simoptions)>","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."}},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed with confidence level 1-number. \nThe value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"BYCATEGORY|BYCAT","StatementOptionHelp":{"#cdata":"Requests that in models for nominal data (generalized logit models) estimates be reported separately \nfor each category."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the estimate."},"StatementOptionType":"S"},{"StatementOptionName":"GROUP","StatementOptionHelp":{"#cdata":"[Syntax: GROUP coeffs] \n          \nSets up random-effect contrasts between different groups when a GROUP= variable \nappears in the RANDOM statement."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the mean \n(the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test statistic."},"StatementOptionType":"S"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the CONTRAST statement."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further \nadjusted in a step-down fashion.\n\nYou can specify the following step-down-options in parentheses after the STEPDOWN option.\n\nMAXTIME=n \n  specifies the time (in seconds) to spend computing the maximal logically consistent sequential subsets \n  of equality hypotheses for TYPE=LOGICAL.\nORDER=PVALUE | ROWS \n  specifies the order in which the step-down tests are performed. ORDER=PVALUE is the default, with estimates \n  being declared significant only if all estimates with smaller (unadjusted) p-values are significant. If you \n  specify ORDER=ROWS, then significances are evaluated in the order in which they are specified in the syntax.\nREPORT \n  specifies that a report on the step-down adjustment be displayed, including a listing of the sequential \n  subsets (Westfall 1997) and, for ADJUST= SIMULATE, the step-down simulation results. \nTYPE=LOGICAL<(n)> | FREE \n  If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically consistent \n  sequential subsets of equality hypotheses (Shaffer 1986; Westfall 1997). Alternatively, for TYPE=FREE, \n  sequential subsets are computed ignoring logical constraints. The TYPE=FREE results are more conservative \n  than those for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. For example, \n  it is not feasible to take logical constraints between all pairwise comparisons of more than about 10 groups. \n  For this reason, TYPE=FREE is the default."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|ORDER=|REPORT|TYPE="},{"StatementOptionName":"SUBJECT","StatementOptionHelp":{"#cdata":"[Syntax: SUBJECT coeffs] \n          \nSets up random-effect contrasts between different subjects when a SUBJECT= variable \nappears in the RANDOM statement."},"StatementOptionType":"S"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the \ntest statistic."},"StatementOptionType":"S"}]}},{"StatementName":"FREQ","StatementHelp":{"#cdata":"Syntax: FREQ variable;\n      \nThe variable in the FREQ statement identifies a numeric variable in the data set or \none computed through PROC GLIMMIX programming statements that contains the frequency \nof occurrence for each observation. PROC GLIMMIX treats each observation as if it \nappears f times, where f is the value of the FREQ variable for the observation. If \nit is not an integer, the frequency value is truncated to an integer. If the frequency \nvalue is less than 1 or missing, the observation is not used in the analysis. When the \nFREQ statement is not specified, each observation is assigned a frequency of 1."},"StatementOptions":null},{"StatementName":"ID","StatementHelp":{"#cdata":"Syntax: ID variables ; \n    \nThe ID statement specifies which quantities to include in the OUT= data set from the \nOUTPUT statement in addition to any statistics requested in the OUTPUT statement."},"StatementOptions":null},{"StatementName":"LSMEANS","StatementHelp":{"#cdata":"Syntax: LSMEANS fixed-effects </ options> ; \n     \nThe LSMEANS statement computes least squares means (LS-means) of fixed effects. As \nin the GLM and the MIXED procedures, LS-means are predicted population margins\u2014that \nis, they estimate the marginal means over a balanced population. In a sense, LS-means \nare to unbalanced designs as class and subclass arithmetic means are to balanced \ndesigns."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence limits are adjusted\nfor multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.       CVADJUST      specifies that the quantile should be estimated by the control variate adjustment method of     Hsu and Nelson (1998) instead of simply as the quantile of the simulated sample.      EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile.       NSAMP=n      specifies the sample size for the simulation.       REPORT      specifies that a report on the simulation should be displayed, including a listing of the parameters,     such as \u03b3, \u03b5, and \u03b1, as well as an analysis of various methods for estimating or approximating      the quantile.       SEED=number      specifies an integer used to start the pseudo-random number generator for the simulation.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956) and  identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|CVADJUST|EPS=|NSAMP=|REPORT|SEED="},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default value is 0.05, corresponding to a 95% confidence interval."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nEnables you to modify the values of the covariates used in computing LS-means."},"StatementOptionType":"S","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The confidence level \nis 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences, and it is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the upper confidence  limits for the control minus the noncontrol levels are considered to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the upper confidence  limits for the noncontrol levels minus the control are considered to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for all LSMEANS effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" table also be reported \non the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing the means in descending \norder and indicating nonsignificant subsets by line segments beside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"ODDS","StatementOptionHelp":{"#cdata":"Requests that in models with logit, cumulative logit, and generalized logit link function the odds of the \nlevels of the fixed effects are reported."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) and simple effect comparisons (SLICEDIFF option) \nare also reported in terms of odds ratios."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS|OM","StatementOptionHelp":{"#cdata":"Specifies a potentially different weighting scheme for the computation of LS-means coefficients."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided that the \nODS GRAPHICS statement has been specified and the plot request does not conflict with other options \nin the LSMEANS statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"CONTROLPLOT|CONTROL","@Value4":"DIFFPLOT|DIFFOGRAM|DIFF","@Value5":"MEANPLOT","@Value6":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip4":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES      suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip5":"Requests displays of the least squares means.   Syntax: MEANPLOT<(meanplot-options)>  The following meanplot-options control the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip6":"Requests that no plots be produced."},"SubOptionsKeywords":"ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|CONNECT|SLICEBY=|PLOTBY="},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the CONTRAST statement."},"StatementOptionType":"V"},{"StatementOptionName":"SLICE=","StatementOptionHelp":{"#cdata":"[Syntax: SLICE=fixed-effect | (fixed-effects)] \n          \nSpecifies effects by which to partition interaction LSMEANS effects."},"StatementOptionType":"V"},{"StatementOptionName":"SLICEDIFF=|SIMPLEDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: SLICEDIFF=fixed-effect | SLICEDIFF=(fixed-effects)] \n          \nRequests that differences of simple effects be constructed and tested against zero."},"StatementOptionType":"V"},{"StatementOptionName":"SLICEDIFFTYPE=|SIMPLEDIFFTYPE=","StatementOptionHelp":{"#cdata":"[Syntax: SLICEDIFFTYPE<=difftype>] \n          \nDetermines the type of simple effect differences produced with the SLICEDIFF= option."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"CONTROL","@Value3":"CONTROLL","@Value4":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all simple effects differences, and it is the default.","@ToolTip2":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip3":"Tests whether the noncontrol levels are significantly smaller than the control; the upper confidence  limits for the control minus the noncontrol levels are considered to be infinity and are displayed as missing.","@ToolTip4":"Tests whether the noncontrol levels are significantly larger than the control; the upper confidence  limits for the noncontrol levels minus the control are considered to be infinity and are displayed as missing."}},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> | TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="}]}},{"StatementName":"LSMESTIMATE","StatementHelp":{"#cdata":"Syntax: LSMESTIMATE fixed-effect <'label'> values <divisor=> \n    <, <'label'> values <divisor=>> <, .\n    ..> < / options> ; \n\nThe LSMESTIMATE statement provides a mechanism for obtaining custom hypothesis tests among the \nleast squares means."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the estimates."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.       CVADJUST      specifies that the quantile should be estimated by the control variate adjustment method of     Hsu and Nelson (1998) instead of simply as the quantile of the simulated sample.      EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile.       NSAMP=n      specifies the sample size for the simulation.       REPORT      specifies that a report on the simulation should be displayed, including a listing of the parameters,     such as \u03b3, \u03b5, and \u03b1, as well as an analysis of various methods for estimating or approximating      the quantile.       SEED=number      specifies an integer used to start the pseudo-random number generator for the simulation.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."}},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed with confidence level 1-number. \nThe value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nEnables you to modify the values of the covariates used in computing LS-means."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that PROC GLIMMIX compute separate margins for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the FTEST option."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the linear combination of the least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the linear combination of the least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ELSM","StatementOptionHelp":{"#cdata":"Requests that the K matrix coefficients be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the estimate."},"StatementOptionType":"S"},{"StatementOptionName":"FTEST|JOINT","StatementOptionHelp":{"#cdata":"[Syntax: FTEST<(joint-test-options)> | JOINT<(joint-test-options)>  \n          \nProduces an F test that jointly tests the rows of the LSMESTIMATE against zero.\n\nYou can specify the following joint-test-options in parentheses: \n\n ACC=gamma \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based approach of Silvapulle \n  and Sen (2004) for tests with order restrictions.\n BOUNDS=value-list \n  specifies boundary values for the estimable linear function. \n EPS=epsilon\n  specifies the accuracy confidence level for determining the necessary sample size in the simulation-based approach \n  of Silvapulle and Sen (2004) for F tests with order restrictions.\n LABEL='label' \n  enables you to assign a label to the joint test that identifies the results in the \"LSMFtest\" table.\n NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004)."},"StatementOptionType":"S","SubOptionsKeywords":"ACC=|BOUNDS=|EPS=|LABEL=|NSAMP="},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the \nmean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test statistic."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS|OM","StatementOptionHelp":{"#cdata":"Specifies a potentially different weighting scheme for the computation of LS-means coefficients."},"StatementOptionType":"S"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the CONTRAST statement."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. You can specify the following step-down-options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential subsets \n    of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60.\n\n    ORDER=PVALUE | ORDER=ROWS \n    specifies the order in which the step-down tests are performed. ORDER=PVALUE is the default, with LS-mean\n    estimates being declared significant only if all LS-mean estimates with smaller (unadjusted) p-values are\n    significant. If you specify ORDER=ROWS, then significances are evaluated in the order in which they are specified. \n\n    REPORT \n    specifies that a report on the step-down adjustment be displayed, including a listing of the sequential \n    subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n    TYPE=LOGICAL<(n)> | TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically consistent \n    sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, \n    sequential subsets are computed ignoring logical constraints. The TYPE=FREE results are more conservative \n    than those for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. Default: TYPE=FREE."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|ORDER=|REPORT|TYPE="},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test statistic."},"StatementOptionType":"S"}]}},{"StatementName":"MODEL","StatementHelp":{"#cdata":"Syntax: MODEL response <(response variable options)> = <fixed-effects> </ model-options> ;          \nSyntax:  MODEL events/trials = <fixed-effects> < / model-options> ; \n\nThe MODEL statement is required and names the dependent variable and the fixed effects. \nThe fixed-effects determine the X matrix of the model. The specification of effects is \nthe same as in the GLM or MIXED procedure. In contrast to PROC GLM, you do not specify \nrandom effects in the MODEL statement. However, in contrast to PROC GLM and PROC MIXED, \ncontinuous variables on the left and right side of the MODEL statement can be computed \nthrough PROC GLIMMIX programming statements. \n\nResponse Variable Options:\n \n    DESCENDING reverses the order of response categories \n \n    EVENT='category'|FIRST|LAST\n      specifies the event category in binary models \n \n    ORDER=DATA|FORMATTED|FREQ|INTERNAL\n      specifies the sort order for the response variable \n \n    REFERENCE= specifies the reference category in generalized logit models"},"StatementOptions":{"#comment":[{},{}],"StatementOption":[{"StatementOptionName":"DESCENDING","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"S"},{"StatementOptionName":"EVENT=","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"V"},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"V"},{"StatementOptionName":"REFERENCE=","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"V"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the fixed-effects \nparameters with confidence level 1-number. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed for all specified effects in addition to the F tests."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the fixed-effects parameter estimates.\nThe confidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORRB","StatementOptionHelp":{"#cdata":"Produces the correlation matrix from the approximate covariance matrix of the fixed-effects \nparameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"COVB","StatementOptionHelp":{"#cdata":"[Syntax: COVB | COVB(DETAILS)] \n          \nProduces the approximate variance-covariance matrix of the fixed-effects parameter estimates.\nThe DETAILS suboption of the COVB option enables you to obtain a table of statistics about the \ncovariance matrix of the fixed effects."},"StatementOptionType":"S"},{"StatementOptionName":"COVB(DETAILS)","StatementOptionHelp":{"#cdata":"Produces the approximate variance-covariance matrix of the fixed-effects parameter estimates. \nThe DETAILS suboption of the COVB option enables you to obtain a table of statistics about the \ncovariance matrix of the fixed effects."},"StatementOptionType":"S","SubOptionsKeywords":"DETAILS"},{"StatementOptionName":"COVBI","StatementOptionHelp":{"#cdata":"Produces the inverse of the approximate covariance matrix of the fixed-effects parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"DDF=|DF=","StatementOptionHelp":{"#cdata":"[Syntax: DDF=value-list | DF=value-list] \n          \nEnables you to specify your own denominator degrees of freedom for the fixed effects."},"StatementOptionType":"V"},{"StatementOptionName":"DDFM=","StatementOptionHelp":{"#cdata":"Specifies the method for computing the denominator degrees of freedom for the tests of fixed \neffects resulting from the MODEL, CONTRAST, ESTIMATE, LSMEANS, and LSMESTIMATE statements."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BETWITHIN","@Value2":"CONTAIN","@Value3":"KENWARDROGER|KENROGER|KR","@Value4":"KENWARDROGER2","@Value5":"NONE","@Value6":"RESIDUAL","@Value7":"SATTERTHWAITE"},"StatementOptionToolTips":{"@ToolTip1":"Divides the residual degrees of freedom into between-subject and within-subject portions.","@ToolTip2":"Invokes the containment method to compute denominator degrees of freedom, and this method is the  default when the model contains G-side random effects.","@ToolTip3":"[Syntax: KENWARDROGER<(FIRSTORDER)>]                                      Applies the (prediction) standard error and degrees-of-freedom correction detailed  by Kenward and Roger (1997). The FIRSTORDER suboption eliminates the second derivatives  from the calculation of the covariance matrix adjustment.","@ToolTip4":"[Syntax: KENWARDROGER2|KENROGER2|KR2]                                      Applies the (prediction) standard error and degrees-of-freedom correction that are detailed  by Kenward and Roger (2009). This correction further reduces the precision estimator bias for  the fixed and random effects under nonlinear covariance structures.","@ToolTip5":"Specifies that no denominator degrees of freedom be applied.","@ToolTip6":"Performs all tests by using the residual degrees of freedom, n-rank(X), where n is the sum  of the frequencies used.","@ToolTip7":"Performs a general Satterthwaite approximation for the denominator degrees of freedom in a  generalized linear mixed model."}},{"StatementOptionName":"DISTRIBUTION=|DIST=|D=|ERROR=|E=","StatementOptionHelp":{"#cdata":"Specifies the built-in (conditional) probability distribution of the data."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BETA","@Value2":"BINARY","@Value3":"BINOMIAL","@Value4":"EXPONENTIAL","@Value5":"GAMMA","@Value6":"GAUSSIAN","@Value7":"GEOMETRIC","@Value8":"INVGAUSS","@Value9":"LOGNORMAL","@Value10":"MULTINOMIAL","@Value11":"NEGBINOMIAL","@Value12":"POISSON","@Value13":"TCENTRAL","@Value14":"BYOBS"},"StatementOptionToolTips":{"@ToolTip1":"Beta distribution","@ToolTip2":"Binary distribution","@ToolTip3":"Binomial distribution","@ToolTip4":"Exponential distribution","@ToolTip5":"Gamma distribution","@ToolTip6":"Gaussian/Normal distribution","@ToolTip7":"Geometric distribution","@ToolTip8":"Inverse Gaussian distribution","@ToolTip9":"Lognormal distribution","@ToolTip10":"Multinomial distribution","@ToolTip11":"Negative binomial distribution","@ToolTip12":"Poisson distribution","@ToolTip13":"t distribution","@ToolTip14":"Multivariate                                     Syntax: BYOBS(variable)  The BYOBS(variable) syntax designates a variable whose value identifies the distribution to which an observation belongs."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that Type I, Type II, and Type III L matrix coefficients be displayed for all specified effects."},"StatementOptionType":"S"},{"StatementOptionName":"E1|EI","StatementOptionHelp":{"#cdata":"Requests that Type I L matrix coefficients be displayed for all specified effects."},"StatementOptionType":"S"},{"StatementOptionName":"E2|EII","StatementOptionHelp":{"#cdata":"Requests that Type II L matrix coefficients be displayed for all specified effects."},"StatementOptionType":"S"},{"StatementOptionName":"E3|EIII","StatementOptionHelp":{"#cdata":"Requests that Type III L matrix coefficients be displayed for all specified effects."},"StatementOptionType":"S"},{"StatementOptionName":"INTERCEPT","StatementOptionHelp":{"#cdata":"Adds a row to the tables for Type I, II, and III tests corresponding to the overall intercept."},"StatementOptionType":"S"},{"StatementOptionName":"HTYPE=","StatementOptionHelp":{"#cdata":"[Syntax: HTYPE=value-list] \n          \nIndicates the type of hypothesis test to perform on the fixed effects."},"StatementOptionType":"V"},{"StatementOptionName":"LINK=","StatementOptionHelp":{"#cdata":"Specifies the link function in the generalized linear mixed model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CUMCLL","@Value2":"CUMLOGIT","@Value3":"CUMLOGLOG","@Value4":"CUMPROBIT","@Value5":"CLOGLOG","@Value6":"GLOGIT","@Value7":"IDENTITY","@Value8":"LOG","@Value9":"LOGIT","@Value10":"LOGLOG","@Value11":"PROBIT","@Value12":"POWER(number)","@Value13":"POWERMINUS2","@Value14":"RECIPROCAL"},"StatementOptionToolTips":{"@ToolTip1":"Cumulative complementary log-log function","@ToolTip2":"Cumulative logit function","@ToolTip3":"Cumulative log-log function","@ToolTip4":"Cumulative probit function","@ToolTip5":"Complementary log-log function","@ToolTip6":"Generalized logit","@ToolTip7":"Identity function","@ToolTip8":"Log function","@ToolTip9":"Logit function","@ToolTip10":"Log-log function","@ToolTip11":"Probit function","@ToolTip12":"Power with \u03bb=number function","@ToolTip13":"Power with exponent -2","@ToolTip14":"Reciprocal"},"#text":"\"\n        "},{"StatementOptionName":"LWEIGHT=","StatementOptionHelp":{"#cdata":"Determines how weights are used in constructing the coefficients for Type I through Type III L matrices."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"FIRSTORDER|FIRO","@Value2":"NONE","@Value3":"VAR"},"StatementOptionToolTips":{"@ToolTip1":"The weights incorporate the WEIGHT variable as well as the first-order weights of the linearized model.","@ToolTip2":"The L matrix coefficients are based on the raw crossproduct matrix, whether a WEIGHT variable is specified or not.","@ToolTip3":"Values of the WEIGHT variable are used in forming crossproduct matrices. This is the default."}},{"StatementOptionName":"NOCENTER","StatementOptionHelp":{"#cdata":"Requests that the columns of the X matrix are not centered and scaled."},"StatementOptionType":"S"},{"StatementOptionName":"NOINT","StatementOptionHelp":{"#cdata":"Requests that no intercept be included in the fixed-effects model. An intercept is included by default."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests estimates of odds ratios and their confidence limits, provided the link function is the \nlogit, cumulative logit, or generalized logit.\n\nSyntax: ODDSRATIO<(odds-ratio-options)>\n\nYou can specify the following odds-ratio-options to create customized odds ratio results. \n\n    AT var-list=value-list \n    specifies the reference values for continuous variables in the model.\n\n    DIFF<=difftype> \n    controls the type of differences for classification main effects.\n\n    LABEL \n    displays a label in the \"Odds Ratio Estimates\" table. The table describes the comparison associated with the table row. \n\n    UNIT var-list=value-list \n    specifies the units in which the effects of continuous variable in the model are assessed."},"StatementOptionType":"S","SubOptionsKeywords":"AT|DIFF|LABEL|UNIT"},{"StatementOptionName":"OFFSET=","StatementOptionHelp":{"#cdata":"[Syntax: OFFSET=variable] \n          \nSpecifies a variable to be used as an offset for the linear predictor."},"StatementOptionType":"V"},{"StatementOptionName":"REFLINP=","StatementOptionHelp":{"#cdata":"[Syntax: REFLINP=r] \n          \nSpecifies a value for the linear predictor of the reference level in the generalized \nlogit model for nominal data. By default r=0."},"StatementOptionType":"V"},{"StatementOptionName":"SOLUTION|S","StatementOptionHelp":{"#cdata":"Requests that a solution for the fixed-effects parameters be produced."},"StatementOptionType":"S"},{"StatementOptionName":"STDCOEF","StatementOptionHelp":{"#cdata":"Reports solutions for fixed effects in terms of the standardized (scaled and/or \ncentered) coefficients."},"StatementOptionType":"S"},{"StatementOptionName":"OBSWEIGHT|OBSWT","StatementOptionHelp":{"#cdata":"[Syntax: OBSWEIGHT<=variable> | OBSWT<=variable> ]\n          \nSpecifies a variable to be used as the weight for the observation-level unit in a weighted multilevel \nmodel. If a weight variable is not specified in the OBSWEIGHT option, a weight of 1 is used."},"StatementOptionType":"S|V"},{"StatementOptionName":"ZETA=","StatementOptionHelp":{"#cdata":"[Syntax: ZETA=number] \n          \nTunes the sensitivity in forming Type III functions. Any element in the estimable \nfunction basis with an absolute value less than number is set to 0. The default \nis 1E-8."},"StatementOptionType":"V"}]}},{"StatementName":"NLOPTIONS","StatementHelp":{"#cdata":"Syntax: NLOPTIONS <options> ;\n      \nMost models fit with the GLIMMIX procedure typically have one or more nonlinear parameters. \nEstimation requires nonlinear optimization methods. You can control the optimization through \noptions in the NLOPTIONS statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ABSCONV=|ABSTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSCONV= | ABSTOL=r] \n          \nSpecifies an absolute function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ABSFCONV=|ABSFTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSFCONV=r <n>  | ABSFTOL=r<n>] \n          \nSpecifies an absolute function difference convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ABSGCONV=|ABSGTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSGCONV= | ABSGTOL=r <n>] \n          \nSpecifies an absolute gradient convergence criterion. \n\n  o For all techniques except NMSIMP (specified by the TECHNIQUE= option), Termination requires the maximum \n    absolute gradient element to be small.\n  o This criterion is not used by the NMSIMP technique."},"StatementOptionType":"V"},{"StatementOptionName":"ABSXCONV=|ABSXTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSXCONV= | ABSXTOL=r <n>] \n          \nSpecifies the absolute parameter convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ASINGULAR=|ASING=","StatementOptionHelp":{"#cdata":"[Syntax: ASINGULAR | ASING=r] \n          \nSpecifies an absolute singularity criterion r, r > 0, for the inversion of \nthe information matrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"DAMPSTEP|DS","StatementOptionHelp":{"#cdata":"[Syntax: DAMPSTEP | DS  <=r>] \n          \nSpecifies that the initial step-size value a\u207f (where n=0) for each line search \n(used by the QUANEW, CONGRA, or NEWRAP technique) cannot be larger than r times \nthe step-size value used in the former iteration."},"StatementOptionType":"S|V"},{"StatementOptionName":"FCONV=|FTOL=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV=r | FTOL=r] \n          \nSpecifies the relative function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"FCONV2=|FTOL2=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV2= | FTOL2=r <n>] \n          \nSpecifies a second function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"FSIZE=","StatementOptionHelp":{"#cdata":"[Syntax:FSIZE=r] \n          \nSpecifies the FSIZE parameter of the relative function and relative gradient termination \ncriteria. The default value is r=0."},"StatementOptionType":"V"},{"StatementOptionName":"GCONV=|GTOL=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV=r | GTOL=r] \n          \nSpecifies the relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"GCONV2=|GTOL2=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV2=r | GTOL2=r] \n          \nSpecifies another relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"HESCAL=|HS=","StatementOptionHelp":{"#cdata":"Specifies the scaling version of the Hessian or crossproduct Jacobian matrix used in NRRIDG, TRUREG, \nLEVMAR, NEWRAP, or DBLDOG optimization."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"0","@Value2":"1","@Value3":"2","@Value4":"3"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that no scaling is done.","@ToolTip2":"Specifies the Mor\u00e9 (1978) scaling update","@ToolTip3":"Specifies the Dennis, Gay, and Welsch (1981) scaling update","@ToolTip4":"Specifies that di is reset in each iteration"}},{"StatementOptionName":"INHESSIAN|INHESS","StatementOptionHelp":{"#cdata":"[Syntax: INHESSIAN<=r>] \n          \nSpecifies how the initial estimate of the approximate Hessian is defined for the quasi-Newton \ntechniques QUANEW and DBLDOG."},"StatementOptionType":"S|V"},{"StatementOptionName":"INSTEP=|SALPHA=|RADIUS=","StatementOptionHelp":{"#cdata":"[Syntax: INSTEP=r] \n          \nReduces the length of the first trial step during the line search of the first iterations."},"StatementOptionType":"V"},{"StatementOptionName":"LCDEACT=|LCD=","StatementOptionHelp":{"#cdata":"[Syntax: LCDEACT= | LCD=r] \n          \nSpecifies a threshold r for the Lagrange multiplier that decides whether an active \ninequality constraint remains active or can be deactivated."},"StatementOptionType":"V"},{"StatementOptionName":"LCEPSILON=|LCEPS=|LCE=","StatementOptionHelp":{"#cdata":"[Syntax: LCEPSILON= | LCEPS= | LCE=r] \n          \nSpecifies the range r, r \u2265 0, for active and violated boundary and linear constraints."},"StatementOptionType":"V"},{"StatementOptionName":"LCSINGULAR=|LCSING=|LCS=","StatementOptionHelp":{"#cdata":"[Syntax: LCSINGULAR= | LCSING= | LCS=r] \n          \nSpecifies a criterion r, r \u2265 0, used in the update of the QR decomposition that \ndecides whether an active constraint is linearly dependent on a set of other \nactive constraints. "},"StatementOptionType":"V"},{"StatementOptionName":"LINESEARCH=|LIS=|SMETHOD=|SM=","StatementOptionHelp":{"#cdata":"[Syntax: LINESEARCH | LIS | SMETHOD | SM=i] \n          \nSpecifies the line-search method for the CONGRA, QUANEW, and NEWRAP optimization \ntechniques."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"1","@Value2":"2","@Value3":"3","@Value4":"4","@Value5":"5","@Value6":"6","@Value7":"7","@Value8":"8"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a line-search method that needs the same number of function and gradient calls for cubic  interpolation and cubic extrapolation; this method is similar to one used by the Harwell subroutine library.","@ToolTip2":"Specifies a line-search method that needs more function calls than gradient calls for quadratic and  cubic interpolation and cubic extrapolation; this method is implemented as shown in Fletcher (1987) and  can be modified to an exact line search by using the LSPRECISION= option.","@ToolTip3":"Specifies a line-search method that needs the same number of function and gradient calls for cubic  interpolation and cubic extrapolation; this method is implemented as shown in Fletcher (1987) and can  be modified to an exact line search by using the LSPRECISION= option.","@ToolTip4":"Specifies a line-search method that needs the same number of function and gradient calls for stepwise  extrapolation and cubic interpolation","@ToolTip5":"Specifies a line-search method that is a modified version of LIS=4.","@ToolTip6":"Specifies golden section line search (Polak 1971), which uses only function values for linear approximation.","@ToolTip7":"Specifies bisection line search (Polak 1971), which uses only function values for linear approximation.","@ToolTip8":"Specifies Armijo line-search technique (Polak 1971), which uses only function values for linear approximation."}},{"StatementOptionName":"LSPRECISION=|LSP=","StatementOptionHelp":{"#cdata":"[Syntax: LSPRECISION=r | LSP=r] \n          \nSpecifies the degree of accuracy that should be obtained by the line-search algorithms \nLIS=2 and LIS=3. The default LSPRECISION= values are:\n\n  o For TECH=QUANEW UPDATE=DBFGS, BFGS: r = 0.4\n  o For TECH=QUANEW UPDATE=DDFP, DFP: r = 0.06 \n  o For TECH=CONGRA UPDATE=all r = 0.1\n  o For TECH=NEWRAP NO UPDATE: r = 0.9"},"StatementOptionType":"V"},{"StatementOptionName":"MAXFUNC=|MAXFU=","StatementOptionHelp":{"#cdata":"[Syntax: MAXFUNC=i | MAXFU=i] \n          \nRequires the number of function calls to be no larger than i. The default values are: \n\n  o For TECH= LEVMAR, NEWRAP, NRRIDG, TRUREG: i=125 \n  o For TECH= DBLDOG, QUANEW: i=500 \n  o For TECH= CONGRA: i=1000"},"StatementOptionType":"V"},{"StatementOptionName":"MAXITER=|MAXIT=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER= | MAXIT=i ] \n          \nRequires the number of iterations to be no larger than i. The default values are:\n  o For TECH= LEVMAR, NEWRAP, NRRIDG, TRUREG: i=50 \n  o For TECH= DBLDOG, QUANEW: i=200 \n  o For TECH= CONGRA: i=400"},"StatementOptionType":"V"},{"StatementOptionName":"MAXSTEP=","StatementOptionHelp":{"#cdata":"[Syntax: MAXSTEP=r<n>] \n          \nSpecifies an upper bound for the step length of the line-search algorithms during the \nfirst n iterations."},"StatementOptionType":"V"},{"StatementOptionName":"MAXTIME=","StatementOptionHelp":{"#cdata":"[Syntax: MAXTIME=r] \n          \nRequires the CPU time to be no larger than r. The default value of the MAXTIME= \noption is the largest double floating-point number on your computer."},"StatementOptionType":"V"},{"StatementOptionName":"MINITER=|MINIT=","StatementOptionHelp":{"#cdata":"[Syntax: MINITER= | MINIT=i] \n          \nSpecifies the minimum number of iterations. The default value is 0."},"StatementOptionType":"V"},{"StatementOptionName":"MSINGULAR=|MSING=","StatementOptionHelp":{"#cdata":"[Syntax: MSINGULAR= | MSING=r] \n          \nSpecifies a relative singularity criterion r, r > 0, for the inversion of \nthe information matrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"NOPRINT","StatementOptionHelp":{"#cdata":"Suppresses output related to optimization such as the iteration history."},"StatementOptionType":"S"},{"StatementOptionName":"PALL","StatementOptionHelp":{"#cdata":"[Displays information about the starting values and final values of the optimization process."},"StatementOptionType":"S"},{"StatementOptionName":"PHISTORY|PHIST","StatementOptionHelp":{"#cdata":"Displays the optimization history. The PHISTORY option is set automatically if the PALL or PRINT \noption is set."},"StatementOptionType":"S"},{"StatementOptionName":"RESTART=|REST=","StatementOptionHelp":{"#cdata":"[Syntax: RESTART= | REST=i] \n          \nSpecifies that the QUANEW or CONGRA algorithm is restarted with a steepest descent/ascent \nsearch direction after at most i iterations, i > 0."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=|SING=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR= | SING=r] \n          \nSpecifies the singularity criterion r, 0 < r < 1, used, for example, for matrix inversion."},"StatementOptionType":"V"},{"StatementOptionName":"SOCKET=","StatementOptionHelp":{"#cdata":"[Syntax: SOCKET=fileref]\n          \nSpecifies the fileref that contains the information needed for remote monitoring."},"StatementOptionType":"V"},{"StatementOptionName":"TECHNIQUE=|TECH=|OMETHOD=|OM=","StatementOptionHelp":{"#cdata":"[Syntax: TECHNIQUE= | TECH=name | OMETHOD= | OM=name] \n          \nSpecifies the optimization technique."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CONGRA","@Value2":"DBLDOG","@Value3":"LEVMAR","@Value4":"NEWRAP","@Value5":"NRRIDG","@Value6":"QUANEW","@Value7":"TRUREG","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Chooses one of four different conjugate-gradient optimization algorithms, which can be more precisely  defined with the UPDATE= option and modified with the LINESEARCH= option.","@ToolTip2":"Performs a version of double-dogleg optimization, which uses the gradient to update an approximation  of the Cholesky factor of the Hessian.","@ToolTip3":"Performs a highly stable but, for large problems, memory- and time-consuming Levenberg-Marquardt  optimization technique, a slightly improved variant of the Mor\u00e9 (1978) implementation. This is  the default optimization technique if there are fewer than 40 parameters to estimate.","@ToolTip4":"Performs a usually stable but, for large problems, memory- and time-consuming Newton-Raphson optimization  technique. The algorithm combines a line-search algorithm with ridging, and it can be modified with the  LINESEARCH= option.","@ToolTip5":"Performs a usually stable but, for large problems, memory- and time-consuming Newton-Raphson optimization  technique. This algorithm does not perform a line search.","@ToolTip6":"Chooses one of four different quasi-Newton optimization algorithms that can be more precisely defined with  the UPDATE= option and modified with the LINESEARCH= option.","@ToolTip7":"Performs a usually very stable but, for large problems, memory- and time-consuming trust-region optimization  technique. The algorithm is implemented similar to Gay (1983) and Mor\u00e9 and Sorensen (1983).","@ToolTip8":"Does not perform any optimization. This option is similar to METHOD=NONE, but TECH=NONE also computes and displays residuals and goodness of fit statistics."}},{"StatementOptionName":"UPDATE=|UPD=","StatementOptionHelp":{"#cdata":"Specifies the update method for the quasi-Newton, double-dogleg, or conjugate-gradient optimization technique."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BFGS","@Value2":"DBFGS","@Value3":"DDFP","@Value4":"DFP","@Value5":"PB","@Value6":"FR","@Value7":"PR","@Value8":"CD"},"StatementOptionToolTips":{"@ToolTip1":"Performs the original Broyden, Fletcher, Goldfarb, and Shanno (BFGS) update of the inverse Hessian matrix.","@ToolTip2":"Performs the dual BFGS update of the Cholesky factor of the Hessian matrix. This is the default update method.","@ToolTip3":"Performs the dual Davidon, Fletcher, and Powell (DFP) update of the Cholesky factor of the Hessian matrix.","@ToolTip4":"Performs the original DFP update of the inverse Hessian matrix.","@ToolTip5":"Performs the automatic restart update method of Powell (1977) and Beale (1972).","@ToolTip6":"Performs the Fletcher-Reeves update (Fletcher 1987).","@ToolTip7":"Performs the Polak-Ribiere update (Fletcher 1987).","@ToolTip8":"Performs a conjugate-descent update of Fletcher (1987)."}},{"StatementOptionName":"VERSION=|VS=","StatementOptionHelp":{"#cdata":"Specifies the version of the quasi-Newton optimization technique with nonlinear constraints."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"1","@Value2":"2"},"StatementOptionToolTips":{"@ToolTip1":"Specifies the update of the U vector as in Powell (1978a, 1978b) (update like VF02AD).","@ToolTip2":"Specifies the update of the U vector as in Powell (1982a, 1982b) (update like VMCWD)."}},{"StatementOptionName":"VSINGULAR=|VSING=","StatementOptionHelp":{"#cdata":"[Syntax: VSINGULAR= | VSING=r] \n            \nSpecifies a relative singularity criterion r, r > 0, for the inversion of the information \nmatrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"XCONV=|XTOL=","StatementOptionHelp":{"#cdata":"[Syntax: XCONV= | XTOL=r <n>] \n          \nSpecifies the relative parameter convergence criterion. Termination requires a small \nrelative parameter change in subsequent iterations."},"StatementOptionType":"V"},{"StatementOptionName":"XSIZE=","StatementOptionHelp":{"#cdata":"[Syntax: XSIZE=r] \n          \nSpecifies the XSIZE parameter of the relative function and relative gradient termination \ncriteria. The default value is r=0."},"StatementOptionType":"V"}]}},{"StatementName":"OUTPUT","StatementHelp":{"#cdata":"The OUTPUT statement creates a data set that contains predicted values and residual diagnostics, \ncomputed after fitting the model.\n      \nSyntax: OUTPUT <OUT=SAS-data-set> <keyword<(keyword-options)><=name>>\n    ... <keyword<(keyword-options)> <=name>> < / options> ; \n    \nwhere:\n\nkeyword<(keyword-options)> <=name> \nspecifies a statistic to include in the output data set and optionally assigns the variable \nthe name, name. You can use the keyword-options to control which type of a particular statistic \nto compute. \n\nThe keyword-options can take on the following values: \n\n    BLUP \n    uses the predictors of the random effects in computing the statistic. \n\n    ILINK \n    computes the statistic on the scale of the data. \n\n    NOBLUP \n    does not use the predictors of the random effects in computing the statistic. \n\n    NOILINK \n    computes the statistic on the scale of the link function. \n\n    The default is to compute statistics by using BLUPs on the scale of the link function (the linearized scale)."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nSpecifies the name of the output data set."},"StatementOptionType":"RV|DV"},{"StatementOptionName":"PREDICTED|PRED","StatementOptionHelp":{"#cdata":"Outputs the following statistic: \n          \n  PREDICTED<=name>\n  Linear predictor; default variable name: \"Pred\"\n\n  PREDICTED(NOBLUP)<=name>\n  Marginal linear predictor; default variable name: \"PredPA\"\n\n  PREDICTED(ILINK)<=name>\n  Predicted mean; default variable name: \"PredMu\"\n\n  PREDICTED(NOBLUP ILINK)<=name>\n  Marginal mean; default variable name: \"PredMuPA\""},"StatementOptionType":"RS|RV","SubOptionsKeywords":"BLUP|NOBLUP|ILINK|NOILINK"},{"StatementOptionName":"STDERR|STD","StatementOptionHelp":{"#cdata":"Outputs the following statistic: \n          \n  STDERR<=name>\n  Standard deviation of linear predictor; default variable name: \"StdErr\"\n\n  STDERR(NOBLUP)<=name>\n  Standard deviation of marginal linear predictor; default variable name: \"StdErrPA\"\n\n  STDERR(ILINK)<=name>\n  Standard deviation of mean; default variable name: \"StdErr\"\n\n  STDERR(NOBLUP ILINK)<=name>\n  Standard deviation of marginal mean; default variable name: \"StdErrMuPA\""},"StatementOptionType":"RS|RV","SubOptionsKeywords":"BLUP|NOBLUP|ILINK|NOILINK"},{"StatementOptionName":"RESIDUAL|RESID","StatementOptionHelp":{"#cdata":"Outputs the following statistic: \n          \nRESIDUAL<=name>\nResidual; default variable name: \"Resid\"\n\nRESIDUAL(NOBLUP)<=name>\nMarginal residual; default variable name: \"ResidPA\"\n\nRESIDUAL(ILINK)<=name>\nResidual on mean scale; default variable name: \"ResidMu\"\n\nRESIDUAL(NOBLUP ILINK)<=name>\nMarginal residual on mean scale; default variable name: \"ResidMuPA\""},"StatementOptionType":"RS|RV","SubOptionsKeywords":"BLUP|NOBLUP|ILINK|NOILINK"},{"StatementOptionName":"PEARSON","StatementOptionHelp":{"#cdata":"Outputs the following statistic: \n          \nPEARSON<=name>\nPearson-type residual; default variable name: \"Pearson\"\n\nPEARSON(NOBLUP)<=name>\nMarginal Pearson-type residual; default variable name: \"PearsonPA\"\n\nPEARSON(ILINK)<=name>\nConditional Pearson-type mean residual; default variable name: \"PearsonMu\""},"StatementOptionType":"RS|RV","SubOptionsKeywords":"NOBLUP|ILINK"},{"StatementOptionName":"STUDENT","StatementOptionHelp":{"#cdata":"Outputs the following statistic: \n          \nSTUDENT<=name>\nStudentized residual; default variable name: \"Student\"\n\nSTUDENT(NOBLUP)<=name>\nStudentized marginal residual; default variable name: \"StudentPA\""},"StatementOptionType":"RS|RV","SubOptionsKeywords":"NOBLUP"},{"StatementOptionName":"LCL","StatementOptionHelp":{"#cdata":"Outputs the following statistic: \n          \n  LCL<=name>\n  Lower prediction limit for linear predictor; default variable name: \"LCL\"\n\n  LCL(NOBLUP)<=name>\n  Lower confidence limit for marginal linear predictor; default variable name: \"LCLPA\"\n\n  LCL(ILINK)<=name>\n  Lower prediction limit for mean; default variable name: \"LCLMu\"\n\n  LCL(NOBLUP ILINK)<=name>\n  Lower confidence limit marginal mean; default variable name: \"LCLMuPA\""},"StatementOptionType":"RS|RV","SubOptionsKeywords":"BLUP|NOBLUP|ILINK|NOILINK"},{"StatementOptionName":"UCL","StatementOptionHelp":{"#cdata":"Outputs the following statistic: \n          \n  UCL<=name>\n  Upper prediction limit for linear predictor; default variable name: \"UCL\"\n\n  UCL(NOBLUP)<=name>\n  Upper confidence limit for marginal linear predictor; default variable name: \"UCLPA\"\n\n  UCL(ILINK)<=name>\n  Upper prediction limit for mean; default variable name: \"UCLMu\"\n\n  UCL(NOBLUP ILINK)<=name>\n  Upper confidence limit marginal mean; default variable name: \"UCLMuPA\""},"StatementOptionType":"RS|RV","SubOptionsKeywords":"BLUP|NOBLUP|ILINK|NOILINK"},{"StatementOptionName":"VARIANCE|VAR","StatementOptionHelp":{"#cdata":"Outputs the following statistic: \n          \n  VARIANCE<=name>\n  Conditional variance of pseudo-data; default variable name: \"Variance\"\n\n  VARIANCE(NOBLUP)<=name>\n  Marginal variance of pseudo-data; default variable name: \"VariancePA\"\n\n  VARIANCE(ILINK)<=name>\n  Conditional variance of response; default variable name: \"Variance_Dep\"\n\n  VARIANCE(NOBLUP ILINK)<=name>\n  Marginal variance of response; default variable name: \"Variance_DepPA\""},"StatementOptionType":"RS|RV","SubOptionsKeywords":"BLUP|NOBLUP|ILINK|NOILINK"},{"StatementOptionName":"ALLSTATS","StatementOptionHelp":{"#cdata":"Requests that all statistics are computed."},"StatementOptionType":"S"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nDetermines the coverage probability for two-sided confidence and prediction intervals. \nThe coverage probability is computed as 1-number. The value of number must be between \n0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"CPSEUDO","StatementOptionHelp":{"#cdata":"Changes the way in which marginal residuals are computed when model parameters are estimated by pseudo-likelihood methods.\n"},"StatementOptionType":"S"},{"StatementOptionName":"DERIVATIVES|DER","StatementOptionHelp":{"#cdata":"Adds derivatives of model quantities to the output data set."},"StatementOptionType":"S"},{"StatementOptionName":"NOMISS","StatementOptionHelp":{"#cdata":"Requests that records be written to the output data only for those observations that were used in \nthe analysis."},"StatementOptionType":"S"},{"StatementOptionName":"NOUNIQUE","StatementOptionHelp":{"#cdata":"Requests that names not be made unique in the case of naming conflicts."},"StatementOptionType":"S"},{"StatementOptionName":"NOVAR","StatementOptionHelp":{"#cdata":"Requests that variables from the input data set not be added to the output data set."},"StatementOptionType":"S"},{"StatementOptionName":"OBSCAT","StatementOptionHelp":{"#cdata":"Requests that in models for multinomial data statistics be written to the output data set \nonly for the response level that corresponds to the observed level of the observation."},"StatementOptionType":"S"},{"StatementOptionName":"SYMBOLS|SYM","StatementOptionHelp":{"#cdata":"Adds to the output data set computed variables that are defined or referenced in the program."},"StatementOptionType":"S"}],"#comment":{}}},{"StatementName":"PARMS","StatementHelp":{"#cdata":"Syntax: PARMS <(value-list)> ...</ options> ;\n      \nThe PARMS statement specifies initial values for the covariance or scale parameters, or it requests \na grid search over several values of these parameters in generalized linear mixed models."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"HOLD=","StatementOptionHelp":{"#cdata":"[Syntax: HOLD=value-list] \n          \nSpecifies which parameter values PROC GLIMMIX should hold equal to the specified values."},"StatementOptionType":"V"},{"StatementOptionName":"LOWERB=","StatementOptionHelp":{"#cdata":"[Syntax: LOWERB=value-list] \n          \nEnables you to specify lower boundary constraints for the covariance or scale parameters."},"StatementOptionType":"V"},{"StatementOptionName":"NOBOUND","StatementOptionHelp":{"#cdata":"Requests the removal of boundary constraints on covariance and scale parameters in mixed models."},"StatementOptionType":"S"},{"StatementOptionName":"NOITER","StatementOptionHelp":{"#cdata":"Requests that no optimization of the covariance parameters be performed."},"StatementOptionType":"S"},{"StatementOptionName":"PARMSDATA=|PDATA=","StatementOptionHelp":{"#cdata":"[Syntax: PARMSDATA=SAS-data-set] \n          \nReads in covariance parameter values from a SAS data set."},"StatementOptionType":"DV"},{"StatementOptionName":"UPPERB=","StatementOptionHelp":{"#cdata":"[Syntax: UPPERB=value-list] \n          \nEnables you to specify upper boundary constraints on the covariance parameters. \nThe value-list specification is a list of numbers or missing values (.) separated \nby commas."},"StatementOptionType":"V"}]}},{"StatementName":"RANDOM","StatementHelp":{"#cdata":"Syntax: RANDOM random-effects </ options> ;\n      \nthe RANDOM statement defines the Z matrix of the mixed model, the random effects \nin the Gamma vector, the structure of G, and the structure of R."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval with confidence level 1-number be constructed \nfor the predictors of G-side random effects in this statement. The value of number must \nbe between 0 and 1; the default is 0.05"},"StatementOptionType":"V"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the predictors of random effects \nin this statement."},"StatementOptionType":"S"},{"StatementOptionName":"G","StatementOptionHelp":{"#cdata":"Requests that the estimated G matrix be displayed for G-side random effects associated with this \nRANDOM statement. PROC GLIMMIX displays blanks for values that are 0."},"StatementOptionType":"S"},{"StatementOptionName":"GC","StatementOptionHelp":{"#cdata":"Displays the lower-triangular Cholesky root of the estimated G matrix for G-side random effects."},"StatementOptionType":"S"},{"StatementOptionName":"GCI","StatementOptionHelp":{"#cdata":"Displays the inverse Cholesky root of the estimated G matrix for G-side random effects."},"StatementOptionType":"S"},{"StatementOptionName":"GCOORD=","StatementOptionHelp":{"#cdata":"Determines how the GLIMMIX procedure associates coordinates for TYPE=SP() covariance \nstructures with effect levels for G-side random effects."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"LAST","@Value2":"FIRST","@Value3":"MEAN"},"StatementOptionToolTips":{"@ToolTip1":"Determines the coordinates for a level of the random effect from the last observation associated with the level.","@ToolTip2":"Determines the coordinate from the first observation.","@ToolTip3":"Determines the coordinate from the average of the observations."}},{"StatementOptionName":"GCORR","StatementOptionHelp":{"#cdata":"Displays the correlation matrix that corresponds to the estimated G matrix for G-side random effects."},"StatementOptionType":"S"},{"StatementOptionName":"GI","StatementOptionHelp":{"#cdata":"Displays the inverse of the estimated G matrix for G-side random effects."},"StatementOptionType":"S"},{"StatementOptionName":"GROUP=|GRP=","StatementOptionHelp":{"#cdata":"[Syntax: GROUP=effect] \n          \nIdentifies groups by which to vary the covariance parameters."},"StatementOptionType":"V"},{"StatementOptionName":"KNOTINFO","StatementOptionHelp":{"#cdata":"Displays the number and coordinates of the knots as determined by the KNOTMETHOD= option."},"StatementOptionType":"S"},{"StatementOptionName":"KNOTMAX=","StatementOptionHelp":{"#cdata":"[Syntax: KNOTMAX=number-list]  \n          \nProvides upper limits for the values of random effects used in the construction of knots for TYPE=RSMOOTH."},"StatementOptionType":"V"},{"StatementOptionName":"KNOTMETHOD=","StatementOptionHelp":{"#cdata":"Determines the method for constructing knots for the radial smoother fit with the \nTYPE=RSMOOTH covariance structure and the TYPE=PSPLINE covariance structure."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"KDTREE","@Value2":"EQUAL","@Value3":"DATA"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: KNOTMETHOD=KDTREE<(tree-options)>              where tree-options can take the following values:    BUCKET=number    determines the bucket size b. A larger bucket size will result in fewer knots.    KNOTTYPE=type    specifies whether the knots are based on vertices of the tree cells or the centroid.     NEAREST    specifies that knot coordinates are the coordinates of the nearest neighbor of either the centroid    or vertex of the cell, as determined by the KNOTTYPE= suboption.     TREEINFO    displays details about the construction of the k-d tree, such as the cell splits and the split values.","@ToolTip2":"Syntax: KNOTMETHOD=EQUAL<(number-list)>                                     This option enables you to define a regular grid of knots. By default, PROC GLIMMIX constructs 10 knots for one-dimensional smooths and 5 knots in each dimension for smoothing in higher dimensions.","@ToolTip3":"Syntax: KNOTMETHOD=DATA(SAS-data-set)                                     You can specify a data set that contains variables whose values give the knot coordinates with the  KNOTMETHOD=DATA option. The data set must contain numeric variables with the same name as the radial  smoothing random-effects. PROC GLIMMIX uses only the unique knot coordinates in the knot data set.  This option is useful to provide knot coordinates different from those that can be produced from a k-d tree."},"SubOptionsKeywords":"BUCKET=|KNOTTYPE=|NEAREST|TREEINFO"},{"StatementOptionName":"KNOTMIN=","StatementOptionHelp":{"#cdata":"[Syntax: KNOTMIN=number-list] \n          \nProvides lower limits for the values of random effects used in the construction \nof knots for TYPE=RSMOOTH."},"StatementOptionType":"V"},{"StatementOptionName":"LDATA=","StatementOptionHelp":{"#cdata":"[Syntax: LDATA=SAS-data-set] \n          \nReads the coefficient matrices A1, ..., Aq for the TYPE=LIN(q) option."},"StatementOptionType":"V"},{"StatementOptionName":"NOFULLZ","StatementOptionHelp":{"#cdata":"Eliminates the columns in Z corresponding to missing levels of random effects involving \nCLASS variables. By default, these columns are included in Z. It is sufficient to specify \nthe NOFULLZ option in any RANDOM statement."},"StatementOptionType":"S"},{"StatementOptionName":"RESIDUAL|RSIDE","StatementOptionHelp":{"#cdata":"Specifies that the random effects listed in this statement be R-side effects."},"StatementOptionType":"S"},{"StatementOptionName":"SOLUTION|S","StatementOptionHelp":{"#cdata":"Requests that the solution for the random-effects parameters be produced."},"StatementOptionType":"S"},{"StatementOptionName":"SUBJECT=|SUB=","StatementOptionHelp":{"#cdata":"[Syntax: SUBJECT=effect | SUB=effect] \n          \nIdentifies the subjects in your mixed model. Complete independence is assumed across \nsubjects; thus, for the RANDOM statement, the SUBJECT= option produces a block-diagonal \nstructure in G with identical blocks."},"StatementOptionType":"V"},{"StatementOptionName":"TYPE=","StatementOptionHelp":{"#cdata":"[Syntax: TYPE=covariance-structure] \n          \nSpecifies the covariance structure of G for G-side effects and the covariance structure \nof R for R-side effects."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ANTE(1)","@Value2":"AR(1)","@Value3":"ARH(1)","@Value4":"ARMA(1,1)","@Value5":"CHOL<(q)>","@Value6":"CS","@Value7":"CSH","@Value8":"FA(q)","@Value9":"FA0(q)","@Value10":"HF","@Value11":"LIN(q)","@Value12":"PSPLINE","@Value13":"RSMOOTH","@Value14":"SIMPLE","@Value15":"SP(EXP)(c-list)","@Value16":"SP(GAU)(c-list)","@Value17":"SP(MAT)(c-list)","@Value18":"SP(POW)(c-list)","@Value19":"SP(POWA)(c-list)","@Value20":"SP(SPH)(c-list)","@Value21":"TOEP","@Value22":"TOEP(q)","@Value23":"TOEPH<(q)>","@Value24":"UN<(q)>","@Value25":"UNR<(q)>","@Value26":"VC"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a first-order ante-dependence structure (Kenward 1987; Patel 1991) parameterized in terms  of variances and correlation parameters.","@ToolTip2":"Specifies a first-order autoregressive structure.","@ToolTip3":"Specifies a heterogeneous first-order autoregressive structure.","@ToolTip4":"Specifies the first-order autoregressive moving-average structure","@ToolTip5":"Specifies an unstructured variance-covariance matrix parameterized through its Cholesky root.","@ToolTip6":"Specifies the compound-symmetry structure, which has constant variance and constant covariance.","@ToolTip7":"Specifies the heterogeneous compound-symmetry structure, which is an equi-correlation structure but  allows for different variances.","@ToolTip8":"Specifies the factor-analytic structure with q factors (Jennrich and Schluchter 1986).","@ToolTip9":"Specifies a factor-analytic structure with q factors.","@ToolTip10":"Specifies a covariance structure that satisfies the general Huynh-Feldt condition (Huynh and Feldt 1970).","@ToolTip11":"Specifies a general linear covariance structure with q parameters.","@ToolTip12":"Requests that PROC GLIMMIX form a \u03b2-spline basis and fits a penalized \u03b2-spline (P-spline, Eilers  and Marx 1996) with random spline coefficients.  Syntax: TYPE=PSPLINE<(options)>  You can specify the following options for TYPE=PSPLINE:       DEGREE=      specifies the degree of the \u03b2-spline. The default is d=3.       DIFFORDER=      specifies the order of the differencing matrix Dr. The default and maximum is r=3.","@ToolTip13":"Specifies a radial smoother covariance structure for G-side random effects.                                     Syntax: TYPE=RSMOOTH<(m|NOLOG>  The NOLOG option removes the log{h-ik} and log{d-kp} terms from the computation of the Z  and \u2126 matrices when nr is even; this yields invariance under rescaling of the coordinates.","@ToolTip14":"Is an alias for TYPE=VC.","@ToolTip15":"Models an exponential spatial or temporal covariance structure, where the covariance between two  observations depends on a distance metric dij.","@ToolTip16":"Models a gaussian covariance structure.","@ToolTip17":"Models a covariance structure in the Mat\u00e9rn class of covariance functions (Mat\u00e9rn 1986).","@ToolTip18":"Models a power covariance structure.","@ToolTip19":"Models an anisotropic power covariance structure in k dimensions, provided that the coordinate  list c-list has k elements.","@ToolTip20":"Models a spherical covariance structure.","@ToolTip21":"Models a Toeplitz covariance structure.","@ToolTip22":"Specifies a banded Toeplitz structure.","@ToolTip23":"Models a Toeplitz covariance structure.                                     Syntax: TYPE=TOEPH<(q)>","@ToolTip24":"Specifies a completely general (unstructured) covariance matrix parameterized directly in terms  of variances and covariances.","@ToolTip25":"Specifies a completely general (unstructured) covariance matrix  parameterized in terms of variances and correlations.","@ToolTip26":"Specifies standard variance components and is the default structure for both G-side and R-side  covariance structures."}},{"StatementOptionName":"V","StatementOptionHelp":{"#cdata":"[Syntax: V<=value-list>] \n          \nRequests that blocks of the estimated V matrix be displayed. You can optionally use \nthe value-list specification, which indicates the subjects for which blocks of V are \nto be displayed."},"StatementOptionType":"S|V"},{"StatementOptionName":"VC","StatementOptionHelp":{"#cdata":"[Syntax: VC<=value-list>] \n          \nDisplays the Cholesky root of the blocks of the estimated V matrix. The value-list \nspecification is the same as in the V= option."},"StatementOptionType":"S|V"},{"StatementOptionName":"VCI","StatementOptionHelp":{"#cdata":"[Syntax: VCI<=value-list>] \n          \nDisplays the inverse of the Cholesky root of the blocks of the estimated V matrix. \nThe value-list specification is the same as in the V= option."},"StatementOptionType":"S|V"},{"StatementOptionName":"VCORR","StatementOptionHelp":{"#cdata":"[Syntax: VCORR<=value-list>] \n          \nDisplays the correlation matrix corresponding to the blocks of the estimated V matrix.  \nThe value-list specification is the same as in the V= option."},"StatementOptionType":"S|V"},{"StatementOptionName":"VI","StatementOptionHelp":{"#cdata":"[Syntax: VI<=value-list>] \n          \nDisplays the inverse of the blocks of the estimated V matrix. The value-list specification \nis the same as in the V= option."},"StatementOptionType":"S|V"},{"StatementOptionName":"WEIGHT|WT","StatementOptionHelp":{"#cdata":"[Syntax: WEIGHT<=variable> | WT<=variable>]\n          \nSpecifies a variable to be used as the weight for the units at the current level in a weighted multilevel model. \nIf a weight variable is not specified in the WEIGHT option, a weight of 1 is used."},"StatementOptionType":"S|V"}]}},{"StatementName":"SLICE","StatementHelp":{"#cdata":"Syntax: SLICE model-effect </ options> ; \n      \nThe SLICE statement provides a general mechanism for performing a partitioned analysis \nof the LS-means for an interaction. This analysis is also known as an analysis of simple \neffects. \n\nThe SLICE statement uses the same options as the LSMEANS statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"SLICEBY|SIMPLE","StatementOptionHelp":{"#cdata":"Determines how to construct the partition of the least squares means for the model-effect.\n          \nSyntax: \nSLICEBY <=> slice-specification \nSIMPLE <=> slice-specification \nSLICEBY(slice-specification <, slice-specification <, >>) \nSIMPLE(slice-specification <, slice-specification <, >>) \n\nA slice-specification consists of an effect name followed by an optional list of formatted \nvalues. For example, the following statements creates partitions of the A*B interaction effect \nfor all levels of variable A: \n\n  class a b;\n  model y = a b a*b;\n  slice a*b / sliceby=a;"},"StatementOptionType":"S|V"},{"StatementOptionName":"NOF","StatementOptionHelp":{"#cdata":"Suppresses the F test for testing the mutual equality of the estimable functions \nin the partition."},"StatementOptionType":"S"},{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence limits are adjusted\nfor multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.       CVADJUST      specifies that the quantile should be estimated by the control variate adjustment method of     Hsu and Nelson (1998) instead of simply as the quantile of the simulated sample.      EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile.       NSAMP=n      specifies the sample size for the simulation.       REPORT      specifies that a report on the simulation should be displayed, including a listing of the parameters,     such as \u03b3, \u03b5, and \u03b1, as well as an analysis of various methods for estimating or approximating      the quantile.       SEED=number      specifies an integer used to start the pseudo-random number generator for the simulation.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956) and  identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|CVADJUST|EPS=|NSAMP=|REPORT|SEED="},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default value is 0.05, corresponding to a 95% confidence interval."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nEnables you to modify the values of the covariates used in computing LS-means."},"StatementOptionType":"S","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The confidence level \nis 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences, and it is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the upper confidence  limits for the control minus the noncontrol levels are considered to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the upper confidence  limits for the noncontrol levels minus the control are considered to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for all LSMEANS effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" table also be reported \non the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing the means in descending \norder and indicating nonsignificant subsets by line segments beside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"ODDS","StatementOptionHelp":{"#cdata":"Requests that in models with logit, cumulative logit, and generalized logit link function the odds of the \nlevels of the fixed effects are reported."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) and simple effect comparisons (SLICEDIFF option) \nare also reported in terms of odds ratios."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS|OM","StatementOptionHelp":{"#cdata":"Specifies a potentially different weighting scheme for the computation of LS-means coefficients."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided that the \nODS GRAPHICS statement has been specified and the plot request does not conflict with other options \nin the LSMEANS statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"CONTROLPLOT|CONTROL","@Value4":"DIFFPLOT|DIFFOGRAM|DIFF","@Value5":"MEANPLOT","@Value6":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip4":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES      suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip5":"Requests displays of the least squares means.   Syntax: MEANPLOT<(meanplot-options)>  The following meanplot-options control the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip6":"Requests that no plots be produced."},"SubOptionsKeywords":"ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|CONNECT|SLICEBY=|PLOTBY="},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the CONTRAST statement."},"StatementOptionType":"V"},{"StatementOptionName":"SLICE=","StatementOptionHelp":{"#cdata":"[Syntax: SLICE=fixed-effect | (fixed-effects)] \n          \nSpecifies effects by which to partition interaction LSMEANS effects."},"StatementOptionType":"V"},{"StatementOptionName":"SLICEDIFF=|SIMPLEDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: SLICEDIFF=fixed-effect | SLICEDIFF=(fixed-effects)] \n          \nRequests that differences of simple effects be constructed and tested against zero."},"StatementOptionType":"V"},{"StatementOptionName":"SLICEDIFFTYPE=|SIMPLEDIFFTYPE=","StatementOptionHelp":{"#cdata":"[Syntax: SLICEDIFFTYPE<=difftype>] \n          \nDetermines the type of simple effect differences produced with the SLICEDIFF= option."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"CONTROL","@Value3":"CONTROLL","@Value4":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all simple effects differences, and it is the default.","@ToolTip2":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip3":"Tests whether the noncontrol levels are significantly smaller than the control; the upper confidence  limits for the control minus the noncontrol levels are considered to be infinity and are displayed as missing.","@ToolTip4":"Tests whether the noncontrol levels are significantly larger than the control; the upper confidence  limits for the noncontrol levels minus the control are considered to be infinity and are displayed as missing."}},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> | TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="}],"#comment":{}}},{"StatementName":"STORE","StatementHelp":{"#cdata":"Syntax: STORE <OUT=>item-store-name </ LABEL='label'> ; \n      \nThe STORE statement requests that the procedure save the context and results of the \nstatistical analysis. The resulting item store is a binary file format that cannot \nbe modified. The contents of the item store can be processed with the PLM procedure. \n\nThe item-store-name is a usual one- or two-level SAS name, like the names that are used \nfor SAS data sets. If you specify a one-level name, then the item store resides in the \nWORK library and is deleted at the end of the SAS session. Since item stores usually are \nused to perform postprocessing tasks, typical usage specifies a two-level name of the form \nlibname.membername. \n\nIf an item store by the same name as specified in the STORE statement already exists, \nthe existing store is replaced."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: <OUT=>item-store-name'] \n          \nThe item-store-name is a usual one- or two-level SAS name, like the names that are used \nfor SAS data sets. If you specify a one-level name, then the item store resides in the \nWORK library and is deleted at the end of the SAS session."},"StatementOptionType":"RV"},{"StatementOptionName":"LABEL=","StatementOptionHelp":{"#cdata":"[Syntax: LABEL='label'] \n          \nAdds a custom label. When the PLM procedure processes an item store, the label appears \nin the PROC PLM output along with other identifying information."},"StatementOptionType":"V"}]}},{"StatementName":"WEIGHT","StatementHelp":{"#cdata":"Syntax: WEIGHT variable;\n      \nThe WEIGHT statement replaces R with (W^-1/2)(RW^-1/2), where W is a diagonal matrix \ncontaining the weights. Observations with nonpositive or missing weights are not included \nin the resulting PROC GLIMMIX analysis. If a WEIGHT statement is not included, all \nobservations used in the analysis are assigned a weight of 1."},"StatementOptions":null},{"StatementName":"ABORT","StatementHelp":{"#cdata":"Syntax: ABORT <ABEND | CANCEL <FILE> | RETURN | > <n> <NOLIST>; \n      \nStops executing the current DATA step, SAS job, or SAS session."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ABEND","StatementOptionHelp":{"#cdata":"Causes abnormal termination of the current SAS job or session. Results depend on the method \nof operation: \n\no batch mode and noninteractive mode \n\n  o stops processing immediately\n  o sends an error message to the SAS log that states that execution was terminated by the ABEND option \n    of the ABORT macro statement\n  o does not execute any subsequent statements or check syntax\n  o returns control to the operating environment; further action is based on how your operating environment \n    and your site treat jobs that end abnormally.\n\no windowing environment and interactive line mode \n\n  o causes your windowing environment and interactive line mode to stop processing immediately \n    and return you to your operating environment."},"StatementOptionType":"S"},{"StatementOptionName":"CANCEL","StatementOptionHelp":{"#cdata":"Causes the cancellation of the current submitted statements. The results depend on the method \nof operation:\n\no batch mode and noninteractive mode\n\n  o The entire SAS program and SAS system are terminated.\n  o The error message is written to the SAS log.\n\no windowing environment and interactive line mode \n\n  o It only clears the current submitted program.\n  o Other subsequent submitted programs are not affected.\n  o The error message is written to the SAS log.\n\no workspace server and stored process server \n\n  o It only clears currently submitted program.\n  o Other subsequent submit calls are not affected.\n  o The error message is written to the SAS log.\n\no SAS IntrNet application server \n\n  o A separate execution is created for each request. The execution submits the request code. A CANCEL \n    argument in the request code clears the current submitted code but does not terminate the execution \n    of the SAS session."},"StatementOptionType":"S"},{"StatementOptionName":"CANCEL FILE","StatementOptionHelp":{"#cdata":"Causes only the contents of the autoexec file or %INCLUDE file to be cleared by the %ABORT statement. \nOther submitted source statements will be executed after the autoexec or %INCLUDE file."},"StatementOptionType":"S"},{"StatementOptionName":"RETURN","StatementOptionHelp":{"#cdata":"Causes abnormal termination of the current SAS job or session. Results depend on the method \nof operation: \n\no batch mode and noninteractive mode \n\n  o stops processing immediately\n  o sends an error message to the SAS log that states that execution was terminated by the RETURN option \n    in the ABORT macro statement\n  o does not execute any subsequent statements or check syntax\n  o returns control to the operating environment with a condition code indicating an error.\n\no windowing environment and interactive line mode \n\n  o causes your windowing environment and interactive line mode to stop processing immediately \n    and return you to your operating environment."},"StatementOptionType":"S"},{"StatementOptionName":"NOLIST","StatementOptionType":"S","StatementOptionHelp":{"#cdata":"suppresses the output of all variables to the SAS log."}}]}},{"StatementName":"ARRAY","StatementHelp":{"#cdata":"Syntax: ARRAY arrayname [ dimensions ] <$> <variables-and-constants> ; \n      \nThe ARRAY statement associates a name (of no more than eight characters) with a list of variables \nand constants. The ARRAY statement is similar to, but not the same as, the ARRAY statement in the \nDATA step, and it is the same as the ARRAY statements in the NLIN, NLP, NLMIXED, and MODEL procedures. \nThe array name is used with subscripts in the program to refer to the array elements, as illustrated in \nthe following statements: \n\n  array r[8] r1-r8;\n   \n  do i = 1 to 8;\n     r[i] = 0;\n  end;\n\nThe ARRAY statement does not support all the features of the ARRAY statement in the \nDATA step. Implicit indexing of variables cannot be used; all array references must \nhave explicit subscript expressions. Only exact array dimensions are allowed; lower-\nbound specifications are not supported. A maximum of six dimensions is allowed."},"StatementOptions":null},{"StatementName":"CALL","StatementHelp":{"#cdata":"Syntax: CALL routine(parameter-1<, ...parameter-n>);  \n      \nInvokes a SAS CALL routine."},"StatementOptions":null},{"StatementName":"DELETE","StatementHelp":{"#cdata":"Syntax: DELETE; \n      \nStops processing the current observation."},"StatementOptions":null},{"StatementName":"DO","StatementHelp":{"#cdata":"Specifies a group of statements to be executed as a unit.\n      \nSyntax: \n(1) DO; \n...more SAS statements...  \nEND;  \n\n(2) DO index-variable=specification-1 <, ... specification-n>; \n... more SAS statements ...  \nEND;  \n\n(3) DO UNTIL (expression); \n...more SAS statements...  \nEND \n\n(4) DO WHILE (expression); \n...more SAS statements...  \nEND;"},"StatementOptions":{"StatementOption":[{"StatementOptionName":"UNTIL","StatementOptionHelp":{"#cdata":"Executes statements in a DO loop repetitively until a condition is true.\n          \nSyntax: \nDO UNTIL (expression); \n...more SAS statements...  \nEND"},"StatementOptionType":"S"},{"StatementOptionName":"WHILE","StatementOptionHelp":{"#cdata":"Executes statements in a DO-loop repetitively while a condition is true. \n          \nSyntax: \nDO WHILE (expression); \n...more SAS statements...  \nEND;"},"StatementOptionType":"S"},{"StatementOptionName":"OVER","StatementOptionType":"S"},{"StatementOptionName":"TO","StatementOptionHelp":{"#cdata":"Separates the start and stop integers or expressions that control the number of times the \nportion of the DATA step between the iterative DO and END statements is processed."},"StatementOptionType":"S"},{"StatementOptionName":"BY","StatementOptionHelp":{"#cdata":"Precedes an increment integer (other than 0) or an expression that generates an integer to be \nadded to the value of the index variable in each iteration of the DO loop."},"StatementOptionType":"S"}]}},{"StatementName":"END","StatementHelp":{"#cdata":"Syntax: END; \n      \nEnds a DO group or SELECT group processing."},"StatementOptions":null},{"StatementName":"GOTO","StatementHelp":{"#cdata":"Syntax: GOTO label;\n      \nJumps to a new statement."},"StatementOptions":null},{"StatementName":"IF","StatementHelp":{"#cdata":"Executes a SAS statement for observations that meet specific conditions. \n\nSyntax: \n(1) IF expression THEN statement; \n    <ELSE statement;> \n(2) IF condition;"},"StatementOptions":{"StatementOption":[{"StatementOptionName":"THEN","StatementOptionHelp":{"#cdata":"If the conditions that are specified in the IF clause are met, the IF-THEN statement executes a SAS \nstatement for observations that are read from a SAS data set, for records in an external file, or \nfor computed values."},"StatementOptionType":"S"},{"StatementOptionName":"DO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"WHEN","StatementOptionHelp":{"#cdata":"WHEN statement in an IF-THEN-WHEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"OUTPUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"GO TO|GOTO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct. \n          \nSyntax: ... GO TO label; | ... GOTO label;\n      \nJumps to a new statement."},"StatementOptionType":"S"},{"StatementOptionName":"PUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"STOP","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct. \n          \nStops execution of the current DATA step."},"StatementOptionType":"S"},{"StatementOptionName":"SET","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct.\n          \nSyntax: SET <SAS-data-set(s) <(data-set-options(s) )>>; \n      \nReads an observation from one or more SAS data sets."},"StatementOptionType":"S"},{"StatementOptionName":"NOT","StatementOptionType":"S"},{"StatementOptionName":"OR","StatementOptionType":"S"},{"StatementOptionName":"AND","StatementOptionType":"S"}],"#comment":{}}},{"StatementName":"ELSE","StatementHelp":{"#cdata":"If the condition in an IF-THEN statement is false and an ELSE statement is present, \nthen the ELSE action is carried out."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"THEN","StatementOptionHelp":{"#cdata":"If the conditions that are specified in the IF clause are met, the IF-THEN statement executes a SAS \nstatement for observations that are read from a SAS data set, for records in an external file, or \nfor computed values."},"StatementOptionType":"S"},{"StatementOptionName":"IF","StatementOptionHelp":{"#cdata":"Executes a SAS statement for observations that meet specific conditions."},"StatementOptionType":"S"},{"StatementOptionName":"DO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN-ELSE construct."},"StatementOptionType":"S"},{"StatementOptionName":"OUTPUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN-ELSE construct."},"StatementOptionType":"S"},{"StatementOptionName":"NOT","StatementOptionType":"S"},{"StatementOptionName":"OR","StatementOptionType":"S"},{"StatementOptionName":"AND","StatementOptionType":"S"}],"#comment":{}}},{"StatementName":"LINK","StatementHelp":{"#cdata":"Syntax: LINK statement-label; \n      \nDirects program execution immediately to the statement label that is specified and, if followed \nby a RETURN statement, returns execution to the statement that follows the LINK statement."},"StatementOptions":null},{"StatementName":"RETURN","StatementHelp":{"#cdata":"Syntax: RETURN; \n      \nStops executing statements at the current point in the DATA step and returns to a predetermined \npoint in the step."},"StatementOptions":null},{"StatementName":"SELECT","StatementHelp":{"#cdata":"Executes one of several statements or groups of statements.\n      \nSyntax: \nSELECT <(select-expression)>;  \n  WHEN-1 (when-expression-1 <..., when-expression-n>) statement;  \n    <... WHEN-n (when-expression-1 <..., when-expression-n>) statement;>  \n      <OTHERWISE statement;> \nEND;"},"StatementOptions":null},{"StatementName":"WHEN","StatementHelp":{"#cdata":"SELECT groups contain WHEN statements that identify SAS statements that are executed when a particular \ncondition is true. Use at least one WHEN statement in a SELECT group.\n      \nSyntax: WHEN-1 (when-expression-1 <..., when-expression-n>) statement; "},"StatementOptions":{"StatementOption":{"StatementOptionName":"DO","StatementOptionType":"S"}}},{"StatementName":"OTHERWISE","StatementHelp":{"#cdata":"An optional OTHERWISE statement specifies a statement to be executed if no WHEN condition is met. \nAn END statement ends a SELECT group.\n\n      \nSyntax: \n  <... WHEN-n (when-expression-1 <..., when-expression-n>) statement;>  \n    <OTHERWISE statement;>"},"StatementOptions":null},{"StatementName":"STOP","StatementHelp":{"#cdata":"Syntax: STOP ;\n\nThe STOP statement halts the execution of all statements that contain it, including \nDO statements and other control or looping statements. Execution continues with the \nnext top-level source statement."},"StatementOptions":null},{"StatementName":"PUT","StatementHelp":{"#cdata":"Syntax: PUT print-item ...< @ > < @@ > ;\n\nThe PUT statement writes text data to the current output file."},"StatementOptions":{"StatementOption":{"StatementOptionName":"_PAGE_","StatementOptionHelp":{"#cdata":"Outputs any pending line data and moves to the top of the next page."},"StatementOptionType":"S"}}}],"#comment":{}}}}