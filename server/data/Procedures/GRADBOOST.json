{"Procedure":{"Name":"GRADBOOST","ProductGroup":"CAS","#comment":{},"ProcedureHelp":{"#cdata":"Syntax: PROC GRADBOOST <options>; \n    AUTOTUNE <options>; \n    CODE <options>; \n    CROSSVALIDATION <options>; \n    ID variables; \n    INPUT variables </ options>; \n    OUTPUT OUT=CAS-libref.data-table <option>; \n    PARTITION partition-option; \n    SAVESTATE RSTORE=CAS-libref.data-table; \n    TARGET variable </ LEVEL=NOMINAL | INTERVAL>; \n    TRANSFERLEARN variable </ options>; \n    VIICODE <options>; \n    WEIGHT variable; \n    \nThe GRADBOOST procedure creates a predictive model called a gradient boosting model in SAS Viya.\nA gradient boosting model consists of multiple decision trees. A predictive model defines a relationship\nbetween input variables and a target variable. The purpose of a predictive model is to predict a target value\nfrom inputs. The GRADBOOST procedure creates the model by using training data in which the target\nvalues are known. The model can then be applied to observations in which the target is unknown. If the\npredictions fit the new data well, the model is said to generalize well. Good generalization is the primary\ngoal of predictive tasks. A predictive model might fit the training data well but generalize poorly."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"ADDTREES|ADDTREE","ProcedureOptionHelp":{"#cdata":"Adds trees to an already generated gradient boosting model, which is specified in the INMODEL= option."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"Syntax: DATA=CAS-libref.data-table\n      \nNames the input data table for PROC GRADBOOST to use. The default is the most recently created\ndata table. CAS-libref.data-table is a two-level name, where\n\n  CAS-libref refers to a collection of information that is defined in the LIBNAME statement and\n    includes the caslib, which includes a path to the data, and a session identifier, which\n    defaults to the active session but which can be explicitly defined in the LIBNAME\n    statement.\n    \n  data-table specifies the name of the input data table."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"ASSIGNMISSING=","ProcedureOptionHelp":{"#cdata":"Syntax: ASSIGNMISSING=NONE |MACSMALL |USEINSEARCH  \n      \nSpecifies how to handle missing values during training and creates a splitting rule to handle missing\nvalues and unknown levels during scoring. An unknown level is a level of a categorical predictor\nvariable that does not exist in the training data but is encountered during scoring.\n\nBy default, ASSIGNMISSING=USEINSEARCH."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"NONE","@Value2":"MACSMALL","@Value3":"USEINSEARCH"},"ProcedureOptionToolTips":{"@ToolTip1":"During training, excludes observations that have any missing variables from the model.","@ToolTip2":"During training, treats a missing value as a separate, legitimate value in the search for a split for the primary splitting rule.","@ToolTip3":"During training, treats a missing value as a separate, legitimate value in the search for a split for the primary splitting rule."}},{"ProcedureOptionName":"BINMETHOD=","ProcedureOptionHelp":{"#cdata":"Syntax: BINMETHOD=BUCKET | QUANTILE \n      \nSpecifies how to bin interval input variables prior to growing the forest model. The number of bins \nthat are created is determined by the NUMBIN= option."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"BUCKET","@Value2":"QUANTILE"},"ProcedureOptionToolTips":{"@ToolTip1":"Bins interval input variables into fixed-width bins.","@ToolTip2":"Bins interval input variables into bins according to their quantile. "}},{"ProcedureOptionName":"EARLYSTOP","ProcedureOptionHelp":{"#cdata":"Syntax: EARLYSTOP(suboption \u2026) \n      \nSpecifies options for stopping the gradient boosting model training early.\n\nYou can specify one or more of the following suboptions: \nSTAGNATION=number \n  specifies the number of iterations in the gradient boosting model to consider for early stopping, \n  where number must be a nonnegative integer. By default, STAGNATION=0. \n  \nTOLERANCE=number \n  specifies the number to be used as the tolerance for early stopping, where number must be nonnegative. \n  By default TOLERANCE=0."},"ProcedureOptionType":"S","SubOptionsKeywords":"STAGNATION=|TOLERANCE="},{"ProcedureOptionName":"INMODEL=","ProcedureOptionHelp":{"#cdata":"Syntax: INMODEL=CAS-libref.data-table\n      \nSpecifies the data table that you previously saved as a gradient boosting model by using the OUTMODEL=\noption in a previous run of PROC GRADBOOST. CAS-libref.data-table is a two-level name,\nwhere CAS-libref refers to the caslib and session identifier, and data-table specifies the name of the\ninput data table."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"LASSO=|L1=","ProcedureOptionHelp":{"#cdata":"Syntax: LASSO=number | L1=number \n      \nSpecifies the L1 norm regularization parameter, where number must be nonnegative. \n\nBy default, LASSO=0. This value can be tuned with the AUTOTUNE statement. "},"ProcedureOptionType":"V"},{"ProcedureOptionName":"LEARNINGRATE=","ProcedureOptionHelp":{"#cdata":"Syntax: LEARNINGRATE=number\n      \nSpecifies the learning rate for the gradient boosting algorithm.\n\nBy default, LEARNINGRATE=0.1."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MAXBRANCH=","ProcedureOptionHelp":{"#cdata":"Syntax: MAXBRANCH=b\n      \nSpecifies the maximum number of children per node in the tree. PROC GRADBOOST tries to create\nthis number of children unless it is impossible (for example, if a split variable does not have enough\nlevels).\n\nBy default, MAXBRANCH=2."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MAXDEPTH=","ProcedureOptionHelp":{"#cdata":"Syntax: MAXDEPTH=number\n      \nSpecifies the maximum depth of the tree to be grown."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MINLEAFSIZE=","ProcedureOptionHelp":{"#cdata":"Syntax: MINLEAFSIZE=number\n      \nSpecifies the minimum number of observations that each child of a split must contain in the training\ndata table in order for the split to be considered.\n\nBy default, MINLEAFSIZE=1."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MINUSEINSEARCH=","ProcedureOptionHelp":{"#cdata":"Syntax: MINUSEINSEARCH=number\n      \nSpecifies a threshold for using missing values in the split search when ASSIGNMISSING=\nUSEINSEARCH. If the number of observations in which the splitting variable has missing\nvalues is greater than or equal to number, then PROC GRADBOOST uses the USEINSEARCH policy\nto handle missing values for that variable.\n\nBy default, MINUSERINSEARCH=1."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NOPRINT","ProcedureOptionHelp":{"#cdata":"Suppresses ODS output."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NTREES=","ProcedureOptionHelp":{"#cdata":"Syntax: NTREES=number\n      \nSpecifies the number of trees to grow in the gradient boosting model.\n\nBy default, NTREES=100."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NUMBIN=","ProcedureOptionHelp":{"#cdata":"Syntax: NUMBIN=number\n      \nSpecifies the number of bins in which to bin the interval input variables. PROC GRADBOOST bins\ncontinuous predictors to a fixed bin size. This option controls the number of bins and thereby also the\nsize of the bins.\n\nBy default, NUMBIN=100."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"OUTMODEL=","ProcedureOptionHelp":{"#cdata":"Syntax: OUTMODEL=<CAS-libref.>data-table\n      \nSpecifies the data table to which you want to save the gradient boosting model. CAS-libref.data-table is\na two-level name, where CAS-libref refers to the caslib and session identifier, and data-table specifies\nthe name of the output data table. For more information, see the DATA= option and the section \u201cUsing\nCAS Sessions and CAS Engine Librefs\u201d on page 50.\nIf you do not specify a CAS-libref , the data-table is saved to the Work library."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"PRINTTARGET","ProcedureOptionHelp":{"#cdata":"Outputs tables that indicate generated columns in the OUT= table from the OUTPUT statement."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"RBAIMP","ProcedureOptionHelp":{"#cdata":"Creates a variable importance table by using random branch assignment (RBA)."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"RIDGE=|L2=","ProcedureOptionHelp":{"#cdata":"Syntax: RIDGE=number | L2=number \n      \nSpecifies the L2 norm regularization parameter on prediction. The number must be nonnegative. \n\nBy default, RIDGE=0. This value can be tuned with the AUTOTUNE statement."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SAMPLINGRATE=","ProcedureOptionHelp":{"#cdata":"Syntax: SAMPLINGRATE=number\n      \nSpecifies the fraction of the random sample of the training data to be used for growing each tree in the\nboosting model.\n\nBy default, SAMPLINGRATE=0.5."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SEED=","ProcedureOptionHelp":{"#cdata":"Syntax: SEED=number\n      \nSpecifies the initial seed for random number generation for model building. The value of number must\nbe an integer. If you do not specify a seed or you specify a value less than or equal to 0, the seed is\ngenerated from reading the time of day from the computer\u2019s clock."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"VARS_TO_TRY=|M=","ProcedureOptionHelp":{"#cdata":"Syntax: VARS_TO_TRY=m\n      \nSpecifies the number of input variables to consider splitting on in a node, where m ranges from 1 to the\nnumber of input variables.\n\nBy default, m is the square root of the number of input variables."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"VII=|INTERACTIONIMP=","ProcedureOptionHelp":{"#cdata":"Syntax: VII=2|3 | INTERACTIONIMP=2|3 \n      \nCalculates the variable interaction importance, which is described in the section Variable \nnteraction Importance."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"2","@Value2":"3"},"ProcedureOptionToolTips":{"@ToolTip1":"Calculates the importance of all two-way variable interactions. ","@ToolTip2":"Calculates the importance of all three-way and all two-way variable interactions."}}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"AUTOTUNE","StatementHelp":{"#cdata":"Syntax: AUTOTUNE < options > ;\n      \nThe AUTOTUNE statement searches for the best combination of values of the LASSO=, LEARNINGRATE=, NTREES=,\nRIDGE=, SAMPLINGRATE=, and VARS_TO_TRY= options in the PROC GRADBOOST statement. You cannot specify both \nthe AUTOTUNE statement and the CROSSVALIDATION statement in the same procedure run."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"EVALHISTORY=","StatementOptionHelp":{"#cdata":"Syntax: EVALHISTORY=ALL |LOG |NONE |TABLE \n          \nSpecifies how to report the evaluation history of the tuner."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"LOG","@Value3":"NONE","@Value4":"TABLE"},"StatementOptionToolTips":{"@ToolTip1":"Reports each evaluation in the log and creates the EvaluationHistory ODS table. ","@ToolTip2":"Prints the following information to the log for each evaluation: evaluation number, objective value, best objective value up to that point, evaluation time, and elapsed time since the beginning of the  tuning process.","@ToolTip3":"Suppresses reporting of evaluations in the log and does not create the EvaluationHistory ODS table.","@ToolTip4":"Creates the EvaluationHistory ODS table, which contains all evaluated points. The table contains columns  for the evaluation number, all tuning parameters, and the objective function value."}},{"StatementOptionName":"FRACTION=","StatementOptionHelp":{"#cdata":"Syntax: FRACTION=number\n          \nSpecifies the fraction of all data to be used for validation, where number must be between 0.01 and\n0.99, inclusive. If you specify this option, the tuner uses a single partition validation for finding the\nobjective value (validation error estimate). This option might not be advisable for small or unbalanced\ndata tables where the random assignment of the validation subset might not provide a good estimate of\nerror. For large, balanced data tables, a single validation partition is usually sufficient for estimating\nerror; a single partition is more efficient than cross validation in terms of the total execution time.\nBy default, FRACTION=0.3. You cannot specify this option in combination with the KFOLD= option."},"StatementOptionType":"V"},{"StatementOptionName":"KFOLD=","StatementOptionHelp":{"#cdata":"Syntax: KFOLD=number\n          \nSpecifies the number of partition folds in the cross validation process, where number must be between\n2 and 20, inclusive. If you specify this option, the tuner uses cross validation to find the objective value.\nIn cross validation, each model evaluation requires number of training executions (on number\u20131 data\nfolds) and number of scoring executions (on 1 hold-out fold). Thus, the evaluation time is increased by\napproximately number. For small to medium data tables or for unbalanced data tables, cross validation\nprovides on average a better representation of error across the entire data table (a better generalization\nerror).\nBy default, KFOLD=5. You cannot specify this option in combination with the FRACTION= option."},"StatementOptionType":"V"},{"StatementOptionName":"MAXEVALS=","StatementOptionHelp":{"#cdata":"Syntax: MAXEVALS=number \n          \nSpecifies the maximum number of configuration evaluations allowed for the tuner, where number\nmust be an integer greater than or equal to 3. When the number of evaluations is reached, the tuner\nterminates the search and returns the results. To produce a single objective function value (validation\nerror estimate), each configuration evaluation requires either a single model training and scoring\nexecution on a validation partition, or a number of training and scoring executions equal to the value of\nthe KFOLD= option for cross validation. The MAXEVALS= option might lead to termination before\nthe value of the MAXITER= option or the MAXTIME= option is reached.\nBy default, MAXEVALS=50."},"StatementOptionType":"V"},{"StatementOptionName":"MAXITER=","StatementOptionHelp":{"#cdata":"Syntax: MAXITER=number\n          \nSpecifies the maximum number of iterations of the optimization tuner, where number must be greater\nthan or equal to 1. Each iteration normally involves a number of objective evaluations up to the value\nof the POPSIZE= option. The MAXITER= option might lead to termination before the value of the\nMAXEVALS= option or the MAXTIME= option is reached.\nBy default, MAXITER=5."},"StatementOptionType":"V"},{"StatementOptionName":"MAXTIME=","StatementOptionHelp":{"#cdata":"Syntax: MAXTIME=number\n          \nSpecifies the maximum time (in seconds) allowed for the tuner, where number must be greater than or\nequal to 1. When this value is reached, the tuner terminates the search and returns results. The actual\nrun time for optimization might be longer because it includes the remaining time needed to finish\nthe current evaluation. For long-running model training (large data tables), the actual run time might\nsignificantly exceed number. The MAXTIME= option might lead to termination before the value of\nthe MAXEVALS= option or the MAXITER= option is reached.\nBy default, MAXTIME=36000."},"StatementOptionType":"V"},{"StatementOptionName":"NSUBSESSIONWORKERS=","StatementOptionHelp":{"#cdata":"Syntax: NSUBSESSIONWORKERS=number \n          \nSpecifies the number of workers to use in parallel subsessions. When evaluating alternative configurations \nin parallel, a number of subsessions is created by the tuner, with each subsession potentially using multiple \nworkers. The number of workers used in a parallel subsession is determined by using either NSUBSESSIONWORKERS=number, \nif specified, or determined automatically based upon the size of the data."},"StatementOptionType":"V"},{"StatementOptionName":"NPARALLEL=","StatementOptionHelp":{"#cdata":"Syntax: NPARALLEL=number \n          \nSpecifies the number of evaluations to be performed in parallel, where number must be greater than or \nequal to 0. When SEARCHMETHOD=GA is specified, the value of number is equal to the value of the POPSIZE= \noption minus one. When SEARCHMETHOD=LHS or SEARCHMETHOD=RANDOM is specified, the value of number is equal \nto the value of SAMPLESIZE= option."},"StatementOptionType":"V"},{"StatementOptionName":"OBJECTIVE=","StatementOptionHelp":{"#cdata":"Syntax: OBJECTIVE=function \n          \nSpecifies which measure of model performance the tuner uses as the objective function.\n\nBy default, OBJECTIVE=MISC for nominal targets, and OBJECTIVE=MSE for interval targets."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ASE","@Value2":"AUC","@Value3":"F05","@Value4":"F1","@Value5":"GAMMA","@Value6":"GINI","@Value7":"KS","@Value8":"MAE","@Value9":"MCE","@Value10":"MCLL","@Value11":"MISC","@Value12":"MSE","@Value13":"MSLE","@Value14":"RASE","@Value15":"RMAE","@Value16":"RMSLE","@Value17":"TAU"},"StatementOptionToolTips":{"@ToolTip1":"Uses average squared error as the objective function.","@ToolTip2":"Uses area under the curve as the objective function (nominal type only).","@ToolTip3":"Uses the F0.5 coefficient as the objective function (nominal type only). ","@ToolTip4":"Uses the F1 coefficient as the objective function (nominal type only).","@ToolTip5":"Uses the gamma coefficient as the objective function (nominal type only).","@ToolTip6":"Uses the Gini coefficient as the objective function (nominal type only). ","@ToolTip7":"Uses the Kolmogorov-Smirnov coefficient as the objective function (nominal type only).","@ToolTip8":"Uses the mean absolute error as the objective function (interval type only).","@ToolTip9":"Uses the misclassification rate as the objective function (nominal type only).","@ToolTip10":"Uses the multiclass log loss as the objective function (nominal type only).","@ToolTip11":"Uses the misclassification error percentage as the objective function (nominal type only).","@ToolTip12":"Uses the mean squared error as the objective function (interval type only).","@ToolTip13":"Uses the mean squared logarithmic error as the objective function (interval type only).","@ToolTip14":"Uses the root average squared error as the objective function.","@ToolTip15":"Uses the root mean absolute error as the objective function (interval type only).","@ToolTip16":"Uses the root mean squared logarithmic error as the objective function (interval type only).","@ToolTip17":"Uses the tau coefficient as the objective function (nominal type only)."}},{"StatementOptionName":"POPSIZE=","StatementOptionHelp":{"#cdata":"Syntax: POPSIZE=number\n          \nSpecifies the maximum number of evaluations in one iteration (population), where number must\nbe greater than or equal to 1. In some cases, the tuner algorithm might generate a number of new\nconfigurations smaller than number.\nBy default, POPSIZE=10."},"StatementOptionType":"V"},{"StatementOptionName":"SAMPLESIZE=","StatementOptionHelp":{"#cdata":"Syntax: SAMPLESIZE=number \n          \nSpecifies the total number of evaluations, where number must be greater than or equal to 1. \nYou can specify this option when SEARCHMETHOD=RANDOM or SEARCHMETHOD=LHS. This option is \nignored when SEARCHMETHOD=GA. \n\nBy default, SAMPLESIZE=50."},"StatementOptionType":"V"},{"StatementOptionName":"SEARCHMETHOD=","StatementOptionHelp":{"#cdata":"Syntax: SEARCHMETHOD=BAYESIAN| GA |LHS |RANDOM \n          \nSpecifies the search method to use for tuning.\n\nBy default, SEARCHMETHOD=GA."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BAYESIAN","@Value2":"GA","@Value3":"LHS","@Value4":"RANDOM"},"StatementOptionToolTips":{"@ToolTip1":"Builds a Kriging surrogate model to approximate the objective value, and uses this surrogate model  for generating new alternative configurations at each iteration.","@ToolTip2":"Uses an initial Latin hypercube sample that seeds a genetic algorithm to generate a new population  of alternative configurations at each iteration.","@ToolTip3":"Uses a Latin hypercube to generate a single sample of configurations that is uniform in each tuning  parameter, but random in combinations.","@ToolTip4":"Generates a single sample of purely random configurations. "}},{"StatementOptionName":"TARGETEVENT=","StatementOptionHelp":{"#cdata":"Syntax: TARGETEVENT=string \n          \nSpecifies the target event to use for calculating the selected objective function. This option \nis ignored when the value of the OBJECTIVE= option is not AUC, F1, F05, GINI, GAMMA, TAU, or KS."},"StatementOptionType":"V"},{"StatementOptionName":"TUNINGPARAMETERS=","StatementOptionHelp":{"#cdata":"Syntax: TUNINGPARAMETERS=(suboption |\u2026|<suboption>) \nSyntax: TUNEPARMS=(suboption |\u2026|<suboption>) \n\nSpecifies which parameters to tune and which ranges to tune over. If USEPARAMETERS=STANDARD, \nthis option is ignored. \n\nFor more information about which tuning suboptions are available, see the specific procedure chapters."},"StatementOptionType":"V","SubOptionsKeywords":"NFACTORS|LB=|UB=|VALUES=|INIT=|EXCLUDE|LEARNSTEP|MAXITER"},{"StatementOptionName":"USEPARAMETERS=","StatementOptionHelp":{"#cdata":"Syntax: USEPARAMETERS=tuning-parameter-option \n          \nSpecifies how to handle the TUNINGPARAMETERS= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"STANDARD","@Value2":"CUSTOM","@Value3":"COMBINED"},"StatementOptionToolTips":{"@ToolTip1":"Tunes using the default bounds and initial values for all parameters.","@ToolTip2":"Tunes only the parameters that are specified in the TUNINGPARAMETERS= option.","@ToolTip3":"Tunes the parameters that are specified in the TUNINGPARAMETERS= option and uses default bounds  and initial values to tune all other parameters."}}]}},{"StatementName":"CODE","StatementHelp":{"#cdata":"Syntax: CODE < options > ;\n      \nThe CODE statement writes SAS DATA step code for computing predicted values of the fitted model either\nto a file or to a catalog entry. This code can then be included in a DATA step to score new data."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"COMMENT","StatementOptionHelp":{"#cdata":"Adds comments to the generated code."},"StatementOptionType":"V"},{"StatementOptionName":"FILE=","StatementOptionHelp":{"#cdata":"Syntax: FILE=filename \n          \nNames the file where the generated code is saved."},"StatementOptionType":"V"},{"StatementOptionName":"FORMATWIDTH=","StatementOptionHelp":{"#cdata":"Syntax: FORMATWIDTH=width\n          \nSpecifies the numeric format width for the regression coefficients."},"StatementOptionType":"V"},{"StatementOptionName":"INDENTSIZE=","StatementOptionHelp":{"#cdata":"Syntax: INDENTSIZE=number\n          \nSpecifies the number of spaces to indent the generated code."},"StatementOptionType":"V"},{"StatementOptionName":"LABELID=","StatementOptionHelp":{"#cdata":"Syntax: LABELID=id\n          \nSpecifies a number used to construct names and labels."},"StatementOptionType":"V"},{"StatementOptionName":"LINESIZE=","StatementOptionHelp":{"#cdata":"Syntax: LINESIZE=number\n          \nSpecifies the line size for the generated code."},"StatementOptionType":"V"},{"StatementOptionName":"NOTRIM","StatementOptionHelp":{"#cdata":"Compares formatted values, including blank padding."},"StatementOptionType":"S"},{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"Syntax: OUT=CAS-libref.data-table \n          \nCreates a CAS table that contains the score code. CAS-libref.data-table is a two-level name, \nwhere CAS-libref refers to the caslib and session identifier, and data-table specifies the \nname of the output data table."},"StatementOptionType":"V"}]}},{"StatementName":"CROSSVALIDATION","StatementHelp":{"#cdata":"Syntax: CROSSVALIDATION <KFOLD=number > ;\n      \nThe CROSSVALIDATION statement performs a k-fold cross validation process to find the average estimated\nvalidation error. You cannot specify the CROSSVALIDATION statement if you specify either the\nAUTOTUNE statement or the PARTITION statement."},"StatementOptions":{"StatementOption":{"StatementOptionName":"KFOLD=","StatementOptionHelp":{"#cdata":"Syntax: KFOLD=number\n          \nSpecifies the number of partition folds in the cross validation process, where number must be between\n2 and 20, inclusive.\n\nBy default, KFOLD=5."},"StatementOptionType":"V","#text":" />\n        "}}},{"StatementName":"ID","StatementHelp":{"#cdata":"Syntax: ID variables;\n\nThe ID statement lists one or more variables that are to be copied from the input data table to the \noutput data tables that are specified in the OUT= option in the OUTPUT statement and the RSTORE= option \nin the SAVESTATE statement."},"StatementOptions":null},{"StatementName":"INPUT","StatementHelp":{"#cdata":"Syntax: INPUT variables < / LEVEL=NOMINAL | INTERVAL > ;\n      \nThe INPUT statement names input variables that share common options. The INPUT statement can be\nrepeated."},"StatementOptions":{"StatementOption":{"StatementOptionName":"LEVEL=","StatementOptionHelp":{"#cdata":"Syntax: LEVEL=NOMINAL | INTERVAL\n          \nSpecifies the level of measurement of two variables.\n\nBy default, LEVEL=INTERVAL for numeric variables and LEVEL=NOMINAL for categorical variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"NOMINAL","@Value2":"INTERVAL"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the level of measurement of the variables is nominal.","@ToolTip2":"Specifies that the level of measurement of the variables is interval."}}}},{"StatementName":"OUTPUT","StatementHelp":{"#cdata":"Syntax: OUTPUT OUT=CAS-libref.data-table < option > ;\n      \nThe OUTPUT statement creates an output data table that contains the results of running PROC GRADBOOST."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"Syntax: OUT=CAS-libref.data-table\nnames the output data table for PROC GRADBOOST to use. CAS-libref.data-table is a two-level name,\nwhere\n\n  CAS-libref refers to a collection of information that is defined in the LIBNAME statement and\n    includes the caslib, which includes a path to where the data table is to be stored, and\n    a session identifier, which defaults to the active session but which can be explicitly\n    defined in the LIBNAME statement.\n    \n  data-table specifies the name of the output data table."},"StatementOptionType":"V"},{"StatementOptionName":"COPYVAR=|COPYVARS=","StatementOptionHelp":{"#cdata":"Syntax: COPYVAR=variable | COPYVARS=(variables)\n          \nLists one or more variables from the input data table to be transferred to the output data table."},"StatementOptionType":"V"},{"StatementOptionName":"ROLE","StatementOptionHelp":{"#cdata":"Syntax: ROLE<=name> \n          \nGenerates a numeric variable that indicates the role played by each observation in fitting the model. \nBy default, the variable is named _ROLE_."},"StatementOptionType":"S|V"}]}},{"StatementName":"PARTITION","StatementHelp":{"#cdata":"Syntax: PARTITION partition-option ;\n      \nThe PARTITION statement specifies how observations in the input data set are logically partitioned into\ndisjoint subsets for model training, validation, and testing"},"StatementOptions":{"StatementOption":[{"StatementOptionName":"FRACTION","StatementOptionHelp":{"#cdata":"Syntax: FRACTION(< TEST=fraction > < VALIDATE=fraction > < SEED=number >)\n          \nRandomly assigns specified proportions of the observations in the input data table to the roles. You\nspecify the proportions for testing and validation by using the TEST= and VALIDATE= suboptions.\nIf you specify both the TEST= and VALIDATE= suboptions, then the sum of the specified fractions\nmust be less than 1 and the remaining fraction of the observations are assigned to the training role. The\nSEED= option specifies an integer that is used to start the pseudorandom number generator for random\npartitioning of data for training, testing, and validation. If you do not specify SEED=number or if\nnumber is less than or equal to 0, the seed is generated by reading the time of day from the computer\u2019s"},"StatementOptionType":"V","SubOptionsKeywords":"VALIDATE=|TEST=|SEED="},{"StatementOptionName":"ROLE=|ROLEVAR=","StatementOptionHelp":{"#cdata":"Syntax: ROLE=|ROLEVAR=variable (< TEST='value' > < TRAIN='value' > < VALIDATE='value' >)  \n\nNames the variable in the input data table whose values are used to assign roles to each observation.\nThis variable cannot also appear as an analysis variable in other statements or options. The TEST=,\nTRAIN=, and VALIDATE= suboptions specify the formatted values of this variable that are used to\nassign observation roles. If you do not specify the TRAIN= suboption, then all observations whose\nrole is not determined by the TEST= or VALIDATE= suboption are assigned to the training role."},"StatementOptionType":"V","SubOptionsKeywords":"TRAIN=|VALIDATE=|TEST="}]}},{"StatementName":"SAVESTATE","StatementHelp":{"#cdata":"Syntax: SAVESTATE RSTORE=CAS-libref.data-table;  \n      \nThe SAVESTATE statement creates an analytic store for the model and saves it as a binary object \nin a data table. You can use the analytic store in the ASTORE procedure to score new data."},"StatementOptions":{"StatementOption":{"StatementOptionName":"RSTORE=","StatementOptionHelp":{"#cdata":"Syntax: RSTORE=CAS-libref.data-table \n          \nSpecifies a data table in which to save the analytic store for the model. CAS-libref.data-table \nis a two-level name, where CAS-libref refers to the caslib and session identifier, and data-table \nspecifies the name of the output data table."},"StatementOptionType":"V"}}},{"StatementName":"TARGET","StatementHelp":{"#cdata":"Syntax: TARGET variable < / LEVEL=NOMINAL | INTERVAL > ;\n      \nThe TARGET statement names the variable whose values PROC GRADBOOST predicts."},"StatementOptions":{"StatementOption":{"StatementOptionName":"LEVEL=","StatementOptionHelp":{"#cdata":"Syntax: INPUT variables / < LEVEL= NOMINAL | INTERVAL > ; \n          \nSpecifies the level of measurement.\n\nBy default, LEVEL=INTERVAL for numeric variables and LEVEL=NOMINAL for categorical\nvariables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"NOMINAL","@Value2":"INTERVAL"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the level of measurement of the variables is nominal.","@ToolTip2":"Specifies that the level of measurement of the variables is interval."}}}},{"StatementName":"TRANSFERLEARN","StatementHelp":{"#cdata":"Syntax: TRANSFERLEARN variable </ options>;\n\nThe TRANSFERLEARN statement enables you to train the gradient boosting model by using auxiliary \ndata that are added to your training data. "},"StatementOptions":{"StatementOption":[{"StatementOptionName":"BURN=","StatementOptionHelp":{"#cdata":"Syntax: BURN=number \n          \nSpecifies the number of trees to create before downweighting any observation in the auxiliary data. \n\nBy default, BURN=0."},"StatementOptionType":"V"},{"StatementOptionName":"SHRINKAGE=","StatementOptionHelp":{"#cdata":"Syntax: SHRINKAGE=number \n          \nSpecifies the number to apply as the weighting factor for downweighting auxiliary data, where number \nmust be between 0 and 1, exclusive. \nBy default, SHRINKAGE=0.9."},"StatementOptionType":"V"},{"StatementOptionName":"TRIMMING=","StatementOptionHelp":{"#cdata":"Syntax: TRIMMING=number \n          \nSpecifies the number to use as a fraction of the distribution of gradients on the training data \nbeyond which auxiliary observations are downweighted, where number must be greater than 0 less \nthan or equal to 1/2. \n\nBy default, TRIMMING=0.01."},"StatementOptionType":"V"}]}},{"StatementName":" VIICODE","StatementHelp":{"#cdata":"Syntax: VIICODE <options>;\n\nThe VIICODE statement writes SAS DATA step code to a file or to a catalog entry. The SAS DATA step \ncode creates new variables on the basis of the detected variable interactions. "},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADD","StatementOptionHelp":{"#cdata":"Requests that the newly created variables be of the form V + W."},"StatementOptionType":"S"},{"StatementOptionName":"IMIT=","StatementOptionHelp":{"#cdata":"Syntax: IMIT=number \n          \nSpecifies the maximum number of new variables to create. By default, LIMIT=200. "},"StatementOptionType":"V"},{"StatementOptionName":"MISS","StatementOptionHelp":{"#cdata":"Requests that the generated code handle missing values."},"StatementOptionType":"V"},{"StatementOptionName":"MULTIPLY","StatementOptionHelp":{"#cdata":"Requests that the newly created variables be of the form V x W."},"StatementOptionType":"V"},{"StatementOptionName":"SUBSTRACT","StatementOptionHelp":{"#cdata":"Requests that the newly created variables be of the form V - W."},"StatementOptionType":"V"},{"StatementOptionName":"THRESHOLD=","StatementOptionHelp":{"#cdata":"Syntax: THRESHOLD=number \n          \nRequests that interactions with an importance less than number times the maximum interaction importance \nbe ignored, where number must be between 0 and 1. By default, THRESHOLD=0.0001."},"StatementOptionType":"V"}]}},{"StatementName":"WEIGHT","StatementHelp":{"#cdata":"Syntax: WEIGHT variable;\n\nThe variable in the WEIGHT statement is used as a weight to perform a weighted analysis of the data. \nObservations that have nonpositive or missing weights are not included in the analysis. If a WEIGHT \nstatement is not included, all observations that are used in the analysis are assigned a weight of 1."},"StatementOptions":null}]}}}