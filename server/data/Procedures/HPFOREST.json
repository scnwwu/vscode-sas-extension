{"Procedure":{"Name":"HPFOREST","ProductGroup":"Enterprise Miner/HPA","#comment":{},"ProcedureHelp":{"#cdata":"Syntax: PROC HPFOREST <options>; \n    FREQ variable; \n    INPUT variables <options>; \n    ID variables; \n    PARTITION ROLEVAR=variable <TRAIN='value'> <VALIDATE='value'> ; \n    PERFORMANCE performance-options; \n    SAVE <options>; \n    SCORE <score-options>; \n    TARGET variable <options>; \n    TREATMENT variable <ORDER=order>; \n    \nThe HPFOREST procedure is a high-performance procedure that creates a predictive model called a forest\nthat consists of several decision trees. A predictive model defines a relationship between input variables and\na target variable. The purpose of a predictive model is to predict a target value from inputs. The HPFOREST\nprocedure trains the model; that is, it creates the model, using training data in which the target values are\nknown. The model can then be applied to observations in which the target is unknown. If the predictions\nfit the new data well, the model is said to generalize well. Good generalization is the primary goal for\npredictive tasks. A predictive model might fit the training data well but generalize poorly.\n\nA decision tree is a type of predictive model that has been developed independently in the statistics and\nartificial intelligence communities. The HPFOREST procedure creates a tree recursively. An input variable\nis chosen and used to create a rule to split the data into two segments. The process is then repeated in each\nsegment, and then again in each new segment, and so on until some constraint is met. In the terminology of\nthe tree metaphor, the segments are nodes, the original data set is the root node, and the final unpartitioned\nsegments are leaves or terminal nodes. A node is an internal node if it is not a leaf. The data in a leaf\ndetermine the estimates of the value of the target variable. These estimates are subsequently applied to\npredict the target of a new observation assigned to the leaf."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"Syntax: DATA= <libref.>SAS-data-set\n      \nNames the SAS data set to be used by PROC HPFOREST for training the model. The default is the\nmost recently created data set.\n\nIf the data are already distributed, the procedure reads the data alongside the distributed database.\nSee the section \u201cSMP and MPP Modes\u201d on page 10 for the various execution modes and the section\n\u201cAlongside-the-Database Execution\u201d on page 15 for the alongside-the-database model. Data from\nall the computer grid nodes are combined into a structure that is optimized for model training and\nredistributed to the nodes. The different nodes then proceed independently with identical data to\ncreate decision trees."},"ProcedureOptionType":"DV|RV"},{"ProcedureOptionName":"ALPHA=","ProcedureOptionHelp":{"#cdata":"Syntax: ALPHA=number\n      \nSpecifies a threshold p-value for the significance level of a test of association of \na candidate variable with the target. If no association meets this threshold, the node \nis not split. The default value is 0.05."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"BALANCE=","ProcedureOptionHelp":{"#cdata":"Syntax: BALANCE=YES | NO\n      \nSpecifies whether to modify the splitting criterion for a nominal target so that the number \nof observations in each target class are effectively equal. A weight is applied to the count \nof observations in a class. The weight is different in different nodes."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"YES","@Value2":"NO"},"ProcedureOptionToolTips":{"@ToolTip1":"Modifies the splitting criterion so that the number of observations in each target class are effectively equal.","@ToolTip2":"Does not modify the splitting criterion."}},{"ProcedureOptionName":"CATBINS=","ProcedureOptionHelp":{"#cdata":"Syntax: CATBINS=k \n      \nSpecifies the maximum number of categories of a nominal candidate variable to use in the association\ntest. k refers only to the categories that are present in the training data in the node and that satisfy\nthe MINCATSIZE= option. The categories are counted independently in each node. If more than k\n\ncategories are present, then the least frequent categories are removed from the association test. Many\ninfrequent categories can dilute a strong predictive ability of common categories. The search for a\nsplitting rule uses all categories that satisfy the MINCATSIZE= options. The value of k must be a\npositive integer. The default value is 30."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"EXHAUSTIVE=","ProcedureOptionHelp":{"#cdata":"Syntax: EXHAUSTIVE=number\n      \nSpecifies the maximum number of splits to examine in a complete enumeration of all possible splits\nwhen the input variable is nominal and the target has more than two nominal categories. The exhaustive\nmethod of searching for a split examines all possible splits. If the number of possible splits is\ngreater than number, then a heuristic search is done instead of an exhaustive search. The default value\nof number is 5,000."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"GRIDCLASSSIZE=","ProcedureOptionHelp":{"#cdata":"Syntax: GRIDCLASSSIZE=n \n      \nSpecifies the minimum number of observations of any value of a binary or nominal target \nto exist on a grid node when GRIDCOPY=MINIMAL is specified."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"GRIDCOPY=","ProcedureOptionHelp":{"#cdata":"Syntax: GRIDCOPY=ALL | MINIMAL | NONE | TRAINING \n      \nSpecifies how many observations to copy between grid nodes when PROC HPFOREST runs in distributed mode."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"ALL","@Value2":"MINIMAL","@Value3":"NONE","@Value4":"TRAINING"},"ProcedureOptionToolTips":{"@ToolTip1":"Copies all training and validation data.","@ToolTip2":"Copies enough training data to achieve a minimum on each node.","@ToolTip3":"Does not copy any observations. ","@ToolTip4":"Copies all training data."}},{"ProcedureOptionName":"INBAGFRACTION=","ProcedureOptionHelp":{"#cdata":"Syntax: INBAGFRACTION=f \n      \nSpecifies the fraction of training observations to train a tree with, where f can be any number \ngreater than 0 and at most 1. Using less than all the available data often improves the generalization \nerror. A different in-bag sample is taken for each tree. The default value of f is 0.6."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"INBAGN=","ProcedureOptionHelp":{"#cdata":"Syntax: INBAGN=n \n      \nSpecifies how many observations to use to train each tree. The observations are counted without \nregard to the variable specified in the FREQ statement. Using less than all the available data \noften improves the generalization error. A different in-bag sample is taken for each tree. n can \nbe any positive integer. If n is greater than the number of observations in the data set specified \nin the DATA= option, then all the available data are used. n must be at least 3 and large enough \nto accommodate the values of the LEAFSIZE=, LEAFFRACTION=, and SPLITSIZE options. The default \nvalue is 0.6 times the number of available observations in DATA= data set."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"INTERVALBINS=","ProcedureOptionHelp":{"#cdata":"Syntax: INTERVALBINS=k \n      \nSpecifies the number of equally spaced bins into which variables are divided when the \nPRESELECT=BINNEDSEARCH algorithm is executed. The default value is 100."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"LEAFFRACTION=","ProcedureOptionHelp":{"#cdata":"Syntax: LEAFFRACTION=f\n      \nSpecifies the smallest number of training observations that a new branch can have, expressed as the\nfraction of the number N of available observations in the DATA= data set. N might be less than\nthe total number of observations in the data set because observations with a missing target value\nor nonpositive value of the variable specified in the FREQ statement are excluded from N. If you\nspecify a number in the LEAFSIZE= option that implies a larger number than that specified in the\nLEAFFRACTION= option, f is ignored. The value f must be larger than 0 and less than 1. The default\nvalue is 0.001."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"LEAFSIZE=","ProcedureOptionHelp":{"#cdata":"Syntax: LEAFSIZE=n\n      \nSpecifies the smallest number of training observations a new branch can have. If you \nspecify a value for the LEAFFRACTION= option that implies a larger value than n, the \nLEAFSIZE= option is ignored. The default value is 5."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MAXDEPTH=","ProcedureOptionHelp":{"#cdata":"Syntax: MAXDEPTH=d \n      \nSpecifies the maximum depth of a node in any tree that PROC HPFOREST creates. The depth \nof a node equals the number of splitting rules needed to define the node. The root node \nhas depth 0. The children of the root have depth 1, and on. The smallest acceptable value \nof d is 1. The default value of d is 50."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MAXTREES=","ProcedureOptionHelp":{"#cdata":"Syntax: MAXTREES=n \n      \nSpecifies the number of trees in the forest. n is a positive integer. The number of \ntrees in the resulting forest can be less than n when the HPFOREST procedure fails \nto split the training data for a tree. Up to two times n trees are attempted. If the \nprocedure fails to split the training data for more than n trees, then less than n \ntrees are created. The ALPHA=, LEAFSIZE=, and MINCATSIZE= options constrain the split \nsearch to form trees that are more likely to predict well using new data. Setting all\nof these options to 1 generally frees the search algorithm to find a split and train \na tree, although the tree might not help the forest predict well. The default value \nof n is 50."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MINCATSIZE=","ProcedureOptionHelp":{"#cdata":"Syntax: MINCATSIZE=n \n      \nSpecifies the minimum number of observations that a given nominal input category must \nhave in order to use the category in a split search. Categorical values that appear in \nfewer than n observations are handled as if they were missing. The categories that occur \nin fewer than n observations are merged into the pseudo category for missing values for \nthe purpose of finding a split. The policy for assigning such observations to a branch \nis the same as the policy for assigning missing values to a branch. The default value \nof n is 5."},"ProcedureOptionType":"V"},{"ProcedureOptionName":" MINUSEINSEARCH=","ProcedureOptionHelp":{"#cdata":"Syntax: MINUSEINSEARCH=n \n      \nSpecifies a threshold for utilizing missing values in the split search when MISSING=USEINSEARCH\nis specified as the missing value policy. If the number of observations in which the splitting variable\nhas missing values in a node is greater than or equal to n, then PROC HPFOREST initiates the\nUSEINSEARCH policy for missing values."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MISSING=","ProcedureOptionHelp":{"#cdata":"Syntax: MISSING=USEINSEARCH | DISTRIBUTE \n      \nSpecifies how the training procedure handles an observation with missing values. If MISSING=\nUSEINSEARCH and the number of training observations in the node is more than n, where n is\nthe value of the MINUSEINSEARCH= option, then the missing value is used as a separate, legitimate\nvalue in the test of association and the split search. If MISSING=DISTRIBUTE, observations with\na missing value of the candidate variable are omitted from the test of association and split search in\nthat node. A splitting rule distributes such an observation to all branches."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"USEINSEARCH","@Value2":"DISTRIBUTE"},"ProcedureOptionToolTips":{"@ToolTip1":"If MISSING= USEINSEARCH and the number of training observations in the node is more than n,  where n is the value of the MINUSEINSEARCH= option, then the missing value is used as a  separate, legitimate value in the test of association and the split search.","@ToolTip2":"If MISSING=DISTRIBUTE, observations with a missing value of the candidate variable are omitted  from the test of association and split search in that node. A splitting rule distributes such  an observation to all branches."}},{"ProcedureOptionName":"NODESIZE=","ProcedureOptionHelp":{"#cdata":"Syntax: NODESIZE=n | ALL \n      \nSpecifies the number of training observations to use for association tests and split searches. \nNODESIZE=ALL requests to use all the observations. The acceptable range is from two to two \nbillion on most machines. The default value of n is 100,000."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"PRESELECT=","ProcedureOptionHelp":{"#cdata":"Syntax: PRESELECT=BINNEDSEARCH | LOH | HOTHORN \n      \nSpecifies the method for selecting the variable to split with."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"BINNEDSEARCH","@Value2":"LOH","@Value3":"HOTHORN"},"ProcedureOptionToolTips":{"@ToolTip1":"Selects the variable that produces the rule that has the largest worth.","@ToolTip2":"selects the variable that has the smallest p-value of a chi-square test of association in a  contingency table.","@ToolTip3":"selects the variable that produces the rule that has the highest association with the target."}},{"ProcedureOptionName":"PRUNEFRACTION=","ProcedureOptionHelp":{"#cdata":"Syntax: PRUNEFRACTION=g \n      \nSpecifies the fraction of training observations that are available for pruning a split. The value \nof g can be any number from 0 and to 1, although a number close to 1 would leave little to grow \nthe tree. The default value of g is 0; the default action is to not prune."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"PRUNETHRESHOLD=","ProcedureOptionHelp":{"#cdata":"Syntax: PRUNETHRESHOLD=t \n      \nSpecifies the lower limit of allowable shrinkage when the distance of the child node from the parent \nis measured by the pruning data instead of the in-bag data. The value of t must be between 0 and 1. \nThe default value of t is 0.1."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SCOREPROLE=","ProcedureOptionHelp":{"#cdata":"Syntax: SCOREPROLE=DEFAULT | INBAG | OOB | VALID \n      \nSpecifies which observations are used for the prediction of a new observation in the SCORE statement."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"DEFAULT","@Value2":"INBAG","@Value3":"OOB","@Value4":"VALID"},"ProcedureOptionToolTips":{"@ToolTip1":"Selects the default value as if the option was not specified. ","@ToolTip2":"Outputs predictions that are based on in-bag observations.","@ToolTip3":"Outputs predictions that are based on out-of-bag observations.","@ToolTip4":"Outputs predictions that are based on validation observations."}},{"ProcedureOptionName":"SEED=","ProcedureOptionHelp":{"#cdata":"Syntax: SEED=n \n      \nSpecifies the seed for generating random numbers. The HPFOREST procedure uses random \nnumbers to select training observations for each tree and to select candidate variables \nin each node to split on. n is a nonnegative integer. Set n to 0 to use the internal \ndefault. The default value of the seed is 8,976,153."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SKIP_SEQ_ROWS=","ProcedureOptionHelp":{"#cdata":"Syntax: SKIP_SEQ_ROWS=n \n      \nSpecifies the number of rows to skip in the \"Fit Statistics\" table in distributed mode. \nAfter every n trees that are trained on a grid node, the fit statistics on the node are \nupdated, consolidated with statistics from other nodes, and eventually output in the \n\"Fit Statistics\" table."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SPLITSIZE=","ProcedureOptionHelp":{"#cdata":"Syntax: SPLITSIZE=n \n      \nSpecifies the requisite number of training observations a node must have for the \nHPFOREST procedure to consider splitting it. By default, n is twice the value of \nthe LEAFSIZE= option (or n is the value implied by LEAFFRACTION= option if the \nprocedure ignores the LEAFSIZE= option). The procedure counts the number of \nobservations in a node without adjusting the number with the values of the variable \nspecified in the FREQ statement when it interprets the value specified in the\nLEAFFRACTION=, LEAFSIZE=, MINCATSIZE=, and SPLITSIZE= options."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"VARS_TO_TRY=","ProcedureOptionHelp":{"#cdata":"Syntax: VARS_TO_TRY=m | ALL \nspecifies the number of input variables to consider splitting on in a node. m ranges from \n1 to the number of input variables, v. The default value of m is square root of v. Specify \nVARS_TO_TRY=ALL to use all the inputs as candidates in a node."},"ProcedureOptionType":"V"}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"FREQ","StatementHelp":{"#cdata":"Syntax: FREQ variable ;\n\nThe variable in the FREQ statement identifies a numeric variable in the data set that \ncontains the frequency of occurrence for each observation. SAS High-Performance Analytics \nprocedures that support the FREQ statement treat each observation as if it appeared f \ntimes, where f is the value of the FREQ variable for the observation. If the frequency \nvalue is not an integer, it is truncated to an integer. If the frequency value is less \nthan 1 or missing, the observation is not used in the analysis. When the FREQ statement \nis not specified, each observation is assigned a frequency of 1."},"StatementOptions":null},{"StatementName":"INPUT","StatementHelp":{"#cdata":"Syntax: INPUT variable(s) < / option(s) > ; \n      \nThe INPUT statement names input variables with common options. The INPUT statement \ncan be repeated."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"LEVEL=","StatementOptionHelp":{"#cdata":"Syntax: LEVEL=level \n          \nSpecifies the level of measurement of the variables. Accepted values of level are: BINARY, NOMINAL,\nORDINAL, and INTERVAL."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BINARY","@Value2":"NOMINAL","@Value3":"ORDINAL","@Value4":"INTERVAL"},"StatementOptionToolTips":{"@ToolTip1":"Binary level of measurement","@ToolTip2":"Nominal level of measurement","@ToolTip3":"Ordinal level of measurement","@ToolTip4":"Interval level of measurement"}},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"Syntax: ORDER=order \n          \nSpecifies the sorting order of the values of an ordinal input variable."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ASCENDING","@Value2":"ASCFORMATTED","@Value3":"DESCENDING","@Value4":"DESFORMATTED","@Value5":"DSORDER"},"StatementOptionToolTips":{"@ToolTip1":"Ascending order of unformatted values (default)","@ToolTip2":"Ascending order of formatted values","@ToolTip3":"Descending order of unformatted values","@ToolTip4":"Descending order of formatted values","@ToolTip5":"Order of appearance in the input data set"}}]}},{"StatementName":"ID","StatementHelp":{"#cdata":"Syntax: ID variables;\n\nThe ID statement lists one or more variables from the input data set that are transferred to the \noutput data set that is specified in the SCORE statement. By default, high-performance analytical \nprocedures do not include all variables from the input data set in output data sets.\n\nThe ID statement is optional."},"StatementOptions":null},{"StatementName":"PARTITION","StatementHelp":{"#cdata":"Syntax: PARTITION ROLEVAR=variable <TRAIN='value'> <VALIDATE='value'> ;\n\nThe PARTITION statement specifies how to divide the input data set into a training subset and \na validation subset. Variable names the variable in the input data set whose values are used \nto assign roles to each observation."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ROLEVAR=","StatementOptionHelp":{"#cdata":"Syntax: ROLEVAR=variable <TRAIN='value'> <VALIDATE='value'> ;\n\nNames the variable in the input data table whose values are used to assign roles to each observation.\nThis variable cannot also appear as an analysis variable in other statements or options. The TRAIN=, \nand VALIDATE= suboptions specify the formatted values of this variable that are used to assign observation \nroles. If you do not specify the TRAIN= suboption, then all observations whose role is not determined \nby the VALIDATE= suboption are assigned to the training role."},"StatementOptionType":"V"},{"StatementOptionName":"TRAIN=","StatementOptionHelp":{"#cdata":"Syntax: TRAIN=value \n          \nRequests that an observation be assigned to training if it matches value."},"StatementOptionType":"V"},{"StatementOptionName":"VALIDATE=","StatementOptionHelp":{"#cdata":"Syntax: VALIDATE=value \n          \nRequests that an observation be assigned to validation if it matches value."},"StatementOptionType":"V"}]}},{"StatementName":"PERFORMANCE","StatementHelp":{"#cdata":"Syntax: PERFORMANCE < performance-options > ;\n      \nThe PERFORMANCE statement defines performance parameters for multithreaded and distributed computing,\npasses variables about the distributed computing environment, and requests detailed results about the\nperformance characteristics of the HPFOREST procedure. \n\nWith the PERFORMANCE statement, you can also control whether the HPFOREST procedure executes in\nsymmetric multiprocessing or massively parallel mode."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"BPC=","StatementOptionHelp":{"#cdata":"Syntax: BPC=n \n          \nSpecifies the number of bytes per character that is used in processing character strings in multibyte \nencodings. The default is the bytes per character of the encoding."},"StatementOptionType":"V"},{"StatementOptionName":"COMMIT=","StatementOptionHelp":{"#cdata":"Syntax: COMMIT=n\n          \nRequests that the High-Performance Analytics procedure write periodic updates to the \nSAS Log when observations are sent from the client to the appliance for distributed \nprocessing.\n\nHigh-Performance Analytics procedures do not have to use input data that are stored \nin the appliance. You can perform distributed computations regardless of the origin \nor format of the input data, provided the data are in a format that can be read by \nthe SAS System (for example, because a SAS/ACCESS engine is available)."},"StatementOptionType":"V"},{"StatementOptionName":"CPUCOUNT=","StatementOptionHelp":{"#cdata":"Syntax: CPUCOUNT=ACTUAL | num\n          \nSpecifies how many processors the procedure assumes are available on each host in the \ncomputing environment. num can be any integer from 1 to 256.\n\nCPUCOUNT=ACTUAL sets CPUCOUNT to the number of physical processors available. This number\ncan be less than the physical number of CPUs if the SAS process has been restricted by system\nadministration tools. Setting CPUCOUNT= to a number greater than the actual number of available\nCPUs might result in reduced performance. This option overrides the CPUCOUNT= SAS system\noption.\n\nIf a High-Performance Analytics procedure executes in SMP mode, this option refers to the client\nmachine of the SAS session. In MPP mode, this option applies to the nodes on the appliance."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ACTUAL","@Value2":"<num>"},"StatementOptionToolTips":{"@ToolTip1":"Sets CPUCOUNT to the number of physical processors available. This number can be less than the physical number of CPUs if the SAS process has been restricted by system administration tools.","@ToolTip2":"Replace <num> with an actual number. Setting CPUCOUNT= to a number  greater than the actual number of available CPUs might result in reduced performance. This  option overrides the CPUCOUNT= SAS system option."}},{"StatementOptionName":"DATASERVER=","StatementOptionHelp":{"#cdata":"Syntax: DATASERVER=\u201cname\u201d\n          \nSpecifies the name of the server on Teradata systems as defined through the hosts file \nand as used in the LIBNAME statement for Teradata. For example, if the hosts file defines\n\n    myservercop1 33.44.55.66\n    \nas the server for Teradata, then a LIBNAME specification would be as follows:\n\n    libname TDLib teradata server=myserver user= password= database= ;\n    \nA PERFORMANCE statement to induce running alongside the Teradata server would specify the\nfollowing:\n\n    performance dataserver=\"myserver\";\n    \nIf the DATASERVER= option is specified, it overrides the GRIDDATASERVER environment \nvariable."},"StatementOptionType":"V"},{"StatementOptionName":"DETAILS","StatementOptionHelp":{"#cdata":"Requests a table that shows a timing breakdown of the procedure steps."},"StatementOptionType":"V"},{"StatementOptionName":"HOST=|GRIDHOST=","StatementOptionHelp":{"#cdata":"Syntax: HOST=\u201cname\u201d | GRIDHOST=\u201cname\u201d \n          \nSpecifies the name of the appliance host in single or double quotes. If the HOST= option \nis specified, it overrides the value of the GRIDHOST environment variable."},"StatementOptionType":"V"},{"StatementOptionName":"MODE=|GRIDMODE=","StatementOptionHelp":{"#cdata":"Syntax: MODE=SYM|ASYM | GRIDMODE=SYM|ASYM \n          \nIs a deprecated option that specifies whether to run the high-performance analytical procedure \nin symmetric (SYM) mode or asymmetric (ASYM) mode. This option overrides the GRIDMODE environment \nvariable."},"StatementOptionType":"V","#text":"SYM\n          ","StatementOptionValues":{"@Value1":"SYM","@Value2":"ASYM"},"StatementOptionToolTips":{"@ToolTip1":"Specifies to run the high-performance analytical procedure in symmetric (SYM) mode.","@ToolTip2":"Specifies to run the high-performance analytical procedure in asymmetric (ASYM) mode."}},{"StatementOptionName":"TIMEOUT=|GRIDTIMEOUT=","StatementOptionHelp":{"#cdata":"Syntax: TIMEOUT=s | GRIDTIMEOUT=s \n \nSpecifies the time-out in seconds for a high-performance analytical procedure to wait for a connection \nto the appliance and establish a connection back to the client. The default is 120 seconds."},"StatementOptionType":"V"},{"StatementOptionName":"INSTALL=|INSTALLLOC=","StatementOptionHelp":{"#cdata":"Syntax: INSTALL=\u201cname\u201d | INSTALLLOC=\u201cname\u201d \n          \nSpecifies the directory in which the High-Performance Analytics shared libraries are \ninstalled on the appliance. Specifying the INSTALL= option overrides the GRIDINSTALLLOC \nenvironment variable."},"StatementOptionType":"V"},{"StatementOptionName":"LASRSERVER=|LASR=","StatementOptionHelp":{"#cdata":"Syntax: LASRSERVER=\"path\" | LASR=\"path\" \n          \nSpecifies the fully qualified path to the description file of a SAS LASR Analytic Server instance. \nIf the input data set is held in memory by this LASR Analytic Server instance, then the procedure \nruns alongside LASR."},"StatementOptionType":"V"},{"StatementOptionName":"NODES=|NNODES=","StatementOptionHelp":{"#cdata":"Syntax: NODES=ALL|n | NNODES=ALL|n\n          \nSpecifies the number of nodes in the distributed computing environment, provided that \nthe data are not processed alongside the database.\n\nSpecifying NODES=0 indicate thats you want to process the data in SMP mode on the client machine. \nIf the input data are not alongside the database, this is the default. The High-Performance \nAnalytics procedures then perform the analysis mutlithreaded on the client.\n\nYou can specify NODES=ALL if you want to use all available nodes on the appliance without \noversubscribing the system."},"StatementOptionType":"V"},{"StatementOptionName":"NTHREADS=|THREADS=","StatementOptionHelp":{"#cdata":"Syntax: NTHREADS=n | THREADS=n\n          \nSpecifies the number of threads for analytic computations and overrides the SAS system option\nTHREADS | NOTHREADS. If you do not specify the NTHREADS= option, the number of threads\nare determined based on the number of CPUs on the host on which the analytic computations execute.\nThe algorithm by which a CPU count is converted to a thread count is specific to the High-\nPerformance Analytics procedure. Most procedures create one thread per CPU for the analytic computations.\nBy default, High-Performance Analytics procedures execute in multiple concurrent threads unless\nturned off by the NOTHREADS system option or you force single-threaded execution with\nNTHREADS=1. The largest number that can be specified for n is 256. Individual High-Performance\nAnalytics procedures can impose more stringent limits if called for by algorithmic considerations.\nYou can affect the determination of the CPU count with the CPUCOUNT= option in the PERFORMANCE\nstatement.\n\nNOTE: The SAS system options THREADS | NOTHREADS apply to the client machine on which\nthe SAS High-Performance Analytics procedures execute. They do not apply to the compute nodes\nin a distributed environment."},"StatementOptionType":"V"}]}},{"StatementName":"SAVE","StatementHelp":{"#cdata":"Syntax: SAVE <option>;\n      \nThe SAVE statement outputs the forest model information into a binary file."},"StatementOptions":{"StatementOption":{"StatementOptionName":"FILE=","StatementOptionHelp":{"#cdata":"Syntax: FILE=filename \n          \nNames the file into which tree information is saved. The filename can be either a SAS file reference \nor the full path and member name of the binary file."},"StatementOptionType":"V"}}},{"StatementName":"SCORE","StatementHelp":{"#cdata":"Syntax: SCORE OUT=libref.SAS-data-set <score-options> ;\n\nThe SCORE statement applies the forest model to the training data and outputs a data set that contains \nthe ID variables that are specified in the ID statement in addition to predictions, residuals, and decisions."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"Syntax: OUT=libref.SAS-data-set \n          \nNames the output data set to contain the scored data."},"StatementOptionType":"RV"},{"StatementOptionName":"MAXDEPTH=","StatementOptionHelp":{"#cdata":"Syntax: MAXDEPTH=<n> \n          \nProduces predictions from trees that are pruned to a depth of n. The trees are not truncated \nby default."},"StatementOptionType":"V"},{"StatementOptionName":"NTREES=","StatementOptionHelp":{"#cdata":"Syntax: NTREES=<n> \n          \nProduces predictions from the first n trees only. If the option is omitted then PROC HPFOREST \nuses all the trees in the model for predictions. Scoring with fewer trees can sometimes increase \nthe speed without significantly reducing the accuracy."},"StatementOptionType":"V"}]}},{"StatementName":"TARGET","StatementHelp":{"#cdata":"Syntax: TARGET variable < / LEVEL=level > ; \n      \nThe TARGET statement names the variable whose values PROC HPFOREST tries to predict."},"StatementOptions":{"StatementOption":{"StatementOptionName":"LEVEL=","StatementOptionHelp":{"#cdata":"Syntax: LEVEL=level \n          \nSpecifies the level of measurement of the variables. Accepted values of level are: BINARY, NOMINAL, \nand INTERVAL.\n\nNote that level cannot be ORDINAL."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BINARY","@Value2":"NOMINAL","@Value3":"INTERVAL"},"StatementOptionToolTips":{"@ToolTip1":"Binary level of measurement","@ToolTip2":"Nominal level of measurement","@ToolTip3":"Interval level of measurement"}}}},{"StatementName":"TREATMENT","StatementHelp":{"#cdata":"Syntax: TREATMENT variable <ORDER=order>;\n      \nThe TREATMENT statement names a binary treatment variable and estimates how much the prediction \nof an observation changes when the treatment changes. The analysis of differential treatment \neffects is sometimes called incremental response modeling (IRM)."},"StatementOptions":{"StatementOption":{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"Syntax: ORDER=order \n          \nSpecifies the sorting order of the treatment values."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ASCENDING","@Value2":"ASCFORMATTED","@Value3":"DESCENDING","@Value4":"DESFORMATTED","@Value5":"DSORDER"},"StatementOptionToolTips":{"@ToolTip1":"Ascending order of unformatted values (default)","@ToolTip2":"Ascending order of formatted values","@ToolTip3":"Descending order of unformatted values","@ToolTip4":"Descending order of formatted values","@ToolTip5":"Order of appearance in the input data set"}}}}]}}}