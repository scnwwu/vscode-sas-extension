{"Procedure":{"Name":"HPTMINE","ProductGroup":"HPA","#comment":{},"ProcedureHelp":{"#cdata":"Syntax: PROC HPTMINE < options > ;\n    VARIABLE variable ;\n    DOC_ID variable ;\n    PARSE < parse-options > ;\n    SVD < svd-options > ;\n    PERFORMANCE performance-options ;\n    \nThe HPTMINE procedure is a high-performance procedure that analyzes large-scale textual\ndata. PROC HPTMINE provides the SAS High-Performance Analytics platform an essential capability\nfor text mining and supports a wide range of fundamental text analysis features, which include tokenizing,\nstemming, part-of-speech tagging, noun group extraction, default or customized stop or start lists, entity\nparsing, multiword tokens, synonym lists, term weighting, term-by-document matrix creation, and dimension\nreduction by term filtering and singular value decomposition (SVD).\n\nPROC HPTMINE integrates the functionalities provided by the TGPARSE, TMUTIL, and SPSVD procedures\nfrom SAS Text Miner, and achieves high efficiency and scalability through parallel processing. The\nHPTMINE procedure can also generate results that can be used to facilitate scoring by the HPTMSCORE\nprocedure. These results include a configuration data set, a term data set, and a data set that contains the\nSVD projection matrix.\n\nYou can use the HPTMINE procedure to read data in distributed form and perform text analysis in parallel\nin symmetric multiprocessing (SMP) or massively parallel processing (MPP) mode.\n\nThe following list summarizes the basic features of PROC HPTMINE:\n\n  o Functionalities that are related to document parsing, term-by-document matrix creation, and dimension\n    reduction are integrated into one procedure to process data more efficiently.\n  o Parsing supports essential natural language processing (NLP) features, which include tokenizing,\n    stemming, part-of-speech tagging, noun group extraction, default or customized stop or start lists,\n    entity parsing, multiword tokens, synonym lists.\n  o Term weighting and filtering are supported for term-by-document matrix creation.\n  o Parsing and term-by-document matrix creation is parallelized.\n  o Computation of singular value decomposition (SVD) is parallelized."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"DATA=|DOC=","ProcedureOptionHelp":{"#cdata":"Syntax: DATA=SAS-data-set | DOC=SAS-data-set \n      \nNames the input SAS data set of documents to be used by PROC HPTMINE. The default is the most\nrecently created data set. If PROC HPTMINE executes in MPP mode, the input data are distributed\nto memory on the appliance nodes and analyzed in parallel, unless the data are already distributed in\nthe appliance database. When data are already distributed, PROC HPTMINE reads the data alongside\nthe distributed database."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"NOPRINT","ProcedureOptionHelp":{"#cdata":"Suppresses the generation of ODS output."},"ProcedureOptionType":"S"}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"PERFORMANCE","StatementHelp":{"#cdata":"Syntax: PERFORMANCE < performance-options > ;\n      \nThe PERFORMANCE statement defines performance parameters for multithreaded and distributed computing,\npasses variables about the distributed computing environment, and requests detailed results about\nthe performance characteristics of the HPTMINE procedure. You can also use the PERFORMANCE statement\nto control whether the HPTMINE procedure executes in SMP or MPP mode."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"COMMIT=","StatementOptionHelp":{"#cdata":"Syntax: COMMIT=n\n          \nThis option specifies the minimum number of observations transferred from the client to the \nappliance necessary to update the SAS Log. For instance, if you specify COMMIT=5000, then \nevery time the number of observations sent exceeds an integer multiple of 5000 a log message \nis produced. This message indicates the actual number of observations distributed, not the \nCOMMIT= value that triggered the message. "},"StatementOptionType":"V"},{"StatementOptionName":"CPUCOUNT=","StatementOptionHelp":{"#cdata":"Syntax: CPUCOUNT=ACTUAL | num\n          \nThis argument specifies how many processors PROC HPBIN assumes are available on each host \nin the computing environment. Valid values for number are integers between 1 and 256, \ninclusive. Setting CPUCOUNT= to a value greater than the actual number of available CPUs \nmight results in reduced performance. Specify CPUCOUNT=ACTUAL to set CPUCOUNT= to the \nnumber of processors physically available. This number can be less than the physical \nnumber of CPUs if the SAS process has been restricted by system administration tools. \nThis option overrides the CPUCOUNT= SAS system option. If PROC HPBIN executes in SMP \nmode, then this option referes to the client machine of the SAS session. If PROC HPBIN \nexecutes in MPP mode, then this option applies the nodes on the appliance."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ACTUAL","@Value2":"<num>"},"StatementOptionToolTips":{"@ToolTip1":"Sets CPUCOUNT to the number of processors physically available. This number can be less than the physical number of CPUs if the SAS process has been restricted by system administration tools.","@ToolTip2":"Replace <num> with an actual number. Setting CPUCOUNT= to a number  greater than the actual number of available CPUs might result in reduced performance. This  option overrides the CPUCOUNT= SAS system option."}},{"StatementOptionName":"DATASERVER=","StatementOptionHelp":{"#cdata":"Syntax: DATASERVER=\u201cname\u201d\n          \nSpecifies the name of the server on Teradata systems as defined through the hosts file \nand as used in the LIBNAME statement for Teradata. For example, if the hosts file defines\n\n    myservercop1 33.44.55.66\n    \nas the server for Teradata, then a LIBNAME specification would be as follows:\n\n    libname TDLib teradata server=myserver user= password= database= ;\n    \nA PERFORMANCE statement to induce running alongside the Teradata server would specify the\nfollowing:\n\n    performance dataserver=\"myserver\";\n    \nIf the DATASERVER= option is specified, it overrides the GRIDDATASERVER environment \nvariable."},"StatementOptionType":"V"},{"StatementOptionName":"DETAILS","StatementOptionHelp":{"#cdata":"Specify this option to request a table that shows a timing breakdown of the procedure steps."},"StatementOptionType":"V"},{"StatementOptionName":"TIMEOUT=","StatementOptionHelp":{"#cdata":"Syntax: TIMEOUT=s\n          \nThis options specifies the length of time, in seconds, PROC HPBIN should wait for a connection \nto the appliance and to establish a connection back to the client. The default value for s is \n120 seconds. If jobs are submitted to the appliance through workload management tools that might \nsuspend access to the appliance for a longer period, you might want to increase the timeout value. "},"StatementOptionType":"V"},{"StatementOptionName":"HOST=|GRIDHOST=","StatementOptionHelp":{"#cdata":"Syntax: HOST=name | GRIDHOST=name\n          \nThis option specifies the name of the appliance host. The HOST= option overrides the value \nof the GRIDHOST environment variable."},"StatementOptionType":"V"},{"StatementOptionName":"INSTALL=|INSTALLLOC=","StatementOptionHelp":{"#cdata":"Syntax: INSTALL=\u201cname\u201d | INSTALLLOC=\u201cname\u201d \n          \nThis option specifies the directory where the High-Performance Analytics shared libraries \nare installed on the appliance. Specifying the INSTALL= option overrides the GRIDINSTALLLOC \nenvironment variable."},"StatementOptionType":"V"},{"StatementOptionName":"NODES=|NNODES=","StatementOptionHelp":{"#cdata":"Syntax: NODES=n | NNODES=n\n          \nThis option specifies the number of nodes in the distributed computing environment, \nprovided that the data are not processed alongside the database. \n\nSpecify NODES=0 to indicate that you want to process the data in SMP mode on the client \nmachine. If the input data are not alongside the database, this is the default setting. \nThe HPBIN procedure then performs multithreaded analysis on the client. If the data are \nnot read alongside the database, the NODES= option specifies the number of nodes on the \nappliance that are involved in the analysis. If the number of nodes can be modified by \nthe application, you can specify a NODES= option where n exceeds the number of physical \nnodes on the appliance. The High-Performance Analytics software then oversubscribes the \nnodes and associates nodes with multiple units of work. For example, on a system with \n16 appliance nodes, the following statement would oversubscribe the system by a factor \nof 3: \n\n  performance nodes=48 host=\"hpa.sas.com\"; \n  \nGenerally, it is not advisable to oversubscribe the system because the analytic code \nis optimized for a certain level of multithreading on the nodes that depend on the CPU \ncount. If the data are read alongside the distributed database on the appliance, specifying \na nonzero value for the NODES= option has no effect. The number of units of work in the \ndistributed computing environment is then determined by the distribution of the data and \ncannot be altered."},"StatementOptionType":"V"},{"StatementOptionName":"NTHREADS=","StatementOptionHelp":{"#cdata":"Syntax: NTHREADS=n \n          \nThis option specifies the number of threads used for analytic computations and overrides the \nSAS system option THREADS | NOTHREADS. If you do not specify the NTHREADS= option, then the \nnumber of threads is determined based on the number of CPUs on the host machine where the \nanalytic computations execute. By default, High-Performance Analytics procedures execute in \nmultiple concurrent threads, unless you disable this behavior with the NOTHREADS system option \nor you specify NTHREADS=1 to force single-threaded execution. The value specified here must \nnot exceed 256.\n\nNote:The SAS system option THREADS | NOTHREADS applies to the current machine where the SAS \nHigh-Performance Analytics procedures execute. This option does not apply to the compute nodes \nin a distributed environment."},"StatementOptionType":"V"}]}},{"StatementName":"DOC_ID","StatementHelp":{"#cdata":"Syntax: DOC_ID variable ; \n      \nThis statement specifies the variable that contains the ID of each document. In the input data set, each \nrow corresponds to one document. The ID of each document must be unique; it can be either a number or a\nstring of characters."},"StatementOptions":{"StatementOption":{"StatementOptionName":"DUPLICATIONCHECK|DUPCHK","StatementOptionHelp":{"#cdata":"Syntax: DUPLICATIONCHECK | DUPCHK \n          \nChecks the uniqueness of the ID of each document. When this option is not specified, no duplication\ncheck is performed. When this option is specified in the DOC_ID statement and duplicate document\nIDs are detected, the HPTMINE procedure outputs a warning message, which shows the number of\nduplicate document IDs that have been detected."},"StatementOptionType":"S"}}},{"StatementName":"SVD","StatementHelp":{"#cdata":"Syntax: SVD < svd-options > ; \n      \nThe SVD statement specifies the options for calculating a truncated singular value decomposition (SVD) of\nthe large, sparse term-by-document frequency matrix that was created during the parsing phase of PROC\nHPTMINE."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"K=","StatementOptionHelp":{"#cdata":"Syntax: K=k \n          \nSpecifies the number of columns in the matrices U, V, and S. This value is the number of dimensions\nof the data set after the SVD is performed. If the value of k is too large, then the HPTMINE procedure\nruns for an unnecessarily long time. You cannot specify both this option and the MAX_K= option."},"StatementOptionType":"V"},{"StatementOptionName":"MAX_K=","StatementOptionHelp":{"#cdata":"Syntax: MAX_K=n \n          \nspecifies the maximum value that the HPTMINE procedure should return as the recommended value\nof n. If the RES= argument is specified to recommend the value of k, this option limits that value to\nat most n. The HPTMINE procedure attempts to calculate (as opposed to recommends) k dimensions\nwhen it performs SVD. You cannot specify both this option and the K= option."},"StatementOptionType":"V"},{"StatementOptionName":"OUTDOCPRO=","StatementOptionHelp":{"#cdata":"Syntax: OUTDOCPRO=SAS-data-set \n          \nSpecifies the data set to contain the projections of the columns of the term-by-document frequency\nmatrix onto the columns of U. Since each column of the term-by-document frequency matrix corresponds\nto a document, the output forms a new representation of the input documents in a space with\nmuch lower dimensionality."},"StatementOptionType":"V"},{"StatementOptionName":"RESOLUTION|RES=","StatementOptionHelp":{"#cdata":"Syntax: RESOLUTION|RES=LOW | MED | HIGH \n          \nSpecifies the recommended number of dimensions (resolution) for the singular value decomposition.\nIf you specify this option, you must also specify the MAX_K= option. A low-resolution singular value\ndecomposition returns fewer dimensions than a high-resolution singular value decomposition. This\noption recommends the value of k heuristically based on the value specified in the MAX_K= option.\nAssume that the MAX_K= option is set to be n and a singular value decomposition with n dimensions\naccounts for t% of the total variance. The option HIGH always recommends the maximum number\nof dimensions, that is, k=n. The option MED recommends a k that explains (5/6)*t% of the total\nvariance. The option LOW recommends a k that explains (2/3)* t% of the total variance."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"LOW","@Value2":"MED","@Value3":"HIGH"},"StatementOptionToolTips":{"@ToolTip1":"The option LOW recommends a k that explains (2/3)* t% of the total variance.","@ToolTip2":"The option MED recommends a k that explains (5/6)*t% of the total variance.","@ToolTip3":"The option HIGH always recommends the maximum number of dimensions, that is, k=n."}},{"StatementOptionName":"SVDS=","StatementOptionHelp":{"#cdata":"Syntax: SVDS=SAS-data-set \n          \nSpecifies the data set to contain the calculated singular values."},"StatementOptionType":"V"},{"StatementOptionName":"SVDU=","StatementOptionHelp":{"#cdata":"Syntax: SVDU=SAS-data-set \n          \nSpecifies the data set to contain the calculated left singular vectors."},"StatementOptionType":"V"},{"StatementOptionName":"SVDV=","StatementOptionHelp":{"#cdata":"Syntax: SVDV=SAS-data-set \n          \nspecifies the data set to contain the calculated right singular vectors."},"StatementOptionType":"V"},{"StatementOptionName":"TOL=","StatementOptionHelp":{"#cdata":"Syntax: TOL=e\n          \nSpecifies the maximum allowable tolerance for the singular value. \n\nThe default value of e is 10-6, which is more than adequate for most text mining problems."},"StatementOptionType":"V"}]}},{"StatementName":"VARIABLE|VAR","StatementHelp":{"#cdata":"Syntax: VARIABLE|VAR variable ;\n      \nThis statement specifies the variable that contains the text to be processed."}},{"StatementName":"PARSE","StatementHelp":{"#cdata":"Syntax: PARSE < parse-options > ; \n      \nThe PARSE statement specifies the options for parsing the input documents and creating the term-bydocument\nmatrix."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CELLWGT=","StatementOptionHelp":{"#cdata":"Syntax: CELLWGT=LOG | NONE \n          \nSpecifies how the elements in the term-by-document matrix are weighted. The available cell weights\nare as follows: \n\nLOG specifies that cells be weighted by using the LOG formulation.\nNONE specifies that no cell weight be applied."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"LOG","@Value2":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that cells be weighted by using the LOG formulation.","@ToolTip2":"Specifies that no cell weight be applied."}},{"StatementOptionName":"ENTITIES=","StatementOptionHelp":{"#cdata":"Syntax: ENTITIES=STD | NONE \n          \nDetermines whether the entity extractor should use the standard list of entities. When ENTITIES=STD,\nentity extraction is turned on and standard entities are used; terms such as \u201cGeorge W. Bush\u201d are\nrecognized as an entity and given the corresponding entity role and attribute. For this example, the\nentity role is PERSON and the attribute is Entity. While the entity is treated as the single term,\n\u201cgeorge w. bush,\u201d the individual tokens \u201cgeorge,\u201d \u201cw,\u201d and \u201cbush\u201d are also included. By default,\nENTITIES=NONE."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"STD","@Value2":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Entity extraction is turned on and standard entities are used; terms such as \u201cGeorge W. Bush\u201d are recognized as an entity and given the corresponding entity role and attribute. For this example, the entity role is PERSON and the attribute is Entity. While the entity is treated as the single term, \u201cgeorge w. bush,\u201d the individual tokens \u201cgeorge,\u201d \u201cw,\u201d and \u201cbush\u201d are also included.","@ToolTip2":"Entity extraction is turned off."}},{"StatementOptionName":"MULTITERM=","StatementOptionHelp":{"#cdata":"Syntax: MULTITERM=OS-file-reference \n          \nspecifies the path to a file that contains a list of multiword terms. These terms are case-sensitive and\nare treated as a single entry by the HPTMINE procedure. Thus, the terms \u201cThank You\u201d and \u201cthank you\u201d\nare processed differently. Consequently, you must convert all text strings to lowercase or add each of\nthe multiterm\u2019s case variations to the list before using the HPTMINE procedure to create consistent\nmultiword terms. The multiterm file can be any file type as long as it is formatted in the following\nmanner:\n\nmultiterm: 3: pos\n\nSpecifically, the first item is the mutliword term itself followed by a colon, the second item is a number\nthat is specific to Teragram and represents the token type followed by a colon, and the third item is the\npart of speech that the multiword term represents. NOTE: The token type 3 is the most common token\ntype for multiterm lists and represents compound words."},"StatementOptionType":"V"},{"StatementOptionName":"NONOUNGROUPS|NONG","StatementOptionHelp":{"#cdata":"Determines whether the noun group extractor should be used. When this option is not specified, noun\ngroup are extracted and the HPTMINE procedure returns maximal groups and subgroups (which do\nnot include groups that contain determiners or prepositions). If stemming is turned on, then noun group\nelements are also stemmed."},"StatementOptionType":"S"},{"StatementOptionName":"NOSTEMMING","StatementOptionHelp":{"#cdata":"Determines whether words should be stemmed. When this option is not specified, words are stemmed\nand terms such as \u201cadvises\u201d and \u201cadvising\u201d are mapped to the parent term \u201cadvise.\u201d"},"StatementOptionType":"S"},{"StatementOptionName":"NOTAGGING","StatementOptionHelp":{"#cdata":"Determines whether terms should be tagged. When this option is not specified, terms are tagged and\nthe HPTMINE procedure identifies a term\u2019s part of speech based on context clues. The identified part\nof speech is provided in the Role variable of the OUTTERMS= data set."},"StatementOptionType":"S"},{"StatementOptionName":"OUTCHILD=","StatementOptionHelp":{"#cdata":"Syntax: OUTCHILD=SAS-data-set \n          \nSpecifies the data set to contain a compressed representation of the sparse term-by-document frequency\nmatrix. The term counts cannot be weighted. The data set saves only the kept, representative terms.\nThe child frequencies are not attributed to their corresponding parent (as they are in the OUTPARENT=\ndata set)."},"StatementOptionType":"V"},{"StatementOptionName":"OUTCONFIG=","StatementOptionHelp":{"#cdata":"Syntax: OUTCONFIG=SAS-data-set \n          \nSpecifies the data set to contain configuration information that is used for the current run of PROC\nHPTMINE. The primary purpose of this data set is to relay the configuration information from the\nHPTMINE procedure to the HPTMSCORE procedure. The HPTMSCORE procedure is forced to\nuse options that are consistent with the HPTMINE procedure. Thus, the data set created with the\nOUTCONFIG= option becomes an input data set for PROC HPTMSCORE and ensures that the parsing\noptions are consistent between the two runs."},"StatementOptionType":"V"},{"StatementOptionName":"OUTPARENT=","StatementOptionHelp":{"#cdata":"Syntax: OUTPARENT=SAS-data-set \n          \nSpecifies the data set to contain a compressed representation of the sparse term-by-document frequency\nmatrix. The term counts can be weighted, if requested. The data set contains only the kept, representative\nterms, and the child frequencies are attributed to the corresponding parent. To obtain information\nabout the children, use the OUTCHILD= option."},"StatementOptionType":"V"},{"StatementOptionName":"OUTTERMS=","StatementOptionHelp":{"#cdata":"Syntax: OUTTERMS=SAS-data-set \n          \nSpecifies the data set to contain the summary information about the terms in the document collection."},"StatementOptionType":"V"},{"StatementOptionName":"REDUCEF=","StatementOptionHelp":{"#cdata":"Syntax: REDUCEF=n \n          \nRemoves terms that are not in at least n documents. The value of n must be a positive integer. By\ndefault, REDUCEF=4."},"StatementOptionType":"V"},{"StatementOptionName":"START=","StatementOptionHelp":{"#cdata":"Syntax: START=SAS-data-set \n          \nSpecifies the data set that contains the terms that are to be kept for the analysis. These terms are\ndisplayed in the OUTTERMS= data set with a keep status of Y, and all other terms have a keep status \nof N. The START data set must have a Term variable and can also have a Role variable. You cannot\nspecify both the START and the STOP options."},"StatementOptionType":"V"},{"StatementOptionName":"STOP=","StatementOptionHelp":{"#cdata":"Syntax: STOP=SAS-data-set \n          \nSpecifies the data set that contains the terms to exclude from the analysis. These terms are displayed in\nthe OUTTERMS= data set with a keep status of N. They are not identified as parents or children. The\nSTOP data set must have a Term variable and can also have a Role variable. You cannot specify both\nthe START and the STOP options."},"StatementOptionType":"V"},{"StatementOptionName":"SYNONYM=|SYN=","StatementOptionHelp":{"#cdata":"Syntax: SYNONYM=SAS-data-set | SYN=SAS-data-set \n          \nSpecifies the data set that contains user-defined synonyms to be used in the analysis. The data set\nspecifies parent-child relationships that enable you to map child terms to a representative parent. The\nsynonym relationship is indicated in the data set that is specified in the OUTTERMS= option and is\nalso reflected in the term-by-document data set that is specified in the OUTPARENT= option. The\ninput synonym data set must have either the two variables Term and Parent, or the four variables Term,\nParent, Termrole, and Parentrole. When stemming is turned on, this list overrides any relationships\nthat are identified when terms are stemmed."},"StatementOptionType":"V"},{"StatementOptionName":"TERMWGT=","StatementOptionHelp":{"#cdata":"Syntax: TERMWGT=ENTROPY | NONE \n          \nSpecifies how terms are weighted. The available term weights are as follows: \n\nENTROPY specifies that terms be weighted using the entropy formulation.\nNONE specifies that no term weight is applied."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ENTROPY","@Value2":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that terms be weighted using the entropy formulation.","@ToolTip2":"Specifies that no term weight is applied."}}]}}]}}}