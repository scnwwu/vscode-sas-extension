{"Procedure":{"Name":"LOGISTIC","ProductGroup":"SAS/STAT","#comment":{},"ProcedureHelp":{"#cdata":"Syntax: PROC LOGISTIC <options> ; \n    BY variables ; \n    CLASS variable <(options)> <variable <(options)> \u2026> </ options>;  \n    CODE <options>; \n    CONTRAST 'label' effect values<, effect values, \u2026> </ options>; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    EFFECTPLOT <plot-type<(plot-definition-options)>></ options> ; \n    ESTIMATE <'label'> estimate-specification </ options> ; \n    EXACT <'label'><INTERCEPT><effects></ options> ; \n    EXACTOPTIONS options ; \n    FREQ variable ;    \n    ID variable<variable,...> ;\n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification </ options> ;     \n    <label:> MODEL variable <(variable_options)> = <effects> </ options>; \n    <label:> MODEL events/trials = <effects> </ options>;\n    NLOPTIONS options;\n    ODDSRATIO <'label'> variable </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name <keyword=name \u2026>> </ option>;\n    ROC <'label'> <specification> </ options> ; \n    ROCCONTRAST <'label'><contrast></ options> ; \n    SCORE <options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    STRATA effects </ options> ; \n    <label:> TEST equation1 <,equation2, \u2026> </ option>;\n    UNITS <independent1=list1 <independent2=list2 \u2026>> </ option>; \n    WEIGHT variable </ option> ; \n\nBinary responses (for example, success and failure), ordinal responses (for example, normal, \nmild, and severe), and nominal responses (for example, major TV networks viewed at a certain \nhour) arise in many fields of study. Logistic regression analysis is often used to investigate \nthe relationship between these discrete responses and a set of explanatory variables."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"ALPHA=","ProcedureOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n      \nSpecifies the level of significance \u03b1 for 100(1 - \u03b1)% confidence intervals. \nThe value number must be between 0 and 1; the default value is 0.05, which \nresults in 95% intervals."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"COVOUT","ProcedureOptionHelp":{"#cdata":"Adds the estimated covariance matrix to the OUTEST= data set. For the COVOUT option to have an effect, \nthe OUTEST= option must be specified."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"[Syntax: DATA=SAS-data-set] \n      \nNames the SAS data set containing the data to be analyzed. If you omit the \nDATA= option, the procedure uses the most recently created SAS data set."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"DESCENDING|DESC","ProcedureOptionHelp":{"#cdata":"Reverses the sorting order for the levels of the response variable."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"EXACTONLY","ProcedureOptionHelp":{"#cdata":"Requests only the exact analyses. The asymptotic analysis that PROC LOGISTIC usually performs \nis suppressed."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"EXACTOPTIONS","ProcedureOptionHelp":{"#cdata":"[Syntax: EXACTOPTIONS (options)] \n      \nSpecifies options that apply to every EXACT statement in the program.\n\nThe following options are available: \n\n  ADDTOBS -- adds the observed sufficient statistic to the sampled exact distribution if the statistic was not sampled.\n\n  BUILDSUBSETS -- suppresses this subsetting behavior and instead builds every distribution for sampling. \n\n  EPSILON=value -- controls how the partial sums \u2211yixi are compared. value must be between 0 and 1; by default, value=1E\u20138. \n\n  MAXTIME=seconds -- specifies the maximum clock time (in seconds) that PROC LOGISTIC can use to calculate the exact distributions.\n\n  METHOD=keyword -- specifies which exact conditional algorithm to use for every EXACT statement specified. \n  You can specify one of the following keywords: \n\n    DIRECT -- invokes the multivariate shift algorithm of Hirji, Mehta, and Patel (1987). \n\n    NETWORK -- invokes an algorithm described in Mehta, Patel, and Senchaudhuri (1992). \n\n    NETWORKMC -- invokes the hybrid network and Monte Carlo algorithm of Mehta, Patel, and Senchaudhuri (1992). \n\n  N=n -- specifies the number of Monte Carlo samples to take when the METHOD=NETWORKMC option is specified. By default, n.= 10,000.\n\n  ONDISK -- uses disk space instead of random access memory to build the exact conditional distribution.  \n\n  SEED=seed -- specifies the initial seed for the random number generator used to take the Monte Carlo samples \n  when the METHOD=NETWORKMC option is specified. \n\n  STATUSN=number -- prints a status line in the SAS log after every number Monte Carlo samples when the METHOD=NETWORKMC option is specified.\n\n  STATUSTIME=seconds -- specifies the time interval (in seconds) for printing a status line in the LOG. \n  \n  XCONV -- specifies the relative parameter convergence criterion."},"ProcedureOptionType":"S","SubOptionsKeywords":"STATUSTIME=|STATUSN=|ONDISK|SEED=|N=|METHOD=|MAXTIME=|EPSILON=|BUILDSUBSETS|ADDTOBS|XCONV"},{"ProcedureOptionName":"INEST=","ProcedureOptionHelp":{"#cdata":"[Syntax: INEST=SAS-data-set] \n      \nNames the SAS data set that contains initial estimates for all the parameters \nin the model."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"INMODEL=","ProcedureOptionHelp":{"#cdata":"[Syntax: INMODEL=SAS-data-set] \n      \nSpecifies the name of the SAS data set that contains the model information \nneeded for scoring new data."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"MULTIPASS","ProcedureOptionHelp":{"#cdata":"Forces the procedure to reread the DATA= data set as needed rather than require its storage in memory \nor in a temporary file on disk."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NAMELEN=","ProcedureOptionHelp":{"#cdata":"[Syntax: NAMELEN=n] \n      \nSpecifies the maximum length of effect names in tables and output data sets to \nbe n characters, where n is a value between 20 and 200. The default length is \n20 characters."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NOCOV","ProcedureOptionHelp":{"#cdata":"Specifies that the covariance matrix not be saved in the OUTMODEL= data set."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOPRINT","ProcedureOptionHelp":{"#cdata":"Suppresses all displayed output. Note that this option temporarily disables the Output Delivery System (ODS)."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"ORDER=|RORDER=","ProcedureOptionHelp":{"#cdata":"Specifies the sorting order for the levels of the response variable."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"ProcedureOptionToolTips":{"@ToolTip1":"Levels are sorted by the order of appearance in the input data set.","@ToolTip2":"Levels are sorted by the external formatted value, except for numeric variables with no explicit  format, which are sorted by their unformatted (internal) value.","@ToolTip3":"Levels are sorted by the descending frequency count; levels with the most observations come first  in the order.","@ToolTip4":"Levels are sorted by the unformatted value."}},{"ProcedureOptionName":"OUTDESIGN=","ProcedureOptionHelp":{"#cdata":"[Syntax: OUTDESIGN=SAS-data-set] \n      \nSpecifies the name of the data set that contains the design matrix for the model."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"OUTDESIGNONLY","ProcedureOptionHelp":{"#cdata":"Suppresses the model fitting and creates only the OUTDESIGN= data set."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"OUTEST=","ProcedureOptionHelp":{"#cdata":"[Syntax: OUTEST=SAS-data-set] \n      \nCreates an output SAS data set that contains the final parameter estimates and, \noptionally, their estimated covariances (see the preceding COVOUT option)."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"OUTMODEL=","ProcedureOptionHelp":{"#cdata":"[Syntax: OUTMODEL=SAS-data-set] \n      \nSpecifies the name of the SAS data set that contains the information about the fitted model."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"PLOTS=","ProcedureOptionHelp":{"#cdata":"Controls the plots produced through ODS Graphics. \n      \nSyntax: \n(1) PLOTS <(global-plot-options)><=plot-request<(options)>> \n(2) PLOTS <(global-plot-options)> =(plot-request<(options)>< plot-request<(options)>>) \n\nThe following global-plot-options are available: \n\n  LABEL \n  displays the case number on diagnostic plots, to aid in identifying the outlying observations. \n  \n  MAXPOINTS=NONE | number \n  suppresses the plots produced by the DFBETAS, DPC, INFLUENCE, LEVERAGE, and PHAT options if \n  there are more than number observations. Also, observations are not displayed on the EFFECT \n  plots when the cutoff is exceeded. The default is MAXPOINTS=5000. The cutoff is ignored if \n  you specify MAXPOINTS=NONE.\n\n  ONLY \n  suppresses the default plots. Only specifically requested plot-requests are displayed. \n\n  UNPACKPANELS | UNPACK \n  suppresses paneling. By default, multiple plots can appear in some output panels."},"ProcedureOptionType":"S|V","ProcedureOptionValues":{"@Value1":"ALL","@Value2":"DFBETAS","@Value3":"DPC","@Value4":"EFFECT","@Value5":"INFLUENCE","@Value6":"LEVERAGE","@Value7":"NONE","@Value8":"ODDSRATIO","@Value9":"PHAT","@Value10":"ROC"},"ProcedureOptionToolTips":{"@ToolTip1":"Produces all appropriate plots.","@ToolTip2":"Syntax: DFBETAS<(UNPACK)>                                  Displays plots of DFBETAS versus the case (observation) number.","@ToolTip3":"Syntax: DPC<(UNPACK)>                                  Displays plots of DIFCHISQ and DIFDEV versus the predicted event probability, and colors the  markers according to the value of the confidence interval displacement C. The UNPACK option  displays the plots separately.","@ToolTip4":"Syntax: EFFECT<(effect-options)>                                  Displays and enhances the effect plots for the model. The following effect-options specify  the type of graphic to produce.     AT(variable=value-list | ALL<...variable=value-list | ALL>) -- specifies fixed values for a covariate.    FITOBSONLY -- computes the predicted values only at the observed data.    INDIVIDUAL -- displays the individual probabilities instead of the cumulative probabilities.     LINK -- displays the linear predictors instead of the probabilities on the Y axis.     PLOTBY=effect -- displays an effect plot at each unique level of the PLOTBY= effect.    SLICEBY=effect -- displays predicted probabilities at each unique level of the SLICEBY= effect.    X=effect | X=(effect...effect) -- specifies effects to be used on the X axis of the effect plots.    The following effect-options enhance the graphical output.    ALPHA=number -- specifies the size of the confidence limits.     CLBAND<=YES | NO> -- displays confidence limits on the plots.      CLBAR -- displays the error bars on the plots when you have CLASS covariates on the X axis;      if the X axis is continuous, then this invokes the CLBAND option.      CLUSTER<=percent> -- displays the levels of the SLICEBY= effect in a side-by-side fashion      instead of stacking them. This option is available when you have CLASS covariates on the X axis.      You can specify percent as a percentage of half the distance between X levels.     CONNECT<=YES | NO>    JOIN<=YES | NO>     connects the predicted values with a line. This option is available when you have CLASS covariates      on the X axis. Default connecting lines can be suppressed by specifying the NOCONNECT option.    EXTEND=value -- extends continuous X axes by a factor of value/2 in each direction. By default, EXTEND=0.2.     MAXATLEN=length -- specifies the maximum number of characters used to display the levels of all the fixed variables.    POLYBAR -- replaces scatter plots of polytomous response models with bar charts.     SHOWOBS<=YES | NO> -- displays observations on the plot.    YRANGE=(<min><,max>) -- displays the Y axis as [min,max].","@ToolTip5":"Syntax: INFLUENCE<(UNPACK)>                                  Displays index plots of RESCHI, RESDEV, leverage, confidence interval displacements C and CBar,  DIFCHISQ, and DIFDEV. These plots are produced by default when ods graphics on is specified.  The UNPACK option displays the plots separately.","@ToolTip6":"Syntax: LEVERAGE<(UNPACK)>                                  Displays plots of DIFCHISQ, DIFDEV, confidence interval displacement C, and the predicted  probability versus the leverage. The UNPACK option displays the plots separately.","@ToolTip7":"Suppresses all plots.","@ToolTip8":"Syntax: ODDSRATIO<(oddsratio-options)>                                  Displays and enhances the odds ratio plots for the model when the CLODDS= option or ODDSRATIO  statements are also specified. The following oddsratio-options modify the default odds ratio plot.     DOTPLOT -- displays dotted gridlines on the plot.     GROUP -- displays the odds ratios in panels defined by the ODDSRATIO statements.    LOGBASE=2 | E | 10 -- displays the odds ratio axis on the specified log scale.     NPANELPOS=n -- breaks the plot into multiple graphics having at most |n| odds ratios per graphic.    ORDER=ASCENDING | DESCENDING -- displays the odds ratios in sorted order.    RANGE=(<min><,max>) | CLIP    specifies the range of the displayed odds ratio axis. The RANGE=CLIP option has the same effect as    specifying the minimum odds ratio as min and the maximum odds ratio as max.","@ToolTip9":"Syntax: PHAT<(UNPACK)>                                    Displays plots of DIFCHISQ, DIFDEV, confidence interval displacement C, and leverage versus the  predicted event probability. The UNPACK option displays the plots separately.","@ToolTip10":"Syntax: ROC<(ID=keyword)>                                  Displays the ROC curve. If you also specify a SELECTION= method, then an overlaid plot of  all the ROC curves for each step of the selection process is displayed."},"SubOptionsKeywords":"\n        |ID=|RANGE=|ORDER=|NPANELPOS=|GROUP|LOGBASE=|DOTPLOT|UNPACK|YRANGE=|SHOWOBS|POLYBAR|MAXATLEN=|\n        |EXTEND=|CLBAND|ALPHA=|X=|SLICEBY=|PLOTBY=|LINK|INDIVIDUAL|FITOBSONLY|AT|LABEL|ONLY|UNPACKPANELS|\n        |CLBAR|CLUSTER|CONNECT|CONNECT=|JOIN|JOIN=|\n      "},{"ProcedureOptionName":"ROCOPTIONS","ProcedureOptionHelp":{"#cdata":"[Syntax: ROCOPTIONS (options)] \n      \nSpecifies options that apply to every model specified in a ROC statement.\n\nThe following options are available: \n\n ALPHA=number \n  sets the significance level for creating confidence limits of the areas and the pairwise differences.\n CROSSVALIDATE | X \n  uses cross validated predicted probabilities instead of the model-predicted probabilities for all ROC \n  and area under the ROC curve (AUC) computations;\n EPS=value \n  is an alias for the ROCEPS= option in the MODEL statement. \n ID<=keyword> \n  displays labels on certain points on the individual ROC curves and also on the SCORE statement\u2019s ROC curve. \n  The following keywords are available: \n    PROB     displays the model predicted probability. \n    OBS    displays the (last) observation number. \n    SENSIT    displays the true positive fraction (sensitivity). \n    1MSPEC    displays the false positive fraction (1\u2013specificity). \n    FALPOS    displays the fraction of nonevents that are predicted as events. \n    FALNEG    displays the fraction of events that are predicted as nonevents. \n    POSPRED    displays the positive predictive value (1\u2013FALPOS). \n    NEGPRED    displays the negative predictive value (1\u2013FALNEG). \n    MISCLASS    displays the misclassification rate. \n    ID    displays the ID variables. \n NODETAILS \n  suppresses the display of the model fitting information for the models specified in the ROC statements.\n OUT=SAS-data-set-name \n  is an alias for the OUTROC= option in the MODEL statement. \n WEIGHTED \n  uses frequency x weight in the ROC computations (Izrael et al. 2002) instead of just frequency."},"ProcedureOptionType":"S","SubOptionsKeywords":"ALPHA=|EPS=|ID=|NODETAILS|OUT=|WEIGHTED"},{"ProcedureOptionName":"SIMPLE","ProcedureOptionHelp":{"#cdata":"Displays simple descriptive statistics (mean, standard deviation, minimum and maximum) for each \ncontinuous explanatory variable."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"TRUNCATE","ProcedureOptionHelp":{"#cdata":"Determines class levels by using no more than the first 16 characters of the formatted values \nof CLASS, response, and strata variables."},"ProcedureOptionType":"S"}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"BY","StatementHelp":{"#cdata":"Syntax: BY variables; \n\nYou can specify a BY statement with PROC LOGISTIC to obtain separate analyses of observations in groups that \nare defined by the BY variables. When a BY statement appears, the procedure expects the input data set to be \nsorted in order of the BY variables. If you specify more than one BY statement, only the last one specified is used. \n\nIf your input data set is not sorted in ascending order, use one of the following alternatives: \n\n  \u2022 Sort the data by using the SORT procedure with a similar BY statement. \n  \u2022 Specify the NOTSORTED or DESCENDING option in the BY statement for the BCHOICE procedure. The NOTSORTED \n    option does not mean that the data are unsorted but rather that the data are arranged in groups (according to values \n    of the BY variables) and that these groups are not necessarily in alphabetical or increasing numeric order. \n  \u2022 Create an index on the BY variables by using the DATASETS procedure (in Base SAS software)."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING","StatementOptionHelp":{"#cdata":"Specifies that the observations are sorted in descending order by the variable that \nimmediately follows the word DESCENDING in the BY statement."},"StatementOptionType":"S"},{"StatementOptionName":"NOTSORTED","StatementOptionHelp":{"#cdata":"Specifies that observations are not necessarily sorted in alphabetic or numeric order."},"StatementOptionType":"S"}]}},{"StatementName":"CLASS","StatementHelp":{"#cdata":"Syntax: CLASS variable<(options)><variable<(options)>></options> ; \n      \nThe CLASS statement names the classification variables to be used in the analysis. \nThe CLASS statement must precede the MODEL statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CPREFIX=","StatementOptionHelp":{"#cdata":"[Syntax: CPREFIX=n] \n          \nSpecifies that, at most, the first n characters of a CLASS variable label be used \nin creating labels for the corresponding design variables."},"StatementOptionType":"V"},{"StatementOptionName":"DESCENDING|DESC","StatementOptionHelp":{"#cdata":"Reverses the sorting order of the classification variable. If both the DESCENDING and \nORDER= options are specified, PROC LOGISTICS orders the categories according to the \nORDER= option and then reverses that order."},"StatementOptionType":"S"},{"StatementOptionName":"LPREFIX=","StatementOptionHelp":{"#cdata":"[Syntax: LPREFIX=n] \n          \nSpecifies that, at most, the first n characters of a CLASS variable label be used \nin creating labels for the corresponding design variables."},"StatementOptionType":"V"},{"StatementOptionName":"MISSING","StatementOptionHelp":{"#cdata":"Treats missing values (\".\", \".A\", ..., \".Z\" for numeric variables and blanks for character \nvariables) as valid values for the CLASS variable."},"StatementOptionType":"S"},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"Specifies the sorting order for the levels of classification variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"StatementOptionToolTips":{"@ToolTip1":"Orders values according to their order in the input data set.","@ToolTip2":"Orders values by their ascending formatted values. This order depends on your operating environment.","@ToolTip3":"Orders values by descending frequency count so that levels with the most observations are listed first.","@ToolTip4":"Orders values by their unformatted values, which yields the same order as PROC SORT. This order  depends on your operating environment."}},{"StatementOptionName":"PARAM=","StatementOptionHelp":{"#cdata":"Specifies the parameterization method for the classification variable or variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EFFECT","@Value2":"GLM","@Value3":"ORDINAL","@Value4":"POLYNOMIAL","@Value5":"REFERENCE","@Value6":"ORTHEFFECT","@Value7":"ORTHORDINAL","@Value8":"ORTHPOLY","@Value9":"ORTHREF"},"StatementOptionToolTips":{"@ToolTip1":"Specifies effect coding","@ToolTip2":"Specifies less-than-full-rank, reference-cell coding; this option can be used only as a global option.","@ToolTip3":"Specifies the cumulative parameterization for an ordinal CLASS variable.","@ToolTip4":"Specifies polynomial coding.","@ToolTip5":"Specifies reference-cell coding.","@ToolTip6":"Orthogonalizes PARAM=EFFECT coding.","@ToolTip7":"Orthogonalizes PARAM=ORDINAL coding.","@ToolTip8":"Orthogonalizes PARAM=POLYNOMIAL coding.","@ToolTip9":"Orthogonalizes PARAM=REFERENCE coding."}},{"StatementOptionName":"REF=","StatementOptionHelp":{"#cdata":"[Syntax: REF='level' | FIRST | LAST] \n          \nSpecifies the reference level for PARAM=EFFECT, PARAM=REFERENCE, and their orthogonalizations."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"<'level'>","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"For an individual (but not a global) variable, you can specify the level of the variable to use as  the reference level. Specify the formatted value of the variable if a format is assigned.","@ToolTip2":"For a global or individual variable, designates the first ordered level as reference.","@ToolTip3":"For a global or individual variable, designates the last ordered level as reference."}},{"StatementOptionName":"TRUNCATE=","StatementOptionHelp":{"#cdata":"[Syntax: TRUNCATE<=n>] \n          \nSpecifies the length n of CLASS variable values to use in determining CLASS variable levels. \nThe default is to use the full formatted length of the CLASS variable. If you specify TRUNCATE \nwithout the length n, the first 16 characters of the formatted values are used."},"StatementOptionType":"S|V"}]}},{"StatementName":"CODE","StatementHelp":{"#cdata":"Syntax: CODE <option(s)> ; \n\nThe CODE statement writes SAS DATA step code for computing predicted values of the fitted model either \nto a file or to a catalog entry. This code can then be included in a DATA step to score new data."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CATALOG=|CAT=","StatementOptionHelp":{"#cdata":"Syntax: CATALOG=library.catalog.entry.type\n Syntax: CAT=library.catalog.entry.type \n  \nSpecifies where to write the generated code in the form of library.catalog.entry.type. The compound\nname can have from one to four levels. The default library is determined by the USER= SAS system\noption, which by default is WORK. The default entry is SASCODE, and the default type is SOURCE."},"StatementOptionType":"V"},{"StatementOptionName":"DUMMIES","StatementOptionHelp":{"#cdata":"Specifies to keep dummy variables that represent the CLASS levels in the data set. The default\nis NODUMMIES, which specifies that dummy variables not be retained."},"StatementOptionType":"S"},{"StatementOptionName":"NODUMMIES","StatementOptionHelp":{"#cdata":"Specifies that dummy variables not be retained."},"StatementOptionType":"S"},{"StatementOptionName":"ERROR","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"S"},{"StatementOptionName":"NOERROR","StatementOptionHelp":{"#cdata":"The default is NOERROR, which specifies that the error function not be generated."},"StatementOptionType":"S"},{"StatementOptionName":"FILE=","StatementOptionHelp":{"#cdata":"Syntax: FILE= filename \n          \nNames the external file that saves the generated code. When enclosed in a quoted string (for example,\nFILE=\"c:nmydirnscorecode.sas\"), this option specifies the path for writing the code to an external\nfile. You can also specify unquoted SAS filenames of no more than eight characters for filename. If\nthe filename is assigned as a fileref in a Base SAS FILENAME statement, the file specified in the\nFILENAME statement is opened. The special filerefs LOG and PRINT are always assigned. If the\nspecified filename is not an assigned fileref, the specified value for filename is concatenated with a .txt\nextension before the file is opened. For example, if FOO is not an assigned fileref, FILE=FOO causes\nFOO.txt to be opened. If filename has more than eight characters, an error message is printed."},"StatementOptionType":"V"},{"StatementOptionName":"FORMAT=","StatementOptionHelp":{"#cdata":"Syntax: FORMAT=format \n         \nSpecifies the format for the regression coefficients and other numerical values that do not have a format\nfrom the input data set. The default format is BEST20."},"StatementOptionType":"V"},{"StatementOptionName":"GROUP=","StatementOptionHelp":{"#cdata":"Syntax: GROUP=group-name \n         \nSpecifies the group identifier for group processing. The group-name should be a valid SAS name of no\nmore than 16 characters. It is used to construct array names and statement labels in the generated code."},"StatementOptionType":"V"},{"StatementOptionName":"IMPUTE","StatementOptionHelp":{"#cdata":"Imputes the predicted values according to an intercept-only model for observations with missing or\ninvalid covariate values. For a continuous response, the predicted value is the mean of the response\nvariable; for a categorical response, the predicted values are the proportions of the response categories.\nWhen the IMPUTE option is specified, the scoring code also creates a variable named _WARN_ that\ncontains one or more single-character codes that indicate problems in computing predicted values. The\ncharacter codes used in _WARN_ go in the following positions:\n\nCode Column Meaning\nM     1     Missing covariate value\nU     2     Unrecognized covariate category"},"StatementOptionType":"S"},{"StatementOptionName":"LINESIZE=|LS=","StatementOptionHelp":{"#cdata":"Syntax: LINESIZE=value |  LS=value \n         \nSpecifies the line size for the generated code. The default is 72. The permissible range is 64 to 254."},"StatementOptionType":"V"},{"StatementOptionName":"LOOKUP=","StatementOptionHelp":{"#cdata":"Syntax: LOOKUP=lookup-method \n          \nSpecifies the algorithm for looking up CLASS levels. The default is LOOKUP=AUTO."},"StatementOptionValues":{"@Value1":"AUTO","@Value2":"BINARY","@Value3":"LINEAR","@Value4":"SELECT"},"StatementOptionToolTips":{"@ToolTip1":"Selects the LINEAR algorithm if a CLASS variable has fewer than five categories; otherwise, the BINARY algorithm is used. This is the default.","@ToolTip2":"Uses a binary search. This method is fast, but might produce incorrect results and the normalized category values might contain characters that collate in different orders in ASCII and EBCDIC, if you generate the code on an ASCII machine and execute the code on an EBCDIC machine or vice versa.","@ToolTip3":"Uses a linear search with IF statements that have categories in the order of the class levels. This method is slow if there are many categories.","@ToolTip4":"Uses a SELECT statement."},"StatementOptionType":"V"},{"StatementOptionName":"RESIDUAL","StatementOptionHelp":{"#cdata":"Specifies to generate code to compute residual values. If you request code for residuals and\nthen score a data set that does not contain target values, the residuals will have missing values. The\ndefault is NORESIDUAL, which specifies that the code for residuals not be generated."},"StatementOptionType":"S"},{"StatementOptionName":"NORESIDUAL","StatementOptionHelp":{"#cdata":"The default is NORESIDUAL, which specifies that the code for residuals not be generated."},"StatementOptionType":"S"}]}},{"StatementName":"CONTRAST","StatementHelp":{"#cdata":"Syntax: CONTRAST 'label' row-description<, ...,row-description></ options> ; \n\nThe CONTRAST statement provides a mechanism for obtaining customized hypothesis tests. \nIt is similar to the CONTRAST and ESTIMATE statements in other modeling procedures."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSpecifies the level of significance a for the 100(1 - \u03b1)% confidence interval for each \ncontrast when the ESTIMATE option is specified. The value of number must be between 0 \nand 1. By default, number is equal to the value of the ALPHA= option in the PROC LOGISTIC \nstatement, or 0.05 if that option is not specified."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"displays the L matrix."},"StatementOptionType":"S"},{"StatementOptionName":"ESTIMATE=","StatementOptionHelp":{"#cdata":"Estimates and tests each individual contrast."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"PARM","@Value2":"EXP","@Value3":"BOTH","@Value4":"PROB","@Value5":"ALL"},"StatementOptionToolTips":{"@ToolTip1":"Estimates the individual contrast.","@ToolTip2":"Estimates the exponentiated contrast.","@ToolTip3":"Estimates both the individual contrast and the exponentiated contrast.","@ToolTip4":"Estimates the predicted probability of the contrast.","@ToolTip5":"Estimates the individual contrast, the exponentiated contrast, and the predicted  probability of the contrast."}},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. This option is ignored when a full-rank parameterization is specified."},"StatementOptionType":"V"}]}},{"StatementName":"EFFECT","StatementHelp":{"#cdata":"Syntax: EFFECT effect-name = effect-type (var-list < / effect-options >) ; \n\nThe name of the effect is specified after the EFFECT keyword. This name can appear \nin only one EFFECT statement and cannot be the name of a variable in the input data \nset. The effect-type is specified after an equal sign, followed by a list of variables \nwithin parentheses which are used in constructing the effect. Effect-options that are \nspecific to an effect-type can be specified after a slash (/) following the variable list. \n\nThe EFFECT statement enables you to construct special collections of columns for design \nmatrices. These collections are referred to as constructed effects to distinguish them \nfrom the usual model effects formed from continuous or classification variables."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"EFFECT-NAME=","StatementOptionHelp":{"#cdata":"Replace 'EFFECT-NAME' with the name of the effect, specified after the EFFECT keyword. \nThis name can appear in only one EFFECT statement and cannot be the name of a \nvariable in the input data set."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"COLLECTION","@Value2":"LAG","@Value3":"MULTIMEMBER|MM","@Value4":"POLYNOMIAL|POLY","@Value5":"SPLINE"},"StatementOptionToolTips":{"@ToolTip1":"Is a collection effect that defines one or more variables as a single effect with  multiple degrees of freedom. The variables in a collection are considered as a  unit for estimation and inference.  Option(s) available (specified after a slash (/) following the variable list):   DETAILS  Displays the constituents of the collection effect","@ToolTip2":"Is a classification effect in which the level that is used for a given period  corresponds to the level in the preceding period.   Options available (specified after a slash (/) following the variable list):    DESIGNROLE=    Names a variable that controls to which lag design an observation is assigned     DETAILS    Displays the lag design of the lag effect     NLAG=    Specifies the number of periods in the lag     PERIOD=    Names the variable that defines the period     WITHIN=    Names the variable or variables that define the group within which each period is defined","@ToolTip3":"Is a multimember classification effect whose levels are determined by one or  more variables that appear in a CLASS statement.   Options available (specified after a slash (/) following the variable list):     NOEFFECT    Specifies that observations with all missing levels for the multimember variables should    have zero values in the corresponding design matrix columns     WEIGHT=    Specifies the weight variable for the contributions of each of the classification effects","@ToolTip4":"Is a multivariate polynomial effect in the specified numeric variables.                                      Options available (specified after a slash (/) following the variable list):     DEGREE=    Specifies the degree of the polynomial     MDEGREE=    Specifies the maximum degree of any variable in a term of the polynomial     STANDARDIZE=    Specifies centering and scaling suboptions for the variables that define the polynomial","@ToolTip5":"Is a regression spline effect whose columns are univariate spline expansions of  one or more variables. A spline expansion replaces the original variable with  an expanded or larger set of new variables.   Options available (specified after a slash (/) following the variable list):     BASIS=    Specifies the type of basis (B-spline basis or truncated power function basis) for the spline expansion     DEGREE=    Specifies the degree of the spline transformation     KNOTMETHOD=    Specifies how to construct the knots for spline effects"},"SubOptionsKeywords":"DETAILS|DESIGNROLE=|NLAG=|WITHIN=|NOEFFECT|WEIGHT=|DEGREE=|MDEGREE=|STANDARDIZE=|BASIS=|KNOTMETHOD="},{"StatementOptionName":"PERIOD=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only]\n          \n[Syntax: PERIOD=variable] \n          \nSpecifies the period variable of the LAG design. The number of periods is the number \nof unique formatted values of the PERIOD= variable, and the ordering of the period is \nformed by sorting these formatted values in ascending order. You must specify a PERIOD= \nvariable."},"StatementOptionType":"V"},{"StatementOptionName":"WITHIN=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: WITHIN=(variables) | WITHIN=variable] \n\nSpecifies a variable (or a list of variables within parentheses) that defines the \nsubject grouping of the lag design. If there is only one WITHIN= variable, then the \nparentheses are not required. Each subject is defined by the unique set of formatted \nvalues of the variables in the WITHIN= list. The subjects are sorted in ascending \nlexicographic order. You must specify a WITHIN= variable."},"StatementOptionType":"V"},{"StatementOptionName":"DESIGNROLE=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: DESIGNROLE=variable] \n\nSpecifies a numeric variable that is used to subset observations into a fitting group \nin which the value of the DESIGNROW= variable is nonzero and a second group in which \nthe value of the specified variable is zero. The observations in the fitting group are \nused to form the LAG design matrix that is used in fitting the model. The LAG design \nthat corresponds to the non-fitting group is used when scoring observations in the \ninput data set that do not belong to the fitting group. This option is useful when \nyou want to obtain predicted values in an output data set for observations that are \nnot used in fitting the model. If you do not specify a DESIGNROLE= variable, then all \nobservations are assigned to the fitting group."},"StatementOptionType":"V"},{"StatementOptionName":"DETAILS","StatementOptionHelp":{"#cdata":"[For the LAG | COLLECTION | MULTIMEMBER | POLYNOMIAL |SPLINE effect-type] \n          \nRequests a table that shows the (1) lag design matrix of the lag effect, or (2) constituents \nof the collection effect, or (3) levels of the multimember effect, or (4) details of the specified \npolynomial, or (5) knot locations and the knots associated with each spline basis function."},"StatementOptionType":"S"},{"StatementOptionName":"NLAG=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: NLAG= n] \n\nSpecifies the number of lags. By default NLAG=1."},"StatementOptionType":"V"},{"StatementOptionName":"NOEFFECT","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \nSpecifies that, for observations with all missing levels of the multimember variables, \nthe values in the corresponding design matrix columns be set to zero."},"StatementOptionType":"S"},{"StatementOptionName":"STDIZE","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \nSpecifies that for each observation, the entries in the design matrix that corresponds \nto the multimember effect be scaled to have a sum of one."},"StatementOptionType":"S"},{"StatementOptionName":"WEIGHT=","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \n[Syntax: WEIGHT=wght-list] \n\nSpecifies numeric variables used to weigh the contributions of each of the classification \neffects that define the constructed multimember effect. The number of variables in wght-list \nmust match the number of classification variables that define the effect."},"StatementOptionType":"V"},{"StatementOptionName":"DEGREE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL and SPLINE effect-type only] \n          \n[Syntax: DEGREE=n] \n\nSpecifies the (1) degree of the polynomial, or (2) degree of the spline transformation. \nThe degree must be a positive integer. The n degree is typically a small integer, such as \n1, 2, or 3. The default for polynomial effect is DEGREE=1, and DEGREE=3 for spline \ntransformation."},"StatementOptionType":"V"},{"StatementOptionName":"LABELSTYLE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: LABELSTYLE=(style-opts) | LABELSTYLE=style-opt] \n\nSpecifies how the terms in the polynomial are labeled. By default, powers are shown \nwith ^ as the exponentiation operator and * as the multiplication operator."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EXPAND","@Value2":"EXPONENT","@Value3":"INCLUDENAME","@Value4":"PRODUCTSYMBOL="},"StatementOptionToolTips":{"@ToolTip1":"Specifies that each variable with an exponent greater than 1 be written as products of that variable.","@ToolTip2":"Syntax: EXPONENT <=quoted string>                                      Specifies that each variable with an exponent greater than 1 be written using exponential  notation. By default, the symbol ^ is used as the exponentiation operator. If you supply the  optional quoted string after an equal sign, then that string is used as the exponentiation  operator.","@ToolTip3":"Specifies that the name of the effect followed by an underscore be used as a prefix  for term labels.","@ToolTip4":"Syntax: PRODUCTSYMBOL=NONE | quoted string                                      Specifies that the supplied string be used as the product symbol."}},{"StatementOptionName":"MDEGREE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: MDEGREE=n] \n\nSpecifies the maximum degree of any variable in a term of the polynomial. This degree \nmust be a positive integer. The default is the degree of the specified polynomial."},"StatementOptionType":"V"},{"StatementOptionName":"NOSEPARATE","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \nSpecifies that the polynomial be treated as a single effect with multiple degrees \nof freedom. The effect name that you specify is used as the constructed effect name, \nand the labels of the terms are used as labels of the corresponding parameters."},"StatementOptionType":"S"},{"StatementOptionName":"STANDARDIZE","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: STANDARDIZE <(centerscale-opts)> <= standardize-opt>] \n\nSpecifies that the variables that define the polynomial be standardized. By default, \nthe standardized variables receive prefix \"s_\" in the variable names. \n\nYou can use the following centerscale-opts to specify how the center and scale are estimated: \n\n  METHOD=MOMENTS \n  specifies that the center be estimated by the variable mean and the scale be estimated by the standard deviation. \n\n  METHOD=RANGE \n  specifies that the center be estimated by the midpoint of the variable range and the scale be estimated as half the variable range.\n\n  METHOD=WMOMENTS \n  is the same as METHOD=MOMENTS except that weighted means and weighted standard deviations are used. \n\n  PREFIX=NONE | quoted-string \n  specifies the prefix that is appended to standardized variables when forming the term labels."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"CENTER","@Value2":"CENTERSCALE","@Value3":"NONE","@Value4":"SCALE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that variables be centered but not scaled.","@ToolTip2":"Specifies that variables be centered and scaled. This is the default if you do not  specify a standardization-opt.","@ToolTip3":"Specifies that no standardization be performed.","@ToolTip4":"Specifies that variables be scaled but not centered."}},{"StatementOptionName":"BASIS=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies a basis for the spline expansion."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BSPLINE","@Value2":"TPF"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a B-spline basis for the spline expansion.","@ToolTip2":"Syntax: TPF(options)                                      Specifies a truncated power function basis for the spline expansion.   You can modify the number of columns when you request BASIS=TPF with the following options:     NOINT    excludes the intercept column.     NOPOWERS    excludes the intercept and polynomial columns."}},{"StatementOptionName":"DATABOUNDARY","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only]\n          \nSpecifies that the extremes of the data be used as boundary knots when building a B-spline basis."},"StatementOptionType":"S"},{"StatementOptionName":"KNOTMAX=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only]\n          \n[Syntax: KNOTMAX=value] \n\nSpecifies that, for each variable in the EFFECT statement, the right-side boundary \nknots be equally spaced starting at the maximum of the variable and ending at the \nspecified value. This option is ignored for variables whose maximum value is greater \nthan the specified value or if the DATABOUNDARY option is also specified."},"StatementOptionType":"V"},{"StatementOptionName":"KNOTMETHOD=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies how to construct the knots for spline effects."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EQUAL","@Value2":"LIST","@Value3":"LISTWITHBOUNDARY","@Value4":"MULTISCALE","@Value5":"PERCENTILES","@Value6":"RANGEFRACTIONS"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: EQUAL<(n)>               Specifies that n equally spaced knots be positioned between the extremes of the data.  The default is n=3. For a B-spline basis, any needed boundary knots continue to be  equally spaced unless the DATABOUNDARY option has also been specified. KNOTMETHOD=EQUAL  is the default if no knot-method is specified.","@ToolTip2":"Syntax: LIST(number-list)                                      Specifies the list of internal knots to be used in forming the spline basis columns.  For a B-spline basis, the data extremes are used as boundary knots.","@ToolTip3":"Syntax: LISTWITHBOUNDARY(number-list)                                      Specifies the list of all knots that are used in forming the spline basis columns.","@ToolTip4":"Syntax: MULTISCALE<(multiscale-options)>                                      Specifies that multiple B-spline bases be generated, corresponding to sets with an  increasing number of internal knots.   You can control which scales are included with the following multiscale-options:     STARTSCALE=n    specifies the start scale, where n is a positive integer. The default is STARTSCALE=0.     ENDSCALE=n    specifies the end scale, where n is a positive integer. The default is ENDSCALE=7.","@ToolTip5":"Syntax: PERCENTILES(n)                                      Requests that internal knots be placed at n equally spaced percentiles of the variable  or variables named in the EFFECT statement.","@ToolTip6":"Syntax: RANGEFRACTIONS(fraction-list)                                      Requests that internal knots be placed at each fraction of the ranges of the variables  in the EFFECT statement."}},{"StatementOptionName":"KNOTMIN=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \n[Syntax: KNOTMIN=value] \n\nSpecifies that for each variable in the EFFECT statement, the left-side boundary knots be \nequally spaced starting at the specified value and ending at the minimum of the variable. \nThis option is ignored for variables whose minimum value is less than the specified value \nor if the DATABOUNDARY option is also specified."},"StatementOptionType":"V"},{"StatementOptionName":"SEPARATE","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies that when multiple variables are specified in the EFFECT statement, \nthe spline basis for each variable be treated as a separate effect. The names \nof these separated effects are formed by appending an underscore followed by \nthe name of the variable to the name that you specify in the EFFECT statement."},"StatementOptionType":"S"},{"StatementOptionName":"SPLIT","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies that each individual column in the design matrix that corresponds to the spline \neffect be treated as a separate effect that can enter or leave the model independently. \nNames for these split effects are generated by appending the variable name and an index \nfor each column to the name that you specify in the EFFECT statement."},"StatementOptionType":"S"}]}},{"StatementName":"EFFECTPLOT","StatementHelp":{"#cdata":"Syntax: EFFECTPLOT <plot-type <(plot-definition-options)>> </ options> ; \n      \nThe EFFECTPLOT statement produces a display of the fitted model and provides options \nfor changing and enhancing the displays."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"BOX","StatementOptionHelp":{"#cdata":"Displays a box plot of continuous response data at each level of a CLASS effect, with \npredicted values superimposed and connected by a line. This is an alternative to the \nINTERACTION plot-type."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X="},{"StatementOptionName":"CONTOUR","StatementOptionHelp":{"#cdata":"Displays a contour plot of predicted values against two continuous covariates."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X=|Y="},{"StatementOptionName":"FIT","StatementOptionHelp":{"#cdata":"Displays a curve of predicted values versus a continuous variable."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X="},{"StatementOptionName":"INTERACTION","StatementOptionHelp":{"#cdata":"Displays a curve of predicted values versus a continuous variable grouped by the levels \nof a CLASS effect."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|SLICEBY=|X="},{"StatementOptionName":"MOSAIC","StatementOptionHelp":{"#cdata":"Displays a mosaic plot of predicted values using up to three CLASS effects."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X="},{"StatementOptionName":"SLICEFIT","StatementOptionHelp":{"#cdata":"[Syntax: ]"},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|SLICEBY=|X="},{"StatementOptionName":"ADCELL","StatementOptionHelp":{"#cdata":"[Syntax: ADDCELL<=value> ]\n          \nAdds value to the weight of every cell in the MOSAIC plot-type. You can specify value as any nonnegative number. \nIf you do not specify a value, then value=0.5. This enables you to add some dimension to zero frequency cells."},"StatementOptionType":"V"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=value] \n          \nSpecifies the significance level, 0 \u2265 value \u2265 1, for producing 100(1-value/2)% \nprediction and confidence limits. By default, value=0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT <contopt> <classopt> <variable1=varopt <variable2=varopt...>> \n\nwhere contopt= MEAN | MIN | MAX | MIDRANGE \nclassopt= ALL | REF \nvaropt= contopts | number-list |  classopts | 'class-level'...'class-level'] \n\nSpecifies values at which to fix continuous and class variables when they are not used \nin X=, Y=, SLICEBY=, or PLOTBY= effects. The contopt keyword fixes continuous variables \nat their mean, minimum, maximum, or midrange; the default is to use the mean. The classopt \nkeyword either fixes a CLASS variable at its reference (last) level or indicates that all \nlevels of the CLASS variable should be processed; the default is to use the reference level. \nThe varopt values enable you to specify contopt and classopt keywords, or to specify lists \nof numbers or class levels. You can specify a CLASS variable only once in the AT specification, \nbut you can specify a continuous variable multiple times."},"StatementOptionType":"S"},{"StatementOptionName":"ATLEN=","StatementOptionHelp":{"#cdata":"[Syntax: ATLEN=n] \n          \nSpecifies the maximum length (1 < n < 256) of the levels of the AT variables that are displayed \nin footnotes and headers. By default, up to 256 characters of the CLASS levels are displayed, \nand the continuous AT levels are displayed with a BEST format that has a width greater than \nor equal to 5, which distinguishes each level. Caution:If the levels of your AT variables are \nnot unique when the first n characters are displayed, then the levels are combined in the plots \nbut not in the underlying computations. Also, at most n characters for continuous AT variables \nare displayed."},"StatementOptionType":"V"},{"StatementOptionName":"ATORDER=","StatementOptionHelp":{"#cdata":"Uses the AT values for continuous variables in ascending or descending order as specified. \nBy default, values are used in the order of their first appearance in the AT option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ASCENDING","@Value2":"DESCENDING"},"StatementOptionToolTips":{"@ToolTip1":"Uses the AT values for continuous variables in ascending order","@ToolTip2":"Uses the AT values for continuous variables in descending order"}},{"StatementOptionName":"CLI","StatementOptionHelp":{"#cdata":"Displays normal (Wald) prediction limits. This option is available only for normal \ndistributions with identity links. If your model is from a Bayesian analysis, then \nsampling-based intervals are computed."},"StatementOptionType":"S"},{"StatementOptionName":"CLM","StatementOptionHelp":{"#cdata":"Displays confidence limits. These are computed as the normal (Wald) confidence limits \nfor the linear predictor, and if the ILINK option is specified, the limits are also \nback-transformed by the inverse link function. If your model is from a Bayesian analysis, \nthen sampling-based intervals are computed."},"StatementOptionType":"S"},{"StatementOptionName":"CLUSTER","StatementOptionHelp":{"#cdata":"Syntax: CLUSTER<=percent> \n          \nModifies the BOX and INTERACTION plot-types by displaying the levels of the SLICEBY= effect in \na side-by-side fashion. You can specify percent as a percentage of half the distance between X \nlevels. The percent value must be between 0.1 and 1; the default percent depends on the number \nof X levels, the number of SLICEBY levels, and the number of PLOTBY levels for INTERACTION \nplot-types. Default clustering can be removed by specifying the NOCLUSTER option."},"StatementOptionType":"S|V"},{"StatementOptionName":"CONNECT","StatementOptionHelp":{"#cdata":"Modifies the BOX and INTERACTION plot-types by connecting the predicted values with a line. \nDefault connecting lines can be removed by specifying the NOCONNECT option."},"StatementOptionType":"S"},{"StatementOptionName":"EXTEND=","StatementOptionHelp":{"#cdata":"Extends continuous covariate axes by value x \u00bdrange in both directions, where range \nis the range of the X axis."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"<value>"},"StatementOptionToolTips":{"@ToolTip1":"Displays curves to the range of the data within the appropriate SLICEBY=, PLOTBY=, and AT level.","@ToolTip2":"Replace <value> with an actual value."}},{"StatementOptionName":"GRIDSIZE=","StatementOptionHelp":{"#cdata":"[Syntax: GRIDSIZE=n] \n          \nSpecifies the resolution of curves by computing the predicted values at n equally spaced \nx-values and specifies the resolution of surfaces by computing the predicted values on an \nnxn grid of points. Default values are n=200 for curves and bands, n=50 for surfaces, and \nn=2 for lines. If results of a Bayesian or bootstrap analysis are being displayed, then \nthe defaults are n=500000/B, where B is the number of samples, the upper limit is equal \nto the usual defaults, and the lower limit equal to 20."},"StatementOptionType":"V"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Displays the fit on the scale of the inverse link function. In particular, the results \nare displayed on the probability scale for logistic regression. By default, a procedure \ndisplays the fit on either the link or inverse link scale."},"StatementOptionType":"S"},{"StatementOptionName":"INDIVIDUAL","StatementOptionHelp":{"#cdata":"Displays individual probabilities for polytomous response models with cumulative links \non the scale of the inverse link function. This option is not available when the LINK \noption is specified, and confidence limits are not available with this option."},"StatementOptionType":"S"},{"StatementOptionName":"LIMITS","StatementOptionHelp":{"#cdata":"Invokes the CLI and CLM options."},"StatementOptionType":"S"},{"StatementOptionName":"LINK","StatementOptionHelp":{"#cdata":"Displays the fit on the scale of the link function; that is, the linear predictor. \nNote that probabilities or observed proportions near 0 and 1 are transformed to . \nBy default, a procedure displays the fit on either the link or inverse link scale."},"StatementOptionType":"S"},{"StatementOptionName":"MOFF","StatementOptionHelp":{"#cdata":"Moves the offset for a Poisson regression model to the response side of the equation. \nIf the ILINK option is also in effect, then the rate is displayed on the Y axis, while \nthe LINK option displays the log of the rate on the Y axis. Without this option, the \npredicted values are computed and displayed only for the observations."},"StatementOptionType":"S"},{"StatementOptionName":"NCOLS=","StatementOptionHelp":{"#cdata":"[Syntax: NCOLS=n] \n          \nSpecifies the maximum number of columns in a paneled plot. This option is not available \nwith the BOX plot-type. \n\nThe default choice of NROWS= and NCOLS= is based on the number of PLOTBY= and AT levels. \nIf there is only one plot being displayed in a panel, then NROWS=1 and NCOLS=1 and the \nplots are produced as if you specified only the UNPACK option. If only two plots are \ndisplayed in a panel, then NROWS=1 and NCOLS=2. For all other cases, a 2x2, 2x3, or 3x3 \npanel is chosen based on how much of the last panel is used, with ties going to the larger \npanels. For example, if 14 plots are being created, then this requires either four 2x2 \npanels with 50% of the last panel filled, three 2x3 panels with 33% of the last panel \nfilled, or two 3x3 panels with 55% of the last panel filled; in this case, the 3x3 panels \nare chosen. \n\nIf you specify both of the NROWS= and NCOLS= options, then those are the values used. However, \nif you only specify one of the options but have fewer plots, then the panel size is reduced; \nfor example, if you specify NROWS=6 but only have four plots, then a plot with four rows and \none column is produced."},"StatementOptionType":"V"},{"StatementOptionName":"NOCLI","StatementOptionHelp":{"#cdata":"Suppresses the prediction limits."},"StatementOptionType":"S"},{"StatementOptionName":"NOCLM","StatementOptionHelp":{"#cdata":"Suppresses the confidence limits."},"StatementOptionType":"S"},{"StatementOptionName":"NOLIMITS","StatementOptionHelp":{"#cdata":"Invokes the NOCLI and NOCLM options."},"StatementOptionType":"S"},{"StatementOptionName":"NOOBS","StatementOptionHelp":{"#cdata":"Suppresses the display of observations and overrides the specification of the OBS= option."},"StatementOptionType":"S"},{"StatementOptionName":"NROWS=","StatementOptionHelp":{"#cdata":"[Syntax: NROWS=n] \n          \nSpecifies the maximum number of rows in a paneled plot. This option is not available \nwith the BOX plot-type. See the NCOLS= option for more details."},"StatementOptionType":"V"},{"StatementOptionName":"OBS","StatementOptionHelp":{"#cdata":"[Syntax: OBS<(options)>] \n          \nDisplays observations on the effect plots. An input data set is required; hence the OBS option \nis not available with PROC PLM. The OBS option is overridden by the NOOBS option. When the ILINK \noption is specified with binary response variables, then either the observed proportions or a coded \nvalue of the response is displayed. For polytomous response variables, the observed values are overlaid \nonto the fitted curves unless the LOCATION= option is specified. Whether observations are displayed by \ndefault or not depends upon the procedure. If the PLOTBY= option is specified, then the observations \ndisplayed on each plot are from the corresponding PLOTBY= level for classification effects; for \ncontinuous effects, all observations are displayed on every plot. \n\nThe following options are available: \n\n  BYAT -- subsets the observations by AT level and by the PLOTBY= level. \n\n  CDISPLAY=NONE | OUTLINE | GRADIENT | OUTLINEGRADIENT \n  controls the display of observations on contour plots. \n\n  CGRADIENT=RESIDUAL | DEPENDENT \n  specifies what the gradient-shading of the observed values on the CONTOUR plot-type represents. \n\n  DEPTH=depth (you can specify 1 \u2264 depth \u2264 100. By default, DEPTH=1)\n  specifies the number of overlapping observations that can be distinguished by adjusting their transparency.\n\n  DISTANCE \n  displays observations on FIT plot-types with a color-gradient that indicates how far the \n  observation is from the AT and PLOTBY= level. \n\n  FITATCLASS --  computes fitted values only for class levels that are observed in the data set.  \n\n  FRINGE -- displays observations in a fringe (rug) plot at the bottom of the plot.  \n\n  JITTER<(FACTOR=factor SEED=seed X=x-jitter Y=y-jitter)> --  shifts (jitters) the observations. \n  \n  LABEL<=OBS> --  labels markers with their observation number. \n\n  LOCATION= BOTTOM | CURVE | FIRST | MAX | MIDDLE | MIN | SPREAD | TOP<=factor>\n  specifies where the observed values for polytomous response models are displayed when the SLICEBY= variable is the response."},"StatementOptionType":"S","SubOptionsKeywords":"BYAT|CDISPLAY=|CGRADIENT=|DEPTH=|DISTANCE|FITATCLASS|FRINGE|JITTER|FACTOR=|SEED=|X=|Y=|LABEL|LABEL=|LOCATION="},{"StatementOptionName":"PLOTBY=","StatementOptionHelp":{"#cdata":"[Syntax: PLOTBY<(panel-type)>=effect<=numeric-list>] \n          \nSpecifies a variable or CLASS effect at whose levels the predicted values are computed \nand the plots are displayed. You can specify the response variable as the effect for \npolytomous response models. The panel-type argument specifies the method in which the \nplots are grouped for the display. The following panel-types are available. \n\n  COLUMNS \n  specifies that the columns within each panel correspond to different levels of the PLOTBY= \n  effect and hence the rows correspond to different AT levels. \n\n  PACK \n  specifies that plots be displayed in the panels as they are produced with no control over \n  the placement of the PLOTBY= and AT levels. \n\n  PANELS | LEVELS \n  specifies that each level of the PLOTBY= effect begin a new panel of plots and the AT \n  levels define the plots within the panels. \n\n  ROWS \n  specifies that the rows within each panel correspond to different levels of the PLOTBY= \n  effect and hence the columns correspond to different AT levels. \n\nThis option is ignored with the BOX plot-type; box plots are always displayed in an unpacked \nfashion, grouped by the PLOTBY= and AT levels. If you specify a continuous variable as the \neffect, then you can either specify a numeric-list of values at which to display that variable \nor, by default, five equally spaced values from the minimum variable value to its maximum are \ndisplayed."},"StatementOptionType":"S|V","SubOptionsKeywords":"COLUMNS|PACK|PANELS|LEVELS|ROWS"},{"StatementOptionName":"PLOTBYLEN=","StatementOptionHelp":{"#cdata":"[Syntax: PLOTBYLEN=n] \n          \nSpecifies the maximum length (1 \u2264 n \u2264 256) of the levels of the PLOTBY= variables, which are displayed \nin footnotes and headers. By default, up to 256 characters of the CLASS levels are displayed. \n\nCaution:If the levels of your PLOTBY= variables are not unique when the first n characters \nare displayed, then the levels are combined in the plots but not in the underlying computations."},"StatementOptionType":"V"},{"StatementOptionName":"POLYBAR","StatementOptionHelp":{"#cdata":"Displays polytomous response data as a stacked histogram with bar heights defined \nby the individual predicted value. Your response variable must be the SLICEBY= \nvariable, and the INDIVIDUAL and ILINK options must be in effect; otherwise, the \noption is ignored. Confidence limits are ignored."},"StatementOptionType":"S"},{"StatementOptionName":"PREDLABEL=","StatementOptionHelp":{"#cdata":"[Syntax: PREDLABEL=label] \n          \nSpecifies a label to be displayed on the Y axis. The default Y axis label is determined \nby your model. For the CONTOUR plot-type, this option changes the title to \"label for Y.\""},"StatementOptionType":"V"},{"StatementOptionName":"SHOWCLEGEND","StatementOptionHelp":{"#cdata":"Displays the gradient-legend for the CONTOUR plot-type. This option has no effect \nwhen the OBS(CGRADIENT=RESIDUAL) option is also specified."},"StatementOptionType":"S"},{"StatementOptionName":"SLICEBY=","StatementOptionHelp":{"#cdata":"[Syntax: SLICEBY=NONE | effect<=numeric-list>] \n          \nDisplays the fitted values at the different levels of the specified variable or CLASS effect."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"NONE","@Value2":"effect<=numeric-list>"},"StatementOptionToolTips":{"@ToolTip1":"Preventing the INTERACTION plot-type from slicing by a second class covariate. Note  that the SLICEBY=NONE option is not available for the SLICEFIT plot-type, since that  is the same as the FIT plot-type.","@ToolTip2":"You can specify the response variable as the effect for polytomous response models. Use   this option to modify SLICEFIT and INTERACTION plot-types. If you specify a continuous  variable as the effect, then you can either specify a numeric-list of values at which  to display that variable or, by default, five equally spaced values from the minimum  variable value to its maximum are displayed."}},{"StatementOptionName":"SMOOTH","StatementOptionHelp":{"#cdata":"Overlays a loess smooth on the FIT plot-type for models that have only one continuous \npredictor. This option is not available for binary or polytomous response models."},"StatementOptionType":"S"},{"StatementOptionName":"UNPACK","StatementOptionHelp":{"#cdata":"Suppresses paneling. By default, multiple plots can appear in some output panels. \nSpecify UNPACK to display each plot separately.]"},"StatementOptionType":"S"},{"StatementOptionName":"X=","StatementOptionHelp":{"#cdata":"[Syntax: X=effect] \n          \nSpecifies values to display on the X axis. For BOX and INTERACTION plot-types, effect \ncan be a CLASS effect in the MODEL statement. For FIT, SLICEFIT, and CONTOUR plot-types, \neffect can be any continuous variable in the model."},"StatementOptionType":"V"},{"StatementOptionName":"Y=","StatementOptionHelp":{"#cdata":"[Syntax: Y=args] \n          \nSpecifies values to display on the Y axis for the CONTOUR plot-type. The Y= argument \ncan be any continuous variable in the model."},"StatementOptionType":"V"},{"StatementOptionName":"YRANGE=","StatementOptionHelp":{"#cdata":"Displays the predicted values on the Y axis in the range [min,max]. \n          \nBy default, when the Y axis displays predicted probabilities, the entire Y axis, [0,1], \nis displayed. This option is useful if your predicted probabilities are all contained \nin some subset of this range. This option is not available with the CONTOUR plot-type. "},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CLIP","@Value2":"<(<min><,max>)>"},"StatementOptionToolTips":{"@ToolTip1":"Has the same effect as specifying the minimum predicted value as min and the maximum predicted value as max.","@ToolTip2":"Replace min and max with actual values."}}],"#comment":{}}},{"StatementName":"ESTIMATE","StatementHelp":{"#cdata":"Syntax: ESTIMATE <'label'> estimate-specification <(divisor=n)>\n  <, ...<'label'> estimate-specification <(divisor=n)>> < / options> ; \n  \nThe ESTIMATE statement provides a mechanism for obtaining custom hypothesis tests. \nEstimates are formed as linear estimable functions of the form L\u03b2. You can perform \nhypothesis tests for the estimable functions, construct confidence limits, and obtain \nspecific nonlinear transformations. \n\nThe basic element of the ESTIMATE statement is the estimate-specification, which consists \nof model effects and their coefficients. A estimate-specification takes the general form \n\n  effect name <effect values ...> \n  \nThe following variables can appear in the ESTIMATE statement: \n\n  label \n  is an optional label that identifies the particular row of the estimate in the output. \n\n  effect \n  identifies an effect that appears in the MODEL statement. The keyword INTERCEPT can be \n  used as an effect when an intercept is fitted in the model. You do not need to include \n  all effects that are in the MODEL statement. \n\n  values \n  are constants that are elements of the L matrix and are associated with the fixed and random effects."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \n  limits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator    degrees of freedom for the final effect listed in the ESTIMATE statement from the 'Type    III' table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees    of freedom are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the estimates."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE<(simoptions)>","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum    or maximum absolute value of a multivariate t random vector.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."}},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed with confidence level 1-number.  \nThe value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F or chi-square tests with the JOINT option. \n\nThe category-options are used to indicate how response variable levels are treated in \nconstructing the estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row ESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row ESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed. If the procedure shows the degrees \nof freedom in the \"Estimates\" table as infinite, then the confidence limits are z intervals. \nThe confidence level is 0.95 by default, and you can change the confidence level with the \nALPHA= option. The confidence intervals are adjusted for multiplicity when you specify the \nADJUST= option. However, if a step-down p-value adjustment is requested with the STEPDOWN \noption, only the p-values are adjusted for multiplicity."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the linear combination of the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the linear combination of the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. This option \nis not supported by the procedures that perform chi-square-based inference (LOGISTIC, \nPHREG, and SUVEYLOGISTIC)."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0. \n\nIf the number of elements in value-list exceeds the number of rows of the estimate, the \nextra values are ignored. If the number of elements in value-list is less than the number \nof rows of the estimate, the last value in value-list is copied forward. \n\nIf you specify a row-specific divisor as part of the specification of the estimate row, \nthis value multiplies the corresponding divisor that is implied by the value-list. For \nexample, the following statement divides the coefficients in the first row by 8, and the \ncoefficients in the third and fourth row by 3: \n\n  estimate 'One vs. two'   A 2 -2  (divisor=2),\n           'One vs. three' A 1  0 -1         ,\n           'One vs. four'  A 3  0  0 -3      ,\n           'One vs. five'  A 1  0  0  0  -1  / divisor=4,.,3;\n\nCoefficients in the second row are not altered."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the estimate. When you model data with the logit, cumulative \nlogit, or generalized logit link functions, and the estimate represents a log odds ratio \nor log cumulative odds ratio, the EXP option produces an odds ratio. In proportional hazards \nmodel, this option produces estimates of hazard ratios. If you specify the CL or ALPHA= option, \nthe (adjusted) confidence bounds are also exponentiated. \n\nThe EXP option is supported only by PROC PHREG, PROC SURVEYPHREG, the procedures that support \ngeneralized linear modeling (LOGISTIC and SURVEYLOGISTIC), and by PROC PLM when it is used to \nperform statistical analyses on item stores created by these procedures."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the mean \n(the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \nThe JOINT option in the ESTIMATE statement essentially replaces the CONTRAST statement. \n\nWhen the LOWERTAILED or the UPPERTAILED options are in effect, or if the BOUNDS option \ndescribed below is in effect, the JOINT option produces the chi-bar-square statistic \naccording to Silvapulle and Sen (2004). This statistic uses a simulation-based approach \nto compute p-values in situations where the alternative hypotheses of the estimable \nfunctions are not simple two-sided hypotheses. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004).   \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option. "},"StatementOptionType":"S"},{"StatementOptionName":"NOFILL","StatementOptionHelp":{"#cdata":"Suppresses the automatic fill-in of coefficients of higher-order effects."},"StatementOptionType":"V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Produces all possible plots with their default settings.","@ToolTip2":"Syntax: BOXPLOT<(boxplot-options)>                                      Produces box plots of the distribution of the estimable function across the posterior  sample. A separate box is generated for each estimable function, and all boxes appear  on a single graph by default. You can affect the appearance of the box plot graph with  the following options:     ORIENTATION=VERTICAL|HORIZONTAL    ORIENT=VERT|HORIZ    specifies the orientation of the boxes. The default is vertical orientation of the box plots.     NPANELPOS=number    specifies how to break the series of box plots across multiple panels. If the NPANELPOS option    is not specified, or if number equals zero, then all box plots are displayed in a single graph;    this is the default.","@ToolTip3":"Syntax: DISTPLOT<(distplot-options)>                                      Generates panels of histograms with a kernel density overlaid. A separate plot in each  panel contains the results for each estimable function. You can specify the following  distplot-options in parentheses:     BOX|NOBOX    controls the display of a horizontal box plot of the estimable function's distribution    across the posterior sample below the graph. The BOX option is enabled by default.     HIST|NOHIST    controls the display of the histogram of the estimable function's distribution across the    posterior sample. The HIST option is enabled by default.     NORMAL|NONORMAL    controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.     KERNEL|NOKERNEL    controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.     NROWS=number    specifies the highest number of rows in a panel. The default is 3.     NCOLS=number    specifies the highest number of columns in a panel. The default is 3.     UNPACK    unpacks the panel into separate graphics.","@ToolTip4":"Does not produce any plots."},"SubOptionsKeywords":"BOX|NOBOX|HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the \nESTIMATE statement (for example, chi-bar-square statistics and simulated p-values). \nnumber specifies an integer that is used to start the pseudo-random number generator \nfor the simulation. If you do not specify a seed, or if you specify a value less than \nor equal to zero, the seed is generated from reading the time of day from the computer \nclock. There could be multiple ESTIMATE statements with SEED= specifications and there \ncould be other statements that can supply a random number seed. Since the procedure has \nonly one random number stream, the initial seed is shown in the SAS log."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant. \n\nYou can specify the following step-down-options in parentheses after the STEPDOWN option: \n\n  MAXTIME=n \n  specifies the time (in seconds) to be spent computing the maximal logically consistent \n  sequential subsets of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60. \n\n  ORDER=PVALUE | ORDER=ROWS   \n  specifies the order in which the step-down tests to be performed. ORDER=PVALUE is the default, \n  with estimates being declared significant only if all estimates with smaller (unadjusted) \n  p-values are significant. If you specify ORDER=ROWS, then significances are evaluated in the \n  order in which they are specified in the syntax. \n  \n  REPORT \n  specifies that a report on the step-down adjustment be displayed, including a listing of the \n  sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n  TYPE=LOGICAL<(n)> | TYPE=FREE \n  specifies how step-down adjustment are made. If you specify TYPE=LOGICAL, the step-down \n  adjustments are computed by using maximal logically consistent sequential subsets of equality \n  hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, sequential subsets are \n  computed ignoring logical constraints. The TYPE=FREE results are more conservative than those \n  for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. For example, \n  it is not feasible to take logical constraints between all pairwise comparisons of more than about \n  10 groups. For this reason, TYPE=FREE is the default."},"StatementOptionType":"S","SubOptionsKeywords":"TYPE=|REPORT|ORDER=|MAXTIME="},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nESTIMATE statement. The rules for specifying the value-list are very similar to those for \nspecifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"EXACT","StatementHelp":{"#cdata":"Syntax: EXACT <'label'><INTERCEPT><effects></ options> ;"},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSpecifies the level of significance \u03b1 for 100(1 - \u03b1)% confidence limits for the \nparameters or odds ratios. The value of number must be between 0 and 1."},"StatementOptionType":"V"},{"StatementOptionName":"CLTYPE=","StatementOptionHelp":{"#cdata":"Requests either the exact or mid-p confidence intervals for the parameter estimates. By default, \nthe exact intervals are produced."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EXACT","@Value2":"MIDP"},"StatementOptionToolTips":{"@ToolTip1":"Requests the exact confidence intervals for the parameter estimates.","@ToolTip2":"Requests the mid-p confidence intervals for the parameter estimates."}},{"StatementOptionName":"ESTIMATE=","StatementOptionHelp":{"#cdata":"Estimates the individual parameters (conditioned on all other parameters) for the \neffects specified in the EXACT statement."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"PARM","@Value2":"ODDS","@Value3":"BOTH"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the parameters be estimated. This is the default.","@ToolTip2":"Specifies that the odds ratios be estimated. For classification variables, use of the  reference parameterization is required.","@ToolTip3":"Specifies that the parameters and odds ratios be estimated."}},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"Performs the joint test that all of the parameters are simultaneously equal to zero, performs \nindividual hypothesis tests for the parameter of each continuous variable, and performs joint \ntests for the parameters of each classification variable."},"StatementOptionType":"S"},{"StatementOptionName":"JOINTONLY","StatementOptionHelp":{"#cdata":"Performs only the joint test of the parameters."},"StatementOptionType":"S"},{"StatementOptionName":"MIDPFACTOR=|MIDP=","StatementOptionHelp":{"#cdata":"[Syntax: MIDPFACTOR=\u03b41 | (\u03b41,\u03b42)] \n          \nSets the tie factors used to produce the mid-p hypothesis statistics and the mid-p \nconfidence intervals. \u03b41 modifies both the hypothesis tests and confidence intervals, \nwhile \u03b42 affects only the hypothesis tests. By default, \u03b41=0.5 and \u03b42=1.0."},"StatementOptionType":"V"},{"StatementOptionName":"ONESIDED","StatementOptionHelp":{"#cdata":"Requests one-sided confidence intervals and p-values for the individual parameter estimates \nand odds ratios."},"StatementOptionType":"S"},{"StatementOptionName":"OUTDIST=","StatementOptionHelp":{"#cdata":"[Syntax: OUTDIST=SAS-data-set] \n          \nNames the SAS data set containing the exact conditional distributions."},"StatementOptionType":"DV"}]}},{"StatementName":"EXACTOPTIONS","StatementHelp":{"#cdata":"Syntax: EXACTOPTIONS options ;\n      \nThe EXACTOPTIONS statement specifies options that apply to every EXACT statement \nin the program."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ABSFCONV=","StatementOptionHelp":{"#cdata":"[Syntax: ABSFCONV=value] \n          \nSpecifies the absolute function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ADDTOBS","StatementOptionHelp":{"#cdata":"Adds the observed sufficient statistic to the sampled exact distribution if the statistic \nwas not sampled. This option has no effect unless the METHOD=NETWORKMC option is specified \nand the ESTIMATE option is specified in the EXACT statement. If the observed statistic has \nnot been sampled, then the parameter estimate does not exist; by specifying this option, you \ncan produce (biased) estimates."},"StatementOptionType":"S"},{"StatementOptionName":"BUILDSUBSETS","StatementOptionHelp":{"#cdata":"Builds every distribution for sampling. By default, some exact distributions are \ncreated by taking a subset of a previously generated exact distribution. When \nthe METHOD=NETWORKMC option is invoked, this subsetting behavior has the effect \nof using fewer than the desired n samples; see the N= option for more details. \nUse the BUILDSUBSETS option to suppress this subsetting."},"StatementOptionType":"S"},{"StatementOptionName":"EPSILON=","StatementOptionHelp":{"#cdata":"[Syntax: EPSILON=value] \n          \nControls how the partial sums \u2211 yixi (where i=1 to j) are compared. value must be \nbetween 0 and 1; by default, value=1E\u20138."},"StatementOptionType":"V"},{"StatementOptionName":"FCONV=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV=value] \n          \nSpecifies the relative function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"MAXSWAP=|MAXR=","StatementOptionHelp":{"#cdata":"[Syntax: MAXSWAP=n | MAXR=n ]\n          \nSpecifies the maximum number of swaps for each sample that PROC LOGISTIC makes when you specify the METHOD=MCMC \noption. If an intercept or a stratum is conditioned out, then n swaps are performed: one event is changed to a \nnonevent, and one nonevent is changed to an event. Although you might need large values of n in order to transition \nbetween any two points in the exact distribution, such values quickly increase computation time. By default, MAXSWAP=2."},"StatementOptionType":"V"},{"StatementOptionName":"MAXTIME=","StatementOptionHelp":{"#cdata":"[Syntax: MAXTIME=seconds] \n          \nSpecifies the maximum clock time (in seconds) that PROC GENMOD can use to calculate \nthe exact distributions. If the limit is exceeded, the procedure halts all computations \nand prints a note to the LOG. The default maximum clock time is seven days."},"StatementOptionType":"V"},{"StatementOptionName":"METHOD=","StatementOptionHelp":{"#cdata":"Specifies which exact conditional algorithm to use for every EXACT statement specified."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DIRECT","@Value2":"NETWORK","@Value3":"NETWORKMC","@Value4":"MCMC"},"StatementOptionToolTips":{"@ToolTip1":"Invokes the multivariate shift algorithm of Hirji, Mehta, and Patel (1987). This method  directly builds the exact distribution, but it can require an excessive amount of memory  in its intermediate stages. METHOD=DIRECT is invoked by default when you are conditioning  out at most the intercept.","@ToolTip2":"Invokes an algorithm described in Mehta, Patel, and Senchaudhuri (1992). This method builds  a network for each parameter that you are conditioning out, combines the networks, then uses  the multivariate shift algorithm to create the exact distribution. The NETWORK method can be  faster and require less memory than the DIRECT method. The NETWORK method is invoked by default  for most analyses.","@ToolTip3":"Invokes the hybrid network and Monte Carlo algorithm of Mehta, Patel, and Senchaudhuri (1992).  This method creates a network, then samples from that network; this method does not reject  any of the samples at the cost of using a large amount of memory to create the network.  METHOD=NETWORKMC is most useful for producing parameter estimates for problems that are  too large for the DIRECT and NETWORK methods to handle and for which asymptotic methods  are invalid\u2014for example, for sparse data on a large grid.","@ToolTip4":"Invokes the Markov chain Monte Carlo (MCMC) algorithm of Forster, McDonald, and Smith (2003). This method uses a Metropolis-Hastings algorithm to generate samples from the exact distribution by repeatedly  perturbing the response vector to obtain a new response vector while maintaining the sufficient  statistics for the nuisance parameters. You must also condition out the intercept or the strata."}},{"StatementOptionName":"N=","StatementOptionHelp":{"#cdata":"[Syntax: N=n] \n          \nSpecifies the number of Monte Carlo samples to take when the METHOD=NETWORKMC option \nis specified. By default, n=100,000."},"StatementOptionType":"V"},{"StatementOptionName":"NBI=|BURNIN=","StatementOptionHelp":{"#cdata":"[NBI=n | BURNIN=n ]\n          \nSpecifies the number of burn-in samples that are discarded when you specify the METHOD=MCMC option. \nBy default, NBI=0."},"StatementOptionType":"V"},{"StatementOptionName":"NOLOGSCALE","StatementOptionHelp":{"#cdata":"Specifies that computations for the exact conditional models be computed by using \nnormal scaling. Log scaling can handle numerically larger problems than normal \nscaling; however, computations in the log scale are slower than computations in \nnormal scale."},"StatementOptionType":"S"},{"StatementOptionName":"NTHIN=","StatementOptionHelp":{"#cdata":"[NTHIN=n ]\n          \nControls the thinning rate of the sampling when you specify the METHOD=MCMC option. Every nth sample \nis kept and the rest are discarded. By default, NTHIN=1."},"StatementOptionType":"V"},{"StatementOptionName":"ONDISK","StatementOptionHelp":{"#cdata":"Uses disk space instead of random access memory to build the exact conditional \ndistribution. Use this option to handle larger problems at the cost of slower processing."},"StatementOptionType":"S"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=seed] \n          \nSpecifies the initial seed for the random number generator used to take the Monte Carlo \nsamples when the METHOD=NETWORKMC option is specified. The value of the SEED= option must \nbe an integer. If you do not specify a seed, or if you specify a value less than or equal \nto zero, then PROC GENMOD uses the time of day from the computer's clock to generate an \ninitial seed."},"StatementOptionType":"V"},{"StatementOptionName":"STATUSN=","StatementOptionHelp":{"#cdata":"[Syntax: STATUSN=number] \n          \nPrints a status line in the SAS log after every number of Monte Carlo samples when the \nMETHOD=NETWORKMC option is specified. The number of samples taken and the current exact \np-value for testing the significance of the model are displayed. You can use this status \nline to track the progress of the computation of the exact conditional distributions."},"StatementOptionType":"V"},{"StatementOptionName":"STATUSTIME=","StatementOptionHelp":{"#cdata":"[Syntax: STATUSTIME=seconds] \n          \nSpecifies the time interval (in seconds) for printing a status line in the LOG. \nYou can use this status line to track the progress of the computation of the exact \nconditional distributions. The time interval you specify is approximate; the actual \ntime interval varies. By default, no status reports are produced."},"StatementOptionType":"V"},{"StatementOptionName":"XCONV=","StatementOptionHelp":{"#cdata":"[Syntax: XCONV=value] \n          \nSpecifies the relative parameter convergence criterion."},"StatementOptionType":"V"}]}},{"StatementName":"FREQ","StatementHelp":{"#cdata":"Syntax: FREQ variable ;\n      \nThe FREQ statement identifies a variable that contains the frequency of occurrence of each observation. \nPROC LOGISTIC treats each observation as if it appears n times, where n is the value of the FREQ variable \nfor the observation. If it is not an integer, the frequency value is truncated to an integer. If the frequency \nvalue is less than 1 or missing, the observation is not used in the model fitting. When the FREQ statement is \nnot specified, each observation is assigned a frequency of 1. If you specify more than one FREQ statement, \nthen the first statement is used."},"StatementOptions":null},{"StatementName":"ID","StatementHelp":{"#cdata":"Syntax: ID variable<variable,...> ; \n\nThe ID statement specifies variables in the DATA= data set that are used for labeling ROC curves \nand influence diagnostic plots. If more than one ID variable is specified, then the plots are labeled \nby concatenating the ID variable values together."},"StatementOptions":null},{"StatementName":"LSMEANS","StatementHelp":{"#cdata":"Syntax: LSMEANS <model-effects> </ options> ; \n      \nThe LSMEANS statement computes and compares least squares means (LS-means) of fixed \neffects. LS-means are predicted population margins\u2014that is, they estimate the marginal \nmeans over a balanced population. In a sense, LS-means are to unbalanced designs as \nclass and subclass arithmetic means are to balanced designs."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the LSMEANS effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the LSMEANS statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function's distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function's distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            |ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            |CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            |HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK|\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the LSMEANS \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> |  TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="}]}},{"StatementName":"LSMESTIMATE","StatementHelp":{"#cdata":"Syntax: LSMESTIMATE model-effect <'label'> values <divisor=> \n  <, ...<'label'> values <divisor=>> < / options> ; \n  \nThe LSMESTIMATE statement provides a mechanism for obtaining custom hypothesis \ntests among least squares means."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the \nLS-mean estimates. The adjusted quantities are produced in addition to the unadjusted \np-values and confidence limits. Adjusted confidence limits are produced if the CL or \nALPHA= option is in effect."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means with \nconfidence level 1-number. The value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates used in computing LS-means. By default, all \ncovariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that the procedure compute separate margins for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F tests with the JOINT option. \n\nThe category-options indicate how response variable levels are treated in constructing \nthe estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row LSESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row LSESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. \nThe confidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L coefficients of the estimable function be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ELSM","StatementOptionHelp":{"#cdata":"Requests that the K matrix coefficients be displayed. These are the coefficients \nthat apply to the LS-means. This option is useful to ensure that you assigned the \ncoefficients correctly to the LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the least squares means estimate. When you model data \nwith the logit link function and the estimate represents a log odds ratio, the \nEXP option produces an odds ratio. If you specify the CL or ALPHA= option, the \n(adjusted) confidence limits for the estimate are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the \nmean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004). \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to \nthose found in the OM-data-set. This adjustment is reasonable when you want your \ninferences to apply to a population that is not necessarily balanced but has the \nmargins observed in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip3":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function's distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function's distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip4":"Requests that no plots be produced."},"SubOptionsKeywords":"ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the ESTIMATE statement."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant.\n\nYou can specify the following step-down-options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential subsets \n    of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60.\n\n    ORDER=PVALUE \n    ORDER=ROWS \n    specifies the order in which the step-down tests are performed. ORDER=PVALUE is the default, with LS-mean\n    estimates being declared significant only if all LS-mean estimates with smaller (unadjusted) p-values are\n    significant. If you specify ORDER=ROWS, then significances are evaluated in the order in which they are specified. \n\n    REPORT \n    specifies that a report on the step-down adjustment be displayed, including a listing of the sequential \n    subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically consistent \n    sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, \n    sequential subsets are computed ignoring logical constraints. The TYPE=FREE results are more conservative \n    than those for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. Default: TYPE=FREE."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|ORDER=|REPORT|TYPE="},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nLSMESTIMATE statement. The rules for specifying the value-list are very similar to those  \nfor specifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"MODEL","StatementHelp":{"#cdata":"Syntax: <label:> MODEL events/trials=<effects></ options> ; \n\n<label:> MODEL variable<(variable_options)>=<effects></ options> ; \n\nThe MODEL statement names the response variable and the explanatory effects, including \ncovariates, main effects, interactions, and nested effects."},"StatementOptions":{"#comment":[{},{}],"StatementOption":[{"StatementOptionName":"DESCENDING|DESC","StatementOptionHelp":{"#cdata":"[response variable option] \n          \nReverses the order of the response categories."},"StatementOptionType":"RS"},{"StatementOptionName":"EVENT=","StatementOptionHelp":{"#cdata":"[response variable option] \n          \n[Syntax: EVENT='category'|FIRST|LAST] \n          \nSpecifies the event category for the binary response model."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"<'category'>","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"Replace 'category' with an actual event category.","@ToolTip2":"Designates the first ordered category as the event.","@ToolTip3":"Designates the last ordered category as the event. This is the default."}},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"[response variable option] \n          \nSpecifies the sort order for the levels of the response variable."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"StatementOptionToolTips":{"@ToolTip1":"Levels are sorted by the order of appearance in the input data set.","@ToolTip2":"Levels are sorted by the external formatted value, except for numeric variables with no explicit  format, which are sorted by their unformatted (internal) value.","@ToolTip3":"Levels are sorted by the descending frequency count; levels with the most observations come first  in the order.","@ToolTip4":"Levels are sorted by the unformatted value."}},{"StatementOptionName":"REFERENCE=|REF=","StatementOptionHelp":{"#cdata":"[response variable option] \n          \nSpecifies the reference category for the generalized logit model and the \nbinary response model."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"'category'","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"Replace <'category'> with an actual value (formatted if a format is applied) of the event  category in quotes.","@ToolTip2":"Designates the first ordered category as the reference category.","@ToolTip3":"Designates the last ordered category as the reference category. This is the default."}},{"StatementOptionName":"ABSFCONV=","StatementOptionHelp":{"#cdata":"[Syntax: ABSFCONV=value] \n          \nSpecifies the absolute function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"AGGREGATE=","StatementOptionHelp":{"#cdata":"[Syntax: AGGREGATE<=(variable-list)>] \n          \nSpecifies the subpopulations on which the Pearson chi-square test statistic and the \nlikelihood ratio chi-square test statistic (deviance) are calculated."},"StatementOptionType":"S|V"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSets the level of significance, a, for 100(1 - \u03b1)% confidence intervals for \nregression parameters or odds ratios. The value of number must be between 0 \nand 1."},"StatementOptionType":"V"},{"StatementOptionName":"BEST=","StatementOptionHelp":{"#cdata":"[Syntax: BEST=n] \n          \nSpecifies that n models with the highest score chi-square statistics are to be \ndisplayed for each model size."},"StatementOptionType":"V"},{"StatementOptionName":"BINWIDTH=","StatementOptionHelp":{"#cdata":"[Syntax: BINWIDTH=width] \n          \nSpecifies the size of the bins used for estimating the association statistics."},"StatementOptionType":"V"},{"StatementOptionName":"CLODDS=","StatementOptionHelp":{"#cdata":"Produces confidence intervals for odds ratios of main effects not involved in interactions or nestings."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"PL","@Value2":"WALD","@Value3":"BOTH"},"StatementOptionToolTips":{"@ToolTip1":"Computation of confidence intervals is based on the profile likelihood (CLODDS=PL)","@ToolTip2":"Computation of confidence intervals is based on the individual Wald tests (CLODDS=WALD).","@ToolTip3":"Computation of confidence intervals is based on both the profile likelihood and  individual Wald tests"}},{"StatementOptionName":"CLPARM=","StatementOptionHelp":{"#cdata":"Requests confidence intervals for the parameters."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"PL","@Value2":"WALD","@Value3":"BOTH"},"StatementOptionToolTips":{"@ToolTip1":"Computation of confidence intervals is based on the profile likelihood (CLODDS=PL)","@ToolTip2":"Computation of confidence intervals is based on the individual Wald tests (CLODDS=WALD).","@ToolTip3":"Computation of confidence intervals is based on both the profile likelihood and  individual Wald tests"}},{"StatementOptionName":"CORRB","StatementOptionHelp":{"#cdata":"Displays the correlation matrix of the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"COVB","StatementOptionHelp":{"#cdata":"Displays the covariance matrix of the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"CTABLE","StatementOptionHelp":{"#cdata":"Classifies the input binary response observations according to whether the predicted event probabilities \nare above or below some cutpoint value z in the range (0,1)."},"StatementOptionType":"S"},{"StatementOptionName":"DETAILS","StatementOptionHelp":{"#cdata":"Produces a summary of computational details for each step of the effect selection process."},"StatementOptionType":"S"},{"StatementOptionName":"EQUALSLOPES","StatementOptionHelp":{"#cdata":"[Syntax: EQUALSLOPES<=effect | (effect-list)> ]\n          \nSpecifies one or more effects that have the same parameters for each response function in a polytomous\nresponse model. If you specify more than one effect, enclose the effects in parentheses. The effects must \nbe explanatory effects that are specified in the MODEL statement."},"StatementOptionType":"S|V"},{"StatementOptionName":"EXPB|EXPEST","StatementOptionHelp":{"#cdata":"Displays the exponentiated values of the parameter estimates Bi in the \"Analysis of Maximum Likelihood \nEstimates\" table for the logit model."},"StatementOptionType":"S"},{"StatementOptionName":"FAST","StatementOptionHelp":{"#cdata":"Uses a computational algorithm of Lawless and Singhal (1978) to compute a first-order approximation \nto the remaining slope estimates for each subsequent elimination of a variable from the model."},"StatementOptionType":"S"},{"StatementOptionName":"FCONV=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV=value] \n          \nSpecifies the relative function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"FIRTH","StatementOptionHelp":{"#cdata":"Performs Firth's penalized maximum likelihood estimation to reduce bias in the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"GCONV=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV=value] \n          \nSpecifies the relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"HIERARCHY=|HIER=","StatementOptionHelp":{"#cdata":"Specifies whether and how the model hierarchy requirement is applied and whether a single effect or \nmultiple effects are allowed to enter or leave the model in one step."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"NONE","@Value2":"SINGLE","@Value3":"SINGLECLASS","@Value4":"MULTIPLE","@Value5":"MULTIPLECLASS"},"StatementOptionToolTips":{"@ToolTip1":"Indicates that the model hierarchy is not maintained.","@ToolTip2":"Indicates that only one effect can enter or leave the model at one time, subject  to the model hierarchy requirement.","@ToolTip3":"Is the same as HIERARCHY=SINGLE except that only CLASS effects are subject to the  hierarchy requirement.","@ToolTip4":"Indicates that more than one effect can enter or leave the model at one time","@ToolTip5":"Is the same as HIERARCHY=MULTIPLE except that only CLASS effects are subject to the  hierarchy requirement."}},{"StatementOptionName":"INCLUDE=","StatementOptionHelp":{"#cdata":"[Syntax: INCLUDE=number | EQUALSLOPES ]\n          \nSpecifies effects in the MODEL statement to include in every model during model selection. You can \nspecify the following values: \n\nnumber\n  requests that the first number effects be included in every model. \nEQUALSLOPES\n  enables you to include all the equal slope effects in every model and perform the selection process \n  on the unequal slope effects."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"<number>","@Value2":"EQUALSLOPES"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the first number effects be included in every model.","@ToolTip2":"Enables you to include all the equal slope effects in every model and perform the selection process    on the unequal slope effects."}},{"StatementOptionName":"INFLUENCE","StatementOptionHelp":{"#cdata":"Syntax: INFLUENCE<(STDRES)>\n          \nDisplays diagnostic measures for identifying influential observations in the case of \na binary response model. For each observation, the INFLUENCE option displays the case \nnumber (which is the sequence number of the observation), the values of the explanatory \nvariables included in the final model, and the regression diagnostic measures developed \nby Pregibon (1981). \n\nThe STDRES option includes standardized and likelihood residuals in the display."},"StatementOptionType":"S","SubOptionsKeywords":"STDRES"},{"StatementOptionName":"IPLOTS","StatementOptionHelp":{"#cdata":"Produces an index plot for each regression diagnostic statistic. An index plot is a scatter plot with \nthe regression diagnostic statistic represented on the Y axis and the case number on the X axis."},"StatementOptionType":"S"},{"StatementOptionName":"ITPRINT","StatementOptionHelp":{"#cdata":"Displays the iteration history of the maximum-likelihood model fitting."},"StatementOptionType":"S"},{"StatementOptionName":"LACKFIT","StatementOptionHelp":{"#cdata":"[Syntax: LACKFIT&lt;(n)&gt;] \n          \nPerforms the Hosmer and Lemeshow goodness-of-fit test for the case of a binary response \nmodel. The subjects are divided into approximately 10 groups of roughly the same size \nbased on the percentiles of the estimated probabilities. The discrepancies between the \nobserved and expected number of observations in these groups are summarized by the Pearson \nchi-square statistic, which is then compared to a chi-square distribution with t degrees \nof freedom, where t is the number of groups minus n. By default, n=2. A small p-value \nsuggests that the fitted model is not an adequate model."},"StatementOptionType":"S"},{"StatementOptionName":"LINK=|L=","StatementOptionHelp":{"#cdata":"Specifies the link function linking the response probabilities to the linear predictors."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALOGIT","@Value2":"CLOGLOG","@Value3":"GLOGIT","@Value4":"LOGIT","@Value5":"PROBIT"},"StatementOptionToolTips":{"@ToolTip1":"Is the adjacent-category logit function. PROC LOGISTIC fits the adjacent-category logit model,  in which each category is contrasted with the following category.","@ToolTip2":"Complementary log-log function. PROC LOGISTIC fits the binary complementary log-log model when there  are two response categories and fits the cumulative complementary log-log model when there are more  than two response categories.","@ToolTip3":"Generalized logit function. PROC LOGISTIC fits the generalized logit model, in which each nonreference  category is contrasted with the reference category. You can use the response variable option REF= to  specify the reference category.","@ToolTip4":"Log odds function. PROC LOGISTIC fits the binary logit model when there are two response categories and  fits the cumulative logit model when there are more than two response categories.","@ToolTip5":"Inverse standard normal distribution function. PROC LOGISTIC fits the binary probit model when there  are two response categories and fits the cumulative probit model when there are more than two response  categories."}},{"StatementOptionName":"MAXFUNCTION=","StatementOptionHelp":{"#cdata":"[Syntax: MAXFUNCTION=number] \n          \nSpecifies the maximum number of function calls to perform when maximizing the \nconditional likelihood."},"StatementOptionType":"V"},{"StatementOptionName":"MAXITER=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER=number] \n          \nSpecifies the maximum number of iterations to perform. By default, MAXITER=25."},"StatementOptionType":"V"},{"StatementOptionName":"MAXSTEP=","StatementOptionHelp":{"#cdata":"[Syntax: MAXSTEP=n] \n          \nSpecifies the maximum number of times any explanatory variable is added to or \nremoved from the model when SELECTION=STEPWISE."},"StatementOptionType":"V"},{"StatementOptionName":"NOCHECK","StatementOptionHelp":{"#cdata":"Disables the checking process to determine whether maximum likelihood estimates of the \nregression parameters exist."},"StatementOptionType":"S"},{"StatementOptionName":"NODUMMYPRINT|NODESIGNPRINT|NODP","StatementOptionHelp":{"#cdata":"Suppresses the \"Class Level Information\" table, which shows how the design matrix columns \nfor the CLASS variables are coded."},"StatementOptionType":"S"},{"StatementOptionName":"NOINT","StatementOptionHelp":{"#cdata":"Suppresses the intercept for the binary response model, the first intercept for the \nordinal response model (which forces all intercepts to be nonnegative), or all \nintercepts for the generalized logit model."},"StatementOptionType":"S"},{"StatementOptionName":"NOFIT","StatementOptionHelp":{"#cdata":"Performs the global score test without fitting the model."},"StatementOptionType":"S"},{"StatementOptionName":"NOLOGSCALE","StatementOptionHelp":{"#cdata":"Specifies that computations for the conditional and exact conditional logistic models \nshould be computed by using normal scaling."},"StatementOptionType":"S"},{"StatementOptionName":"NOODDSRATIO|NOOR","StatementOptionHelp":{"#cdata":"Suppresses the default \"Odds Ratio\" table."},"StatementOptionType":"S"},{"StatementOptionName":"OFFSET=","StatementOptionHelp":{"#cdata":"[Syntax: OFFSET=name] \n          \nNames the offset variable."},"StatementOptionType":"V"},{"StatementOptionName":"ORPVALUE","StatementOptionHelp":{"#cdata":"Displays p-values in tables produced by the CLODDS= option and the ODDSRATIO statement. A p-value \nfor an odds ratio corresponds to the significance level such that the two-sided confidence interval \nfor the odds ratio has \"1\" as one of its endpoints. Computing profile-likelihood p-values requires\noptimizing restricted log-likelihood equations."},"StatementOptionType":"S"},{"StatementOptionName":"OUTROC=|OUTR=","StatementOptionHelp":{"#cdata":"[Syntax: OUTROC=SAS-data-set] \n          \nCreates, for binary response models, an output SAS data set that contains the data \nnecessary to produce the receiver operating characteristic (ROC) curve."},"StatementOptionType":"DV"},{"StatementOptionName":"PARMLABEL","StatementOptionHelp":{"#cdata":"Displays the labels of the parameters in the \"Analysis of Maximum Likelihood Estimates\" table."},"StatementOptionType":"S"},{"StatementOptionName":"PCORR","StatementOptionHelp":{"#cdata":"Specifies to compute the partial correlation statistic for each model parameter (excluding the intercept)."},"StatementOptionType":"S"},{"StatementOptionName":"PEVENT=","StatementOptionHelp":{"#cdata":"[Syntax: PEVENT=value | PEVENT=(list)] \n          \nSpecifies one prior probability or a list of prior probabilities for the event of interest."},"StatementOptionType":"V"},{"StatementOptionName":"PLCL","StatementOptionHelp":{"#cdata":"Is the same as specifying CLPARM=PL."},"StatementOptionType":"S"},{"StatementOptionName":"PLCONV=","StatementOptionHelp":{"#cdata":"[Syntax: PLCONV=value] \n          \nControls the convergence criterion for confidence intervals based on the profile-likelihood \nfunction. The quantity value must be a positive number, with a default value of 1E\u20134."},"StatementOptionType":"V"},{"StatementOptionName":"PLRL","StatementOptionHelp":{"#cdata":"Is the same as specifying CLODDS=PL."},"StatementOptionType":"S"},{"StatementOptionName":"PPROB=","StatementOptionHelp":{"#cdata":"[Syntax: PPROB=value | PPROB=(list)] \n          \nSpecifies one critical probability value (or cutpoint) or a list of critical probability \nvalues for classifying observations with the CTABLE option."},"StatementOptionType":"V"},{"StatementOptionName":"RIDGING=","StatementOptionHelp":{"#cdata":"Specifies the technique used to improve the log-likelihood function when its value in the current \niteration is less than that in the previous iteration."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ABSOLUTE","@Value2":"RELATIVE","@Value3":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"The diagonal elements of the negative (expected) Hessian are inflated by adding the ridge value.","@ToolTip2":"The diagonal elements are inflated by a factor of 1 plus the ridge value. This is the default.","@ToolTip3":"The crude line search method of taking half a step is used instead of ridging."}},{"StatementOptionName":"RISKLIMITS|RL|WALDRL","StatementOptionHelp":{"#cdata":"Is the same as specifying CLODDS=WALD."},"StatementOptionType":"S"},{"StatementOptionName":"ROCCI","StatementOptionHelp":{"#cdata":"Displays standard errors and confidence limits for the area under the ROC curve (AUC) statistic when \nyou have a binary response variable. This option replaces the \"Association of Predicted Probabilities \nand Observed Responses\" table with the \"ROC Association Statistics\" table."},"StatementOptionType":"S"},{"StatementOptionName":"ROCEPS=","StatementOptionHelp":{"#cdata":"[Syntax: ROCEPS=number] \n          \nSpecifies a criterion for the ROC curve used for grouping estimated event probabilities \nthat are close to each other."},"StatementOptionType":"V"},{"StatementOptionName":"RSQUARE|RSQ","StatementOptionHelp":{"#cdata":"Requests a generalized R\u00b2 measure for the fitted model."},"StatementOptionType":"S"},{"StatementOptionName":"SCALE=","StatementOptionHelp":{"#cdata":"Enables you to supply the value of the dispersion parameter or to specify the method for estimating \nthe dispersion parameter."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DEVIANCE|D","@Value2":"PEARSON|P","@Value3":"WILLIAMS","@Value4":"NONE","@Value5":"<(constant)>"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the dispersion parameter be estimated by the deviance divided by its  degrees of freedom.","@ToolTip2":"Specifies that the dispersion parameter be estimated by the Pearson chi-square statistic  divided by its degrees of freedom.","@ToolTip3":"Syntax: WILLIAMS<(constant)>                                      Specifies that Williams' method be used to model overdispersion. This option can be used only with  the events/trials syntax. An optional constant can be specified as the scale parameter.","@ToolTip4":"Specifies that no correction is needed for the dispersion parameter; that is,  the dispersion parameter remains as 1.","@ToolTip5":"Sets the estimate of the dispersion parameter to be the square of the given constant."}},{"StatementOptionName":"SELECTION=","StatementOptionHelp":{"#cdata":"Specifies the method used to select the variables in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BACKWARD|B","@Value2":"FORWARD|F","@Value3":"NONE|N","@Value4":"STEPWISE|S","@Value5":"SCORE"},"StatementOptionToolTips":{"@ToolTip1":"Requests backward elimination.","@ToolTip2":"Requests forward selection.","@ToolTip3":"Fits the complete model specified in the MODEL statement. This is the default.","@ToolTip4":"Requests stepwise selection.","@ToolTip5":"Requests best subset selection."}},{"StatementOptionName":"SEQUENTIAL|SEQ","StatementOptionHelp":{"#cdata":"Forces effects to be added to the model in the order specified in the MODEL statement or eliminated \nfrom the model in the reverse order of that specified in the MODEL statement."},"StatementOptionType":"S"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=value] \n          \nSpecifies the tolerance for testing the singularity of the Hessian matrix \n(Newton-Raphson algorithm) or the expected value of the Hessian matrix \n(Fisher scoring algorithm)."},"StatementOptionType":"V"},{"StatementOptionName":"SLENTRY=|SLE=","StatementOptionHelp":{"#cdata":"[Syntax: SLENTRY=value] \n          \nSpecifies the significance level of the score chi-square for entering an \neffect into the model in the FORWARD or STEPWISE method."},"StatementOptionType":"V"},{"StatementOptionName":"SLSTAY=|SLS=","StatementOptionHelp":{"#cdata":"[Syntax: SLSTAY=value] \n          \nSpecifies the significance level of the Wald chi-square for an effect to \nstay in the model in a backward elimination step."},"StatementOptionType":"V"},{"StatementOptionName":"START=","StatementOptionHelp":{"#cdata":"[Syntax: START=number | EQUALSLOPES ] \n          \nSpecifies which effects in the MODEL statement are included in the initial model. You can specify \nthe following values: \n\nnumber\n  requests that the first number effects be included in the initial model. The value of number ranges \n  from 0 to s, where s is the total number of effects that are specified in the MODEL statement.\nEQUALSLOPES\n  enables you to begin the model selection process with all the equal slope effects in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"<number>","@Value2":"EQUALSLOPES"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the first number effects be included in the initial model. The value of number ranges  from 0 to s, where s is the total number of effects that are specified in the MODEL statement.","@ToolTip2":"Enables you to begin the model selection process with all the equal slope effects in the model."}},{"StatementOptionName":"STB","StatementOptionHelp":{"#cdata":"Displays the standardized estimates for the parameters for the continuous explanatory \nvariables in the \"Analysis of Maximum Likelihood Estimates\" table."},"StatementOptionType":"S"},{"StatementOptionName":"STOP=","StatementOptionHelp":{"#cdata":"[Syntax: STOP=n] \n          \nSpecifies the maximum (SELECTION=FORWARD) or minimum (SELECTION=BACKWARD) number \nof effects to be included in the final model."},"StatementOptionType":"V"},{"StatementOptionName":"STOPRES|SR","StatementOptionHelp":{"#cdata":"Specifies that the removal or entry of effects be based on the value of the residual \nchi-square."},"StatementOptionType":"S"},{"StatementOptionName":"TECHNIQUE=|TECH=","StatementOptionHelp":{"#cdata":"Specifies the optimization technique for estimating the regression parameters."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"FISHER","@Value2":"NEWTON"},"StatementOptionToolTips":{"@ToolTip1":"Fisher scoring algorithm","@ToolTip2":"Newton-Raphson algorithm"}},{"StatementOptionName":"UNEQUALSLOPES","StatementOptionHelp":{"#cdata":"Syntax: UNEQUALSLOPES<=effect | (effect-list)>  \n          \nSpecifies one or more effects in a cumulative response model that have a different set of parameters \nfor each response function. If you specify more than one effect, enclose the effects in parentheses. \nThe effects must be explanatory effects that are specified in the MODEL statement. \n\nIf you specify this option without an effect or effect-list, all slope parameters vary across the \nresponse functions. Specifying an effect or effect-list enables you to choose which effects have \ndifferent parameters across the response functions."},"StatementOptionType":"S|V"},{"StatementOptionName":"WALDCL|CL","StatementOptionHelp":{"#cdata":"Is the same as specifying CLPARM=WALD."},"StatementOptionType":"S"},{"StatementOptionName":"XCONV=","StatementOptionHelp":{"#cdata":"[Syntax: XCONV=value] \n          \nSpecifies the relative parameter convergence criterion."},"StatementOptionType":"V"}]}},{"StatementName":"NLOPTIONS","StatementHelp":{"#cdata":"Syntax: NLOPTIONS <options> ;\n      \nMost models fit with the GLIMMIX procedure typically have one or more nonlinear parameters. \nEstimation requires nonlinear optimization methods. You can control the optimization through \noptions in the NLOPTIONS statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ABSCONV=|ABSTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSCONV= | ABSTOL=r] \n          \nSpecifies an absolute function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ABSFCONV=|ABSFTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSFCONV=r <n>  | ABSFTOL=r<n>] \n          \nSpecifies an absolute function difference convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ABSGCONV=|ABSGTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSGCONV= | ABSGTOL=r <n>] \n          \nSpecifies an absolute gradient convergence criterion. \n\n  o For all techniques except NMSIMP (specified by the TECHNIQUE= option), Termination requires the maximum \n    absolute gradient element to be small.\n  o This criterion is not used by the NMSIMP technique."},"StatementOptionType":"V"},{"StatementOptionName":"ABSXCONV=|ABSXTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSXCONV= | ABSXTOL=r <n>] \n          \nSpecifies the absolute parameter convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ASINGULAR=|ASING=","StatementOptionHelp":{"#cdata":"[Syntax: ASINGULAR | ASING=r] \n          \nSpecifies an absolute singularity criterion r, r > 0, for the inversion of \nthe information matrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"DAMPSTEP|DS","StatementOptionHelp":{"#cdata":"[Syntax: DAMPSTEP | DS  <=r>] \n          \nSpecifies that the initial step-size value a\u207f (where n=0) for each line search \n(used by the QUANEW, CONGRA, or NEWRAP technique) cannot be larger than r times \nthe step-size value used in the former iteration."},"StatementOptionType":"S|V"},{"StatementOptionName":"FCONV=|FTOL=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV=r | FTOL=r] \n          \nSpecifies the relative function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"FCONV2=|FTOL2=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV2= | FTOL2=r <n>] \n          \nSpecifies a second function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"FSIZE=","StatementOptionHelp":{"#cdata":"[Syntax:FSIZE=r] \n          \nSpecifies the FSIZE parameter of the relative function and relative gradient termination \ncriteria. The default value is r=0."},"StatementOptionType":"V"},{"StatementOptionName":"GCONV=|GTOL=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV=r | GTOL=r] \n          \nSpecifies the relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"GCONV2=|GTOL2=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV2=r | GTOL2=r] \n          \nSpecifies another relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"HESCAL=|HS=","StatementOptionHelp":{"#cdata":"Specifies the scaling version of the Hessian or crossproduct Jacobian matrix used in NRRIDG, TRUREG, \nLEVMAR, NEWRAP, or DBLDOG optimization."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"0","@Value2":"1","@Value3":"2","@Value4":"3"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that no scaling is done.","@ToolTip2":"Specifies the Mor\u00e9 (1978) scaling update","@ToolTip3":"Specifies the Dennis, Gay, and Welsch (1981) scaling update","@ToolTip4":"Specifies that di is reset in each iteration"}},{"StatementOptionName":"INHESSIAN|INHESS","StatementOptionHelp":{"#cdata":"[Syntax: INHESSIAN<=r>] \n          \nSpecifies how the initial estimate of the approximate Hessian is defined for the quasi-Newton \ntechniques QUANEW and DBLDOG."},"StatementOptionType":"S|V"},{"StatementOptionName":"INSTEP=|SALPHA=|RADIUS=","StatementOptionHelp":{"#cdata":"[Syntax: INSTEP=r] \n          \nReduces the length of the first trial step during the line search of the first iterations."},"StatementOptionType":"V"},{"StatementOptionName":"LCDEACT=|LCD=","StatementOptionHelp":{"#cdata":"[Syntax: LCDEACT= | LCD=r] \n          \nSpecifies a threshold r for the Lagrange multiplier that decides whether an active \ninequality constraint remains active or can be deactivated."},"StatementOptionType":"V"},{"StatementOptionName":"LCEPSILON=|LCEPS=|LCE=","StatementOptionHelp":{"#cdata":"[Syntax: LCEPSILON= | LCEPS= | LCE=r] \n          \nSpecifies the range r, r \u2265 0, for active and violated boundary and linear constraints."},"StatementOptionType":"V"},{"StatementOptionName":"LCSINGULAR=|LCSING=|LCS=","StatementOptionHelp":{"#cdata":"[Syntax: LCSINGULAR= | LCSING= | LCS=r] \n          \nSpecifies a criterion r, r \u2265 0, used in the update of the QR decomposition that \ndecides whether an active constraint is linearly dependent on a set of other \nactive constraints. "},"StatementOptionType":"V"},{"StatementOptionName":"LINESEARCH=|LIS=|SMETHOD=|SM=","StatementOptionHelp":{"#cdata":"[Syntax: LINESEARCH | LIS | SMETHOD | SM=i] \n          \nSpecifies the line-search method for the CONGRA, QUANEW, and NEWRAP optimization \ntechniques."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"1","@Value2":"2","@Value3":"3","@Value4":"4","@Value5":"5","@Value6":"6","@Value7":"7","@Value8":"8"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a line-search method that needs the same number of function and gradient calls for cubic  interpolation and cubic extrapolation; this method is similar to one used by the Harwell subroutine library.","@ToolTip2":"Specifies a line-search method that needs more function calls than gradient calls for quadratic and  cubic interpolation and cubic extrapolation; this method is implemented as shown in Fletcher (1987) and  can be modified to an exact line search by using the LSPRECISION= option.","@ToolTip3":"Specifies a line-search method that needs the same number of function and gradient calls for cubic  interpolation and cubic extrapolation; this method is implemented as shown in Fletcher (1987) and can  be modified to an exact line search by using the LSPRECISION= option.","@ToolTip4":"Specifies a line-search method that needs the same number of function and gradient calls for stepwise  extrapolation and cubic interpolation","@ToolTip5":"Specifies a line-search method that is a modified version of LIS=4.","@ToolTip6":"Specifies golden section line search (Polak 1971), which uses only function values for linear approximation.","@ToolTip7":"Specifies bisection line search (Polak 1971), which uses only function values for linear approximation.","@ToolTip8":"Specifies Armijo line-search technique (Polak 1971), which uses only function values for linear approximation."}},{"StatementOptionName":"LSPRECISION=|LSP=","StatementOptionHelp":{"#cdata":"[Syntax: LSPRECISION=r | LSP=r] \n          \nSpecifies the degree of accuracy that should be obtained by the line-search algorithms \nLIS=2 and LIS=3. The default LSPRECISION= values are:\n\n  o For TECH=QUANEW UPDATE=DBFGS, BFGS: r = 0.4\n  o For TECH=QUANEW UPDATE=DDFP, DFP: r = 0.06 \n  o For TECH=CONGRA UPDATE=all r = 0.1\n  o For TECH=NEWRAP NO UPDATE: r = 0.9"},"StatementOptionType":"V"},{"StatementOptionName":"MAXFUNC=|MAXFU=","StatementOptionHelp":{"#cdata":"[Syntax: MAXFUNC=i | MAXFU=i] \n          \nRequires the number of function calls to be no larger than i. The default values are: \n\n  o For TECH= LEVMAR, NEWRAP, NRRIDG, TRUREG: i=125 \n  o For TECH= DBLDOG, QUANEW: i=500 \n  o For TECH= CONGRA: i=1000"},"StatementOptionType":"V"},{"StatementOptionName":"MAXITER=|MAXIT=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER= | MAXIT=i ] \n          \nRequires the number of iterations to be no larger than i. The default values are:\n  o For TECH= LEVMAR, NEWRAP, NRRIDG, TRUREG: i=50 \n  o For TECH= DBLDOG, QUANEW: i=200 \n  o For TECH= CONGRA: i=400"},"StatementOptionType":"V"},{"StatementOptionName":"MAXSTEP=","StatementOptionHelp":{"#cdata":"[Syntax: MAXSTEP=r<n>] \n          \nSpecifies an upper bound for the step length of the line-search algorithms during the \nfirst n iterations."},"StatementOptionType":"V"},{"StatementOptionName":"MAXTIME=","StatementOptionHelp":{"#cdata":"[Syntax: MAXTIME=r] \n          \nRequires the CPU time to be no larger than r. The default value of the MAXTIME= \noption is the largest double floating-point number on your computer."},"StatementOptionType":"V"},{"StatementOptionName":"MINITER=|MINIT=","StatementOptionHelp":{"#cdata":"[Syntax: MINITER= | MINIT=i] \n          \nSpecifies the minimum number of iterations. The default value is 0."},"StatementOptionType":"V"},{"StatementOptionName":"MSINGULAR=|MSING=","StatementOptionHelp":{"#cdata":"[Syntax: MSINGULAR= | MSING=r] \n          \nSpecifies a relative singularity criterion r, r > 0, for the inversion of \nthe information matrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"NOPRINT","StatementOptionHelp":{"#cdata":"Suppresses output related to optimization such as the iteration history."},"StatementOptionType":"S"},{"StatementOptionName":"PALL","StatementOptionHelp":{"#cdata":"[Displays information about the starting values and final values of the optimization process."},"StatementOptionType":"S"},{"StatementOptionName":"PHISTORY|PHIST","StatementOptionHelp":{"#cdata":"Displays the optimization history. The PHISTORY option is set automatically if the PALL or PRINT \noption is set."},"StatementOptionType":"S"},{"StatementOptionName":"RESTART=|REST=","StatementOptionHelp":{"#cdata":"[Syntax: RESTART= | REST=i] \n          \nSpecifies that the QUANEW or CONGRA algorithm is restarted with a steepest descent/ascent \nsearch direction after at most i iterations, i > 0."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=|SING=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR= | SING=r] \n          \nSpecifies the singularity criterion r, 0 < r < 1, used, for example, for matrix inversion."},"StatementOptionType":"V"},{"StatementOptionName":"SOCKET=","StatementOptionHelp":{"#cdata":"[Syntax: SOCKET=fileref]\n          \nSpecifies the fileref that contains the information needed for remote monitoring."},"StatementOptionType":"V"},{"StatementOptionName":"TECHNIQUE=|TECH=|OMETHOD=|OM=","StatementOptionHelp":{"#cdata":"[Syntax: TECHNIQUE= | TECH=name | OMETHOD= | OM=name] \n          \nSpecifies the optimization technique."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CONGRA","@Value2":"DBLDOG","@Value3":"LEVMAR","@Value4":"NEWRAP","@Value5":"NRRIDG","@Value6":"QUANEW","@Value7":"TRUREG","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Chooses one of four different conjugate-gradient optimization algorithms, which can be more precisely  defined with the UPDATE= option and modified with the LINESEARCH= option.","@ToolTip2":"Performs a version of double-dogleg optimization, which uses the gradient to update an approximation  of the Cholesky factor of the Hessian.","@ToolTip3":"Performs a highly stable but, for large problems, memory- and time-consuming Levenberg-Marquardt  optimization technique, a slightly improved variant of the Mor\u00e9 (1978) implementation. This is  the default optimization technique if there are fewer than 40 parameters to estimate.","@ToolTip4":"Performs a usually stable but, for large problems, memory- and time-consuming Newton-Raphson optimization  technique. The algorithm combines a line-search algorithm with ridging, and it can be modified with the  LINESEARCH= option.","@ToolTip5":"Performs a usually stable but, for large problems, memory- and time-consuming Newton-Raphson optimization  technique. This algorithm does not perform a line search.","@ToolTip6":"Chooses one of four different quasi-Newton optimization algorithms that can be more precisely defined with  the UPDATE= option and modified with the LINESEARCH= option.","@ToolTip7":"Performs a usually very stable but, for large problems, memory- and time-consuming trust-region optimization  technique. The algorithm is implemented similar to Gay (1983) and Mor\u00e9 and Sorensen (1983).","@ToolTip8":"Does not perform any optimization. This option is similar to METHOD=NONE, but TECH=NONE also computes and displays residuals and goodness of fit statistics."}},{"StatementOptionName":"UPDATE=|UPD=","StatementOptionHelp":{"#cdata":"Specifies the update method for the quasi-Newton, double-dogleg, or conjugate-gradient optimization technique."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BFGS","@Value2":"DBFGS","@Value3":"DDFP","@Value4":"DFP","@Value5":"PB","@Value6":"FR","@Value7":"PR","@Value8":"CD"},"StatementOptionToolTips":{"@ToolTip1":"Performs the original Broyden, Fletcher, Goldfarb, and Shanno (BFGS) update of the inverse Hessian matrix.","@ToolTip2":"Performs the dual BFGS update of the Cholesky factor of the Hessian matrix. This is the default update method.","@ToolTip3":"Performs the dual Davidon, Fletcher, and Powell (DFP) update of the Cholesky factor of the Hessian matrix.","@ToolTip4":"Performs the original DFP update of the inverse Hessian matrix.","@ToolTip5":"Performs the automatic restart update method of Powell (1977) and Beale (1972).","@ToolTip6":"Performs the Fletcher-Reeves update (Fletcher 1987).","@ToolTip7":"Performs the Polak-Ribiere update (Fletcher 1987).","@ToolTip8":"Performs a conjugate-descent update of Fletcher (1987)."}},{"StatementOptionName":"VERSION=|VS=","StatementOptionHelp":{"#cdata":"Specifies the version of the quasi-Newton optimization technique with nonlinear constraints."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"1","@Value2":"2"},"StatementOptionToolTips":{"@ToolTip1":"Specifies the update of the U vector as in Powell (1978a, 1978b) (update like VF02AD).","@ToolTip2":"Specifies the update of the U vector as in Powell (1982a, 1982b) (update like VMCWD)."}},{"StatementOptionName":"VSINGULAR=|VSING=","StatementOptionHelp":{"#cdata":"[Syntax: VSINGULAR= | VSING=r] \n            \nSpecifies a relative singularity criterion r, r > 0, for the inversion of the information \nmatrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"XCONV=|XTOL=","StatementOptionHelp":{"#cdata":"[Syntax: XCONV= | XTOL=r <n>] \n          \nSpecifies the relative parameter convergence criterion. Termination requires a small \nrelative parameter change in subsequent iterations."},"StatementOptionType":"V"},{"StatementOptionName":"XSIZE=","StatementOptionHelp":{"#cdata":"[Syntax: XSIZE=r] \n          \nSpecifies the XSIZE parameter of the relative function and relative gradient termination \ncriteria. The default value is r=0."},"StatementOptionType":"V"}]}},{"StatementName":"ODDSRATIO","StatementHelp":{"#cdata":"Syntax: ODDSRATIO <'label'> variable </ options> ; \n      \nThe ODDSRATIO statement produces odds ratios for variable even when the variable \nis involved in interactions with other covariates, and for classification variables \nthat use any parameterization. You can also specify variables on which constructed \neffects are based, in addition to the names of COLLECTION or MULTIMEMBER effects. \nYou can specify several ODDSRATIO statements."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT(covariate=value-list | REF | ALL<...covariate=value-list | REF | ALL>)] \n          \nSpecifies fixed levels of the interacting covariates. If a specified covariate does \nnot interact with the variable, then its AT list is ignored. \n\nFor continuous interacting covariates, you can specify one or more numbers in the \nvalue-list. For classification covariates, you can specify one or more formatted \nlevels of the covariate enclosed in single quotes (for example, A='cat' 'dog'), you \ncan specify the keyword REF to select the reference-level, or you can specify the \nkeyword ALL to select all levels of the classification variable. By default, continuous \ncovariates are set to their means, while CLASS covariates are set to ALL."},"StatementOptionType":"S","SubOptionsKeywords":"REF|ALL"},{"StatementOptionName":"CL=","StatementOptionHelp":{"#cdata":"Specifies whether to create Wald or profile-likelihood confidence limits, or both. \nBy default, Wald confidence limits are produced."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"WALD","@Value2":"PL","@Value3":"BOTH"},"StatementOptionToolTips":{"@ToolTip1":"Specifies to create Wald confidence limits.","@ToolTip2":"Specifies to create profile-likelihood confidence limits.","@ToolTip3":"Specifies to create both Wald and profile-likelihood confidence limits."}},{"StatementOptionName":"DIFF=","StatementOptionHelp":{"#cdata":"Specifies whether the odds ratios for a classification variable are computed against \nthe reference level, or all pairs of variable are compared."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"REF","@Value2":"ALL"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the odds ratios for a classification variable are computed against  the reference level.","@ToolTip2":"Specifies that the odds ratios for a classification variable are computed against  all pairs of variable."}},{"StatementOptionName":"PLCONV=","StatementOptionHelp":{"#cdata":"[Syntax: PLCONV=value] \n          \nControls the convergence criterion for confidence intervals based on the \nprofile-likelihood function. The quantity value must be a positive number, \nwith a default value of 1E\u20134. The PLCONV= option has no effect if profile-\nlikelihood confidence intervals (CL=PL) are not requested. "},"StatementOptionType":"V"},{"StatementOptionName":"PLMAXITER=","StatementOptionHelp":{"#cdata":"[Syntax: PLMAXITER=n] \n          \nSpecifies the maximum number of iterations to perform. By default, PLMAXITER=25. \nIf convergence is not attained in n iterations, the odds ratio or the confidence \nlimits are set to missing. The PLMAXITER= option has no effect if profile-likelihood \nconfidence intervals (CL=PL) are not requested."},"StatementOptionType":"V"},{"StatementOptionName":"PLSINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: PLSINGULAR=value] \n          \nSpecifies the tolerance for testing the singularity of the Hessian matrix (Newton-Raphson \nalgorithm) or the expected value of the Hessian matrix (Fisher scoring algorithm). The test \nrequires that a pivot for sweeping this matrix be at least this number times a norm of the \nmatrix. Values of the PLSINGULAR= option must be numeric. By default, value is the machine \nepsilon times 1E7, which is approximately 1E\u20139. The PLSINGULAR= option has no effect if \nprofile-likelihood confidence intervals (CL=PL) are not requested."},"StatementOptionType":"V"}]}},{"StatementName":"OUTPUT","StatementHelp":{"#cdata":"Syntax: OUTPUT <OUT=SAS-data-set> / <options>; \n      \nThe OUTPUT statement creates a new SAS data set that contains all the variables in the \ninput data set and, optionally, the estimated linear predictors and their standard error \nestimates, the estimates of the cumulative or individual response probabilities, and the \nconfidence limits for the cumulative probabilities."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nNames the output data set. If you omit the OUT= option, the output data set is created \nand given a default name by using the DATAn convention."},"StatementOptionType":"RV"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSets the level of significance \u03b1 for 100(1 - \u03b1)% confidence limits for the appropriate \nresponse probabilities. The value of number must be between 0 and 1."},"StatementOptionType":"V"},{"StatementOptionName":"C=","StatementOptionHelp":{"#cdata":"[Syntax: C=name] \n          \nSpecifies the confidence interval displacement diagnostic that measures the influence \nof individual observations on the regression estimates."},"StatementOptionType":"V"},{"StatementOptionName":"CBAR=","StatementOptionHelp":{"#cdata":"[Syntax: CBAR=name] \n          \nSpecifies the confidence interval displacement diagnostic that measures the overall \nchange in the global regression estimates due to deleting an individual observation."},"StatementOptionType":"V"},{"StatementOptionName":"DFBETAS=","StatementOptionHelp":{"#cdata":"[Syntax: DFBETAS=var-list | ALL] \n          \nSpecifies the standardized differences in the regression estimates for assessing the \neffects of individual observations on the estimated regression parameters in the fitted \nmodel."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"_ALL_","@Value2":"<var-list>"},"StatementOptionToolTips":{"@ToolTip1":"The DFBETAS statistics are named DFBETA_xxx, where xxx is the name of the regression parameter.","@ToolTip2":"You can specify a list of up to s + 1 variable names, where s is the number of explanatory variables  in the MODEL statement."}},{"StatementOptionName":"DIFCHISQ=","StatementOptionHelp":{"#cdata":"[Syntax: DIFCHISQ=name] \n          \nSpecifies the change in the chi-square goodness-of-fit statistic attributable \nto deleting the individual observation."},"StatementOptionType":"V"},{"StatementOptionName":"DIFDEV=","StatementOptionHelp":{"#cdata":"[Syntax: DIFDEV=name] \n          \nSpecifies the change in the deviance attributable to deleting the individual \nobservation."},"StatementOptionType":"V"},{"StatementOptionName":"H=","StatementOptionHelp":{"#cdata":"[Syntax: H=name] \n          \nSpecifies the diagonal element of the hat matrix for detecting extreme points in \nthe design space."},"StatementOptionType":"V"},{"StatementOptionName":"LOWER=|L=","StatementOptionHelp":{"#cdata":"[Syntax: LOWER=name] \n          \nNames the variable containing the lower confidence limits for \u03c0, where \u03c0 is the \nprobability of the event response if events/trials syntax or single-trial syntax \nwith binary response is specified."},"StatementOptionType":"V"},{"StatementOptionName":"PREDICTED=|PRED=|PROB=|P=","StatementOptionHelp":{"#cdata":"Names the variable containing the predicted probabilities."},"StatementOptionType":"V"},{"StatementOptionName":"PREDPROBS=","StatementOptionHelp":{"#cdata":"Requests individual, cumulative, or cross validated predicted probabilities."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"(INDIVIDUAL CUMULATIVE)|(I C)","@Value2":"(INDIVIDUAL CROSSVALIDATE)|(I X)","@Value3":"(CUMULATIVE CROSSVALIDATE)|(C X)","@Value4":"(INDIVIDUAL CUMULATIVE CROSSVALIDATE)|(I C X)"},"StatementOptionToolTips":{"@ToolTip1":"Requests the predicted probability and cumulative predicted probability of each response level.","@ToolTip2":"Requests the predicted probability and cross validated individual predicted probability  of each response level.","@ToolTip3":"Requests the cumulative predicted probability and cross validated individual predicted  probability of each response level.","@ToolTip4":"Requests the predicted probability, cumulative predicted probability, and cross validated  individual predicted probability of each response level."}},{"StatementOptionName":"RESCHI=","StatementOptionHelp":{"#cdata":"[Syntax: RESCHI=name] \n          \nSpecifies the Pearson (chi-square) residual for identifying observations that \nare poorly accounted for by the model."},"StatementOptionType":"V"},{"StatementOptionName":"RESDEV=","StatementOptionHelp":{"#cdata":"[Syntax: RESDEV=name] \n          \nSpecifies the deviance residual for identifying poorly fitted observations."},"StatementOptionType":"V"},{"StatementOptionName":"RESLIK=","StatementOptionHelp":{"#cdata":"[Syntax: RESLIK=name ]\n          \nSpecifies the likelihood residual for identifying poorly fitted observations."},"StatementOptionType":"V"},{"StatementOptionName":"STDRESCHI=","StatementOptionHelp":{"#cdata":"[Syntax: STDRESCHI=name ]\n          \nSpecifies the standardized Pearson (chi-square) residual for identifying observations that are poorly \naccounted for by the model."},"StatementOptionType":"V"},{"StatementOptionName":"STDRESDEV=","StatementOptionHelp":{"#cdata":"[Syntax: STDRESDEV=name ]\n          \nSpecifies the standardized deviance residual for identifying poorly fitted observations."},"StatementOptionType":"V"},{"StatementOptionName":"STDXBETA=","StatementOptionHelp":{"#cdata":"[Syntax: STDXBETA=name] \n          \nNames the variable containing the standard error estimates of XBETA."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER=|U=","StatementOptionHelp":{"#cdata":"[Syntax: UPPER=name] \n          \nNames the variable containing the upper confidence limits for \u03c0, where \u03c0 is the \nprobability of the event response if events/trials syntax or single-trial syntax \nwith binary response is specified."},"StatementOptionType":"V"},{"StatementOptionName":"XBETA=","StatementOptionHelp":{"#cdata":"[Syntax: XBETA=name] \n          \nNames the variable containing the estimates of the linear predictor \u03b1i + \u03b2'x, where \ni is the corresponding ordered value of _LEVEL_."},"StatementOptionType":"V"}]}},{"StatementName":"ROC","StatementHelp":{"#cdata":"Syntax: ROC <'label'> <specification> </ options> ;\n      \nThe ROC statements specify models to be used in the ROC comparisons. You can specify \nmore than one ROC statement. ROC statements are identified by their label\u2014if you do \nnot specify a label, the ith ROC statement is labeled \"ROCi\". Additionally, the \nspecified or selected model is labeled with the MODEL statement label or \"Model\" if \nthe MODEL label is not present. The specification can be either a list of effects \nthat have previously been specified in the MODEL statement, or PRED=variable, where \nthe variable does not have to be specified in the MODEL statement. The PRED= option \nallows you to input a criterion produced outside PROC LOGISTIC; for example, you \ncan fit a random-intercept model by using PROC GLIMMIX or use survey weights in \nPROC SURVEYLOGISTIC, then use the predicted values from those models to produce \nan ROC curve for the comparisons. If you do not make a specification, then an \nintercept-only model is fit to the data, resulting in a noninformative ROC curve \nthat can be used for comparing the area under another ROC curve to 0.5."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"NOINT","StatementOptionHelp":{"#cdata":"Suppresses the intercept for the model. Note that specifying the NOINT option in the MODEL statement \ndoes not affect the ROC model."},"StatementOptionType":"S"},{"StatementOptionName":"NOOFFSET","StatementOptionHelp":{"#cdata":"Does not include an offset variable if the OFFSET= option is specified in the MODEL statement."},"StatementOptionType":"S"},{"StatementOptionName":"LINK=","StatementOptionHelp":{"#cdata":"Specifies the link function to be used in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"LOGIT","@Value2":"NORMIT","@Value3":"CLOGLOG"},"StatementOptionToolTips":{"@ToolTip1":"Log odds function","@ToolTip2":"Inverse standard normal probability integral function","@ToolTip3":"Complementary log-log function"}}]}},{"StatementName":"ROCCONTRAST","StatementHelp":{"#cdata":"Syntax: ROCCONTRAST <'label'><contrast></ options> ;\n      \nThe ROCCONTRAST statement compares the different ROC models."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"REFERENCE","StatementOptionHelp":{"#cdata":"Syntax: REFERENCE<(MODEL | 'roc-label')> \n          \nProduces a contrast matrix of differences between each ROC curve and a reference curve."},"StatementOptionType":"RS","SubOptionsKeywords":"MODEL"},{"StatementOptionName":"ADJACENTPAIRS","StatementOptionHelp":{"#cdata":"Produces a contrast matrix of each ROC curve minus the succeeding curve."},"StatementOptionType":"RS"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Displays the contrast."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays covariance matrices used in the computations."},"StatementOptionType":"S"},{"StatementOptionName":"ESTIMATE=","StatementOptionHelp":{"#cdata":"[Syntax: ESTIMATE <= ROWS | ALLPAIRS>] \n          \nProduces estimates of each row of the contrast, or estimates of every pairwise \ndifference of ROC curves."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ROWS","@Value2":"ALLPAIRS"},"StatementOptionToolTips":{"@ToolTip1":"Produces estimates of each row of the contrast. Same effect as spefifying ESTIMATE.","@ToolTip2":"Produces estimates of every pairwise difference of ROC curves."}}]}},{"StatementName":"SCORE","StatementHelp":{"#cdata":"Syntax: SCORE <options> ;\n      \nThe SCORE statement creates a data set that contains all the data in the DATA= data \nset together with posterior probabilities and, optionally, prediction confidence \nintervals."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSpecifies the significance level \u03b1 for 100(1 - \u03b1)% confidence intervals."},"StatementOptionType":"V"},{"StatementOptionName":"CLM","StatementOptionHelp":{"#cdata":"Outputs the Wald-test-based confidence limits for the predicted probabilities."},"StatementOptionType":"S"},{"StatementOptionName":"CUMULATIVE","StatementOptionHelp":{"#cdata":"Outputs the cumulative predicted probabilities Pr(Y  \u2264  i), i = 1,...k+1, to the OUT= data set."},"StatementOptionType":"S"},{"StatementOptionName":"DATA=","StatementOptionHelp":{"#cdata":"[Syntax: DATA=SAS-data-set] \n          \nNames the SAS data set that you want to score."},"StatementOptionType":"DV"},{"StatementOptionName":"FITSTAT","StatementOptionHelp":{"#cdata":"Displays fit statistics for the data set you are scoring. The data set must contain \n the response variable."},"StatementOptionType":"S"},{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nNames the SAS data set that contains the predicted information."},"StatementOptionType":"DV"},{"StatementOptionName":"OUTROC=","StatementOptionHelp":{"#cdata":"[Syntax: OUTROC=SAS-data-set] \n          \nNames the SAS data set that contains the ROC curve for the DATA= data set."},"StatementOptionType":"DV"},{"StatementOptionName":"PRIOR=","StatementOptionHelp":{"#cdata":"[Syntax: PRIOR=SAS-data-set] \n          \nNames the SAS data set that contains the priors of the response categories."},"StatementOptionType":"DV"},{"StatementOptionName":"PRIOREVENT=","StatementOptionHelp":{"#cdata":"[Syntax: PRIOREVENT=value] \n          \nSpecifies the prior event probability for a binary response model."},"StatementOptionType":"V"},{"StatementOptionName":"ROCEPS=","StatementOptionHelp":{"#cdata":"[Syntax: ROCEPS=value] \n          \nSpecifies the criterion for grouping estimated event probabilities that are close \nto each other for the ROC curve."},"StatementOptionType":"V"}]}},{"StatementName":"SLICE","StatementHelp":{"#cdata":"Syntax: SLICE model-effect </ options> ; \n      \nThe SLICE statement provides a general mechanism for performing a partitioned analysis \nof the LS-means for an interaction. This analysis is also known as an analysis of simple \neffects. \n\nThe SLICE statement uses the same options as the LSMEANS statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the SLICE model-effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified SLICE effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the SLICE effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the SLICE statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this SLICE statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function's distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function's distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            |ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            |CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            |HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK|\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the SLICE \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="},{"StatementOptionName":"SLICEBY=|SIMPLE=","StatementOptionHelp":{"#cdata":"Determines how to construct the partition of the least squares means for the model-effect.\n          \nSyntax: \nSLICEBY <=> slice-specification \nSIMPLE <=> slice-specification \nSLICEBY(slice-specification <, slice-specification <, >>) \nSIMPLE(slice-specification <, slice-specification <, >>) \n\nA slice-specification consists of an effect name followed by an optional list of formatted \nvalues. For example, the following statements creates partitions of the A*B interaction effect \nfor all levels of variable A: \n\n  class a b;\n  model y = a b a*b;\n  slice a*b / sliceby=a;"},"StatementOptionType":"S|V"},{"StatementOptionName":"NOF","StatementOptionHelp":{"#cdata":"Suppresses the F test for testing the mutual equality of the estimable functions \nin the partition."},"StatementOptionType":"S"}]}},{"StatementName":"STORE","StatementHelp":{"#cdata":"Syntax: STORE <OUT=>item-store-name </ LABEL='label'> ; \n      \nThe STORE statement requests that the procedure save the context and results of the \nstatistical analysis. The resulting item store is a binary file format that cannot \nbe modified. The contents of the item store can be processed with the PLM procedure. \n\nThe item-store-name is a usual one- or two-level SAS name, like the names that are used \nfor SAS data sets. If you specify a one-level name, then the item store resides in the \nWORK library and is deleted at the end of the SAS session. Since item stores usually are \nused to perform postprocessing tasks, typical usage specifies a two-level name of the form \nlibname.membername. \n\nIf an item store by the same name as specified in the STORE statement already exists, \nthe existing store is replaced."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: <OUT=>item-store-name] \n          \nThe item-store-name is a usual one- or two-level SAS name, like the names that are used \nfor SAS data sets. If you specify a one-level name, then the item store resides in the \nWORK library and is deleted at the end of the SAS session."},"StatementOptionType":"V"},{"StatementOptionName":"LABEL=","StatementOptionHelp":{"#cdata":"[Syntax: LABEL='label'] \n          \nAdds a custom label. When the PLM procedure processes an item store, the label appears \nin the PROC PLM output along with other identifying information."},"StatementOptionType":"V"}]}},{"StatementName":"STRATA","StatementHelp":{"#cdata":"Syntax: STRATA variable <(option)> \u2026<variable <(option)>> </ options>;\n      \nThe STRATA statement names the variables that define strata or matched sets to use in a stratified conditional \nlogistic regression of binary response data."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"MISSING","StatementOptionHelp":{"#cdata":"Treats missing values ('.','.A',...,'.Z' for numeric variables and blanks for character variables) \nas valid STRATA variable values."},"StatementOptionType":"S"},{"StatementOptionName":"CHECKDEPENDENCY=|CHECK=","StatementOptionHelp":{"#cdata":"Specifies which variables are to be tested for dependency before the analysis is performed."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"NONE","@Value2":"COVARIATES","@Value3":"ALL"},"StatementOptionToolTips":{"@ToolTip1":"Performs no dependence checking.","@ToolTip2":"Checks dependence between covariates and an added intercept.","@ToolTip3":"Checks dependence between all the strata and covariates"}},{"StatementOptionName":"NOSUMMARY","StatementOptionHelp":{"#cdata":"Suppresses the display of the \"Strata Summary\" table."},"StatementOptionType":"S"},{"StatementOptionName":"INFO","StatementOptionHelp":{"#cdata":"Displays the \"Strata Information\" table, which includes the stratum number, levels of the STRATA \nvariables that define the stratum, the number of events, the number of nonevents, and the total \nfrequency for each stratum."},"StatementOptionType":"S"}]}},{"StatementName":"TEST","StatementHelp":{"#cdata":"Syntax: <label:> TEST equation1 <, equation2, \u2026> </ option>;\n      \nThe TEST statement tests linear hypotheses about the regression coefficients."},"StatementOptions":{"StatementOption":{"StatementOptionName":"PRINT","StatementOptionHelp":{"#cdata":"Displays intermediate calculations in the testing of the null hypothesis."},"StatementOptionType":"S"}}},{"StatementName":"UNITS","StatementHelp":{"#cdata":"Syntax: UNITS independent1=list1 <independent2 = list2 ></ option> ;\n      \nThe UNITS statement enables you to specify units of change for the continuous explanatory variables \nso that customized odds ratios can be estimated."},"StatementOptions":{"StatementOption":{"StatementOptionName":"DEFAULT=","StatementOptionHelp":{"#cdata":"[Syntax: DEFAULT=list] \n          \nGives a list of units of change for all explanatory variables that are not specified \nin the UNITS statement."},"StatementOptionType":"V"}}},{"StatementName":"WEIGHT","StatementHelp":{"#cdata":"Syntax: WEIGHT variable </ option> ;\n      \nWhen a WEIGHT statement appears, each observation in the input data set is weighted by the \nvalue of the WEIGHT variable."},"StatementOptions":{"StatementOption":{"StatementOptionName":"NORMALIZE|NORM","StatementOptionHelp":{"#cdata":"Causes the weights specified by the WEIGHT variable to be normalized so that they \nadd up to the actual sample size."},"StatementOptionType":"S"}}}]}}}