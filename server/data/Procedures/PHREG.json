{"Procedure":{"Name":"PHREG","#comment":{},"ProductGroup":"SAS/STAT","ProcedureHelp":{"#cdata":"Syntax: PROC PHREG <options> ; \n    ASSESS keyword </ options> ; \n    BASELINE <OUT=SAS-data-set> <COVARIATES=SAS-data-set> <keyword=name ...keyword=name > </ options> ; \n    BAYES <options> ; \n    BY variables ; \n    CLASS variable <(options)> <...variable <(options)> > </ options> ; \n    CONTRAST <'label'> effect values <,..., effect values> </ options> ; \n    FREQ variable ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    ESTIMATE <'label'> estimate-specification </ options> ; \n    HAZARDRATIO <'label'> variable </options> ; \n    ID variables ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification </ options> ; \n    MODEL response <*censor(list)> = <effects> </options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name ...keyword=name > </ options> ; \n    programming statements ; \n    \n    RANDOM variable </ options> ;\n    SLICE model-effect </ options> ; \n    STORE <OUT=> item-store-name </ LABEL='label'> ; \n    STRATA variable <(list)> <...variable <(list)>> < / option> ; \n    <label:>TEST equation <,..., equation >< / options> ; \n    WEIGHT variable </ option> ; \n\nThe analysis of survival data requires special techniques because the data are almost always \nincomplete and familiar parametric assumptions might be unjustifiable. Investigators follow \nsubjects until they reach a prespecified endpoint (for example, death). However, subjects \nsometimes withdraw from a study, or the study is completed before the endpoint is reached. \nIn these cases, the survival times (also known as failure times) are censored; subjects \nsurvived to a certain time beyond which their status is unknown. The uncensored survival \ntimes are sometimes referred to as event times. Methods of survival analysis must account \nfor both censored and uncensored data. \n\nThe PHREG procedure performs regression analysis of survival data based on the Cox proportional \nhazards model."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"ALPHA=","ProcedureOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n      \nSpecifies the level of significance \u03b1 for 100(1 - \u03b1)% confidence intervals. The value number must be \nbetween 0 and 1; the default value is 0.05, which results in 95% intervals."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"ATRISK","ProcedureOptionHelp":{"#cdata":"Displays a table that contains the number of units at risk at each event time and \nthe corresponding number of events in the risk sets."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"COVOUT","ProcedureOptionHelp":{"#cdata":"Adds the estimated covariance matrix to the OUTEST= data set. For the COVOUT option \nto have an effect, the OUTEST= option must be specified."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"COVM","ProcedureOptionHelp":{"#cdata":"Requests that the model-based covariance matrix (which is the inverse of the observed \ninformation matrix) be used in the analysis if the COVS option is also specified."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"COVSANDWICH|COVS","ProcedureOptionHelp":{"#cdata":"Syntax: COVSANDWICH <(AGGREGATE)> \n      \nRequests the robust sandwich estimate of Lin and Wei (1989) for the covariance matrix. \n\nOptionally, you can specify the keyword AGGREGATE enclosed in parentheses after the COVSANDWICH \n(or COVS) option, which requests a summing up of the score residuals for each distinct ID pattern \nin the computation of the robust sandwich covariance estimate. This AGGREGATE option has no effects \nif the ID statement is not specified."},"ProcedureOptionType":"S","SubOptionsKeywords":"AGGREGATE"},{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"[Syntax: DATA=SAS-data-set] \n      \nNames the SAS data set containing the data to be analyzed. If you omit the DATA= option, the \nprocedure uses the most recently created SAS data set."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"INEST=","ProcedureOptionHelp":{"#cdata":"[Syntax: INEST=SAS-data-set] \n      \nNames the SAS data set that contains initial estimates for all the parameters in the model."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"MULTIPASS","ProcedureOptionHelp":{"#cdata":"Requests that, for each Newton-Raphson iteration, PROC PHREG recompile the risk sets corresponding \nto the event times for the (start,stop) style of response and recomputes the values of the time-\ndependent variables defined by the programming statements for each observation in the risk sets."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NAMELEN=","ProcedureOptionHelp":{"#cdata":"[Syntax: NAMELEN=n] \n      \nSpecifies the maximum length of effect names in tables and output data sets to be n characters, \nwhere n is a value between 20 and 200. The default length is 20 characters."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NOPRINT","ProcedureOptionHelp":{"#cdata":"Suppresses all displayed output. Note that this option temporarily disables the \nOutput Delivery System (ODS)."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOSUMMARY","ProcedureOptionHelp":{"#cdata":"Suppresses the summary display of the event and censored observation frequencies."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"OUTEST=","ProcedureOptionHelp":{"#cdata":"[Syntax: OUTEST=SAS-data-set] \n      \nCreates an output SAS data set that contains estimates of the regression coefficients."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"PLOTS=","ProcedureOptionHelp":{"#cdata":"Controls the baseline functions plots produced through ODS Graphics. \n      \nSyntax: \n(1) PLOTS<(global-plot-options)> = plot-request \n(2) PLOTS<(global-plot-options)> = (plot-request <...<plot-request>>) \n\nThe following global-plot-options are available: \n\n  CL<=EQTAIL | HPD> \n  displays the pointwise interval limits for the specified curves\n\n  OVERLAY <=BYGROUP|INDIVIDUAL|BYROW|BYSTRATUM> \n  specifies how the curves for the various strata and covariate sets are overlaid.\n   \n  TIMERANGE=(<min> <,max>) \n  specifies the range of values on the time axis to clip the display."},"ProcedureOptionType":"S|V","ProcedureOptionValues":{"@Value1":"CUMHAZ","@Value2":"MCF","@Value3":"NONE","@Value4":"SURVIVAL"},"ProcedureOptionToolTips":{"@ToolTip1":"Plots the estimated cumulative hazard function for each set of covariates in the COVARIATES= data set  in the BASELINE statement.","@ToolTip2":"Plots the estimated mean cumulative function for each set of covariates in the COVARIATES= data set in  the BASELINE statement.","@ToolTip3":"Suppresses all the plots in the procedure. Specifying this option is equivalent to disabling ODS Graphics  for the entire procedure.","@ToolTip4":"Plots the estimated survivor function for each set of covariates in the COVARIATES= data set in the  BASELINE statement."},"SubOptionsKeywords":"CL|CL=|OVERLAY|OVERLAY=|TIMERANGE="},{"ProcedureOptionName":"SIMPLE","ProcedureOptionHelp":{"#cdata":"Displays simple descriptive statistics (mean, standard deviation, minimum and maximum) for each \nexplanatory variable in the MODEL statement."},"ProcedureOptionType":"S"}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"ASSESS","StatementHelp":{"#cdata":"Syntax: ASSESS <VAR=(list)> <PH> </options> ; \n\nThe ASSESS statement performs the graphical and numerical methods of Lin, Wei, and Ying (1993) \nfor checking the adequacy of the Cox regression model. The methods are derived from cumulative \nsums of martingale residuals over follow-up times or covariate values. You can assess the \nfunctional form of a covariate or you can check the proportional hazards assumption for each \ncovariate in the Cox model."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"VAR=","StatementOptionHelp":{"#cdata":"[Syntax: VAR=(variable-list)] \n          \nSpecifies the list of explanatory variables for which their functional forms are assessed."},"StatementOptionType":"RV"},{"StatementOptionName":"PROPORTIONALHAZARDS|PH","StatementOptionHelp":{"#cdata":"Requests the checking of the proportional hazards assumption."},"StatementOptionType":"RS"},{"StatementOptionName":"NPATHS=","StatementOptionHelp":{"#cdata":"[Syntax: NPATHS=n] \n          \nSpecifies the number of simulated residual patterns to be displayed in a cumulative martingale residual \nplot or a score process plot. The default is n=20."},"StatementOptionType":"V"},{"StatementOptionName":"CRPANEL","StatementOptionHelp":{"#cdata":"Requests that a plot with four panels, each containing the observed cumulative martingale residuals \nand two simulated residual patterns, be created."},"StatementOptionType":"S"},{"StatementOptionName":"RESAMPLE=","StatementOptionHelp":{"#cdata":"[Syntax: RESAMPLE<=n>] \n          \nRequests that the Kolmogorov-type supremum test be computed on 1,000 simulated patterns or on n \nsimulated patterns if n is specified. "},"StatementOptionType":"S|V"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=n] \n          \nSpecifies an integer seed for the random number generator used in creating simulated realizations \nfor plots and for the Kolmogorov-type supremum tests."},"StatementOptionType":"V"}]}},{"StatementName":"BASELINE","StatementHelp":{"#cdata":"Syntax: BASELINE <OUT=SAS-data-set > < OUTDIFF=SAS-data-set > <COVARIATES=SAS-data-set >\n  < TIMELIST=list > < keyword=name . . . keyword=name > < / options > ;\n         \nThe BASELINE statement creates a new SAS data set that contains the baseline function estimates at \nthe event times of each stratum for every set of covariates (x) given in the COVARIATES= data set."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nNames the output BASELINE data set. If you omit the OUT= option, the data set is created and given a \ndefault name by using the DATAn convention."},"StatementOptionType":"RV|DV"},{"StatementOptionName":"OUTDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: OUTDIFF=SAS-data-set] \n          \nNames the output data set that contains all pairwise differences of direct adjusted probabilities between\ngroups if the GROUP= variable is specified, or between strata if the GROUP= variable is not specified.\nIt is required that the DIRADJ option be specified to use the OUTDIFF= option."},"StatementOptionType":"RV|DV"},{"StatementOptionName":"COVARIATES=","StatementOptionHelp":{"#cdata":"[Syntax: COVARIATES=SAS-data-set] \n          \nNames the SAS data set that contains the sets of explanatory variable values for which the \nquantities of interest are estimated."},"StatementOptionType":"RV|DV"},{"StatementOptionName":"TIMELIST=","StatementOptionHelp":{"#cdata":"[Syntax: TIMELIST=list] \n          \nSpecifies a list of time points at which the survival function estimates, cumulative function \nestimates, or MCF estimates are computed."},"StatementOptionType":"RV"},{"StatementOptionName":"CMF=|MCF=","StatementOptionHelp":{"#cdata":"Specifies the cumulative mean function estimate for recurrent events data."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"<name>","@Value2":"_ALL_"},"StatementOptionToolTips":{"@ToolTip1":"Replace <name> with the name of the variable for the statistic.","@ToolTip2":"Equivalent to specifying CMF=CMF, STDCMF=StdErrCMF, LOWERCMF=LowerCMF, and UPPERCMF=UpperCMF.  Nelson (2002) refers to the mean function estimate as MCF (mean cumulative function)."}},{"StatementOptionName":"CUMHAZ=","StatementOptionHelp":{"#cdata":"Specifies the cumulative hazard function estimate."},"StatementOptionType":"RV","StatementOptionToolTips":{"@ToolTip1":"Replace <name> with the name of the variable for the statistic.","@ToolTip2":"Equivalent to specifying CUMHAZ=CumHaz, STDCUMHAZ=StdErrCumHaz, LOWERCUMHAZ=LowerCumHaz, and  UPPERCUMHAZ=UpperCumHaz.   For a Bayesian analysis, CUMHAZ=_ALL_ also includes LOWERHPDCUMHAZ= LowerHPDCumHaz  and UpperHPDCUMHAZ=UpperHPDCumHaz."}},{"StatementOptionName":"LOGLOGS=","StatementOptionHelp":{"#cdata":"[Syntax: LOGLOGS=name] \n          \nSpecifies the log of the negative log of SURVIVAL."},"StatementOptionType":"RV"},{"StatementOptionName":"LOGSURV=","StatementOptionHelp":{"#cdata":"[Syntax: LOGSURV==name] \n          \nSpecifies the log of SURVIVAL."},"StatementOptionType":"RV"},{"StatementOptionName":"LOWER=|L=","StatementOptionHelp":{"#cdata":"[Syntax: LOWER=name] \n          \nSpecifies the lower pointwise confidence limit for the survivor function. For a Bayesian \nanalysis, this is the lower limit of the equal-tail credible interval for the survivor \nfunction. The confidence level is determined by the ALPHA= option."},"StatementOptionType":"RV"},{"StatementOptionName":"LOWERCMF=|LOWERMCF=","StatementOptionHelp":{"#cdata":"[Syntax: LOWERCMF=name | LOWERMCF=name] \n          \nSpecifies the lower pointwise confidence limit for the cumulative mean function. The \nconfidence level is determined by the ALPHA= option."},"StatementOptionType":"RV"},{"StatementOptionName":"LOWERHPD=","StatementOptionHelp":{"#cdata":"[Syntax: LOWERHPD=name] \n          \nSpecifies the lower limit of the HPD interval for the survivor function. \nThe confidence level is determined by the ALPHA= option."},"StatementOptionType":"RV"},{"StatementOptionName":"LOWERHPDCUMHAZ=","StatementOptionHelp":{"#cdata":"[Syntax: LOWERHPDCUMHAZ=name] \n          \nSpecifies the lower limit of the HPD interval for the cumulative hazard \nfunction. The confidence level is determined by the ALPHA= option."},"StatementOptionType":"RV"},{"StatementOptionName":"LOWERCUMHAZ=","StatementOptionHelp":{"#cdata":"[Syntax: LOWERCUMHAZ=name] \n          \nSpecifies the lower pointwise confidence limit for the cumulative hazard function. \nFor a Bayesian analysis, this is the lower limit of the equal-tail credible interval \nfor the cumulative hazard function. The confidence level is determined by the ALPHA= \noption."},"StatementOptionType":"RV"},{"StatementOptionName":"STDERR=","StatementOptionHelp":{"#cdata":"[Syntax: STDERR=name] \n          \nSpecifies the standard error of the survivor function estimator. For a Bayesian \nanalysis, this is the standard deviation of the posterior distribution of the \nsurvivor function."},"StatementOptionType":"RV"},{"StatementOptionName":"STDCMF=|STDMCF=","StatementOptionHelp":{"#cdata":"[Syntax: STDCMF==name] \n          \nSpecifies the estimated standard error of the cumulative mean function estimator."},"StatementOptionType":"RV"},{"StatementOptionName":"STDCUMHAZ=","StatementOptionHelp":{"#cdata":"[Syntax: STDCUMHAZ=name] \n          \nSpecifies the estimated standard error of the cumulative hazard function estimator. \nFor a Bayesian analysis, this is the standard deviation of the posterior distribution \nof the cumulative hazard function."},"StatementOptionType":"RV"},{"StatementOptionName":"STDXBETA=","StatementOptionHelp":{"#cdata":"[Syntax: STDXBETA=name] \n          \nSpecifies the estimated standard error of the linear predictor estimator. For a \nBayesian analysis, this is the standard deviation of the posterior distribution \nof the linear predictor."},"StatementOptionType":"RV"},{"StatementOptionName":"SURVIVAL=","StatementOptionHelp":{"#cdata":"[Syntax: SURVIVAL=name] \n          \nSpecifies a survivor function estimate."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"<name>","@Value2":"_ALL_"},"StatementOptionToolTips":{"@ToolTip1":"Replace <name> with the name of the variable for the statistic.","@ToolTip2":"Equivalent to specifying SURVIVAL=Survival, STDERR=StdErrSurvival, LOWER=LowerSurvival, and  UPPER=UpperSurvival; and for a Bayesian analyis, SURVIVAL=_ALL_ also specifies LOWERHPD= LowerHPDSurvival  and UPPERHPD=UpperHPDSurvival."}},{"StatementOptionName":"UPPER=|U=","StatementOptionHelp":{"#cdata":"[Syntax: UPPER=name] \n          \nSpecifies the upper pointwise confidence limit for the survivor function. For a \nBayesian analysis, this is the upper limit of the equal-tail credible interval for \nthe survivor function. The confidence level is determined by the ALPHA= option."},"StatementOptionType":"RV"},{"StatementOptionName":"UPPERCMF=|UPPERMCF=","StatementOptionHelp":{"#cdata":"[Syntax: UPPERCMF=name] \n          \nSpecifies the upper pointwise confidence limit for the cumulative mean function. \nThe confidence level is determined by the ALPHA= option."},"StatementOptionType":"RV"},{"StatementOptionName":"UPPERCUMHAZ=","StatementOptionHelp":{"#cdata":"[Syntax: UPPERCUMHAZ=name] \n          \nSpecifies the upper pointwise confidence limit for the cumulative hazard function. \nFor a Bayesian analysis, this is the upper limit of the equal-tail credible interval \nfor the cumulative hazard function. The confidence level is determined by the ALPHA= \noption."},"StatementOptionType":"RV"},{"StatementOptionName":"UPPERHPD=","StatementOptionHelp":{"#cdata":"[Syntax: UPPERHPD=name] \n          \nSpecifies the upper limit of the equal-tail credible interval for the survivor \nfunction. The confidence level is determined by the ALPHA= option."},"StatementOptionType":"RV"},{"StatementOptionName":"UPPERHPDCUMHAZ=","StatementOptionHelp":{"#cdata":"[Syntax: UPPERHPDCUMHAZ =name] \n          \nSpecifies the upper limit of the equal-tail credible interval for the cumulative \nhazard function. The confidence level is determined by the ALPHA= option."},"StatementOptionType":"RV"},{"StatementOptionName":"XBETA=","StatementOptionHelp":{"#cdata":"[Syntax: XBETA=name] \n          \nSpecifies the estimate of the linear predictor x'\u03b2."},"StatementOptionType":"RV"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=value] \n          \nSpecifies the significance level of the confidence interval for the survivor function. \nThe value must be between 0 and 1."},"StatementOptionType":"V"},{"StatementOptionName":"CLTYPE=","StatementOptionHelp":{"#cdata":"Specifies the method used to compute the confidence limits for S(t,z), the survivor \nfunction for a subject with a fixed covariate vector z at event time t."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"LOG","@Value2":"LOGLOG","@Value3":"NORMAL"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the confidence limits for log(S(t,z)) be computed using the normal theory approximation.","@ToolTip2":"Specifies that the confidence limits for the log(-log(S(t,z))) be computed using normal theory approximation.","@ToolTip3":"Specifies that the confidence limits for S(t,z) be computed directly using normal theory approximation."}},{"StatementOptionName":"DIRADJ","StatementOptionHelp":{"#cdata":"Computes direct adjusted survival curves (Makuch 1982; Gail and Byar 1986; Zhang et al. 2007) by\naveraging the estimated survival curves for the observations in the COVARIATES= data set. If the \nCOVARIATES= data set is not specified, the input data set specified in the DATA= option in the \nPROC PHREG statement is used instead. If you also specify the GROUP= option, PROC PHREG computes \nan adjusted survival curve for each value of the GROUP= variable."},"StatementOptionType":"S"},{"StatementOptionName":"GROUP=","StatementOptionHelp":{"#cdata":"[Syntax: GROUP=variable] \n          \nNames a numeric variable in the COVARIATES= data set to group the baseline function \ncurves for the observations into separate plots."},"StatementOptionType":"V"},{"StatementOptionName":"METHOD=","StatementOptionHelp":{"#cdata":"Specifies the method used to compute the survivor function estimates."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BRESLOW|CH|EMP","@Value2":"FH","@Value3":"PL"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the Breslow (1972) method be used to compute the survivor function\u2014that is, that the  survivor function be estimated by exponentiating the negative empirical cumulative hazard function.","@ToolTip2":"Specifies that the Fleming-Harrington (FH) estimates be computed. The FH estimator is a tie-breaking  modification of the Breslow estimator. If there are no tied event times, this estimator is the same  as the Breslow estimator.","@ToolTip3":"Specifies that the product-limit estimate of the survivor function be computed. This estimator is not  available if you use the model syntax that allows two time variables for counting process style of  input; in such a case the Breslow estimator (METHOD=BRESLOW) is used instead."}},{"StatementOptionName":"ROWID=|ID=|ROW=","StatementOptionHelp":{"#cdata":"[Syntax: ROWID=variable] \n          \nNames a variable in the COVARIATES= data set for identifying the baseline function \ncurves in the plots."},"StatementOptionType":"V"}],"#comment":[{},{}]}},{"StatementName":"BAYES","StatementHelp":{"#cdata":"Syntax: BAYES <options> ; \n      \nThe BAYES statement requests a Bayesian analysis of the regression model by using \nGibbs sampling. The Bayesian posterior samples (also known as the chain) for the \nregression parameters can be output to a SAS data set."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"COEFFPRIOR=|CPRIOR=|COEFF=","StatementOptionHelp":{"#cdata":"Specifies the prior distribution for the regression coefficients."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"UNIFORM","@Value2":"NORMAL","@Value3":"ZELLNER"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a flat prior\u2014that is, the prior that is proportional to a constant.","@ToolTip2":"Syntax: NORMAL<(normal-option)<                                      Specifies a normal distribution. The normal-options include the following:    INPUT=SAS-data-set    specifies a SAS data set containing the mean and covariance information of the normal prior.    RELVAR<=c>    specifies a normal prior N(O,cJ), where J is a diagonal matrix with diagonal elements equal to the    variances of the corresponding ML estimator.    VAR=c    specifies the normal prior N(O,cI), where I is the identity matrix.","@ToolTip3":"Syntax: ZELLNER<(g= g-option)>                                      Specifies the Zellner g-prior for the regression coefficients. The g-prior is a multivariate  normal prior distribution with mean zero and covariance matrix equal to (gX'X)\u02c9\u00b9, where you  can specify one of the following g-options:     number    specifies a constant number for g. The default is 1E-6.     GAMMA<SHAPE=a ISCALE=b)>    specifies that g has a gamma distibution "},"SubOptionsKeywords":"INPUT=|RELVAR|RELVAR=|VAR=|GAMMA|SHAPE=|ISCALE="},{"StatementOptionName":"DIAGNOSTICS=|DIAG=|DIAGNOSTIC=","StatementOptionHelp":{"#cdata":"[Syntax: DIAGNOSTICS=ALL | NONE | keyword | (keyword-list)] \n          \nControls the number of diagnostics produced."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"NONE","@Value3":"AUTOCORR","@Value4":"ESS","@Value5":"MCSE","@Value6":"HEIDELBERGER","@Value7":"GELMAN","@Value8":"GEWEKE","@Value9":"RAFTERY"},"StatementOptionToolTips":{"@ToolTip1":"Requests all the diagnostics.","@ToolTip2":"Specify this if you do not want any of the diagnostics.","@ToolTip3":"Syntax: AUTOCORR<(LAGS= numeric-list)>                                      Computes the autocorrelations of lags given by LAGS= list for each parameter.","@ToolTip4":"Computes the effective sample size of Kass et al. (1998), the correlation time, and the efficiency of the chain for each parameter.","@ToolTip5":"Computes the Monte Carlo standard error for each parameter.","@ToolTip6":"Syntax: HEIDELBERGER<(heidel-options)>                                      Computes the Heidelberger and Welch tests for each parameter.   Optionally, you can specify one or more of the following heidel-options:     SALPHA=value    specifies the \u03b1 level (0 < \u03b1 < 1) for the stationarity test.      HALPHA=value    specifies the \u03b1 level (0 < \u03b1 < 1) for the halfwidth test.     EPS=value    specifies a small positive number \u03b5 such that if the halfwidth is less than \u03b5 times the sample mean of the retaining samples,    the halfwidth test is passed.","@ToolTip7":"Syntax: GELMAN<=(gelman-options)>                                      Computes the Gelman and Rubin convergence diagnostics.   You can specify one or more of the following gelman-options:     NCHAIN=number    specifies the number of parallel chains used to compute the diagnostic and has to be 2 or larger.     ALPHA=value    specifies the significance level for the upper bound.","@ToolTip8":"Syntax: GEWEKE<=geweke-options>                                      Computes the Geweke diagnostics. The diagnostic is essentially a two-sample t-test between the first f1 portion and the last f2 portion of the chain. The default is f1=0.1 and f2=0.5, but you can choose other fractions  by using the following geweke-options:      FRAC1=value    specifies the early f1 fraction of the Markov chain.     FRAC2=value    specifies the latter f2 fraction of the Markov chain.","@ToolTip9":"Syntax: RAFTERY<(raftery-options)>                                        Computes the Raftery and Lewis diagnostics.   The following are available raftery-options:     QUANTILE=value    Q=value    specifies the order (a value between 0 and 1) of the quantile of interest. The default is 0.025.     ACCURACY=value    R=value    specifies a small positive number as the margin of error for measuring the accuracy of estimation of the quantile. The default is 0.005.     PROBABILITY=value    value    specifies the probability of attaining the accuracy of the estimation of the quantile. The default is 0.95.     EPSILON=value    EPS=value    specifies the tolerance level (a small positive number) for the test. The default is 0.001."},"SubOptionsKeywords":"\n            EPSILON=|EPS=|PROBABILITY=|P=|ACCURACY=|R=|QUANTILE=|Q=|FRAC1=|FRAC2=|ALPHA=|NCHAIN=|\n            SALPHA=|HALPHA=|AUTOCORR|ESS|MCSE|HEIDELBERGER|GELMAN|GEWEKE|RAFTERY\"/&gt;\n          "},{"StatementOptionName":"DISPERSIONPRIOR=|DPRIOR=","StatementOptionHelp":{"#cdata":"Syntax: DISPERSIONPRIOR=GAMMA< (gamma-options) > | IGAMMA<(igamma-options) > | IMPROPER\nDPRIOR=GAMMA<(gamma-options) > | IGAMMA<(igamma-options) > | IMPROPER\n          \nSpecifies the prior distribution of the dispersion parameter. For gamma frailty, the dispersion parameter\nis the variance of the gamma frailty; for lognormal frailty, the dispersion parameter is the variance of\nthe normal random component. The default is DISPERSIONPRIOR=IMPROPER."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"GAMMA","@Value2":"IGAMMA","@Value3":"IMPROPER"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: GAMMA<(options)>               Specifies the gamma prior. You can use the following gamma-options enclosed in parentheses  to specify the hyperparameters:      SHAPE=\u03b1 and ISCALE=b      results in a G(a,b) prior when both gamma-options are specified.          SHAPE=c      results in G(c,c) prior when specified alone.       ISCALE=c      results in G(c,c) prior when specified alone.       The default is SHAPE=1E\u20134 and ISCALE=1E\u20134.","@ToolTip2":"Syntax: IGAMMA<(options)>                                      Specifies the inverse-gamma prior. You can use the following gamma-options enclosed in parentheses  to specify the hyperparameters:      SHAPE=\u03b1 and ISCALE=b      results in a IG(a,b) prior when both gamma-options are specified.          SHAPE=c      results in IG(c,c) prior when specified alone.       ISCALE=c      results in IG(c,c) prior when specified alone.       The default is SHAPE=2.001 AND SCALE=0.01.","@ToolTip3":"Specifies the improper prior, which has a density f(\u03b8) proportional to \u03b8\u207b\u207f (where n=1)."},"SubOptionsKeywords":"SHAPE|SCALE=|ISCALE="},{"StatementOptionName":"INITIAL=","StatementOptionHelp":{"#cdata":"[Syntax: INITIAL=SAS-data-set] \n          \nSpecifies the SAS data set that contains the initial values of the Markov chains."},"StatementOptionType":"DV"},{"StatementOptionName":"NBI=","StatementOptionHelp":{"#cdata":"[Syntax: NBI=number] \n          \nSpecifies the number of burn-in iterations before the chains are saved. The default is 2000."},"StatementOptionType":"V"},{"StatementOptionName":"NMC=","StatementOptionHelp":{"#cdata":"[Syntax: NMC=number] \n          \nSpecifies the number of iterations after the burn-in. The default is 10000."},"StatementOptionType":"V"},{"StatementOptionName":"OUTPOST=|OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUTPOST=SAS-data-set] \n          \nNames the SAS data set that contains the posterior samples."},"StatementOptionType":"DV"},{"StatementOptionName":"PIECEWISE=","StatementOptionHelp":{"#cdata":"Syntax: PIECEWISE <=keyword <(<NINTERVAL=number> <INTERVAL=(numeric-list)> <PRIOR=option>)>>\n          \nSpecifies that the piecewise constant baseline hazard model be used in the Bayesian analysis.\nSpecifying PIECEWISE by itself is the same as specifying PIECEWISE=LOGHAZARD."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"HAZARD<(<NINTERVAL=number> <INTERVAL=(numeric-list)> <PRIOR=option>)>>","@Value2":"LOGHAZARD<(<NINTERVAL=number> <INTERVAL=(numeric-list)> <PRIOR=option>)>>"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: HAZARD<(<NINTERVAL=number> <INTERVAL=(numeric-list)> <PRIOR=option>)>>               Models the baseline hazard parameters in the original scale. Hazard parameters are named Lambda1, Lambda2, ..., and so on.   Use the following two options to specify the partition of the time axis into intervals of constant baseline hazards:   NINTERVAL=number | N=number -- specifies the number of intervals with constant baseline hazard rates. PROC PHREG partitions the  time axis into the given number of intervals with approximately equal number of events in each interval.   INTERVAL=(numeric-list) -- specifies the list of numbers that partition the time axis into disjoint intervals with constant  baseline hazard in each interval. For example, INTERVAL=(100, 150, 200, 250, 300) specifies a model  with a constant hazard in the intervals [0,100), [100,150), [150,200), [200,250), [250,300), and [300,\u221e).   PRIOR = IMPROPER | UNIFORM | GAMMA<(gamma-option)> |  ARGAMMA<(argamma-option)>  The default is PRIOR=IMPROPER. The available prior options include the following:    IMPROPER -- specifies a noninformative and improper prior.    UNIFORM -- specifies a uniform prior on the real line.   GAMMA <(gamma-option)> -- specifies an independent gamma prior G(a,b) which can be followed by one of the following gamma-options:      INPUT=SAS-data-set -- specifies a data set containing the hyperparameters of the independent gamma prior.       RELSHAPE<=c> -- specifies independent G(c\u03bbj,c) distribution, where \u03bbj\u2019s are the MLEs of the hazard rates. default, c=10\u207b\u2074.      SHAPE=a and SCALE=b -- together specify the Gamma prior.      SHAPE=c ISCALE=c -- specifies the G(c,c)  prior.     ARGAMMA <(argamma-option)> -- specifies an autoregressive gamma prior of order 1, which can be followed    by one of the following argamma-options.       INPUT=SAS-data-set -- specifies a data set containing the hyperparameters of the correlated gamma prior.       SHAPE=a and SCALE=b -- together specify that \u03bb1 ~ G(a,b) and \u03bbj ~ G(a,b/\u03bbj-1) for 2 \u2264 j \u2264 J.     SHAPE=c ISCALE=c -- specifies that \u03bb1 ~ G(c,c) and \u03bbj ~ G(c,c/\u03bbj-1) for 2 \u2264 j \u2264 J.","@ToolTip2":"Syntax: LOGHAZARD<(<NINTERVAL=number> <INTERVAL=(numeric-list)> <PRIOR=option>)>>                                      Models the baseline hazard parameters in the log scale. The log-hazard parameters are named Alpha1, Alpha2, ..., and so on.   Use the following two options to specify the partition of the time axis into intervals of constant baseline hazards:  NINTERVAL=number | N=number -- specifies the number of intervals with constant baseline hazard rates. PROC PHREG partitions the  time axis into the given number of intervals with approximately equal number of events in each interval.   INTERVAL=(numeric-list) -- specifies the list of numbers that partition the time axis into disjoint intervals with constant  baseline hazard in each interval. For example, INTERVAL=(100, 150, 200, 250, 300) specifies a model  with a constant hazard in the intervals [0,100), [100,150), [150,200), [200,250), [250,300), and [300,\u221e).   To specify the prior for \u03b11,...,\u03b1j, the hazard parameters in the log scale, you specifying the following:    PRIOR=UNIFORM | NORMAL<(normal-option)<    The default is PRIOR=UNIFORM. The available prior options are as follows:     UNIFORM -- specifies the uniform prior on the real line;     NORMAL<(normal-option)<    specifies a normal prior distribution on the log-hazard parameters. The normal options include the following:      INPUT=SAS-data-set -- specifies a SAS data set containing the mean and covariance information of the normal prior.           RELVAR <=c< -- specifies the normal prior N(0,cJ), where J is a diagonal matrix with diagonal elements equal      to the variances of the corresponding ML estimator. By default, c=10\u2076.           VAR=c -- specifies the normal prior N(0,cI), where I is the identity matrix."},"SubOptionsKeywords":"NINTERVAL=|INTERVAL=|PRIOR=|INPUT=|RELVAR|VAR|UNIFORM|NORMAL"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Controls the display of diagnostic plots. \n          \nSyntax: PLOTS <(global-plot-options)> = plot-request \nPLOTS <(global-plot-options)> = (plot-requests) \n\nThe global plot options include the following: \n\n  FRINGE \n  creates a fringe plot on the X axis of the density plot. \n\n  GROUPBY = PARAMETER | TYPE \n  specifies how the plots are to be grouped when there is more than one type of plots. The choices are as follows: \n\n    TYPE \n    specifies that the plots be grouped by type. \n\n    PARAMETER \n    specifies that the plots be grouped by parameter. \n\n    GROUPBY=PARAMETER is the default. \n\n  SMOOTH \n  displays a fitted penalized B-spline curve each trace plot. \n\n  UNPACKPANEL | UNPACK \n  specifies that all paneled plots be unpacked, meaning that each plot in a panel is displayed separately."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"AUTOCORR","@Value3":"DENSITY","@Value4":"NONE","@Value5":"TRACE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies all types of plots.","@ToolTip2":"Displays the autocorrelation function plots for the parameters.","@ToolTip3":"Displays the kernel density plots for the parameters.","@ToolTip4":"Suppresses all diagnostic plots.","@ToolTip5":"Displays the trace plots for the parameters."},"SubOptionsKeywords":"FRINGE|GROUPBY=|SMOOTH|UNPACKPANEL|UNPACK"},{"StatementOptionName":"SAMPLING=","StatementOptionHelp":{"#cdata":"Specifies the sampling algorithm used in the Markov chain Monte Carlo (MCMC) simulations."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ARMS","@Value2":"RWM"},"StatementOptionToolTips":{"@ToolTip1":"Requests the use of the adaptive rejection Metropolis sampling (ARMS) algorithm to  draw the Gibbs samples. ALGORITHM=ARMS is the default.","@ToolTip2":"Requests the use of the random walk Metropolis (RWM) algorithm to draw the samples."}},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies an integer seed in the range 1 to 2\u00b3\u00b9-1 for the random number generator \nin the simulation."},"StatementOptionType":"V"},{"StatementOptionName":"STATISTICS=|STATS=","StatementOptionHelp":{"#cdata":"Controls the number of posterior statistics produced. \n          \nSyntax: \n(1) STATISTICS <(global-options)> = ALL | NONE | keyword | (keyword-list) \n(2) STATS <(global-statoptions)> = ALL | NONE | keyword | (keyword-list) \n\nThe global-options include the following: \n\n  ALPHA=numeric-list \n  controls the probabilities of the credible intervals. The ALPHA= values must be between 0 and 1.\n\n  PERCENT=numeric-list \n  requests the percentile points of the posterior samples. The PERCENT= values must be between 0 and 100. \n  The default is PERCENT= 25, 50, 75, which yield the 25th, 50th, and 75th percentile points for each parameter."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"NONE","@Value3":"CORR","@Value4":"COV","@Value5":"SUMMARY","@Value6":"INTERVAL","@Value7":"<(keyword-list)>"},"StatementOptionToolTips":{"@ToolTip1":"Requests all posterior statistics. Equivalent to specifying STATISTICS= (SUMMARY INTERVAL COV CORR).","@ToolTip2":"Requests no posterior statistics","@ToolTip3":"Produces the posterior correlation matrix.","@ToolTip4":"Produces the posterior covariance matrix.","@ToolTip5":"Produces the means, standard deviations, and percentile points for the posterior samples. The default  is to produce the 25th, 50th, and 75th percentile points, but you can use the global PERCENT= option  to request specific percentile points.","@ToolTip6":"Produces equal-tail credible intervals and HPD intervals. The defult is to produce the 95% equal-tail  credible intervals and 95% HPD intervals, but you can use the global ALPHA= option to request intervals  of any probabilities.","@ToolTip7":"If you want some but not all of the posterior statistics, specify a subset of the following  keywords: SUMMARY INTERVAL COV CORR"},"SubOptionsKeywords":"ALPHA=|PERCENT="},{"StatementOptionName":"THINNING=|THIN=","StatementOptionHelp":{"#cdata":"[Syntax:THINNING=number] \n          \nControls the thinning of the Markov chain."},"StatementOptionType":"V"}]}},{"StatementName":"BY","StatementHelp":{"#cdata":"Syntax: BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>; \n      \nYou can specify a BY statement with PROC PHREG to obtain separate analyses on observations \nin groups that are defined by the BY variables. When a BY statement appears, the procedure \nexpects the input data set to be sorted in order of the BY variables. If you specify more \nthan one BY statement, only the last one specified is used."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING","StatementOptionHelp":{"#cdata":"Specifies that the observations are sorted in descending order by the variable that \nimmediately follows the word DESCENDING in the BY statement."},"StatementOptionType":"S"},{"StatementOptionName":"NOTSORTED","StatementOptionHelp":{"#cdata":"Specifies that observations are not necessarily sorted in alphabetic or numeric order."},"StatementOptionType":"S"}]}},{"StatementName":"CLASS","StatementHelp":{"#cdata":"Syntax: CLASS variable<(options)><variable<(options)>></options> ; \n      \nThe CLASS statement names the classification variables to be used in the analysis. \nThe CLASS statement must precede the MODEL statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CPREFIX=","StatementOptionHelp":{"#cdata":"[Syntax: CPREFIX=n] \n          \nSpecifies that, at most, the first n characters of a CLASS variable name be used in creating names \nfor the corresponding design variables."},"StatementOptionType":"V"},{"StatementOptionName":"DESCENDING|DESC","StatementOptionHelp":{"#cdata":"Reverses the sorting order of the classification variable."},"StatementOptionType":"S"},{"StatementOptionName":"LPREFIX=","StatementOptionHelp":{"#cdata":"[Syntax: LPREFIX=n] \n          \nSpecifies that, at most, the first n characters of a CLASS variable name be used in creating labels \nfor the corresponding design variables."},"StatementOptionType":"V"},{"StatementOptionName":"MISSING","StatementOptionHelp":{"#cdata":"Treats missing value (\".\", \".A\", ..., \".Z\" for numeric variables and blanks for \ncharacter variables) as valid values for the CLASS variable."},"StatementOptionType":"S"},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"Specifies the sorting order for the levels of classification variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"StatementOptionToolTips":{"@ToolTip1":"Levels sorted by the order of appearance in the input data set.","@ToolTip2":"Levels sorted by the external formatted values, except for numeric variables with  no explicit format, which are sorted by their unformatted (internal) values.","@ToolTip3":"Levels sorted by the descending frequency count; levels with more observations  come earlier in the order.","@ToolTip4":"Levels sorted by the unformatted value."}},{"StatementOptionName":"PARAM=","StatementOptionHelp":{"#cdata":"Specifies the parameterization method for the classification variable or variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EFFECT","@Value2":"GLM","@Value3":"ORDINAL|THERMOMETER","@Value4":"POLYNOMIAL|POLY","@Value5":"REFERENCE|REF","@Value6":"ORTHEFFECT","@Value7":"ORTHORDINAL","@Value8":"ORTHPOLY","@Value9":"ORTHREF"},"StatementOptionToolTips":{"@ToolTip1":"Specifies effect coding.","@ToolTip2":"Specifies less-than-full-rank, reference-cell coding; this option can be used only as a global option.","@ToolTip3":"Specifies the cumulative parameterization for an ordinal CLASS variable.","@ToolTip4":"Specifies polynomial coding.","@ToolTip5":"Specifies reference cell coding.","@ToolTip6":"Orthogonalizes PARAM=EFFECT.","@ToolTip7":"Orthogonalizes PARAM=ORDINAL.","@ToolTip8":"Orthogonalizes PARAM=POLYNOMIAL.","@ToolTip9":"Orthogonalizes PARAM=REFERENCE."}},{"StatementOptionName":"REF=","StatementOptionHelp":{"#cdata":"Specifies the reference level for PARAM=EFFECT, PARAM=REFERENCE, and their orthogonalizations."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"<level>","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"Specifies the level of the variable to use as the reference level. Replace <level> with an actual value.","@ToolTip2":"Designates the first ordered level as reference.","@ToolTip3":"Designates the last ordered level as reference."}},{"StatementOptionName":"TRUNCATE","StatementOptionHelp":{"#cdata":"Syntax: TRUNCATE<=n> \n          \nSpecifies that length n of CLASS variable values to use in determining CLASS variable levels. \nThe default is to use the full formatted length of the CLASS variable. If you specify TRUNCATE \nwithout the length n, the first 16 characters of the formatted values are used."},"StatementOptionType":"S|V"}]}},{"StatementName":"CONTRAST","StatementHelp":{"#cdata":"Syntax: CONTRAST \u2019label\u2019 row-description <,...row-description></options> ; \n      \nwhere a row-description is: effect values <,...effect values>\n\nThe CONTRAST statement provides a mechanism for obtaining customized hypothesis tests. \nIt is similar to the CONTRAST statement in PROC GLM and PROC CATMOD, depending on the \ncoding schemes used with any categorical variables involved."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=p] \n          \nSpecifies the level of significance p for the 100(1 - p)% confidence interval for each contrast \nwhen the ESTIMATE option is specified. The value p must be between 0 and 1. By default, p is equal \nto the value of the ALPHA= option in the PROC PHREG statement, or 0.05 if that option is not specified."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking."},"StatementOptionType":"V"},{"StatementOptionName":"ESTIMATE=","StatementOptionHelp":{"#cdata":"Requests that each individual contrast or exponentiated contrast be estimated and tested."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"PARM","@Value2":"EXP","@Value3":"BOTH"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the contrast itself be estimated.","@ToolTip2":"Specifies that the exponentiated contrast be estimated.","@ToolTip3":"Specifies that both the contrast and the exponentiated contrast be estimated."}},{"StatementOptionName":"TEST","StatementOptionHelp":{"#cdata":"[Syntax: TEST<(keywords)>] \n            \nRequests a Type 3 test for each contrast. The default is to use the Wald statistic, \nbut you can requests other statistics by specifying one or more of the following keywords: \n\n  ALL \n  requests the likelihood ratio tests, the score tests, and the Wald tests. Specifying TEST(ALL) \n  is equivalent to specifying TEST=(LR SCORE WALD). \n\n  NONE \n  suppresses the Type 3 analysis. Even if the TEST option is not specified, PROC PHREG displays \n  the Wald test results for each model effect if a CLASS variable is involved in a MODEL effect. \n  The NONE option can be used to suppress such display. \n\n  LR \n  requests the likelihood ratio tests. This request is not honored if the COVS option is also specified. \n\n  SCORE \n  requests the score tests. This request is not honored if the COVS option is also specified. \n\n  WALD \n  requests the Wald tests."},"StatementOptionType":"S","SubOptionsKeywords":"ALL|NONE|LR|SCORE|WALD"}]}},{"StatementName":"EFFECT","StatementHelp":{"#cdata":"Syntax: EFFECT effect-name = effect-type (var-list < / effect-options >) ; \n\nThe name of the effect is specified after the EFFECT keyword. This name can appear \nin only one EFFECT statement and cannot be the name of a variable in the input data \nset. The effect-type is specified after an equal sign, followed by a list of variables \nwithin parentheses which are used in constructing the effect. Effect-options that are \nspecific to an effect-type can be specified after a slash (/) following the variable list. \n\nThe EFFECT statement enables you to construct special collections of columns for design \nmatrices. These collections are referred to as constructed effects to distinguish them \nfrom the usual model effects formed from continuous or classification variables."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"EFFECT-NAME=","StatementOptionHelp":{"#cdata":"Replace 'EFFECT-NAME' with the name of the effect, specified after the EFFECT keyword. \nThis name can appear in only one EFFECT statement and cannot be the name of a \nvariable in the input data set."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"COLLECTION","@Value2":"LAG","@Value3":"MULTIMEMBER|MM","@Value4":"POLYNOMIAL|POLY","@Value5":"SPLINE"},"StatementOptionToolTips":{"@ToolTip1":"Is a collection effect that defines one or more variables as a single effect with  multiple degrees of freedom. The variables in a collection are considered as a  unit for estimation and inference.  Option(s) available (specified after a slash (/) following the variable list):   DETAILS  Displays the constituents of the collection effect","@ToolTip2":"Is a classification effect in which the level that is used for a given period  corresponds to the level in the preceding period.   Options available (specified after a slash (/) following the variable list):    DESIGNROLE=    Names a variable that controls to which lag design an observation is assigned     DETAILS    Displays the lag design of the lag effect     NLAG=    Specifies the number of periods in the lag     PERIOD=    Names the variable that defines the period     WITHIN=    Names the variable or variables that define the group within which each period is defined","@ToolTip3":"Is a multimember classification effect whose levels are determined by one or  more variables that appear in a CLASS statement.   Options available (specified after a slash (/) following the variable list):     NOEFFECT    Specifies that observations with all missing levels for the multimember variables should    have zero values in the corresponding design matrix columns     WEIGHT=    Specifies the weight variable for the contributions of each of the classification effects","@ToolTip4":"Is a multivariate polynomial effect in the specified numeric variables.                                      Options available (specified after a slash (/) following the variable list):     DEGREE=    Specifies the degree of the polynomial     MDEGREE=    Specifies the maximum degree of any variable in a term of the polynomial     STANDARDIZE=    Specifies centering and scaling suboptions for the variables that define the polynomial","@ToolTip5":"Is a regression spline effect whose columns are univariate spline expansions of  one or more variables. A spline expansion replaces the original variable with  an expanded or larger set of new variables.   Options available (specified after a slash (/) following the variable list):     BASIS=    Specifies the type of basis (B-spline basis or truncated power function basis) for the spline expansion     DEGREE=    Specifies the degree of the spline transformation     KNOTMETHOD=    Specifies how to construct the knots for spline effects"},"SubOptionsKeywords":"DETAILS|DESIGNROLE=|NLAG=|WITHIN=|NOEFFECT|WEIGHT=|DEGREE=|MDEGREE=|STANDARDIZE=|BASIS=|KNOTMETHOD="},{"StatementOptionName":"PERIOD=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only]\n          \n[Syntax: PERIOD=variable] \n          \nSpecifies the period variable of the LAG design. The number of periods is the number \nof unique formatted values of the PERIOD= variable, and the ordering of the period is \nformed by sorting these formatted values in ascending order. You must specify a PERIOD= \nvariable."},"StatementOptionType":"V"},{"StatementOptionName":"WITHIN=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: WITHIN=(variables) | WITHIN=variable] \n\nSpecifies a variable (or a list of variables within parentheses) that defines the \nsubject grouping of the lag design. If there is only one WITHIN= variable, then the \nparentheses are not required. Each subject is defined by the unique set of formatted \nvalues of the variables in the WITHIN= list. The subjects are sorted in ascending \nlexicographic order. You must specify a WITHIN= variable."},"StatementOptionType":"V"},{"StatementOptionName":"DESIGNROLE=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: DESIGNROLE=variable] \n\nSpecifies a numeric variable that is used to subset observations into a fitting group \nin which the value of the DESIGNROW= variable is nonzero and a second group in which \nthe value of the specified variable is zero. The observations in the fitting group are \nused to form the LAG design matrix that is used in fitting the model. The LAG design \nthat corresponds to the non-fitting group is used when scoring observations in the \ninput data set that do not belong to the fitting group. This option is useful when \nyou want to obtain predicted values in an output data set for observations that are \nnot used in fitting the model. If you do not specify a DESIGNROLE= variable, then all \nobservations are assigned to the fitting group."},"StatementOptionType":"V"},{"StatementOptionName":"DETAILS","StatementOptionHelp":{"#cdata":"[For the LAG | COLLECTION | MULTIMEMBER | POLYNOMIAL |SPLINE effect-type] \n          \nRequests a table that shows the (1) lag design matrix of the lag effect, or (2) constituents \nof the collection effect, or (3) levels of the multimember effect, or (4) details of the specified \npolynomial, or (5) knot locations and the knots associated with each spline basis function."},"StatementOptionType":"S"},{"StatementOptionName":"NLAG=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: NLAG= n] \n\nSpecifies the number of lags. By default NLAG=1."},"StatementOptionType":"V"},{"StatementOptionName":"NOEFFECT","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \nSpecifies that, for observations with all missing levels of the multimember variables, \nthe values in the corresponding design matrix columns be set to zero."},"StatementOptionType":"S"},{"StatementOptionName":"STDIZE","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \nSpecifies that for each observation, the entries in the design matrix that corresponds \nto the multimember effect be scaled to have a sum of one."},"StatementOptionType":"S"},{"StatementOptionName":"WEIGHT=","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \n[Syntax: WEIGHT=wght-list] \n\nSpecifies numeric variables used to weigh the contributions of each of the classification \neffects that define the constructed multimember effect. The number of variables in wght-list \nmust match the number of classification variables that define the effect."},"StatementOptionType":"V"},{"StatementOptionName":"DEGREE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL and SPLINE effect-type only] \n          \n[Syntax: DEGREE=n] \n\nSpecifies the (1) degree of the polynomial, or (2) degree of the spline transformation. \nThe degree must be a positive integer. The n degree is typically a small integer, such as \n1, 2, or 3. The default for polynomial effect is DEGREE=1, and DEGREE=3 for spline \ntransformation."},"StatementOptionType":"V"},{"StatementOptionName":"LABELSTYLE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: LABELSTYLE=(style-opts) | LABELSTYLE=style-opt] \n\nSpecifies how the terms in the polynomial are labeled. By default, powers are shown \nwith ^ as the exponentiation operator and * as the multiplication operator."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EXPAND","@Value2":"EXPONENT","@Value3":"INCLUDENAME","@Value4":"PRODUCTSYMBOL="},"StatementOptionToolTips":{"@ToolTip1":"Specifies that each variable with an exponent greater than 1 be written as products of that variable.","@ToolTip2":"Syntax: EXPONENT <=quoted string>                                      Specifies that each variable with an exponent greater than 1 be written using exponential  notation. By default, the symbol ^ is used as the exponentiation operator. If you supply the  optional quoted string after an equal sign, then that string is used as the exponentiation  operator.","@ToolTip3":"Specifies that the name of the effect followed by an underscore be used as a prefix  for term labels.","@ToolTip4":"Syntax: PRODUCTSYMBOL=NONE | quoted string                                      Specifies that the supplied string be used as the product symbol."}},{"StatementOptionName":"MDEGREE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: MDEGREE=n] \n\nSpecifies the maximum degree of any variable in a term of the polynomial. This degree \nmust be a positive integer. The default is the degree of the specified polynomial."},"StatementOptionType":"V"},{"StatementOptionName":"NOSEPARATE","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \nSpecifies that the polynomial be treated as a single effect with multiple degrees \nof freedom. The effect name that you specify is used as the constructed effect name, \nand the labels of the terms are used as labels of the corresponding parameters."},"StatementOptionType":"S"},{"StatementOptionName":"STANDARDIZE","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: STANDARDIZE <(centerscale-opts)> <= standardize-opt>] \n\nSpecifies that the variables that define the polynomial be standardized. By default, \nthe standardized variables receive prefix \"s_\" in the variable names. \n\nYou can use the following centerscale-opts to specify how the center and scale are estimated: \n\n  METHOD=MOMENTS \n  specifies that the center be estimated by the variable mean and the scale be estimated by the standard deviation. \n\n  METHOD=RANGE \n  specifies that the center be estimated by the midpoint of the variable range and the scale be estimated as half the variable range.\n\n  METHOD=WMOMENTS \n  is the same as METHOD=MOMENTS except that weighted means and weighted standard deviations are used. \n\n  PREFIX=NONE | quoted-string \n  specifies the prefix that is appended to standardized variables when forming the term labels."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"CENTER","@Value2":"CENTERSCALE","@Value3":"NONE","@Value4":"SCALE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that variables be centered but not scaled.","@ToolTip2":"Specifies that variables be centered and scaled. This is the default if you do not  specify a standardization-opt.","@ToolTip3":"Specifies that no standardization be performed.","@ToolTip4":"Specifies that variables be scaled but not centered."}},{"StatementOptionName":"BASIS=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies a basis for the spline expansion."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BSPLINE","@Value2":"TPF"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a B-spline basis for the spline expansion.","@ToolTip2":"Syntax: TPF(options)                                      Specifies a truncated power function basis for the spline expansion.   You can modify the number of columns when you request BASIS=TPF with the following options:     NOINT    excludes the intercept column.     NOPOWERS    excludes the intercept and polynomial columns."}},{"StatementOptionName":"DATABOUNDARY","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only]\n          \nSpecifies that the extremes of the data be used as boundary knots when building a B-spline basis."},"StatementOptionType":"S"},{"StatementOptionName":"KNOTMAX=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only]\n          \n[Syntax: KNOTMAX=value] \n\nSpecifies that, for each variable in the EFFECT statement, the right-side boundary \nknots be equally spaced starting at the maximum of the variable and ending at the \nspecified value. This option is ignored for variables whose maximum value is greater \nthan the specified value or if the DATABOUNDARY option is also specified."},"StatementOptionType":"V"},{"StatementOptionName":"KNOTMETHOD=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies how to construct the knots for spline effects."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EQUAL","@Value2":"LIST","@Value3":"LISTWITHBOUNDARY","@Value4":"MULTISCALE","@Value5":"PERCENTILES","@Value6":"RANGEFRACTIONS"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: EQUAL<(n)>               Specifies that n equally spaced knots be positioned between the extremes of the data.  The default is n=3. For a B-spline basis, any needed boundary knots continue to be  equally spaced unless the DATABOUNDARY option has also been specified. KNOTMETHOD=EQUAL  is the default if no knot-method is specified.","@ToolTip2":"Syntax: LIST(number-list)                                      Specifies the list of internal knots to be used in forming the spline basis columns.  For a B-spline basis, the data extremes are used as boundary knots.","@ToolTip3":"Syntax: LISTWITHBOUNDARY(number-list)                                      Specifies the list of all knots that are used in forming the spline basis columns.","@ToolTip4":"Syntax: MULTISCALE<(multiscale-options)>                                      Specifies that multiple B-spline bases be generated, corresponding to sets with an  increasing number of internal knots.   You can control which scales are included with the following multiscale-options:     STARTSCALE=n    specifies the start scale, where n is a positive integer. The default is STARTSCALE=0.     ENDSCALE=n    specifies the end scale, where n is a positive integer. The default is ENDSCALE=7.","@ToolTip5":"Syntax: PERCENTILES(n)                                      Requests that internal knots be placed at n equally spaced percentiles of the variable  or variables named in the EFFECT statement.","@ToolTip6":"Syntax: RANGEFRACTIONS(fraction-list)                                      Requests that internal knots be placed at each fraction of the ranges of the variables  in the EFFECT statement."}},{"StatementOptionName":"KNOTMIN=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \n[Syntax: KNOTMIN=value] \n\nSpecifies that for each variable in the EFFECT statement, the left-side boundary knots be \nequally spaced starting at the specified value and ending at the minimum of the variable. \nThis option is ignored for variables whose minimum value is less than the specified value \nor if the DATABOUNDARY option is also specified."},"StatementOptionType":"V"},{"StatementOptionName":"SEPARATE","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies that when multiple variables are specified in the EFFECT statement, \nthe spline basis for each variable be treated as a separate effect. The names \nof these separated effects are formed by appending an underscore followed by \nthe name of the variable to the name that you specify in the EFFECT statement."},"StatementOptionType":"S"},{"StatementOptionName":"SPLIT","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies that each individual column in the design matrix that corresponds to the spline \neffect be treated as a separate effect that can enter or leave the model independently. \nNames for these split effects are generated by appending the variable name and an index \nfor each column to the name that you specify in the EFFECT statement."},"StatementOptionType":"S"}]}},{"StatementName":"ESTIMATE","StatementHelp":{"#cdata":"Syntax: ESTIMATE <'label'> estimate-specification <(divisor=n)>\n  <, ...<'label'> estimate-specification <(divisor=n)> >\n  < / options> ; \n  \nThe ESTIMATE statement provides a mechanism for obtaining custom hypothesis tests. \nEstimates are formed as linear estimable functions of the form L\u03b2. You can perform \nhypothesis tests for the estimable functions, construct confidence limits, and obtain \nspecific nonlinear transformations. \n\nThe basic element of the ESTIMATE statement is the estimate-specification, which consists \nof model effects and their coefficients. A estimate-specification takes the general form \n\n  effect name <effect values ...> \n  \nThe following variables can appear in the ESTIMATE statement: \n\n  label \n  is an optional label that identifies the particular row of the estimate in the output. \n\n  effect \n  identifies an effect that appears in the MODEL statement. The keyword INTERCEPT can be \n  used as an effect when an intercept is fitted in the model. You do not need to include \n  all effects that are in the MODEL statement. \n\n  values \n  are constants that are elements of the L matrix and are associated with the fixed and random effects."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \n  limits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator    degrees of freedom for the final effect listed in the ESTIMATE statement from the 'Type    III' table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees    of freedom are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the estimates."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE<(simoptions)>","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum    or maximum absolute value of a multivariate t random vector.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."}},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed with confidence level 1-number.  \nThe value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F or chi-square tests with the JOINT option. \n\nThe category-options are used to indicate how response variable levels are treated in \nconstructing the estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row ESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row ESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed. If the procedure shows the degrees \nof freedom in the \"Estimates\" table as infinite, then the confidence limits are z intervals. \nThe confidence level is 0.95 by default, and you can change the confidence level with the \nALPHA= option. The confidence intervals are adjusted for multiplicity when you specify the \nADJUST= option. However, if a step-down p-value adjustment is requested with the STEPDOWN \noption, only the p-values are adjusted for multiplicity."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. This option \nis not supported by the procedures that perform chi-square-based inference (LOGISTIC, \nPHREG, and SUVEYLOGISTIC)."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0. \n\nIf the number of elements in value-list exceeds the number of rows of the estimate, the \nextra values are ignored. If the number of elements in value-list is less than the number \nof rows of the estimate, the last value in value-list is copied forward. \n\nIf you specify a row-specific divisor as part of the specification of the estimate row, \nthis value multiplies the corresponding divisor that is implied by the value-list. For \nexample, the following statement divides the coefficients in the first row by 8, and the \ncoefficients in the third and fourth row by 3: \n\n  estimate 'One vs. two'   A 2 -2  (divisor=2),\n           'One vs. three' A 1  0 -1         ,\n           'One vs. four'  A 3  0  0 -3      ,\n           'One vs. five'  A 1  0  0  0  -1  / divisor=4,.,3;\n\nCoefficients in the second row are not altered."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the estimate. When you model data with the logit, cumulative \nlogit, or generalized logit link functions, and the estimate represents a log odds ratio \nor log cumulative odds ratio, the EXP option produces an odds ratio. In proportional hazards \nmodel, this option produces estimates of hazard ratios. If you specify the CL or ALPHA= option, \nthe (adjusted) confidence bounds are also exponentiated. \n\nThe EXP option is supported only by PROC PHREG, PROC SURVEYPHREG, the procedures that support \ngeneralized linear modeling (LOGISTIC and SURVEYLOGISTIC), and by PROC PLM when it is used to \nperform statistical analyses on item stores created by these procedures."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the mean \n(the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \nThe JOINT option in the ESTIMATE statement essentially replaces the CONTRAST statement. \n\nWhen the LOWERTAILED or the UPPERTAILED options are in effect, or if the BOUNDS option \ndescribed below is in effect, the JOINT option produces the chi-bar-square statistic \naccording to Silvapulle and Sen (2004). This statistic uses a simulation-based approach \nto compute p-values in situations where the alternative hypotheses of the estimable \nfunctions are not simple two-sided hypotheses. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004).   \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option. "},"StatementOptionType":"S"},{"StatementOptionName":"NOFILL","StatementOptionHelp":{"#cdata":"Suppresses the automatic fill-in of coefficients of higher-order effects."},"StatementOptionType":"V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Produces all possible plots with their default settings.","@ToolTip2":"Syntax: BOXPLOT<(boxplot-options)>                                      Produces box plots of the distribution of the estimable function across the posterior  sample. A separate box is generated for each estimable function, and all boxes appear  on a single graph by default. You can affect the appearance of the box plot graph with  the following options:     ORIENTATION=VERTICAL|HORIZONTAL    ORIENT=VERT|HORIZ    specifies the orientation of the boxes. The default is vertical orientation of the box plots.     NPANELPOS=number    specifies how to break the series of box plots across multiple panels. If the NPANELPOS option    is not specified, or if number equals zero, then all box plots are displayed in a single graph;    this is the default.","@ToolTip3":"Syntax: DISTPLOT<(distplot-options)>                                      Generates panels of histograms with a kernel density overlaid. A separate plot in each  panel contains the results for each estimable function. You can specify the following  distplot-options in parentheses:     BOX|NOBOX    controls the display of a horizontal box plot of the estimable function\u2019s distribution    across the posterior sample below the graph. The BOX option is enabled by default.     HIST|NOHIST    controls the display of the histogram of the estimable function\u2019s distribution across the    posterior sample. The HIST option is enabled by default.     NORMAL|NONORMAL    controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.     KERNEL|NOKERNEL    controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.     NROWS=number    specifies the highest number of rows in a panel. The default is 3.     NCOLS=number    specifies the highest number of columns in a panel. The default is 3.     UNPACK    unpacks the panel into separate graphics.","@ToolTip4":"Does not produce any plots."},"SubOptionsKeywords":"BOX|NOBOX|HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the \nESTIMATE statement (for example, chi-bar-square statistics and simulated p-values). \nnumber specifies an integer that is used to start the pseudo-random number generator \nfor the simulation. If you do not specify a seed, or if you specify a value less than \nor equal to zero, the seed is generated from reading the time of day from the computer \nclock. There could be multiple ESTIMATE statements with SEED= specifications and there \ncould be other statements that can supply a random number seed. Since the procedure has \nonly one random number stream, the initial seed is shown in the SAS log."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant. \n\nYou can specify the following step-down-options in parentheses after the STEPDOWN option: \n\n  MAXTIME=n \n  specifies the time (in seconds) to be spent computing the maximal logically consistent \n  sequential subsets of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60. \n\n  ORDER=PVALUE | ORDER=ROWS   \n  specifies the order in which the step-down tests to be performed. ORDER=PVALUE is the default, \n  with estimates being declared significant only if all estimates with smaller (unadjusted) \n  p-values are significant. If you specify ORDER=ROWS, then significances are evaluated in the \n  order in which they are specified in the syntax. \n\n  REPORT \n  specifies that a report on the step-down adjustment be displayed, including a listing of the \n  sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n  TYPE=LOGICAL<(n)> | TYPE=FREE \n  specifies how step-down adjustment are made. If you specify TYPE=LOGICAL, the step-down \n  adjustments are computed by using maximal logically consistent sequential subsets of equality \n  hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, sequential subsets are \n  computed ignoring logical constraints. The TYPE=FREE results are more conservative than those \n  for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. For example, \n  it is not feasible to take logical constraints between all pairwise comparisons of more than about \n  10 groups. For this reason, TYPE=FREE is the default."},"StatementOptionType":"S"},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nESTIMATE statement. The rules for specifying the value-list are very similar to those for \nspecifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"FREQ","StatementHelp":{"#cdata":"Syntax: FREQ variable;\n      \nThe variable in the FREQ statement identifies the variable (in the input data set) containing the \nfrequency of occurrence of each observation. PROC PHREG treats each observation as if it appears n \ntimes, where n is the value of the FREQ variable for the observation."},"StatementOptions":{"StatementOption":{"StatementOptionName":"NOTRUNCATE|NOTRUNC","StatementOptionHelp":{"#cdata":"Specifies that frequency values are not truncated to integers."},"StatementOptionType":"S"}}},{"StatementName":"HAZARDRATIO","StatementHelp":{"#cdata":"Syntax: HAZARDRATIO <\u2019label\u2019> variable </ options> ; \n      \nThe HAZARDRATIO statement enables you to request hazard ratios for any variable in the model \nat customized settings."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSpecifies the alpha level of the interval estimates for the hazard ratios. The value must be \nbetween 0 and 1. The default is the value of the ALPHA= option in the PROC PHREG statement, \nor 0.05 if that option is not specified."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"Syntax: AT (variable=ALL | REF | list <...variable=ALL | REF| list> ) \n          \nSpecifies the variables that interact with the variable of interest and the corresponding values \nof the interacting variables. If the interacting variable is continuous and a numeric list is specified \nafter the equal sign, hazard ratios are computed for each value in the list. If the interacting variable \nis a CLASS variable, you can specify, after the equal sign, a list of quoted strings corresponding to \nvarious levels of the CLASS variable, or you can specify the keyword ALL or REF. Hazard ratios are \ncomputed at each value of the list if the list is specified, or at each level of the interacting \nvariable if ALL is specified, or at the reference level of the interacting variable if REF is specified."},"StatementOptionType":"S"},{"StatementOptionName":"CL=","StatementOptionHelp":{"#cdata":"Specifies whether to create the Wald or profile-likelihood confidence limits, or both for the \nclassical analyis."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"WALD","@Value2":"PL","@Value3":"BOTH"},"StatementOptionToolTips":{"@ToolTip1":"Specifies to create the Wald confidence limits for the classical analyis..","@ToolTip2":"Specifies to create the profile-likelihood confidence limits for the classical analyis..","@ToolTip3":"Specifies to create both the Wald and profile-likelihood confidence limits for the classical analyis."}},{"StatementOptionName":"DIFF=","StatementOptionHelp":{"#cdata":"Specifies which differences to consider for the level comparisons of a CLASS variable. The default is DIFF=ALL."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"REF"},"StatementOptionToolTips":{"@ToolTip1":"Requests all differences.","@ToolTip2":"Requests comparisons between the reference level and all other levels of the CLASS variable."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Displays the vector h of linear coefficients such that h'\u03b2 is the log-hazard ratio, with \u03b2 being the \nvector of regression coefficients."},"StatementOptionType":"S"},{"StatementOptionName":"PLCONV=","StatementOptionHelp":{"#cdata":"[Syntax: PLCONV=value] \n          \nControls the convergence criterion for the profile-likelihood confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"PLMAXIT=","StatementOptionHelp":{"#cdata":"[Syntax: PLMAXIT=n] \n          \nSpecifies the maximum number of iterations to achieve the convergence of the profile-likelihood \nconfidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"PLSINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: PLSINGULAR=value] \n          \nSpecifies the tolerance for testing the singularity of the Hessian matrix in the computation of the \nprofile-likelihood confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"UNITS=","StatementOptionHelp":{"#cdata":"[Syntax: UNITS=value] \n          \nSpecifies the units of change in the continuous explanatory variable for which the customized hazard \nratio is estimated."},"StatementOptionType":"V"}]}},{"StatementName":"ID","StatementHelp":{"#cdata":"Syntax: ID variables ;\n      \nThe ID statement specifies additional variables for identifying observations in the input \ndata. These variables are placed in the OUT= data set created by the OUTPUT statement. In \nthe computation of the robust sandwich variance estimate, you can aggregate over distinct \nvalues of these ID variables. \n\nOnly variables in the input data set can be included in the ID statement."},"StatementOptions":null},{"StatementName":"LSMEANS","StatementHelp":{"#cdata":"Syntax: LSMEANS <model-effects> </ options> ; \n      \nThe LSMEANS statement computes and compares least squares means (LS-means) of fixed \neffects. LS-means are predicted population margins\u2014that is, they estimate the marginal \nmeans over a balanced population. In a sense, LS-means are to unbalanced designs as \nclass and subclass arithmetic means are to balanced designs."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the LSMEANS effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the LSMEANS statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the LSMEANS \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="}]}},{"StatementName":"LSMESTIMATE","StatementHelp":{"#cdata":"Syntax: LSMESTIMATE model-effect <'label'> values <divisor=> \n  <, ...<'label'> values <divisor=>>\n  < / options> ; \n  \nThe LSMESTIMATE statement provides a mechanism for obtaining custom hypothesis \ntests among least squares means."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the \nLS-mean estimates. The adjusted quantities are produced in addition to the unadjusted \np-values and confidence limits. Adjusted confidence limits are produced if the CL or \nALPHA= option is in effect."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means with \nconfidence level 1-number. The value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates used in computing LS-means. By default, all \ncovariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that the procedure compute separate margins for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F tests with the JOINT option. \n\nThe category-options indicate how response variable levels are treated in constructing \nthe estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row LSESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row LSESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. \nThe confidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L coefficients of the estimable function be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ELSM","StatementOptionHelp":{"#cdata":"Requests that the K matrix coefficients be displayed. These are the coefficients \nthat apply to the LS-means. This option is useful to ensure that you assigned the \ncoefficients correctly to the LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the least squares means estimate. When you model data \nwith the logit link function and the estimate represents a log odds ratio, the \nEXP option produces an odds ratio. If you specify the CL or ALPHA= option, the \n(adjusted) confidence limits for the estimate are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the \nmean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004). \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to \nthose found in the OM-data-set. This adjustment is reasonable when you want your \ninferences to apply to a population that is not necessarily balanced but has the \nmargins observed in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip3":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip4":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|HIST|NOHIST|\n            NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the ESTIMATE statement."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant.\n\nYou can specify the following step-down-options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential subsets \n    of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60.\n\n    ORDER=PVALUE \n    ORDER=ROWS \n    specifies the order in which the step-down tests are performed. ORDER=PVALUE is the default, with LS-mean\n    estimates being declared significant only if all LS-mean estimates with smaller (unadjusted) p-values are\n    significant. If you specify ORDER=ROWS, then significances are evaluated in the order in which they are specified. \n\n    REPORT \n    specifies that a report on the step-down adjustment be displayed, including a listing of the sequential \n    subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically consistent \n    sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, \n    sequential subsets are computed ignoring logical constraints. The TYPE=FREE results are more conservative \n    than those for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. Default: TYPE=FREE."},"StatementOptionType":"S"},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nLSMESTIMATE statement. The rules for specifying the value-list are very similar to those  \nfor specifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"MODEL","StatementHelp":{"#cdata":"Syntax: \n(1) MODEL response <*censor ( list )> = effects </options> ;\n\n(2) MODEL (t1, t2) <*censor(list)> = effects </options> ; \n\nThe MODEL statement identifies the variables to be used as the failure time variables, \nthe optional censoring variable, and the explanatory effects, including covariates, \nmain effects, interactions, nested effects. \n\nTwo forms of MODEL syntax can be specified; the first form allows one time variable, \nand the second form allows two time variables for the counting process style of input."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSets the significance level used for the confidence limits for the hazard ratios. The value of \nnumber must be between 0 and 1."},"StatementOptionType":"V"},{"StatementOptionName":"ABSFCONV=|CONVERGELIKE=","StatementOptionHelp":{"#cdata":"[Syntax: ABSFCONV=value | CONVERGELIKE=value] \n          \nSpecifies the absolute function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"BEST=","StatementOptionHelp":{"#cdata":"[Syntax: BEST=n] \n          \nIs used exclusively with the SCORE model selection method. Specifies that n models with the highest \nscore chi-square statistics are to be displayed for each model size."},"StatementOptionType":"V"},{"StatementOptionName":"CORRB","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"COVB","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"DETAILS","StatementOptionHelp":{"#cdata":"Produces a detailed display at each step of the model-building process."},"StatementOptionType":"S"},{"StatementOptionName":"ENTRYTIME=|ENTRY=","StatementOptionHelp":{"#cdata":"[Syntax: ENTRYTIME=variable] \n          \nSpecifies the name of the variable that represents the left truncation time."},"StatementOptionType":"V"},{"StatementOptionName":"FAST","StatementOptionHelp":{"#cdata":"Uses a computational algorithm of Lawless and Singhal (1978) to compute a first-order approximation \nto the remaining slope estimates for each subsequent elimination of a variable from the model."},"StatementOptionType":"S"},{"StatementOptionName":"FCONV=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV=value] \n          \nSpecifies the relative function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"FIRTH","StatementOptionHelp":{"#cdata":"Performs Firth\u2019s penalized maximum likelihood estimation to reduce bias in the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"GCONV=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV=value] \n          \nSpecifies the relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"HIERARCHY=|HIER=","StatementOptionHelp":{"#cdata":"Specifies whether and how the model hierarchy requirement is applied and whether a single effect or \nmultiple effects are allowed to enter or leave the model in one step."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"NONE","@Value2":"SINGLE","@Value3":"SINGLECLASS","@Value4":"MULTIPLE","@Value5":"MULTIPLECLASS"},"StatementOptionToolTips":{"@ToolTip1":"Indicates that the model hierarchy is not maintained.","@ToolTip2":"Indicates that only one effect can enter or leave the model at one time, subject to the model  hierarchy requirement.","@ToolTip3":"Is the same as HIERARCHY=SINGLE except that only CLASS effects are subject to the hierarchy requirement.","@ToolTip4":"Indicates that more than one effect can enter or leave the model at one time","@ToolTip5":"Is the same as HIERARCHY=MULTIPLE except that only CLASS effects are subject to the hierarchy requirement."}},{"StatementOptionName":"INCLUDE=","StatementOptionHelp":{"#cdata":"[Syntax: INCLUDE=n] \n          \nIncludes the first n effects in the MODEL statement in every model."},"StatementOptionType":"V"},{"StatementOptionName":"ITPRINT","StatementOptionHelp":{"#cdata":"Displays the iteration history, including the last evaluation of the gradient vector."},"StatementOptionType":"S"},{"StatementOptionName":"MAXITER=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER=number] \n          \nSpecifies the maximum number of iterations allowed. By default, MAXITER=25."},"StatementOptionType":"V"},{"StatementOptionName":"MAXSTEP=","StatementOptionHelp":{"#cdata":"[Syntax: MAXSTEP=n] \n          \nSpecifies the maximum number of times the explanatory variables can move in and out of the model\nbefore the STEPWISE model-building process ends."},"StatementOptionType":"V"},{"StatementOptionName":"NODUMMYPRINT|NODESIGNPRINT|NODP","StatementOptionHelp":{"#cdata":"Suppresses the \"Class Level Information\" table, which shows how the design matrix columns for the \nCLASS variables are coded."},"StatementOptionType":"S"},{"StatementOptionName":"NOFIT","StatementOptionHelp":{"#cdata":"Performs the global score test, which tests the joint significance of all the explanatory variables \nin the MODEL statement."},"StatementOptionType":"S"},{"StatementOptionName":"OFFSET=","StatementOptionHelp":{"#cdata":"[Syntax: OFFSET=name] \n    \nSpecifies the name of an offset variable, which is an explanatory variable with a regression \ncoefficient fixed as one."},"StatementOptionType":"V"},{"StatementOptionName":"PLCONV=","StatementOptionHelp":{"#cdata":"[Syntax: PLCONV=value] \n          \nControls the convergence criterion for confidence intervals based on the profile-likelihood function. \nThe quantity value must be a positive number, with a default value of 1E\u20134."},"StatementOptionType":"V"},{"StatementOptionName":"RIDGING=","StatementOptionHelp":{"#cdata":"Specifies the technique used to improve the log-likelihood function when its value is worse than \nthat of the previous step."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ABSOLUTE","@Value2":"RELATIVE","@Value3":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"The diagonal elements of the negative (expected) Hessian are inflated by adding the ridge value.","@ToolTip2":"The diagonal elements are inflated by a factor of 1 plus the ridge value. This is the default.","@ToolTip3":"The crude line search method of taking half a step is used instead of ridging."}},{"StatementOptionName":"RIDGEINIT=","StatementOptionHelp":{"#cdata":"[Syntax: RIDGEINIT=value] \n          \nSpecifies the initial ridge value. The maximum ridge value is 2000 times the maximum of 1 and the \ninitial ridge value."},"StatementOptionType":"V"},{"StatementOptionName":"RISKLIMITS=|RL=","StatementOptionHelp":{"#cdata":"Syntax: RISKLIMITS<=keyword> \n          \nProduces confidence intervals for hazard ratios of main effects not involved in interactions or nestings."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"PL","@Value2":"WALD","@Value3":"BOTH"},"StatementOptionToolTips":{"@ToolTip1":"Requests profile-likelihood confidence limits.","@ToolTip2":"Requests confidence limits based on the Wald tests.","@ToolTip3":"Request both profile-likelihood and Wald confidence limits."}},{"StatementOptionName":"SELECTION=","StatementOptionHelp":{"#cdata":"Specifies the method used to select the variables in the model."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BACKWARD|B","@Value2":"FORWARD|F","@Value3":"NONE|N","@Value4":"STEPWISE|S","@Value5":"SCORE"},"StatementOptionToolTips":{"@ToolTip1":"Requests backward elimination","@ToolTip2":"Requests forward selection","@ToolTip3":"Fits the complete model specified in the MODEL statement. This is the default.","@ToolTip4":"Requests stepwise selection","@ToolTip5":"Requests best subset selection"}},{"StatementOptionName":"SEQUENTIAL","StatementOptionHelp":{"#cdata":"Forces variables to be added to the model in the order specified in the MODEL statement or \neliminated from the model in the reverse order of that specified in the MODEL statement."},"StatementOptionType":"S"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=value] \n          \nSpecifies the singularity criterion for determining linear dependencies in the set of \nexplanatory variables."},"StatementOptionType":"V"},{"StatementOptionName":"SLENTRY=|SLE=","StatementOptionHelp":{"#cdata":"[Syntax: SLENTRY=value] \n          \nSpecifies the significance level (a value between 0 and 1) for entering an explanatory variable \ninto the model in the FORWARD or STEPWISE method."},"StatementOptionType":"V"},{"StatementOptionName":"SLSTAY=|SLS=","StatementOptionHelp":{"#cdata":"[Syntax: SLSTAY=value] \n          \nSpecifies the significance level (a value between 0 and 1) for removing an explanatory variable \nfrom the model in the BACKWARD or STEPWISE method."},"StatementOptionType":"V"},{"StatementOptionName":"START=","StatementOptionHelp":{"#cdata":"[Syntax: START=n] \n          \nBegins the FORWARD, BACKWARD, or STEPWISE effect selection process with the first n effects \nlisted in the MODEL statement."},"StatementOptionType":"V"},{"StatementOptionName":"STOP=","StatementOptionHelp":{"#cdata":"[Syntax: STOP=n] \n          \nSpecifies the maximum (FORWARD method) or minimum (BACKWARD method) number of effects to be \nincluded in the final model."},"StatementOptionType":"V"},{"StatementOptionName":"STOPRES|SR","StatementOptionHelp":{"#cdata":"Specifies that the addition and deletion of variables be based on the result of the likelihood \nscore test for testing the joint significance of variables not in the model."},"StatementOptionType":"S"},{"StatementOptionName":"TYPE1","StatementOptionHelp":{"#cdata":"Requests that a Type 1 (sequential) analysis of likelihood ratio test be performed. \nThis consists of sequentially fitting models, beginning with the null model and \ncontinuing up to the model specified in the MODEL statement. The likelihood ratio \nstatistic for each successive pair of models is computed and displayed in a table."},"StatementOptionType":"S"},{"StatementOptionName":"TYPE3","StatementOptionHelp":{"#cdata":"[Syntax:  TYPE3 <(keywords)>] \n          \nRequests a Type 3 test for each effect that is specified in the MODEL statement. The default \nis to use the Wald statistic, but you can requests other statistics by specifying one or more \nof the following keywords: \n\n  ALL \n  requests the likelihood ratio tests, the score tests, and the Wald tests. Specifying TYPE3(ALL) \n  is equivalent to specifying TYPE3=(LR SCORE WALD). \n\n  NONE \n  suppresses the Type 3 analysis. Even if the TYPE3 option is not specified, PROC PHREG displays \n  the Wald test results for each model effect if a CLASS variable is involved in a MODEL effect. \n  The NONE option can be used to suppress such display. \n\n  LR \n  requests the likelihood ratio tests. This request is not honored if the COVS option is also specified. \n\n  SCORE \n  requests the score tests. This request is not honored if the COVS option is also specified. \n\n  WALD \n  requests the Wald tests."},"StatementOptionType":"S"},{"StatementOptionName":"TIES=","StatementOptionHelp":{"#cdata":"Specifies the optimization technique for estimating the regression parameters."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BRESLOW","@Value2":"DISCRETE","@Value3":"EFRON","@Value4":"EXACT"},"StatementOptionToolTips":{"@ToolTip1":"Uses the approximate likelihood of Breslow (1974). This is the default value.","@ToolTip2":"Replaces the proportional hazards model by the discrete logistic model","@ToolTip3":"Uses the approximate likelihood of Efron (1977).","@ToolTip4":"Computes the exact conditional probability under the proportional hazards assumption that all tied  event times occur before censored times of the same value or before larger values."}},{"StatementOptionName":"XCONV=|CONVEREPARM=","StatementOptionHelp":{"#cdata":"[Syntax: XCONV=value] \n          \nSpecifies the relative parameter convergence criterion."},"StatementOptionType":"V"}]}},{"StatementName":"OUTPUT","StatementHelp":{"#cdata":"Syntax: OUTPUT <OUT=SAS-data-set> < keyword=name ...keyword=name> </ options> ; \n      \nThe OUTPUT statement creates a new SAS data set containing statistics calculated for each observation."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nNames the output data set. If you omit the OUT= option, the output data set is created and given \na default name by using the DATAn convention."},"StatementOptionType":"RV|DV"},{"StatementOptionName":"ATRISK=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the number of subjects at risk at the observation time ti (or at the right \nendpoint of the at-risk interval when a counting process MODEL specification is used)."},"StatementOptionType":"RV"},{"StatementOptionName":"DFBETA=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the approximate changes in the parameter estimates (\u03b2-\u03b2(j)) when the j-th \nobservation is omitted."},"StatementOptionType":"RV"},{"StatementOptionName":"LD=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the approximate likelihood displacement when the observation is left out."},"StatementOptionType":"RV"},{"StatementOptionName":"LMAX=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the relative influence of observations on the overall fit of the model."},"StatementOptionType":"RV"},{"StatementOptionName":"LOGLOGS=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the log of the negative log of SURVIVAL."},"StatementOptionType":"RV"},{"StatementOptionName":"LOGSURV=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the log of SURVIVAL."},"StatementOptionType":"RV"},{"StatementOptionName":"RESDEV=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the deviance residual Dj"},"StatementOptionType":"RV"},{"StatementOptionName":"RESMART=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the martingale residual Mj."},"StatementOptionType":"RV"},{"StatementOptionName":"RESSCH=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the Schoenfeld residuals."},"StatementOptionType":"RV"},{"StatementOptionName":"RESSCO=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the score residuals."},"StatementOptionType":"RV"},{"StatementOptionName":"STDXBETA=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the standard error of an estimated linear predictor."},"StatementOptionType":"RV"},{"StatementOptionName":"SURVIVAL=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the survivor function estimate."},"StatementOptionType":"RV"},{"StatementOptionName":"WTRESSCH=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the weighted Schoenfeld residuals."},"StatementOptionType":"RV"},{"StatementOptionName":"XBETA=","StatementOptionHelp":{"#cdata":"[keyword] \n          \nSpecifies the estimate of the linear predictor, zj'\u03b2"},"StatementOptionType":"RV"},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"Specifies the order of the observations in the OUTPUT data set."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"SORTED"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the output observations be sorted the same as the input data set.","@ToolTip2":"Requests that the output observations be sorted by strata and descending order of the time  variable within each stratum."}},{"StatementOptionName":"METHOD=","StatementOptionHelp":{"#cdata":"Specifies the method used to compute the survivor function estimates. \n          \nThe default is METHOD=BRESLOW. "},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BRESLOW|CH|EMP","@Value2":"FH","@Value3":"PL"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that the empirical cumulative hazard function estimate of the survivor function be computed;  that is, the survivor function is estimated by exponentiating the negative empirical cumulative  hazard function.","@ToolTip2":"Specifies that the Fleming-Harrington (FH) estimates be computed. The FH estimator is a tie-breaking  modification of the Breslow estimator. If there are no tied event times, this estimator is the same  as the Breslow estimator.","@ToolTip3":"Specifies that the product-limit estimate of the survivor function be computed. This estimator is not available if you use the model syntax that allows two time variables for the counting process style of input; in such a case, the Breslow estimator (METHOD=BRESLOW) is used instead."}}]}},{"StatementName":"STRATA|STRATUM","StatementHelp":{"#cdata":"Syntax: STRATA variable <( list )> < ...variable <( list )>> < /option> ;\n      \nThe proportional hazards assumption might not be realistic for all data. If so, it might still be \nreasonable to perform a stratified analysis. The STRATA statement names the variables that determine \nthe stratification. Strata are formed according to the nonmissing values of the STRATA variables \nunless the MISSING option is specified. In the STRATA statement, variable is a variable with values \nthat are used to determine the strata levels, and list is an optional list of values for a numeric \nvariable. Multiple variables can appear in the STRATA statement."},"StatementOptions":{"StatementOption":{"StatementOptionName":"MISSING","StatementOptionHelp":{"#cdata":"Treats missing values (\u2018.\u2019,\u2018.A\u2019,...,\u2018.Z\u2019 for numeric variables and blanks for character variables) \nas valid STRATA variable values."},"StatementOptionType":"S"}}},{"StatementName":"SLICE","StatementHelp":{"#cdata":"Syntax: SLICE model-effect </ options> ; \n      \nThe SLICE statement provides a general mechanism for performing a partitioned analysis \nof the LS-means for an interaction. This analysis is also known as an analysis of simple \neffects. \n\nThe SLICE statement uses the same options as the LSMEANS statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the SLICE model-effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified SLICE effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the SLICE effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the SLICE statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this SLICE statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the SLICE \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="},{"StatementOptionName":"SLICEBY|SIMPLE","StatementOptionHelp":{"#cdata":"Determines how to construct the partition of the least squares means for the model-effect.\n          \nSyntax: \nSLICEBY <=> slice-specification \nSIMPLE <=> slice-specification \nSLICEBY(slice-specification <, slice-specification <, >>) \nSIMPLE(slice-specification <, slice-specification <, >>) \n\nA slice-specification consists of an effect name followed by an optional list of formatted \nvalues. For example, the following statements creates partitions of the A*B interaction effect \nfor all levels of variable A: \n\n  class a b;\n  model y = a b a*b;\n  slice a*b / sliceby=a;"},"StatementOptionType":"S|V"},{"StatementOptionName":"NOF","StatementOptionHelp":{"#cdata":"Suppresses the F test for testing the mutual equality of the estimable functions \nin the partition."},"StatementOptionType":"S"}]}},{"StatementName":"STORE|ITEMSTORE","StatementHelp":{"#cdata":"Syntax: STORE <OUT=>item-store-name </ LABEL='label'> ; \n      \nThe STORE statement requests that the procedure save the context and results of the \nstatistical analysis. The resulting item store is a binary file format that cannot \nbe modified. The contents of the item store can be processed with the PLM procedure. \n\nThe item-store-name is a usual one- or two-level SAS name, like the names that are used \nfor SAS data sets. If you specify a one-level name, then the item store resides in the \nWORK library and is deleted at the end of the SAS session. Since item stores usually are \nused to perform postprocessing tasks, typical usage specifies a two-level name of the form \nlibname.membername. \n\nIf an item store by the same name as specified in the STORE statement already exists, \nthe existing store is replaced."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=item-store-name] \n          \nThe item-store-name is a usual one- or two-level SAS name, like the names that are used \nfor SAS data sets. If you specify a one-level name, then the item store resides in the \nWORK library and is deleted at the end of the SAS session."},"StatementOptionType":"RV"},{"StatementOptionName":"LABEL=","StatementOptionHelp":{"#cdata":"[Syntax: LABEL='label'] \n          \nAdds a custom label. When the PLM procedure processes an item store, the label appears \nin the PROC PLM output along with other identifying information."},"StatementOptionType":"V"}]}},{"StatementName":"TEST","StatementHelp":{"#cdata":"Syntax: <label:> TEST equation1 <,..., equationk> < /options> ; \n      \nThe TEST statement tests linear hypotheses about the regression coefficients. PROC PHREG performs \na Wald test for the joint hypothesis specified in a single TEST statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"AVERAGE","StatementOptionHelp":{"#cdata":"Enables you to assess the average effect of the variables in the given TEST statement."},"StatementOptionType":"S"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Specifies that the linear coefficients and constants be printed."},"StatementOptionType":"S"},{"StatementOptionName":"PRINT","StatementOptionHelp":{"#cdata":"Displays intermediate calculations."},"StatementOptionType":"S"}]}},{"StatementName":"WEIGHT","StatementHelp":{"#cdata":"Syntax: WEIGHT variable </ option> ;\n\nThe variable in the WEIGHT statement identifies the variable in the input data set that contains the case weights.\nWhen a WEIGHT statement appears, each observation in the input data set is weighted by the value of the WEIGHT variable."},"StatementOptions":{"StatementOption":{"StatementOptionName":"NORMALIZE","StatementOptionHelp":{"#cdata":"Causes the weights specified by the WEIGHT variable to be normalized so that they add up to \nthe actual sample size."},"StatementOptionType":"S"}}},{"StatementName":"RANDOM","StatementHelp":{"#cdata":"Syntax: RANDOM variable </ options> ;\n      \nThe RANDOM statement enables you to fit a shared frailty model for clustered data \nwith normal distributed random effects (see the section The Frailty Model for details). \nThe variable that represents the clusters must be a CLASS variable (declared in the CLASS \nstatement). Currently, Bayesian analysis is not available for the frailty model."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ABSPCONV=","StatementOptionHelp":{"#cdata":"[Syntax: ABSPCONV=r ]\n          \nSpecifies an absolute variance estimate convergence criterion for the doubly \niterative estimation process. The PHREG procedure applies this criterion to \nthe variance parameter estimate of the random effects."},"StatementOptionType":"V"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=value ]\n          \nSpecifies the \u03b1 level of the confidence limits for the random effects. The default \nis the value of the ALPHA= option in the PROC PHREG statement, or 0.05 if that option \nis not specified. This option is ignored if the SOLUTION option is not also specified."},"StatementOptionType":"V"},{"StatementOptionName":"DIST=","StatementOptionHelp":{"#cdata":"[Syntax: DIST=GAMMA | LOGNORMAL ]\n          \nSpecifies the distribution of the shared frailty. DIST=GAMMA specifies a gamma frailty model.\nDIST=LOGNORMAL specifies a lognormal frailty model; that is, the log-frailty random variable has\na normal distribution with mean zero. The default is DIST=LOGNORMAL."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"GAMMA","@Value2":"LOGNORMAL"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a gamma frailty model.","@ToolTip2":"Specifies a lognormal frailty model; that is, the log-frailty random variable has a normal distribution with mean zero."}},{"StatementOptionName":"METHOD=","StatementOptionHelp":{"#cdata":"[Syntax: METHOD=REML | ML ]\n          \nSpecifies the estimation method for the variance parameter. The REML specifications performs \nthe residual maximum likelihood; this is the default method. The ML specification performs \nmaximum likelihood."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"REML","@Value2":"ML"},"StatementOptionToolTips":{"@ToolTip1":"Performs the residual maximum likelihood; this is the default method.","@ToolTip2":"Performs maximum likelihood."}},{"StatementOptionName":"NOCLPRINT","StatementOptionHelp":{"#cdata":"Suppresses the display of the \"Class Level Information for Random Effects\" table."},"StatementOptionType":"S"},{"StatementOptionName":"PCONV=","StatementOptionHelp":{"#cdata":"[Syntax: PCONV=r ]\n          \nSpecifies the variance estimate convergence criterion for the doubly iterative \nestimation process. The PHREG procedure applies this criterion to the variance \nestimate of the random effects."},"StatementOptionType":"V"},{"StatementOptionName":"SOLUTION","StatementOptionHelp":{"#cdata":"Displays estimates of the normal random effects. Also displayed are estimates of \nthe lognormal frailites, which are the exponentiated estimates of the normal \nrandom effects."},"StatementOptionType":"S"},{"StatementOptionName":"INITIALVARIANCE=|INITIAL=","StatementOptionHelp":{"#cdata":"[Syntax: INITIALVARIANCE=value | INITIAL=value ]\n          \nSpecifies an inital value of the variance estimate. The default is INITIAL=1."},"StatementOptionType":"V"}]}},{"StatementName":"ABORT","StatementHelp":{"#cdata":"Syntax: ABORT <ABEND | CANCEL <FILE> | RETURN | > <n> <NOLIST>; \n      \nStops executing the current DATA step, SAS job, or SAS session."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ABEND","StatementOptionHelp":{"#cdata":"Causes abnormal termination of the current SAS job or session. Results depend on the method \nof operation: \n\no batch mode and noninteractive mode \n\n  o stops processing immediately\n  o sends an error message to the SAS log that states that execution was terminated by the ABEND option \n    of the ABORT macro statement\n  o does not execute any subsequent statements or check syntax\n  o returns control to the operating environment; further action is based on how your operating environment \n    and your site treat jobs that end abnormally.\n\no windowing environment and interactive line mode \n\n  o causes your windowing environment and interactive line mode to stop processing immediately \n    and return you to your operating environment."},"StatementOptionType":"S"},{"StatementOptionName":"CANCEL","StatementOptionHelp":{"#cdata":"Causes the cancellation of the current submitted statements. The results depend on the method \nof operation:\n\no batch mode and noninteractive mode\n\n  o The entire SAS program and SAS system are terminated.\n  o The error message is written to the SAS log.\n\no windowing environment and interactive line mode \n\n  o It only clears the current submitted program.\n  o Other subsequent submitted programs are not affected.\n  o The error message is written to the SAS log.\n\no workspace server and stored process server \n\n  o It only clears currently submitted program.\n  o Other subsequent submit calls are not affected.\n  o The error message is written to the SAS log.\n\no SAS IntrNet application server \n\n  o A separate execution is created for each request. The execution submits the request code. A CANCEL \n    argument in the request code clears the current submitted code but does not terminate the execution \n    of the SAS session."},"StatementOptionType":"S"},{"StatementOptionName":"CANCEL FILE","StatementOptionHelp":{"#cdata":"Causes only the contents of the autoexec file or %INCLUDE file to be cleared by the %ABORT statement. \nOther submitted source statements will be executed after the autoexec or %INCLUDE file."},"StatementOptionType":"S"},{"StatementOptionName":"RETURN","StatementOptionHelp":{"#cdata":"Causes abnormal termination of the current SAS job or session. Results depend on the method \nof operation: \n\no batch mode and noninteractive mode \n\n  o stops processing immediately\n  o sends an error message to the SAS log that states that execution was terminated by the RETURN option \n    in the ABORT macro statement\n  o does not execute any subsequent statements or check syntax\n  o returns control to the operating environment with a condition code indicating an error.\n\no windowing environment and interactive line mode \n\n  o causes your windowing environment and interactive line mode to stop processing immediately \n    and return you to your operating environment."},"StatementOptionType":"S"},{"StatementOptionName":"NOLIST","StatementOptionType":"S","StatementOptionHelp":{"#cdata":"suppresses the output of all variables to the SAS log."}}]}},{"StatementName":"CALL","StatementHelp":{"#cdata":"Syntax: CALL routine(parameter-1<, ...parameter-n>);  \n      \nInvokes a SAS CALL routine."},"StatementOptions":null},{"StatementName":"DO","StatementHelp":{"#cdata":"Specifies a group of statements to be executed as a unit.\n      \nSyntax: \n(1) DO; \n...more SAS statements...  \nEND;  \n\n(2) DO index-variable=specification-1 <, ... specification-n>; \n... more SAS statements ...  \nEND;  \n\n(3) DO UNTIL (expression); \n...more SAS statements...  \nEND \n\n(4) DO WHILE (expression); \n...more SAS statements...  \nEND;"},"StatementOptions":{"StatementOption":[{"StatementOptionName":"UNTIL","StatementOptionHelp":{"#cdata":"Executes statements in a DO loop repetitively until a condition is true.\n          \nSyntax: \nDO UNTIL (expression); \n...more SAS statements...  \nEND"},"StatementOptionType":"S"},{"StatementOptionName":"WHILE","StatementOptionHelp":{"#cdata":"Executes statements in a DO-loop repetitively while a condition is true. \n          \nSyntax: \nDO WHILE (expression); \n...more SAS statements...  \nEND;"},"StatementOptionType":"S"},{"StatementOptionName":"OVER","StatementOptionType":"S"},{"StatementOptionName":"TO","StatementOptionHelp":{"#cdata":"Separates the start and stop integers or expressions that control the number of times the \nportion of the DATA step between the iterative DO and END statements is processed."},"StatementOptionType":"S"},{"StatementOptionName":"BY","StatementOptionHelp":{"#cdata":"Precedes an increment integer (other than 0) or an expression that generates an integer to be \nadded to the value of the index variable in each iteration of the DO loop."},"StatementOptionType":"S"}]}},{"StatementName":"END","StatementHelp":{"#cdata":"Syntax: END; \n      \nEnds a DO group or SELECT group processing."},"StatementOptions":null},{"StatementName":"GOTO","StatementHelp":{"#cdata":"Syntax: GOTO label;\n      \nJumps to a new statement."},"StatementOptions":null},{"StatementName":"IF","StatementHelp":{"#cdata":"Executes a SAS statement for observations that meet specific conditions. \n\nSyntax: \n(1) IF expression THEN statement; \n    <ELSE statement;> \n(2) IF condition;"},"StatementOptions":{"StatementOption":[{"StatementOptionName":"THEN","StatementOptionHelp":{"#cdata":"If the conditions that are specified in the IF clause are met, the IF-THEN statement executes a SAS \nstatement for observations that are read from a SAS data set, for records in an external file, or \nfor computed values."},"StatementOptionType":"S"},{"StatementOptionName":"DO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"WHEN","StatementOptionHelp":{"#cdata":"WHEN statement in an IF-THEN-WHEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"OUTPUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"GO TO|GOTO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct. \n          \nSyntax: ... GO TO label; | ... GOTO label;\n      \nJumps to a new statement."},"StatementOptionType":"S"},{"StatementOptionName":"PUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct."},"StatementOptionType":"S"},{"StatementOptionName":"STOP","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct. \n          \nStops execution of the current DATA step."},"StatementOptionType":"S"},{"StatementOptionName":"SET","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN construct.\n          \nSyntax: SET <SAS-data-set(s) <(data-set-options(s) )>>; \n      \nReads an observation from one or more SAS data sets."},"StatementOptionType":"S"},{"StatementOptionName":"NOT","StatementOptionType":"S"},{"StatementOptionName":"OR","StatementOptionType":"S"},{"StatementOptionName":"AND","StatementOptionType":"S"}],"#comment":{}}},{"StatementName":"ELSE","StatementHelp":{"#cdata":"If the condition in a IF-THEN statement is false and an ELSE statement is present, then the ELSE \naction is carried out."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"THEN","StatementOptionHelp":{"#cdata":"If the conditions that are specified in the IF clause are met, the IF-THEN statement executes a SAS \nstatement for observations that are read from a SAS data set, for records in an external file, or \nfor computed values."},"StatementOptionType":"S"},{"StatementOptionName":"IF","StatementOptionHelp":{"#cdata":"Executes a SAS statement for observations that meet specific conditions."},"StatementOptionType":"S"},{"StatementOptionName":"DO","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN-ELSE construct."},"StatementOptionType":"S"},{"StatementOptionName":"OUTPUT","StatementOptionHelp":{"#cdata":"Action statement in an IF-THEN-ELSE construct."},"StatementOptionType":"S"},{"StatementOptionName":"NOT","StatementOptionType":"S"},{"StatementOptionName":"OR","StatementOptionType":"S"},{"StatementOptionName":"AND","StatementOptionType":"S"}],"#comment":{}}},{"StatementName":"LINK","StatementHelp":{"#cdata":"Syntax: LINK statement-label; \n      \nDirects program execution immediately to the statement label that is specified and, if followed \nby a RETURN statement, returns execution to the statement that follows the LINK statement."},"StatementOptions":null},{"StatementName":"RETURN","StatementHelp":{"#cdata":"Syntax: RETURN; \n      \nStops executing statements at the current point in the DATA step and returns to a predetermined \npoint in the step."},"StatementOptions":null},{"StatementName":"SELECT","StatementHelp":{"#cdata":"Executes one of several statements or groups of statements.\n      \nSyntax: \nSELECT <(select-expression)>;  \n  WHEN-1 (when-expression-1 <..., when-expression-n>) statement;  \n    <... WHEN-n (when-expression-1 <..., when-expression-n>) statement;>  \n      <OTHERWISE statement;> \nEND;"},"StatementOptions":null},{"StatementName":"PUT","StatementHelp":{"#cdata":"Syntax: PUT print-item ...< @ > < @@ > ;\n\nThe PUT statement writes text data to the current output file."},"StatementOptions":{"StatementOption":{"StatementOptionName":"_PAGE_","StatementOptionHelp":{"#cdata":"Outputs any pending line data and moves to the top of the next page."},"StatementOptionType":"S"}}},{"StatementName":"ARRAY","StatementHelp":{"#cdata":"Syntax: ARRAY array-name { subscript } <$><length> \n  <array-elements> <(initial-value-list)>; \n  \nDefines the elements of an array."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"_ALL_","StatementOptionHelp":{"#cdata":"Specifies all variables."},"StatementOptionType":"S"},{"StatementOptionName":"_TEMPORARY_","StatementOptionHelp":{"#cdata":"Creates a list of temporary data elements."},"StatementOptionType":"S"},{"StatementOptionName":"_NUMERIC_","StatementOptionHelp":{"#cdata":"Specifies all numeric variables."},"StatementOptionType":"S"},{"StatementOptionName":"_CHARACTER_","StatementOptionHelp":{"#cdata":"Specifies all character variables."},"StatementOptionType":"S"}]}}],"#comment":{}}}}