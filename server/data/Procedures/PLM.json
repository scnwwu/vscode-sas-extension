{"Procedure":{"Name":"PLM","ProductGroup":"SAS/STAT","ProcedureHelp":{"#cdata":"Syntax: PROC PLM SOURCE=item-store-specification <options> ; \n    EFFECTPLOT <plot-type <(plot-definition-options)>> </ options> ; \n    ESTIMATE <'label'> estimate-specification <(divisor=n)>\n      <, ...<'label'> estimate-specification <(divisor=n)>> </ options> ; \n    FILTER expression ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect <'label'> values <divisor=>\n      <, ...<'label'> values <divisor=n>> </ options> ; \n    SCORE DATA=SAS-data-set <OUT=SAS-data-set>\n      <keyword<=name>>...<keyword<=name>> </ options> ; \n    SHOW options ; \n    SLICE model-effect </ options> ; \n    TEST <model-effects> </ options> ; \n    WHERE expression ; \n\n(New in SAS/STAT 9.22!)\n\nThe PLM procedure performs postfitting statistical analyses for the contents of a SAS item \nstore that was previously created with the STORE statement in some other SAS/STAT procedure. \nAn item store is a special SAS-defined binary file format used to store and restore information \nwith a hierarchical structure. \n\nThe statements available in the PLM procedure are designed to reveal the contents of the source \nitem store via the Output Delivery System (ODS) and to perform postfitting tasks such as the following: \n\n  o testing hypotheses \n  o computing confidence intervals \n  o producing prediction plots \n  o scoring a new data set"},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"ALPHA=","ProcedureOptionHelp":{"#cdata":"[Syntax: ALPHA=\u03b1] \n      \nSpecifies the nominal significance level for multiplicity corrections and for the \nconstruction of confidence intervals. The value of \u03b1 must be between 0 and 1. The \ndefault is the value specified in the source item store, or 0.05 if the item store \ndoes not provide a value. The confidence level based on \u03b1 is 1-\u03b1."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"DDFMETHOD=","ProcedureOptionHelp":{"#cdata":"Specifies the method for determining denominator degrees of freedom for tests and \nconfidence intervals. The default degree-of-freedom method is determined by the \ncontents of the item store. You can override the default to some extent with the \nDDFMETHOD= option."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"RESIDUAL|RES|ERROR","@Value2":"NONE","@Value3":"KENROG|KR|KENWARDROGER","@Value4":"SATTERTH|SAT|SATTERTHWAITE"},"ProcedureOptionToolTips":{"@ToolTip1":"Denominator degrees of freedom for tests and confidence intervals are based on residual errors.","@ToolTip2":"Infinite denominator degrees of freedom are assumed for tests and confidence intervals.  This essentially produces z tests and intervals instead of t tests and intervals and  chi-square tests instead of F tests.","@ToolTip3":"KENWARDROGER method for determining denominator degrees of freedom for tests and confidence intervals.","@ToolTip4":"SATTERTHWAITE method for determining denominator degrees of freedom for tests and confidence intervals."}},{"ProcedureOptionName":"ESTEPS=","ProcedureOptionHelp":{"#cdata":"[Syntax: ESTEPS=\u212e] \n      \nSpecifies the tolerance value used in determining the estimability of linear functions. \nThe default value is determined by the contents of the source item store; it is usually 1E-4."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"FORMAT=","ProcedureOptionHelp":{"#cdata":"Specifies how the PLM procedure handles user-defined formats, which are not permanent. \nWhen the item store is created, user-defined formats are stored. When the PLM procedure \nopens an item store, these formats are loaded by default. If the format already exists \nin your SAS session, this operation amounts to a reloading of the format (FORMAT=RELOAD) \nthat replaces the existing format."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"NOLOAD","@Value2":"RELOAD"},"ProcedureOptionToolTips":{"@ToolTip1":"Prevents the PLM procedure from reloading the format from the item store. As a consequence,  PLM statements might fail if a format was present at the item store creation and is not  available in your SAS session.","@ToolTip2":"Allows the PLM procedure to reload the format from the item store."}},{"ProcedureOptionName":"MAXLEN=","ProcedureOptionHelp":{"#cdata":"[Syntax: MAXLEN=n] \n      \nDetermines the maximum length of informational strings in the \"Store Information\" table. \nThis table displays, for example, lists of classification or BY variables and lists of \nmodel effects. The value of n determines the truncation length for these strings. The \nminimum and maximum values for n are 20 and 256, respectively. The default is n=100."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NOCLPRINT","ProcedureOptionHelp":{"#cdata":"[Syntax: NOCLPRINT<=number>] \n      \nSuppresses the display of the \"Class Level Information\" table if you do not specify number. \nIf you specify number, only levels with totals that are less than number are listed in the \ntable. The PLM procedure produces the \"Class Level Information\" table by default when the \nmodel contains effects that depend on classification variables."},"ProcedureOptionType":"S|V"},{"ProcedureOptionName":"NOINFO","ProcedureOptionHelp":{"#cdata":"Suppresses the display of the \"Store Information\" table."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOPRINT","ProcedureOptionHelp":{"#cdata":"Suppresses the generation of tabular and graphical output. When the NOPRINT option \nis in effect, ODS tables are also not produced."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"PERCENTILES=|PERCENTILE=","ProcedureOptionHelp":{"#cdata":"[Syntax: PERCENTILES=value-list] \n      \nSupplies a list of percentiles for the construction of highest posterior density (HPD) \nintervals when the PLM procedure performs a sampling-based analysis (for example, when \nprocessing an item store that contains posterior parameter estimates from a Bayesian \nanalysis). The default set of percentiles depends on the contents of the source item \nstore; it is typically PERCENTILES=25, 50, 75. The entries in value-list must be strictly \nbetween 0 and 100."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"PLOTS=","ProcedureOptionHelp":{"#cdata":"Syntax: PLOTS <(global-plot-option)> <=specific-plot-options>\n      \nRequests that the PLM procedure produce statistical graphics via the Output Delivery \nSystem, provided that the ODS GRAPHICS ON statement has been specified. \n\nThe following global-plot-option applies to all plots produced by PROC PLM. \n\nUNPACKPANEL | UNPACK \nbreaks a graphic that is otherwise paneled into individual component plots."},"ProcedureOptionType":"S|V","ProcedureOptionValues":{"@Value1":"ALL","@Value2":"NONE"},"ProcedureOptionToolTips":{"@ToolTip1":"Requests that all the appropriate plots be produced.","@ToolTip2":"Suppresses all plots."},"SubOptionsKeywords":"UNPACKPANEL|UNPACK"},{"ProcedureOptionName":"SEED=","ProcedureOptionHelp":{"#cdata":"[Syntax: SEED=number] \n      \nSpecifies the random number seed for analyses that depend on a random number stream. \nYou can also specify the random number seed through some PLM statements (for example, \nthrough the SEED= options in the ESTIMATE, LSMEANS, and LSMESTIMATE statements). However, \nnote that there is only a single random number stream per procedure run. Specifying the \nSEED= option in the PROC PLM statement initializes the stream for all subsequent statements. \nIf you do not specify a random number seed, the source item store might supply one for \nyou. If a seed is in effect when the PLM procedure opens the source store, the \"Store \nInformation\" table displays its value. \n\nIf the random number seed is less than or equal to zero, the seed is generated from \nreading the time of day from the computer clock and a log message indicates the chosen \nseed value."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SINGCHOL=","ProcedureOptionHelp":{"#cdata":"[Syntax: SINGCHOL=number] \n      \nTunes the singularity criterion in Cholesky decompositions. The default value depends \non the contents of the source item store. The default value is typically 1E4 times the \nmachine epsilon; this product is approximately 1E-12 on most computers."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SINGRES=","ProcedureOptionHelp":{"#cdata":"[Syntax: SINGRES=number] \n      \nSets the tolerance for which the residual variance or scale parameter is considered \nto be zero. The default value depends on the contents of the source item store. The \ndefault value is typically 1E4 times the machine epsilon; this product is approximately \n1E-12 on most computers."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SINGULAR=","ProcedureOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n      \nTunes the general singularity criterion applied by the PLM procedure in divisions \nand inversions. The default value used by the PLM procedure depends on the contents \nof the item store. The default value is typically 1E4 times the machine epsilon; this \nproduct is approximately 1E-12 on most computers."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SOURCE=|RESTORE=","ProcedureOptionHelp":{"#cdata":"[Syntax: SOURCE=item-store-specification] \n      \nSpecifies the source item store for processing. This option is required because, in contrast \nto SAS data sets, there is no default item store. An item-store-specification consists of a \none- or two-level name as with SAS data sets. As with data sets, the default library association \nof an item store is with the WORK library, and any stores created in this library are deleted \nwhen the SAS session concludes."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"STMTORDER=","ProcedureOptionHelp":{"#cdata":"Affects the order in which statements are grouped during processing. The default \nbehavior depends on the contents of the source item store and can be modified \nwith the STMTORDER= option."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"SYNTAX","@Value2":"GROUP"},"ProcedureOptionToolTips":{"@ToolTip1":"The statements are processed in the order in which they appear. Note that this  precludes the hierarchical grouping of ODS objects.","@ToolTip2":"The statements are processed in groups and in the following order: SHOW, TEST,  LSMEANS, SLICE, LSMESTIMATE, ESTIMATE, and SCORE."}},{"ProcedureOptionName":"WHEREFORMAT","ProcedureOptionHelp":{"#cdata":"Specifies that the constants (literals) specified in WHERE expressions for group selection \nare in terms of the formatted values of the BY variables. By default, WHERE expressions \nare specified in terms of the unformatted (raw) values of the BY variables, as in the SAS \nDATA step."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"ZETA=","ProcedureOptionHelp":{"#cdata":"[Syntax: ZETA=number] \n      \nTunes the sensitivity in forming Type III functions. Any element in the estimable \nfunction basis with an absolute value less than number is set to 0. The default \ndepends on the contents of the source item store; it usually is 1E-8."},"ProcedureOptionType":"V"}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"EFFECTPLOT","StatementHelp":{"#cdata":"Syntax: EFFECTPLOT <plot-type <(plot-definition-options)>> </ options> ; \n      \nThe EFFECTPLOT statement produces a display of the fitted model and provides options \nfor changing and enhancing the displays."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"BOX","StatementOptionHelp":{"#cdata":"Displays a box plot of continuous response data at each level of a CLASS effect, with \npredicted values superimposed and connected by a line. This is an alternative to the \nINTERACTION plot-type."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X="},{"StatementOptionName":"CONTOUR","StatementOptionHelp":{"#cdata":"Displays a contour plot of predicted values against two continuous covariates."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X=|Y="},{"StatementOptionName":"FIT","StatementOptionHelp":{"#cdata":"Displays a curve of predicted values versus a continuous variable."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|X="},{"StatementOptionName":"INTERACTION","StatementOptionHelp":{"#cdata":"Displays a curve of predicted values versus a continuous variable grouped by the levels \nof a CLASS effect."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|SLICEBY=|X="},{"StatementOptionName":"SLICEFIT","StatementOptionHelp":{"#cdata":"Displays a curve of predicted values versus a continuous variable grouped by the \nlevels of a CLASS effect."},"StatementOptionType":"RS","SubOptionsKeywords":"PLOTBY=|SLICEBY=|X="},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=value] \n          \nSpecifies the significance level, 0 \u2265 value \u2265 1, for producing 100(1-value/2)% \nprediction and confidence limits. By default, value=0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT <contopt> <classopt> <variable1=varopt <variable2=varopt...>> \n\nwhere contopt= MEAN | MIN | MAX | MIDRANGE \nclassopt= ALL | REF \nvaropt= contopts | number-list |  classopts | \u2019class-level\u2019...\u2019class-level\u2019] \n\nSpecifies values at which to fix continuous and class variables when they are not used \nin X=, Y=, SLICEBY=, or PLOTBY= effects. The contopt keyword fixes continuous variables \nat their mean, minimum, maximum, or midrange; the default is to use the mean. The classopt \nkeyword either fixes a CLASS variable at its reference (last) level or indicates that all \nlevels of the CLASS variable should be processed; the default is to use the reference level. \nThe varopt values enable you to specify contopt and classopt keywords, or to specify lists \nof numbers or class levels. You can specify a CLASS variable only once in the AT specification, \nbut you can specify a continuous variable multiple times."},"StatementOptionType":"S"},{"StatementOptionName":"ATLEN=","StatementOptionHelp":{"#cdata":"[Syntax: ATLEN=n] \n          \nSpecifies the maximum length (1 < n < 256) of the levels of the AT variables that are displayed \nin footnotes and headers. By default, up to 256 characters of the CLASS levels are displayed, \nand the continuous AT levels are displayed with a BEST format that has a width greater than \nor equal to 5, which distinguishes each level. Caution:If the levels of your AT variables are \nnot unique when the first n characters are displayed, then the levels are combined in the plots \nbut not in the underlying computations. Also, at most n characters for continuous AT variables \nare displayed."},"StatementOptionType":"V"},{"StatementOptionName":"ATORDER=","StatementOptionHelp":{"#cdata":"Uses the AT values for continuous variables in ascending or descending order as specified. \nBy default, values are used in the order of their first appearance in the AT option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ASCENDING","@Value2":"DESCENDING"},"StatementOptionToolTips":{"@ToolTip1":"Uses the AT values for continuous variables in ascending order","@ToolTip2":"Uses the AT values for continuous variables in descending order"}},{"StatementOptionName":"CLI","StatementOptionHelp":{"#cdata":"Displays normal (Wald) prediction limits. This option is available only for normal \ndistributions with identity links. If your model is from a Bayesian analysis, then \nsampling-based intervals are computed."},"StatementOptionType":"S"},{"StatementOptionName":"CLM","StatementOptionHelp":{"#cdata":"Displays confidence limits. These are computed as the normal (Wald) confidence limits \nfor the linear predictor, and if the ILINK option is specified, the limits are also \nback-transformed by the inverse link function. If your model is from a Bayesian analysis, \nthen sampling-based intervals are computed."},"StatementOptionType":"S"},{"StatementOptionName":"CLUSTER","StatementOptionHelp":{"#cdata":"Syntax: CLUSTER<=percent> \n          \nModifies the BOX and INTERACTION plot-types by displaying the levels of the SLICEBY= effect in \na side-by-side fashion. You can specify percent as a percentage of half the distance between X \nlevels. The percent value must be between 0.1 and 1; the default percent depends on the number \nof X levels, the number of SLICEBY levels, and the number of PLOTBY levels for INTERACTION \nplot-types. Default clustering can be removed by specifying the NOCLUSTER option."},"StatementOptionType":"S|V"},{"StatementOptionName":"CONNECT","StatementOptionHelp":{"#cdata":"Modifies the BOX and INTERACTION plot-types by connecting the predicted values with a line. \nDefault connecting lines can be removed by specifying the NOCONNECT option."},"StatementOptionType":"S"},{"StatementOptionName":"EXTEND=","StatementOptionHelp":{"#cdata":"Extends continuous covariate axes by value x \u00bdrange in both directions, where range \nis the range of the X axis."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"<value>"},"StatementOptionToolTips":{"@ToolTip1":"Displays curves to the range of the data within the appropriate SLICEBY=, PLOTBY=, and AT level.","@ToolTip2":"Replace <value> with an actual value."}},{"StatementOptionName":"GRIDSIZE=","StatementOptionHelp":{"#cdata":"[Syntax: GRIDSIZE=n] \n          \nSpecifies the resolution of curves by computing the predicted values at n equally spaced \nx-values and specifies the resolution of surfaces by computing the predicted values on an \nnxn grid of points. Default values are n=200 for curves and bands, n=50 for surfaces, and \nn=2 for lines. If results of a Bayesian or bootstrap analysis are being displayed, then \nthe defaults are n=500000/B, where B is the number of samples, the upper limit is equal \nto the usual defaults, and the lower limit equal to 20."},"StatementOptionType":"V"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Displays the fit on the scale of the inverse link function. In particular, the results \nare displayed on the probability scale for logistic regression. By default, a procedure \ndisplays the fit on either the link or inverse link scale."},"StatementOptionType":"S"},{"StatementOptionName":"INDIVIDUAL","StatementOptionHelp":{"#cdata":"Displays individual probabilities for polytomous response models with cumulative links \non the scale of the inverse link function. This option is not available when the LINK \noption is specified, and confidence limits are not available with this option."},"StatementOptionType":"S"},{"StatementOptionName":"LIMITS","StatementOptionHelp":{"#cdata":"Invokes the CLI and CLM options."},"StatementOptionType":"S"},{"StatementOptionName":"LINK","StatementOptionHelp":{"#cdata":"Displays the fit on the scale of the link function; that is, the linear predictor. \nNote that probabilities or observed proportions near 0 and 1 are transformed to . \nBy default, a procedure displays the fit on either the link or inverse link scale."},"StatementOptionType":"S"},{"StatementOptionName":"MOFF","StatementOptionHelp":{"#cdata":"Moves the offset for a Poisson regression model to the response side of the equation. \nIf the ILINK option is also in effect, then the rate is displayed on the Y axis, while \nthe LINK option displays the log of the rate on the Y axis. Without this option, the \npredicted values are computed and displayed only for the observations."},"StatementOptionType":"S"},{"StatementOptionName":"NCOLS=","StatementOptionHelp":{"#cdata":"[Syntax: NCOLS=n] \n          \nSpecifies the maximum number of columns in a paneled plot. This option is not available \nwith the BOX plot-type. \n\nThe default choice of NROWS= and NCOLS= is based on the number of PLOTBY= and AT levels. \nIf there is only one plot being displayed in a panel, then NROWS=1 and NCOLS=1 and the \nplots are produced as if you specified only the UNPACK option. If only two plots are \ndisplayed in a panel, then NROWS=1 and NCOLS=2. For all other cases, a 2x2, 2x3, or 3x3 \npanel is chosen based on how much of the last panel is used, with ties going to the larger \npanels. For example, if 14 plots are being created, then this requires either four 2x2 \npanels with 50% of the last panel filled, three 2x3 panels with 33% of the last panel \nfilled, or two 3x3 panels with 55% of the last panel filled; in this case, the 3x3 panels \nare chosen. \n\nIf you specify both of the NROWS= and NCOLS= options, then those are the values used. However, \nif you only specify one of the options but have fewer plots, then the panel size is reduced; \nfor example, if you specify NROWS=6 but only have four plots, then a plot with four rows and \none column is produced."},"StatementOptionType":"V"},{"StatementOptionName":"NOCLI","StatementOptionHelp":{"#cdata":"Suppresses the prediction limits."},"StatementOptionType":"S"},{"StatementOptionName":"NOCLM","StatementOptionHelp":{"#cdata":"Suppresses the confidence limits."},"StatementOptionType":"S"},{"StatementOptionName":"NOLIMITS","StatementOptionHelp":{"#cdata":"Invokes the NOCLI and NOCLM options."},"StatementOptionType":"S"},{"StatementOptionName":"NOOBS","StatementOptionHelp":{"#cdata":"Suppresses the display of observations and overrides the specification of the OBS= option."},"StatementOptionType":"S"},{"StatementOptionName":"NROWS=","StatementOptionHelp":{"#cdata":"[Syntax: NROWS=n] \n          \nSpecifies the maximum number of rows in a paneled plot. This option is not available \nwith the BOX plot-type. See the NCOLS= option for more details."},"StatementOptionType":"V"},{"StatementOptionName":"OBS","StatementOptionHelp":{"#cdata":"[Syntax: OBS<(options)>] \n          \nDisplays observations on the effect plots. An input data set is required; hence the OBS option \nis not available with PROC PLM. The OBS option is overridden by the NOOBS option. When the ILINK \noption is specified with binary response variables, then either the observed proportions or a coded \nvalue of the response is displayed. For polytomous response variables, the observed values are overlaid \nonto the fitted curves unless the LOCATION= option is specified. Whether observations are displayed by \ndefault or not depends upon the procedure. If the PLOTBY= option is specified, then the observations \ndisplayed on each plot are from the corresponding PLOTBY= level for classification effects; for \ncontinuous effects, all observations are displayed on every plot. \n\nThe following options are available: \n\n  BYAT -- subsets the observations by AT level and by the PLOTBY= level. \n\n  CDISPLAY=NONE | OUTLINE | GRADIENT | OUTLINEGRADIENT \n  controls the display of observations on contour plots. \n\n  CGRADIENT=RESIDUAL | DEPENDENT \n  specifies what the gradient-shading of the observed values on the CONTOUR plot-type represents. \n\n  DEPTH=depth (you can specify 1 \u2264 depth \u2264 100. By default, DEPTH=1)\n  specifies the number of overlapping observations that can be distinguished by adjusting their transparency.\n\n  DISTANCE \n  displays observations on FIT plot-types with a color-gradient that indicates how far the \n  observation is from the AT and PLOTBY= level. \n\n  FITATCLASS --  computes fitted values only for class levels that are observed in the data set.  \n\n  FRINGE -- displays observations in a fringe (rug) plot at the bottom of the plot.  \n\n  JITTER<(FACTOR=factor SEED=seed X=x-jitter Y=y-jitter)> --  shifts (jitters) the observations. \n  \n  LABEL<=OBS> --  labels markers with their observation number. \n\n  LOCATION= BOTTOM | CURVE | FIRST | MAX | MIDDLE | MIN | SPREAD | TOP<=factor>\n  specifies where the observed values for polytomous response models are displayed when the SLICEBY= variable is the response."},"StatementOptionType":"S","SubOptionsKeywords":"BYAT|CDISPLAY=|CGRADIENT=|DEPTH=|DISTANCE|FITATCLASS|FRINGE|JITTER|FACTOR=|SEED=|X=|Y=|LABEL|LABEL=|LOCATION="},{"StatementOptionName":"PLOTBY=","StatementOptionHelp":{"#cdata":"[Syntax: PLOTBY<(panel-type)>=effect<=numeric-list>] \n          \nSpecifies a variable or CLASS effect at whose levels the predicted values are computed \nand the plots are displayed. You can specify the response variable as the effect for \npolytomous response models. The panel-type argument specifies the method in which the \nplots are grouped for the display. The following panel-types are available. \n\n  COLUMNS \n  specifies that the columns within each panel correspond to different levels of the PLOTBY= \n  effect and hence the rows correspond to different AT levels. \n\n  PACK \n  specifies that plots be displayed in the panels as they are produced with no control over \n  the placement of the PLOTBY= and AT levels. \n\n  PANELS | LEVELS \n  specifies that each level of the PLOTBY= effect begin a new panel of plots and the AT \n  levels define the plots within the panels. \n\n  ROWS \n  specifies that the rows within each panel correspond to different levels of the PLOTBY= \n  effect and hence the columns correspond to different AT levels. \n\nThis option is ignored with the BOX plot-type; box plots are always displayed in an unpacked \nfashion, grouped by the PLOTBY= and AT levels. If you specify a continuous variable as the \neffect, then you can either specify a numeric-list of values at which to display that variable \nor, by default, five equally spaced values from the minimum variable value to its maximum are \ndisplayed."},"StatementOptionType":"S|V","SubOptionsKeywords":"COLUMNS|PACK|PANELS|LEVELS|ROWS"},{"StatementOptionName":"PLOTBYLEN=","StatementOptionHelp":{"#cdata":"[Syntax: PLOTBYLEN=n] \n          \nSpecifies the maximum length (1 \u2264 n \u2264 256) of the levels of the PLOTBY= variables, which are displayed \nin footnotes and headers. By default, up to 256 characters of the CLASS levels are displayed. \n\nCaution:If the levels of your PLOTBY= variables are not unique when the first n characters \nare displayed, then the levels are combined in the plots but not in the underlying computations."},"StatementOptionType":"V"},{"StatementOptionName":"POLYBAR","StatementOptionHelp":{"#cdata":"Displays polytomous response data as a stacked histogram with bar heights defined \nby the individual predicted value. Your response variable must be the SLICEBY= \nvariable, and the INDIVIDUAL and ILINK options must be in effect; otherwise, the \noption is ignored. Confidence limits are ignored."},"StatementOptionType":"S"},{"StatementOptionName":"PREDLABEL=","StatementOptionHelp":{"#cdata":"[Syntax: PREDLABEL=label] \n          \nSpecifies a label to be displayed on the Y axis. The default Y axis label is determined \nby your model. For the CONTOUR plot-type, this option changes the title to \"label for Y.\""},"StatementOptionType":"V"},{"StatementOptionName":"SHOWCLEGEND","StatementOptionHelp":{"#cdata":"Displays the gradient-legend for the CONTOUR plot-type. This option has no effect \nwhen the OBS(CGRADIENT=RESIDUAL) option is also specified."},"StatementOptionType":"S"},{"StatementOptionName":"SLICEBY=","StatementOptionHelp":{"#cdata":"[Syntax: SLICEBY=NONE | effect<=numeric-list>] \n          \nDisplays the fitted values at the different levels of the specified variable or CLASS effect."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"NONE","@Value2":"effect<=numeric-list>"},"StatementOptionToolTips":{"@ToolTip1":"Preventing the INTERACTION plot-type from slicing by a second class covariate. Note  that the SLICEBY=NONE option is not available for the SLICEFIT plot-type, since that  is the same as the FIT plot-type.","@ToolTip2":"You can specify the response variable as the effect for polytomous response models. Use   this option to modify SLICEFIT and INTERACTION plot-types. If you specify a continuous  variable as the effect, then you can either specify a numeric-list of values at which  to display that variable or, by default, five equally spaced values from the minimum  variable value to its maximum are displayed."}},{"StatementOptionName":"SMOOTH","StatementOptionHelp":{"#cdata":"Overlays a loess smooth on the FIT plot-type for models that have only one continuous \npredictor. This option is not available for binary or polytomous response models."},"StatementOptionType":"S"},{"StatementOptionName":"UNPACK","StatementOptionHelp":{"#cdata":"Suppresses paneling. By default, multiple plots can appear in some output panels. \nSpecify UNPACK to display each plot separately.]"},"StatementOptionType":"S"},{"StatementOptionName":"X=","StatementOptionHelp":{"#cdata":"[Syntax: X=effect] \n          \nSpecifies values to display on the X axis. For BOX and INTERACTION plot-types, effect \ncan be a CLASS effect in the MODEL statement. For FIT, SLICEFIT, and CONTOUR plot-types, \neffect can be any continuous variable in the model."},"StatementOptionType":"V"},{"StatementOptionName":"Y=","StatementOptionHelp":{"#cdata":"[Syntax: Y=args] \n          \nSpecifies values to display on the Y axis for the CONTOUR plot-type. The Y= argument \ncan be any continuous variable in the model."},"StatementOptionType":"V"},{"StatementOptionName":"YRANGE=","StatementOptionHelp":{"#cdata":"Displays the predicted values on the Y axis in the range [min,max]. \n          \nBy default, when the Y axis displays predicted probabilities, the entire Y axis, [0,1], \nis displayed. This option is useful if your predicted probabilities are all contained \nin some subset of this range. This option is not available with the CONTOUR plot-type. "},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CLIP","@Value2":"<(<min><,max>)>"},"StatementOptionToolTips":{"@ToolTip1":"Has the same effect as specifying the minimum predicted value as min and the maximum predicted value as max.","@ToolTip2":"Replace min and max with actual values."}}],"#comment":{}}},{"StatementName":"ESTIMATE","StatementHelp":{"#cdata":"Syntax: ESTIMATE <'label'> estimate-specification <(divisor=n)>\n  <, ...<'label'> estimate-specification <(divisor=n)> >\n  < / options> ; \n  \nThe ESTIMATE statement provides a mechanism for obtaining custom hypothesis tests. \nEstimates are formed as linear estimable functions of the form L\u03b2. You can perform \nhypothesis tests for the estimable functions, construct confidence limits, and obtain \nspecific nonlinear transformations. \n\nThe basic element of the ESTIMATE statement is the estimate-specification, which consists \nof model effects and their coefficients. A estimate-specification takes the general form \n\n  effect name <effect values ...> \n  \nThe following variables can appear in the ESTIMATE statement: \n\n  label \n  is an optional label that identifies the particular row of the estimate in the output. \n\n  effect \n  identifies an effect that appears in the MODEL statement. The keyword INTERCEPT can be \n  used as an effect when an intercept is fitted in the model. You do not need to include \n  all effects that are in the MODEL statement. \n\n  values \n  are constants that are elements of the L matrix and are associated with the fixed and random effects."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \n  limits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator    degrees of freedom for the final effect listed in the ESTIMATE statement from the 'Type    III' table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees    of freedom are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the estimates."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE<(simoptions)>","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum    or maximum absolute value of a multivariate t random vector.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."}},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed with confidence level 1-number.  \nThe value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F or chi-square tests with the JOINT option. \n\nThe category-options are used to indicate how response variable levels are treated in \nconstructing the estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row ESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row ESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed. If the procedure shows the degrees \nof freedom in the \"Estimates\" table as infinite, then the confidence limits are z intervals. \nThe confidence level is 0.95 by default, and you can change the confidence level with the \nALPHA= option. The confidence intervals are adjusted for multiplicity when you specify the \nADJUST= option. However, if a step-down p-value adjustment is requested with the STEPDOWN \noption, only the p-values are adjusted for multiplicity."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. This option \nis not supported by the procedures that perform chi-square-based inference (LOGISTIC, \nPHREG, and SUVEYLOGISTIC)."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0. \n\nIf the number of elements in value-list exceeds the number of rows of the estimate, the \nextra values are ignored. If the number of elements in value-list is less than the number \nof rows of the estimate, the last value in value-list is copied forward. \n\nIf you specify a row-specific divisor as part of the specification of the estimate row, \nthis value multiplies the corresponding divisor that is implied by the value-list. For \nexample, the following statement divides the coefficients in the first row by 8, and the \ncoefficients in the third and fourth row by 3: \n\n  estimate 'One vs. two'   A 2 -2  (divisor=2),\n           'One vs. three' A 1  0 -1         ,\n           'One vs. four'  A 3  0  0 -3      ,\n           'One vs. five'  A 1  0  0  0  -1  / divisor=4,.,3;\n\nCoefficients in the second row are not altered."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the estimate. When you model data with the logit, cumulative \nlogit, or generalized logit link functions, and the estimate represents a log odds ratio \nor log cumulative odds ratio, the EXP option produces an odds ratio. In proportional hazards \nmodel, this option produces estimates of hazard ratios. If you specify the CL or ALPHA= option, \nthe (adjusted) confidence bounds are also exponentiated. \n\nThe EXP option is supported only by PROC PHREG, PROC SURVEYPHREG, the procedures that support \ngeneralized linear modeling (LOGISTIC and SURVEYLOGISTIC), and by PROC PLM when it is used to \nperform statistical analyses on item stores created by these procedures."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the mean \n(the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \nThe JOINT option in the ESTIMATE statement essentially replaces the CONTRAST statement. \n\nWhen the LOWERTAILED or the UPPERTAILED options are in effect, or if the BOUNDS option \ndescribed below is in effect, the JOINT option produces the chi-bar-square statistic \naccording to Silvapulle and Sen (2004). This statistic uses a simulation-based approach \nto compute p-values in situations where the alternative hypotheses of the estimable \nfunctions are not simple two-sided hypotheses. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004).   \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option. "},"StatementOptionType":"S"},{"StatementOptionName":"NOFILL","StatementOptionHelp":{"#cdata":"Suppresses the automatic fill-in of coefficients of higher-order effects."},"StatementOptionType":"V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Produces all possible plots with their default settings.","@ToolTip2":"Syntax: BOXPLOT<(boxplot-options)>                                      Produces box plots of the distribution of the estimable function across the posterior  sample. A separate box is generated for each estimable function, and all boxes appear  on a single graph by default. You can affect the appearance of the box plot graph with  the following options:     ORIENTATION=VERTICAL|HORIZONTAL    ORIENT=VERT|HORIZ    specifies the orientation of the boxes. The default is vertical orientation of the box plots.     NPANELPOS=number    specifies how to break the series of box plots across multiple panels. If the NPANELPOS option    is not specified, or if number equals zero, then all box plots are displayed in a single graph;    this is the default.","@ToolTip3":"Syntax: DISTPLOT<(distplot-options)>                                      Generates panels of histograms with a kernel density overlaid. A separate plot in each  panel contains the results for each estimable function. You can specify the following  distplot-options in parentheses:     BOX|NOBOX    controls the display of a horizontal box plot of the estimable function\u2019s distribution    across the posterior sample below the graph. The BOX option is enabled by default.     HIST|NOHIST    controls the display of the histogram of the estimable function\u2019s distribution across the    posterior sample. The HIST option is enabled by default.     NORMAL|NONORMAL    controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.     KERNEL|NOKERNEL    controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.     NROWS=number    specifies the highest number of rows in a panel. The default is 3.     NCOLS=number    specifies the highest number of columns in a panel. The default is 3.     UNPACK    unpacks the panel into separate graphics.","@ToolTip4":"Does not produce any plots."},"SubOptionsKeywords":"BOX|NOBOX|HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the \nESTIMATE statement (for example, chi-bar-square statistics and simulated p-values). \nnumber specifies an integer that is used to start the pseudo-random number generator \nfor the simulation. If you do not specify a seed, or if you specify a value less than \nor equal to zero, the seed is generated from reading the time of day from the computer \nclock. There could be multiple ESTIMATE statements with SEED= specifications and there \ncould be other statements that can supply a random number seed. Since the procedure has \nonly one random number stream, the initial seed is shown in the SAS log."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant. \n\nYou can specify the following step-down-options in parentheses after the STEPDOWN option: \n\n  MAXTIME=n \n  specifies the time (in seconds) to be spent computing the maximal logically consistent \n  sequential subsets of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60. \n\n  ORDER=PVALUE | ORDER=ROWS   \n  specifies the order in which the step-down tests to be performed. ORDER=PVALUE is the default, \n  with estimates being declared significant only if all estimates with smaller (unadjusted) \n  p-values are significant. If you specify ORDER=ROWS, then significances are evaluated in the \n  order in which they are specified in the syntax. \n\n  REPORT \n  specifies that a report on the step-down adjustment be displayed, including a listing of the \n  sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n  TYPE=LOGICAL<(n)> | TYPE=FREE \n  specifies how step-down adjustment are made. If you specify TYPE=LOGICAL, the step-down \n  adjustments are computed by using maximal logically consistent sequential subsets of equality \n  hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, sequential subsets are \n  computed ignoring logical constraints. The TYPE=FREE results are more conservative than those \n  for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. For example, \n  it is not feasible to take logical constraints between all pairwise comparisons of more than about \n  10 groups. For this reason, TYPE=FREE is the default."},"StatementOptionType":"S"},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nESTIMATE statement. The rules for specifying the value-list are very similar to those for \nspecifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"FILTER","StatementHelp":{"#cdata":"Syntax: FILTER expression ; \n      \nThe FILTER statement enables you to filter the results of the PLM procedure, specifically \nthe contents of ODS tables and the output data sets. There can be at most one FILTER statement \nper PROC PLM run, and the filter is applied to all BY groups and to all queries generated through \nWHERE expressions. \n\nA filter expression follows the same pattern as a where-expression in the WHERE statement. \nThe expressions consist of operands and operators."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"Prob","StatementOptionHelp":{"#cdata":"Regular (unadjusted) p-values from t, F, or chi-square tests"},"StatementOptionType":"S"},{"StatementOptionName":"ProbChi","StatementOptionHelp":{"#cdata":"Regular (unadjusted) p-values from chi-square tests"},"StatementOptionType":"S"},{"StatementOptionName":"ProbF","StatementOptionHelp":{"#cdata":"Regular (unadjusted) p-values from F tests"},"StatementOptionType":"S"},{"StatementOptionName":"ProbT","StatementOptionHelp":{"#cdata":"Regular (unadjusted) p-values from t tests"},"StatementOptionType":"S"},{"StatementOptionName":"AdjP","StatementOptionHelp":{"#cdata":"Adjusted p-values]"},"StatementOptionType":"S"},{"StatementOptionName":"Estimate","StatementOptionHelp":{"#cdata":"Results displayed in \"Estimates\" column of ODS tables"},"StatementOptionType":"S"},{"StatementOptionName":"Pred","StatementOptionHelp":{"#cdata":"Predicted values in SCORE output data sets"},"StatementOptionType":"S"},{"StatementOptionName":"Resid","StatementOptionHelp":{"#cdata":"Residuals in SCORE output data sets."},"StatementOptionType":"S"},{"StatementOptionName":"Std","StatementOptionHelp":{"#cdata":"Standard errors in ODS tables and in SCORE results"},"StatementOptionType":"S"},{"StatementOptionName":"Mu","StatementOptionHelp":{"#cdata":"Results displayed in the \"Mean\" column of ODS tables (this column is typically \nproduced by the ILINK option)"},"StatementOptionType":"S"},{"StatementOptionName":"tValue","StatementOptionHelp":{"#cdata":"The value of the usual t statistic"},"StatementOptionType":"S"},{"StatementOptionName":"FValue","StatementOptionHelp":{"#cdata":"[Syntax: The value of the usual F statistic]"},"StatementOptionType":"S"},{"StatementOptionName":"Chisq","StatementOptionHelp":{"#cdata":"The value of the chi-square statistic"},"StatementOptionType":"S"},{"StatementOptionName":"testStat","StatementOptionHelp":{"#cdata":"The value of the test statistic (a generic keyword for the 'tValue', 'FValue', and 'Chisq' tokens)"},"StatementOptionType":"S"},{"StatementOptionName":"Lower","StatementOptionHelp":{"#cdata":"The lower confidence limit displayed in ODS tables"},"StatementOptionType":"S"},{"StatementOptionName":"Upper","StatementOptionHelp":{"#cdata":"The upper confidence limit displayed in ODS tables"},"StatementOptionType":"S"},{"StatementOptionName":"AdjLower","StatementOptionHelp":{"#cdata":"The adjusted lower confidence limit displayed in ODS tables"},"StatementOptionType":"S"},{"StatementOptionName":"AdjUpper","StatementOptionHelp":{"#cdata":"The adjusted upper confidence limit displayed in ODS tables"},"StatementOptionType":"S"},{"StatementOptionName":"LowerMu","StatementOptionHelp":{"#cdata":"The lower confidence limit for the mean displayed in ODS tables"},"StatementOptionType":"S"},{"StatementOptionName":"UpperMu","StatementOptionHelp":{"#cdata":"The upper confidence limit for the mean displayed in ODS tables"},"StatementOptionType":"S"},{"StatementOptionName":"AdjLowerMu","StatementOptionHelp":{"#cdata":"The adjusted lower confidence limit for the mean displayed in ODS tables"},"StatementOptionType":"S"},{"StatementOptionName":"AdjUpperMu","StatementOptionHelp":{"#cdata":"The adjusted upper confidence limit for the mean displayed in ODS tables"},"StatementOptionType":"S"}]}},{"StatementName":"LSMEANS","StatementHelp":{"#cdata":"Syntax: LSMEANS <model-effects> </ options> ; \n      \nThe LSMEANS statement computes and compares least squares means (LS-means) of fixed \neffects. LS-means are predicted population margins\u2014that is, they estimate the marginal \nmeans over a balanced population. In a sense, LS-means are to unbalanced designs as \nclass and subclass arithmetic means are to balanced designs."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the LSMEANS effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the LSMEANS statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the LSMEANS \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="}]}},{"StatementName":"LSMESTIMATE","StatementHelp":{"#cdata":"Syntax: LSMESTIMATE model-effect <'label'> values <divisor=> \n  <, ...<'label'> values <divisor=>>\n  < / options> ; \n  \nThe LSMESTIMATE statement provides a mechanism for obtaining custom hypothesis \ntests among least squares means."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the \nLS-mean estimates. The adjusted quantities are produced in addition to the unadjusted \np-values and confidence limits. Adjusted confidence limits are produced if the CL or \nALPHA= option is in effect."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means with \nconfidence level 1-number. The value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates used in computing LS-means. By default, all \ncovariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that the procedure compute separate margins for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F tests with the JOINT option. \n\nThe category-options indicate how response variable levels are treated in constructing \nthe estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row LSESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row LSESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. \nThe confidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L coefficients of the estimable function be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ELSM","StatementOptionHelp":{"#cdata":"Requests that the K matrix coefficients be displayed. These are the coefficients \nthat apply to the LS-means. This option is useful to ensure that you assigned the \ncoefficients correctly to the LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the least squares means estimate. When you model data \nwith the logit link function and the estimate represents a log odds ratio, the \nEXP option produces an odds ratio. If you specify the CL or ALPHA= option, the \n(adjusted) confidence limits for the estimate are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the \nmean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004). \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to \nthose found in the OM-data-set. This adjustment is reasonable when you want your \ninferences to apply to a population that is not necessarily balanced but has the \nmargins observed in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip3":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip4":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|HIST|NOHIST|\n            NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the ESTIMATE statement."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant.\n\nYou can specify the following step-down-options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential subsets \n    of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60.\n\n    ORDER=PVALUE \n    ORDER=ROWS \n    specifies the order in which the step-down tests are performed. ORDER=PVALUE is the default, with LS-mean\n    estimates being declared significant only if all LS-mean estimates with smaller (unadjusted) p-values are\n    significant. If you specify ORDER=ROWS, then significances are evaluated in the order in which they are specified. \n\n    REPORT \n    specifies that a report on the step-down adjustment be displayed, including a listing of the sequential \n    subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically consistent \n    sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, \n    sequential subsets are computed ignoring logical constraints. The TYPE=FREE results are more conservative \n    than those for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. Default: TYPE=FREE."},"StatementOptionType":"S"},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nLSMESTIMATE statement. The rules for specifying the value-list are very similar to those  \nfor specifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"SCORE","StatementHelp":{"#cdata":"Syntax: SCORE DATA=SAS-data-set <OUT=SAS-data-set>\n  <keyword<=name>>...\n  <keyword<=name>> </ options> ; \n  \nThe SCORE statement applies the contents of the source item store to compute predicted \nvalues and other observation-wise statistics for a SAS data set."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DATA=","StatementOptionHelp":{"#cdata":"[Syntax: DATA=SAS-data-set] \n          \nSpecifies the input data set for scoring. This option is required, and the data set \nis examined for congruity with the previously fitted (and stored) model."},"StatementOptionType":"RV|DV"},{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nSpecifies the name of the output data set. If you do not specify an output data set \nwith the OUT= option, the PLM procedure uses the DATAn convention to name the output \ndata set."},"StatementOptionType":"RV|DV"},{"StatementOptionName":"PREDICTED=","StatementOptionHelp":{"#cdata":"[Keyword for output statistics]           \n          \nLinear predictor"},"StatementOptionType":"RV"},{"StatementOptionName":"STDERR=","StatementOptionHelp":{"#cdata":"[Keyword for output statistics] \n          \nStandard deviation of linear predictor"},"StatementOptionType":"RV"},{"StatementOptionName":"RESIDUAL=","StatementOptionHelp":{"#cdata":"[Keyword for output statistics] \n          \nResidual"},"StatementOptionType":"RV"},{"StatementOptionName":"LCLM=","StatementOptionHelp":{"#cdata":"[Keyword for output statistics] \n          \nLower confidence limit for the linear predictor"},"StatementOptionType":"RV"},{"StatementOptionName":"UCLM=","StatementOptionHelp":{"#cdata":"[Keyword for output statistics] \n          \nUpper confidence limit for the linear predictor"},"StatementOptionType":"RV"},{"StatementOptionName":"LCL=","StatementOptionHelp":{"#cdata":"[Keyword for output statistics] \n          \nLower prediction limit for the linear predictor"},"StatementOptionType":"RV"},{"StatementOptionName":"UCL=","StatementOptionHelp":{"#cdata":"[Keyword for output statistics] \n          \nUpper prediction limit for the linear predictor"},"StatementOptionType":"RV"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nDetermines the coverage probability for two-sided confidence and prediction intervals. \nThe coverage probability is computed as 1 - number. The value of number must be between \n0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom to use in the construction of prediction \nand confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that predicted values be inversely linked to produce predictions on the data \nscale. By default, predictions are produced on the linear scale where covariate effects \nare additive."},"StatementOptionType":"S"},{"StatementOptionName":"NOUNIQUE","StatementOptionHelp":{"#cdata":"Requests that names not be made unique in the case of naming conflicts. By default, \nthe PLM procedure avoids naming conflicts by assigning a unique name to each output \nvariable. If you specify the NOUNIQUE option, variables with conflicting names are not \nrenamed. In that case, the first variable added to the output data set takes precedence."},"StatementOptionType":"S"},{"StatementOptionName":"NOVAR","StatementOptionHelp":{"#cdata":"Requests that variables from the input data set not be added to the output data set."},"StatementOptionType":"S"},{"StatementOptionName":"OBSCAT","StatementOptionHelp":{"#cdata":"Requests that statistics in models for multinomial data be written to the output data set \nonly for the response level that corresponds to the observed level of the observation."},"StatementOptionType":"S"},{"StatementOptionName":"SAMPLE","StatementOptionHelp":{"#cdata":"Requests that the sample of parameter estimates in the item store be used to form \nscoring statistics. This option is useful when the item store contains the results \nof a Bayesian analysis and a posterior sample of parameter estimates."},"StatementOptionType":"S"}]}},{"StatementName":"SHOW","StatementHelp":{"#cdata":"Syntax: SHOW options ; \n\nThe SHOW statement uses the Output Delivery System to display contents of the item store. \nThis statement is useful for verifying that the contents of the item store apply to the \nanalysis and for generating ODS tables."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ALL|_ALL","StatementOptionHelp":{"#cdata":"Displays all applicable contents."},"StatementOptionType":"S"},{"StatementOptionName":"BYVAR|BY","StatementOptionHelp":{"#cdata":"Displays information about the BY variables in the source item store. If a BY statement \nwas present when the item store was created, the PLM procedure performs the analysis \nseparately for each BY group."},"StatementOptionType":"S"},{"StatementOptionName":"CLASSLEVELS|CLASS","StatementOptionHelp":{"#cdata":"Displays the \"Class Level Information\" table. This table is produced by the PLM procedure \nby default if the model contains effects that depend on classification variables."},"StatementOptionType":"S"},{"StatementOptionName":"CORRELATION|CORR|CORRB","StatementOptionHelp":{"#cdata":"Produces the correlation matrix of the parameter estimates. If the source item store \ncontains a posterior sample of parameter estimates, the computed matrix is the \ncorrelation matrix of the sample covariance matrix."},"StatementOptionType":"S"},{"StatementOptionName":"COVARIANCE|COV|COVB","StatementOptionHelp":{"#cdata":"Produces the covariance matrix of the parameter estimates. If the source item store \ncontains a posterior sample of parameter estimates, the PLM procedure computes the \nempirical sample covariance matrix from the posterior estimates. You can convert \nthis matrix into a sample correlation matrix with the CORRELATION option in the SHOW \nstatement."},"StatementOptionType":"S"},{"StatementOptionName":"EFFECTS","StatementOptionHelp":{"#cdata":"Displays information about the constructed effects in the model. Constructed effects \nare those that were created with the EFFECT statement in the procedure run that \ngenerated the source item store."},"StatementOptionType":"S"},{"StatementOptionName":"FITSTATS|FIT","StatementOptionHelp":{"#cdata":"Displays the fit statistics from the item store."},"StatementOptionType":"S"},{"StatementOptionName":"HESSIAN|HESS","StatementOptionHelp":{"#cdata":"Displays the Hessian matrix."},"StatementOptionType":"S"},{"StatementOptionName":"HERMITE|HERM","StatementOptionHelp":{"#cdata":"Generates the Hermite matrix H=(X'X)-(X'X). The PLM procedure chooses a reflexive, \ng2-inverse for the generalized inverse of the crossproduct matrix X'X."},"StatementOptionType":"S"},{"StatementOptionName":"PARAMETERS=|PARMS=","StatementOptionHelp":{"#cdata":"[Syntax: PARAMETERS<=n>] \n          \nDisplays the parameter estimates. The structure of the display depends on whether \na posterior sample of parameter estimates is available in the source item store. \nIf such a sample is present, up to the first 20 parameter vectors are shown in wide \nformat. You can modify this number with the n argument. "},"StatementOptionType":"S|V"},{"StatementOptionName":"PROGRAM|PROG","StatementOptionHelp":{"#cdata":"[Syntax: PROGRAM<(WIDTH=n)>] \n          \nDisplays the SAS program that generated the item store, provided that this was stored \nat store generation time. The program does not include comments, titles, or some other \nglobal statements. The optional width parameter n determines the display width of the \nsource code."},"StatementOptionType":"S","SubOptionsKeywords":"WIDTH="},{"StatementOptionName":"XPX|CROSSPRODUCT","StatementOptionHelp":{"#cdata":"Displays the crossproduct matrix X'X."},"StatementOptionType":"S"},{"StatementOptionName":"XPXI","StatementOptionHelp":{"#cdata":"Displays the generalized inverse of the crossproduct matrix X'X. The PLM procedure \nobtains a reflexive g2-inverse by sweeping."},"StatementOptionType":"S"}]}},{"StatementName":"SLICE","StatementHelp":{"#cdata":"Syntax: SLICE model-effect </ options> ; \n      \nThe SLICE statement provides a general mechanism for performing a partitioned analysis \nof the LS-means for an interaction. This analysis is also known as an analysis of simple \neffects. \n\nThe SLICE statement uses the same options as the LSMEANS statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the SLICE model-effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified SLICE effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the SLICE effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the SLICE statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this SLICE statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the SLICE \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="},{"StatementOptionName":"SLICEBY=","StatementOptionHelp":{"#cdata":"Determines how to construct the partition of the least squares means for the model-effect.\n          \nSyntax: \nSLICEBY <=> slice-specification \nSIMPLE <=> slice-specification \nSLICEBY(slice-specification <, slice-specification <, >>) \nSIMPLE(slice-specification <, slice-specification <, >>) \n\nA slice-specification consists of an effect name followed by an optional list of formatted \nvalues. For example, the following statements creates partitions of the A*B interaction effect \nfor all levels of variable A: \n\n  class a b;\n  model y = a b a*b;\n  slice a*b / sliceby=a;"},"StatementOptionType":"S|V"},{"StatementOptionName":"NOF","StatementOptionHelp":{"#cdata":"Suppresses the F test for testing the mutual equality of the estimable functions \nin the partition."},"StatementOptionType":"S"}]}},{"StatementName":"TEST","StatementHelp":{"#cdata":"Syntax: TEST <model-effects> </ options> ; \n      \nThe TEST statement enables you to perform F tests for model effects that test \nType I, II, or Type III hypotheses."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed for the relevant effects in addition to the \nF tests. Type III tests are the default; you can produce the Type I and Type II tests \nby using the HTYPE= option. This option has no effect when the procedure produces \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"DDF=|DF=","StatementOptionHelp":{"#cdata":"[Syntax: DDF=value-list] \n          \nSpecifies the denominator degrees of freedom for the fixed effects. The value-list \nspecification is a list of numbers or missing values (.) separated by commas. The \norder of degrees of freedom should match the order of the fixed effects that are \nspecified in the TEST statement; otherwise it should match the order in which the \neffects appear in the \"Type III Tests of Fixed Effects\" table."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that Type I, Type II, and Type III L matrix coefficients be displayed for all \nrelevant effects."},"StatementOptionType":"S"},{"StatementOptionName":"E1|EI","StatementOptionHelp":{"#cdata":"Requests that Type I L matrix coefficients be displayed for all relevant effects."},"StatementOptionType":"S"},{"StatementOptionName":"E2|EII","StatementOptionHelp":{"#cdata":"Requests that Type II L matrix coefficients be displayed for all relevant effects.]"},"StatementOptionType":"S"},{"StatementOptionName":"E3|EIII","StatementOptionHelp":{"#cdata":"Requests that Type III L matrix coefficients be displayed for all relevant effects."},"StatementOptionType":"S"},{"StatementOptionName":"HTYPE=","StatementOptionHelp":{"#cdata":"[Syntax: HTYPE=value-list] \n          \nIndicates the type of hypothesis test to perform on the fixed effects. Valid entries \nfor values in the value-list are 1, 2, and 3, which correspond to Type I, Type II, and \nType III tests, respectively. The default value is 3."},"StatementOptionType":"V"},{"StatementOptionName":"INTERCEPT|INT","StatementOptionHelp":{"#cdata":"Adds a row to the tables for Type I, II, and III tests that correspond to the \noverall intercept."},"StatementOptionType":"S"}]}},{"StatementName":"WHERE","StatementHelp":{"#cdata":"Syntax: WHERE expression ; \n      \nThe WHERE statement in the PLM procedure is helpful when the item store contains BY-variable \ninformation and you want to apply the PROC PLM statements to only a subset of the BY groups. \n\nA WHERE expression is a type of SAS expression that defines a condition. In the DATA step and \nin procedures that use SAS data sets as input source, the WHERE expression is used to select \nobservations for inclusion in the DATA step or in the analysis. In the PLM procedure, which \ndoes not accept a SAS data set but rather takes an item store that was created by a qualifying \nSAS/STAT procedure, the WHERE statement is also used to specify conditions. The conditional \nselection does not apply to observations in PROC PLM, however. Instead, you use the WHERE \nstatement in the PLM procedure to select a subset of BY groups from the item store to which \nto apply the PROC PLM statements. \n\nThe general syntax of the WHERE statement is \n\n  WHERE operand <operator> <operand> ; \n\nwhere \n\n  o operand is something to be operated on. The operand can be the name of a BY variable in \n    the item store, a SAS function, a constant, or a predefined name to identify columns in \n    result tables. \n\n  o operator is a symbol that requests a comparison, logical operation, or arithmetic calculation. \n    All SAS expression operators are valid for a WHERE expression."},"StatementOptions":null}]}}}