{"Procedure":{"Name":"SPP","#comment":{},"ProductGroup":"SAS/STAT","ProcedureHelp":{"#cdata":"Syntax: PROC SPP options; \n    BY variables; \n    PROCESS name = (variables </pattern-options>)</process-options <distance-function-options>>; \n    TREND name = FIELD(field-definition ); \n    COVTEST process-name = trend-name <trend-name, \u2026></options>; \n    MODEL process-name = <trend-name, \u2026></model-options>; \n    PARMS value-list </ PARMSDATA=SAS-data set>; \n    NLOPTIONS <options>;\n    \nThe SPP procedure performs analysis for spatial point patterns in two dimensions. You can specify the \npoint process rectangular window or rely on the input data set coordinates. Summary descriptions are \navailable through the F, G, J, K functions, which compare the empirical function distributions to the \ntheoretical homogeneous Poisson functions. \n\nThe SPP procedure uses ODS Graphics to create graphs as part of its output."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"[Syntax: DATA=SAS-data-set] \n      \nSpecifies the SAS data set containing the data to be analyzed. If you omit\nthe DATA= option, the procedure uses the most recently created SAS data set."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"DESCENDING|DESCEND|DESC","ProcedureOptionHelp":{"#cdata":"Requests that the levels of the response variable for the binomial model that uses a single-variable \nresponse syntax be sorted in the reverse of the default order."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NAMELEN=","ProcedureOptionHelp":{"#cdata":"[Syntax: NAMELEN=number] \n      \nSpecifies the length to which long effect names are shortened. The default and minimum value is 20."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"PLOTS=","ProcedureOptionHelp":{"#cdata":"Syntax: PLOTS <= plot-request >\n\nYou can specify the following plot-requests: \n\n ALL \n  requests that all default plots be produced. \n HISTOGRAM \n  creates a histogram for the predicted weights from the missingness model. \n NONE \n  suppresses all plots."},"ProcedureOptionType":"S|V","ProcedureOptionValues":{"@Value1":"ALL","@Value2":"HISTOGRAM","@Value3":"NONE"},"ProcedureOptionToolTips":{"@ToolTip1":"Requests that all default plots be produced.","@ToolTip2":"Creates a histogram for the predicted weights from the missingness model. ","@ToolTip3":"Suppresses all plots."}}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"BY","StatementHelp":{"#cdata":"Syntax: BY variables; \n\nYou can specify a BY statement with PROC SPP to obtain separate analyses of observations in groups that \nare defined by the BY variables. When a BY statement appears, the procedure expects the input data set to be \nsorted in order of the BY variables. If you specify more than one BY statement, only the last one specified is used. \n\nIf your input data set is not sorted in ascending order, use one of the following alternatives: \n\n  \u2022 Sort the data by using the SORT procedure with a similar BY statement. \n  \u2022 Specify the NOTSORTED or DESCENDING option in the BY statement for the BCHOICE procedure. The NOTSORTED \n    option does not mean that the data are unsorted but rather that the data are arranged in groups (according to values \n    of the BY variables) and that these groups are not necessarily in alphabetical or increasing numeric order. \n  \u2022 Create an index on the BY variables by using the DATASETS procedure (in Base SAS software)."},"StatementOptions":[{"StatementOption":[{"StatementOptionName":"DESCENDING","StatementOptionHelp":{"#cdata":"Specifies that the observations are sorted in descending order by the variable that \nimmediately follows the word DESCENDING in the BY statement."},"StatementOptionType":"S"},{"StatementOptionName":"NOTSORTED","StatementOptionHelp":{"#cdata":"Specifies that observations are not necessarily sorted in alphabetic or numeric order."},"StatementOptionType":"S"}]},null]},{"StatementName":"COVTEST","StatementHelp":{"#cdata":"Syntax: \nCOVTEST process-name = trend-name <trend-name, \u2026></options>; \n\nYou use the COVTEST statement to perform covariate dependency tests that are based on an empirical \ndistribution function (EDF). The COVTEST statement contains two essential parts: a process-name \n(which must be declared in a PROCESS statement that precedes the COVTEST statement) that you specify \non the left side and a list of trend-names (which must be defined in a preceding TREND statement within \nthe same PROC SPP call) that you specify on the right side. The procedure performs separate EDF tests \nfor every trend-name that is specified in the right side of the COVTEST statement."},"StatementOptions":{"StatementOption":{"StatementOptionName":"TEST=","StatementOptionHelp":{"#cdata":"Syntax: TEST=CM | D \n          \nRequests the test statistics for any type of requested weighted tests. This option applies only if you\nhave specified a trend on the right side of the COVTEST statement. The requested weighted test statistic \nis applied to every trend that is specified on the right side of the COVTEST statement. You can specify \nthe following values: \n\n  D\n    requests the Kolmogorov-Smirnov D statistic. \n  CM\n    requests the Cram\u00e9r\u2013von Mises W\u00b2 statistic. \n\nBy default, TEST=D."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"D","@Value2":"CM"},"StatementOptionToolTips":{"@ToolTip1":"Requests the Kolmogorov-Smirnov D statistic.","@ToolTip2":"Requests the Cram\u00e9r\u2013von Mises W\u00b2 statistic."}}}},{"StatementName":"MODEL","StatementHelp":{"#cdata":"Syntax: MODEL process-name = <trend-name, \u2026> </model-options>; \n\nThe MODEL statement enables you to fit an inhomogeneous Poisson process model. You must specify a process-name \nas the dependent variable. In addition, the MODEL statement enables you to specify multiple trends as covariates. \nIf you do not specify any trends as covariates in the MODEL statement, PROC SPP fits a second-degree polynomial. \nThe process-name must be defined in a preceding PROCESS statement, and each trend-name must be defined in a \npreceding TREND statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CENSCALE","StatementOptionHelp":{"#cdata":"Lists the centering and scaling (standardization) information for each coordinate and covariate in the model."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Syntax: CL<(alpha-value)>  \n          \nRequests a t-type confidence interval for the estimated parameters. You can also specify the significance \nlevel via the alpha-value. The default alpha-value is 0.05, which corresponds to the default confidence \nlevel of 95%."},"StatementOptionType":"S"},{"StatementOptionName":"CORRB","StatementOptionHelp":{"#cdata":"Requests the estimated correlation matrix for the parameter estimates. To request the estimated correlation \nmatrix for the model parameters with respect to the standardized covariates, specify both this model-option \nand the SOLUTION model-option."},"StatementOptionType":"S"},{"StatementOptionName":"COVB","StatementOptionHelp":{"#cdata":"Requests the estimated covariance matrix for the parameter estimates. To request the estimated covariance \nmatrix for the model parameters with respect to the standardized covariates, specify this model-option \nand the SOLUTION model-option."},"StatementOptionType":"S"},{"StatementOptionName":"GOF","StatementOptionHelp":{"#cdata":"Syntax: GOF(num-simulations ) \n          \nRequests a goodness-of-fit test for the fitted intensity model. You can specify the number of Monte Carlo \nsimulation runs as an integer in num-simulations. By default, the SPP procedure performs 100 simulations \nwhen you specify this option."},"StatementOptionType":"S"},{"StatementOptionName":"GRID","StatementOptionHelp":{"#cdata":"Syntax: GRID(value-NX,value-NY ) \n          \nSpecifies the grid resolution for model fitting, where value-NX specifies the number of grids in the \nhorizontal direction and value-NY specifies the number of grids in the vertical direction. By default, \nthe SPP procedure fits the model on a 128 x 128 grid."},"StatementOptionType":"S"},{"StatementOptionName":"ITHIST","StatementOptionHelp":{"#cdata":"Syntax: ITHIST<(PARM)> \n          \nRequests an iteration history table for the model-fitting optimization. Specify this option to produce \nadditional levels of output detail. You can specify the following value: \n\n PARM \n  includes the fitting parameters in the iteration history table."},"StatementOptionType":"S","SubOptionsKeywords":"PARM"},{"StatementOptionName":"MTYPE=","StatementOptionHelp":{"#cdata":"Syntax: MTYPE=POISSON | NEGBINOMIAL \n          \nSpecifies the type of inhomogeneous intensity model to be fit by PROC SPP. You fit a negative binomial \nmodel only in order to diagnose overdispersion, so in this case no fitted intensity is produced, and \nlikewise none of the goodness-of-fit tests or residual diagnostics that are based on the intensity \nare produced. You can specify the following values: \n\n  POISSON\n    fits a Poisson process model. \n  NEGBINOMIAL\n    fits a negative binomial model. \n\nBy default, MTYPE=POISSON."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"POISSON","@Value2":"NEGBINOMIAL"},"StatementOptionToolTips":{"@ToolTip1":"Fits a Poisson process model.","@ToolTip2":"Fits a negative binomial model."}},{"StatementOptionName":"OUTINTENSITY=","StatementOptionHelp":{"#cdata":"Syntax: OUTINTENSITY=SAS-data-set \n          \nSpecifies a SAS-data-set in which to store the output intensity estimate."},"StatementOptionType":"V"},{"StatementOptionName":"OUTSIM=","StatementOptionHelp":{"#cdata":"Syntax: OUTSIM<(iter-value)>=SAS-data-set \n          \nSpecifies a SAS-data-set in which to store a simulated point pattern from a fitted intensity model. \nSpecify the number of iterations in <iter-value> to generate multiple point pattern data sets. By default, \nthe number of simulation iterations is set to 1."},"StatementOptionType":"S|V"},{"StatementOptionName":"POLYNOMIAL|POLY","StatementOptionHelp":{"#cdata":"Syntax: POLYNOMIAL|POLY<(degree )> \n          \nSpecifies a polynomial trend in the coordinates. You can also specify the degree of the polynomial component. \nIf you do not specify the degree, PROC SPP procedure uses a second-degree polynomial by default."},"StatementOptionType":"S"},{"StatementOptionName":"RESIDUAL","StatementOptionHelp":{"#cdata":"Syntax: RESIDUAL(B=value) \n          \nRequests residual diagnostics for the inhomogeneous Poisson process model. If you specify this option, \nyou must also specify the residual bandwidth for computing smoothed residuals via the B= suboption."},"StatementOptionType":"S","SubOptionsKeywords":"B="},{"StatementOptionName":"SOLUTION","StatementOptionHelp":{"#cdata":"Displays the parameter estimates table in a location- and scale-standardized space. For optimization \npurposes, any polynomial coordinates and covariates in the model are centered and scaled. The parameters \nand the approximate covariance and the correlation matrices are displayed by default in the untransformed, \nunstandardized space. This option causes the output to be displayed on the basis of the actual fitted \nparameters in the transformed space. If you also specify the COVB or CORRB model-option (or both), then \nPROC SPP also displays the estimated covariance or correlation matrix, respectively (or both), in the \ntransformed space."},"StatementOptionType":"S"}]}},{"StatementName":"NLOPTIONS","StatementHelp":{"#cdata":"Syntax: NLOPTIONS <options> ;\n      \nThe NLOPTIONS statement specifies details about the nonlinear optimization technique that PROC SPP \nuses to maximize the log-likelihood function for the first-order intensity model. By default, PROC SPP \nuses the Newton-Raphson with ridging optimization technique."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ABSCONV=|ABSTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSCONV= | ABSTOL=r] \n          \nSpecifies an absolute function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ABSFCONV=|ABSFTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSFCONV=r <n>  | ABSFTOL=r<n>] \n          \nSpecifies an absolute function difference convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ABSGCONV=|ABSGTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSGCONV= | ABSGTOL=r <n>] \n          \nSpecifies an absolute gradient convergence criterion. \n\n  o For all techniques except NMSIMP (specified by the TECHNIQUE= option), Termination requires the maximum \n    absolute gradient element to be small.\n  o This criterion is not used by the NMSIMP technique."},"StatementOptionType":"V"},{"StatementOptionName":"ABSXCONV=|ABSXTOL=","StatementOptionHelp":{"#cdata":"[Syntax: ABSXCONV= | ABSXTOL=r <n>] \n          \nSpecifies the absolute parameter convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ASINGULAR=|ASING=","StatementOptionHelp":{"#cdata":"[Syntax: ASINGULAR | ASING=r] \n          \nSpecifies an absolute singularity criterion r, r > 0, for the inversion of \nthe information matrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"DAMPSTEP|DS","StatementOptionHelp":{"#cdata":"[Syntax: DAMPSTEP | DS  <=r>] \n          \nSpecifies that the initial step-size value a\u207f (where n=0) for each line search \n(used by the QUANEW, CONGRA, or NEWRAP technique) cannot be larger than r times \nthe step-size value used in the former iteration."},"StatementOptionType":"S|V"},{"StatementOptionName":"FCONV=|FTOL=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV=r | FTOL=r] \n          \nSpecifies the relative function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"FCONV2=|FTOL2=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV2= | FTOL2=r <n>] \n          \nSpecifies a second function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"FSIZE=","StatementOptionHelp":{"#cdata":"[Syntax:FSIZE=r] \n          \nSpecifies the FSIZE parameter of the relative function and relative gradient termination \ncriteria. The default value is r=0."},"StatementOptionType":"V"},{"StatementOptionName":"GCONV=|GTOL=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV=r | GTOL=r] \n          \nSpecifies the relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"GCONV2=|GTOL2=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV2=r | GTOL2=r] \n          \nSpecifies another relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"HESCAL=|HS=","StatementOptionHelp":{"#cdata":"Specifies the scaling version of the Hessian or crossproduct Jacobian matrix used in NRRIDG, TRUREG, \nLEVMAR, NEWRAP, or DBLDOG optimization."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"0","@Value2":"1","@Value3":"2","@Value4":"3"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that no scaling is done.","@ToolTip2":"Specifies the Mor\u00e9 (1978) scaling update","@ToolTip3":"Specifies the Dennis, Gay, and Welsch (1981) scaling update","@ToolTip4":"Specifies that di is reset in each iteration"}},{"StatementOptionName":"INHESSIAN|INHESS","StatementOptionHelp":{"#cdata":"[Syntax: INHESSIAN<=r>] \n          \nSpecifies how the initial estimate of the approximate Hessian is defined for the quasi-Newton \ntechniques QUANEW and DBLDOG."},"StatementOptionType":"S|V"},{"StatementOptionName":"INSTEP=|SALPHA=|RADIUS=","StatementOptionHelp":{"#cdata":"[Syntax: INSTEP=r] \n          \nReduces the length of the first trial step during the line search of the first iterations."},"StatementOptionType":"V"},{"StatementOptionName":"LCDEACT=|LCD=","StatementOptionHelp":{"#cdata":"[Syntax: LCDEACT= | LCD=r] \n          \nSpecifies a threshold r for the Lagrange multiplier that decides whether an active \ninequality constraint remains active or can be deactivated."},"StatementOptionType":"V"},{"StatementOptionName":"LCEPSILON=|LCEPS=|LCE=","StatementOptionHelp":{"#cdata":"[Syntax: LCEPSILON= | LCEPS= | LCE=r] \n          \nSpecifies the range r, r \u2265 0, for active and violated boundary and linear constraints."},"StatementOptionType":"V"},{"StatementOptionName":"LCSINGULAR=|LCSING=|LCS=","StatementOptionHelp":{"#cdata":"[Syntax: LCSINGULAR= | LCSING= | LCS=r] \n          \nSpecifies a criterion r, r \u2265 0, used in the update of the QR decomposition that \ndecides whether an active constraint is linearly dependent on a set of other \nactive constraints. "},"StatementOptionType":"V"},{"StatementOptionName":"LINESEARCH=|LIS=|SMETHOD=|SM=","StatementOptionHelp":{"#cdata":"[Syntax: LINESEARCH | LIS | SMETHOD | SM=i] \n          \nSpecifies the line-search method for the CONGRA, QUANEW, and NEWRAP optimization \ntechniques."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"1","@Value2":"2","@Value3":"3","@Value4":"4","@Value5":"5","@Value6":"6","@Value7":"7","@Value8":"8"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a line-search method that needs the same number of function and gradient calls for cubic  interpolation and cubic extrapolation; this method is similar to one used by the Harwell subroutine library.","@ToolTip2":"Specifies a line-search method that needs more function calls than gradient calls for quadratic and  cubic interpolation and cubic extrapolation; this method is implemented as shown in Fletcher (1987) and  can be modified to an exact line search by using the LSPRECISION= option.","@ToolTip3":"Specifies a line-search method that needs the same number of function and gradient calls for cubic  interpolation and cubic extrapolation; this method is implemented as shown in Fletcher (1987) and can  be modified to an exact line search by using the LSPRECISION= option.","@ToolTip4":"Specifies a line-search method that needs the same number of function and gradient calls for stepwise  extrapolation and cubic interpolation","@ToolTip5":"Specifies a line-search method that is a modified version of LIS=4.","@ToolTip6":"Specifies golden section line search (Polak 1971), which uses only function values for linear approximation.","@ToolTip7":"Specifies bisection line search (Polak 1971), which uses only function values for linear approximation.","@ToolTip8":"Specifies Armijo line-search technique (Polak 1971), which uses only function values for linear approximation."}},{"StatementOptionName":"LSPRECISION=|LSP=","StatementOptionHelp":{"#cdata":"[Syntax: LSPRECISION=r | LSP=r] \n          \nSpecifies the degree of accuracy that should be obtained by the line-search algorithms \nLIS=2 and LIS=3. The default LSPRECISION= values are:\n\n  o For TECH=QUANEW UPDATE=DBFGS, BFGS: r = 0.4\n  o For TECH=QUANEW UPDATE=DDFP, DFP: r = 0.06 \n  o For TECH=CONGRA UPDATE=all r = 0.1\n  o For TECH=NEWRAP NO UPDATE: r = 0.9"},"StatementOptionType":"V"},{"StatementOptionName":"MAXFUNC=|MAXFU=","StatementOptionHelp":{"#cdata":"[Syntax: MAXFUNC=i | MAXFU=i] \n          \nRequires the number of function calls to be no larger than i. The default values are: \n\n  o For TECH= LEVMAR, NEWRAP, NRRIDG, TRUREG: i=125 \n  o For TECH= DBLDOG, QUANEW: i=500 \n  o For TECH= CONGRA: i=1000"},"StatementOptionType":"V"},{"StatementOptionName":"MAXITER=|MAXIT=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER= | MAXIT=i ] \n          \nRequires the number of iterations to be no larger than i. The default values are:\n  o For TECH= LEVMAR, NEWRAP, NRRIDG, TRUREG: i=50 \n  o For TECH= DBLDOG, QUANEW: i=200 \n  o For TECH= CONGRA: i=400"},"StatementOptionType":"V"},{"StatementOptionName":"MAXSTEP=","StatementOptionHelp":{"#cdata":"[Syntax: MAXSTEP=r<n>] \n          \nSpecifies an upper bound for the step length of the line-search algorithms during the \nfirst n iterations."},"StatementOptionType":"V"},{"StatementOptionName":"MAXTIME=","StatementOptionHelp":{"#cdata":"[Syntax: MAXTIME=r] \n          \nRequires the CPU time to be no larger than r. The default value of the MAXTIME= \noption is the largest double floating-point number on your computer."},"StatementOptionType":"V"},{"StatementOptionName":"MINITER=|MINIT=","StatementOptionHelp":{"#cdata":"[Syntax: MINITER= | MINIT=i] \n          \nSpecifies the minimum number of iterations. The default value is 0."},"StatementOptionType":"V"},{"StatementOptionName":"MSINGULAR=|MSING=","StatementOptionHelp":{"#cdata":"[Syntax: MSINGULAR= | MSING=r] \n          \nSpecifies a relative singularity criterion r, r > 0, for the inversion of \nthe information matrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"NOPRINT","StatementOptionHelp":{"#cdata":"Suppresses output related to optimization such as the iteration history."},"StatementOptionType":"S"},{"StatementOptionName":"PALL","StatementOptionHelp":{"#cdata":"[Displays information about the starting values and final values of the optimization process."},"StatementOptionType":"S"},{"StatementOptionName":"PHISTORY|PHIST","StatementOptionHelp":{"#cdata":"Displays the optimization history. The PHISTORY option is set automatically if the PALL or PRINT \noption is set."},"StatementOptionType":"S"},{"StatementOptionName":"RESTART=|REST=","StatementOptionHelp":{"#cdata":"[Syntax: RESTART= | REST=i] \n          \nSpecifies that the QUANEW or CONGRA algorithm is restarted with a steepest descent/ascent \nsearch direction after at most i iterations, i > 0."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=|SING=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR= | SING=r] \n          \nSpecifies the singularity criterion r, 0 < r < 1, used, for example, for matrix inversion."},"StatementOptionType":"V"},{"StatementOptionName":"SOCKET=","StatementOptionHelp":{"#cdata":"[Syntax: SOCKET=fileref]\n          \nSpecifies the fileref that contains the information needed for remote monitoring."},"StatementOptionType":"V"},{"StatementOptionName":"TECHNIQUE=|TECH=|OMETHOD=|OM=","StatementOptionHelp":{"#cdata":"[Syntax: TECHNIQUE= | TECH=name | OMETHOD= | OM=name] \n          \nSpecifies the optimization technique."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CONGRA","@Value2":"DBLDOG","@Value3":"LEVMAR","@Value4":"NEWRAP","@Value5":"NRRIDG","@Value6":"QUANEW","@Value7":"TRUREG","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Chooses one of four different conjugate-gradient optimization algorithms, which can be more precisely  defined with the UPDATE= option and modified with the LINESEARCH= option.","@ToolTip2":"Performs a version of double-dogleg optimization, which uses the gradient to update an approximation  of the Cholesky factor of the Hessian.","@ToolTip3":"Performs a highly stable but, for large problems, memory- and time-consuming Levenberg-Marquardt  optimization technique, a slightly improved variant of the Mor\u00e9 (1978) implementation. This is  the default optimization technique if there are fewer than 40 parameters to estimate.","@ToolTip4":"Performs a usually stable but, for large problems, memory- and time-consuming Newton-Raphson optimization  technique. The algorithm combines a line-search algorithm with ridging, and it can be modified with the  LINESEARCH= option.","@ToolTip5":"Performs a usually stable but, for large problems, memory- and time-consuming Newton-Raphson optimization  technique. This algorithm does not perform a line search.","@ToolTip6":"Chooses one of four different quasi-Newton optimization algorithms that can be more precisely defined with  the UPDATE= option and modified with the LINESEARCH= option.","@ToolTip7":"Performs a usually very stable but, for large problems, memory- and time-consuming trust-region optimization  technique. The algorithm is implemented similar to Gay (1983) and Mor\u00e9 and Sorensen (1983).","@ToolTip8":"Does not perform any optimization. This option is similar to METHOD=NONE, but TECH=NONE also computes and displays residuals and goodness of fit statistics."}},{"StatementOptionName":"UPDATE=|UPD=","StatementOptionHelp":{"#cdata":"Specifies the update method for the quasi-Newton, double-dogleg, or conjugate-gradient optimization technique."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BFGS","@Value2":"DBFGS","@Value3":"DDFP","@Value4":"DFP","@Value5":"PB","@Value6":"FR","@Value7":"PR","@Value8":"CD"},"StatementOptionToolTips":{"@ToolTip1":"Performs the original Broyden, Fletcher, Goldfarb, and Shanno (BFGS) update of the inverse Hessian matrix.","@ToolTip2":"Performs the dual BFGS update of the Cholesky factor of the Hessian matrix. This is the default update method.","@ToolTip3":"Performs the dual Davidon, Fletcher, and Powell (DFP) update of the Cholesky factor of the Hessian matrix.","@ToolTip4":"Performs the original DFP update of the inverse Hessian matrix.","@ToolTip5":"Performs the automatic restart update method of Powell (1977) and Beale (1972).","@ToolTip6":"Performs the Fletcher-Reeves update (Fletcher 1987).","@ToolTip7":"Performs the Polak-Ribiere update (Fletcher 1987).","@ToolTip8":"Performs a conjugate-descent update of Fletcher (1987)."}},{"StatementOptionName":"VERSION=|VS=","StatementOptionHelp":{"#cdata":"Specifies the version of the quasi-Newton optimization technique with nonlinear constraints."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"1","@Value2":"2"},"StatementOptionToolTips":{"@ToolTip1":"Specifies the update of the U vector as in Powell (1978a, 1978b) (update like VF02AD).","@ToolTip2":"Specifies the update of the U vector as in Powell (1982a, 1982b) (update like VMCWD)."}},{"StatementOptionName":"VSINGULAR=|VSING=","StatementOptionHelp":{"#cdata":"[Syntax: VSINGULAR= | VSING=r] \n            \nSpecifies a relative singularity criterion r, r > 0, for the inversion of the information \nmatrix, which is needed to compute the covariance matrix."},"StatementOptionType":"V"},{"StatementOptionName":"XCONV=|XTOL=","StatementOptionHelp":{"#cdata":"[Syntax: XCONV= | XTOL=r <n>] \n          \nSpecifies the relative parameter convergence criterion. Termination requires a small \nrelative parameter change in subsequent iterations."},"StatementOptionType":"V"},{"StatementOptionName":"XSIZE=","StatementOptionHelp":{"#cdata":"[Syntax: XSIZE=r] \n          \nSpecifies the XSIZE parameter of the relative function and relative gradient termination \ncriteria. The default value is r=0."},"StatementOptionType":"V"}]}},{"StatementName":"PARMS","StatementHelp":{"#cdata":"Syntax: PARMS value-list </ PARMSDATA=SAS-data-set>;        \n\nThe PARMS statement specifies initial values for the parameters in the MODEL statement. Alternatively, \nthe PARMS statement can request a grid search over several values of these parameters. The PARMS statement \nis optional and must follow the associated MODEL statement."},"StatementOptions":{"StatementOption":{"StatementOptionName":"PARMSDATA=|PDATA=","StatementOptionHelp":{"#cdata":"Syntax: PARMSDATA=SAS-data-set | PDATA=SAS-data-set  \n          \nSpecifies the SAS data set from which to read model parameter values. The data set should contain the \nvalues in the sequence that is required by the PARMS statement in either of the following two ways: \n\n  \u2022Specify one single column under the variable Estimate (Est) that contains all the parameter values. \n\n  \u2022Use one column for each parameter, and place the n columns under the Parm_1\u2013Parm_n variables."},"StatementOptionType":"V"}}},{"StatementName":"PROCESS","StatementHelp":{"#cdata":"Syntax: PROCESS name = (variables </pattern-options> )</process-options <distance-function-options>> ; \n\nThe PROCESS statement defines a point pattern for analysis. You must use a valid SAS variable name \nto define the process, and you can describe it by using variables that contain the x and y coordinates \nof the points within the point pattern. The variables must also be in the DATA= data set. You can specify \nonly one PROCESS statement in PROC SPP."},"StatementOptions":{"#comment":[{},{},{}],"StatementOption":[{"StatementOptionName":"AREA=","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"V"},{"StatementOptionName":"EVENT=","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"V"},{"StatementOptionName":"MARK=","StatementOptionHelp":{"#cdata":""},"StatementOptionType":"V"},{"StatementOptionName":"F","StatementOptionHelp":{"#cdata":"Syntax: F<GRID(value-NX,value-NY)> \n          \nPerforms a test for complete spatial randomness that is based on the empty-space F function. You can \nspecify the following suboption: \n\n  GRID(value-NX, value-NY) \n    specifies a reference grid for computing the empty-space F function, where value-NX represents the \n    number of horizontal divisions and value-NY represents the number of vertical divisions. By default, \n    the SPP procedure uses a 50 x 50 grid."},"StatementOptionType":"S"},{"StatementOptionName":"G","StatementOptionHelp":{"#cdata":"Performs a test for complete spatial randomness that is based on the nearest-neighbor G function."},"StatementOptionType":"S"},{"StatementOptionName":"J","StatementOptionHelp":{"#cdata":"Syntax: J<GRID(value-NX, value-NY)> \n          \nPerforms a test for complete spatial randomness that is based on the J function. You can specify the \nfollowing suboption: \n\n  GRID(value-NX, value-NY) \n    specifies a reference grid for computing the J function, where value-NX represents the number of \n    horizontal divisions and value-NY represents the number of vertical divisions. By default, the \n    SPP procedure uses a 50 x 50 grid."},"StatementOptionType":"S"},{"StatementOptionName":"GRID","StatementOptionHelp":{"#cdata":"Syntax: GRID(value-NX, value-NY) \n          \nSpecifies a reference grid for computing the F/G/J function, where value-NX represents the number of \nhorizontal divisions and value-NY represents the number of vertical divisions. By default, the \nSPP procedure uses a 50 x 50 grid."},"StatementOptionType":"S"},{"StatementOptionName":"K","StatementOptionHelp":{"#cdata":"Performs a test for complete spatial randomness that is based on the K function."},"StatementOptionType":"S"},{"StatementOptionName":"KERNEL","StatementOptionHelp":{"#cdata":"Syntax: KERNEL<(kernel-suboptions)> \n          \nProduces a nonparametric estimate of the first-order intensity, or a nonparametric smoothed estimate \nof a quantitative mark variable of the point pattern, depending on the kernel-suboptions. When you do \nnot specify the kernel-suboptions, PROC SPP computes a nonparametric intensity estimate that is based \non a default bandwidth and uses a Gaussian kernel. You can specify the following kernel-suboptions. \n\n  TYPE=EPANECHNIKOV | GAUSSIAN | QUARTIC | TRIANGULAR | UNIFORM \n    specifies the kernel type for obtaining the nonparametric estimate.\n  B=value \n    specifies the value for the kernel bandwidth parameter. \n  ADAPTIVE \n    performs adaptive kernel estimation. Adaptive kernel estimation requires an initial bandwidth value \n    to compute bandwidth estimates for each data point.\n  OUT=SAS-data-set \n    specifies the name of a SAS-data-set to contain the kernel based nonparametric estimates.\n  GRID(value-NX, value-NY) \n    specifies a reference grid for computing the kernel estimate, where value-NX represents the number \n    of horizontal divisions and value-NY represents the number of vertical divisions."},"StatementOptionType":"S","SubOptionsKeywords":"TYPE=|B=|ADAPTIVE|OUT=|GRID"},{"StatementOptionName":"L","StatementOptionHelp":{"#cdata":"Performs a test for complete spatial randomness that is based on the L function. "},"StatementOptionType":"S"},{"StatementOptionName":"OUTSIM=","StatementOptionHelp":{"#cdata":"Syntax: OUTSIM=SAS-data-set \n          \nSpecifies the name of a SAS-data-set to contain the results of simulations in distance functions. \nThis option is ignored unless one of the distance functions is specified in the PROCESS statement."},"StatementOptionType":"V"},{"StatementOptionName":"PCF","StatementOptionHelp":{"#cdata":"Syntax: PCF<B=value> \n          \nPerforms a test for complete spatial randomness that is based on the pair correlation function (PCF) \nfunction. The pair correlation function is calculated only when you specify EDGECORR=ON in the PROC SPP \nstatement. You can specify the following suboption: \n\n  B=value \n    specifies the bandwidth value to use in the kernel density estimation inside the pair correlation \n    function. The value must be a nonnegative real number."},"StatementOptionType":"S","SubOptionsKeywords":"B="},{"StatementOptionName":"QUADRAT","StatementOptionHelp":{"#cdata":"Syntax: QUADRAT<(<value-NX,value-NY> </DETAILS>)> \n          \nPerforms a test for complete spatial randomness. You can specify value-NX and value-NY to provide a \nquadrat specification that includes the number of horizontal and vertical divisions. If you do not \nspecify the number of horizontal and vertical divisions, PROC SPP computes a default quadrat of \n10 x 10. By default, the QUADRAT option displays only the Pearson chi-square test for CSR. If you \nalso specify the DETAILS suboption, then PROC SPP displays the quadrat count in addition to the \nPearson residual information."},"StatementOptionType":"S"},{"StatementOptionName":"BYTYPE","StatementOptionHelp":{"#cdata":"[For use with F, G, J, K, L, or PCF process-options only]\n          \nSyntax: BYTYPE(ALL|value-list) \n  \nRequests distance function calculation by values of the mark variable. This option produces individual \ndistance function calculations for each mark type. You can specify the following options: \n\n  ALL \n    requests distance function calculation for all available character mark variable values in the DATA= data set. \n  value-list \n    requests distance function calculation for certain formatted mark variable values, which you specify \n    as quoted strings in the value-list. \n\n          \n"},"StatementOptionType":"S","SubOptionsKeywords":"ALL"},{"StatementOptionName":"CROSS=","StatementOptionHelp":{"#cdata":"[For use with F, G, J, K, L, or PCF process-options only]\n          \nSyntax: CROSS=TYPES(value-list1<,value-list2>) \n\nRequests cross-type distance function analysis between different mark values. For cross-type analysis, you must specify a mark variable in the point pattern definition by using the MARK= pattern-option. The CROSS= option applies only to any requested distance functions K, L, G, J, or PCF. You must specify the TYPES suboption as follows: \n\n  TYPES(value-list1<,value-list2>) \n    requests cross-type analysis only among types that are specified in value-list1 and an optional \n    value-list2. If you specify only value-list1, then PROC SPP performs cross-type analysis within \n    all the types that are specified in value-list1. If you also specify the additional value-list2, \n    PROC SPP performs cross-type analysis across both lists. For value-list1 and value-list2, specify \n    quoted strings that correspond to values of the variable that is specified in the MARK=pattern-option."},"StatementOptionType":"V"},{"StatementOptionName":"MAXDIST=","StatementOptionHelp":{"#cdata":"Syntax: MAXDIST=value | MAX | CUT \n          \nSpecifies the option to be used for computing the maximum distance for different distance functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"<value>","@Value2":"MAX","@Value3":"CUT"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a value for the maximum distance for performing distance function calculations. The value  must be positive and larger than the value of the MINDIST=value option. You can specify any positive  value for the maximum distance. However, values that are too large might produce artifacts that do  not reflect the true underlying process.","@ToolTip2":"Uses the maximum possible distance, based on the suggestion by Baddeley and Turner (2013).","@ToolTip3":"Uses the maximum distance at certain cutoff values that are recommended by Baddeley (2014)."}},{"StatementOptionName":"MINDIST=","StatementOptionHelp":{"#cdata":"Syntax: MINDIST=value \n          \nSpecifies a positive number for the minimum distance (or starting) distance for all distance function \ncalculations. The value of this option cannot be more than the value of MAXDIST= option."},"StatementOptionType":"V"},{"StatementOptionName":"NDIST=","StatementOptionHelp":{"#cdata":"Syntax: NDIST=value \n          \nSpecifies the number of distance bins with which to compute all the specified distance functions. \nThis is a global option that applies to all specified distance functions. When you specify a value \nfor this option, the SPP procedure uses this value instead of others for distance function calculations."},"StatementOptionType":"V"},{"StatementOptionName":"NSIM=","StatementOptionHelp":{"#cdata":"Syntax: NSIM=value \n          \nSpecifies a positive integer for the number of simulations to be used to compute envelopes for the CSR tests \nin all distance functions. When you specify this option, it applies to all specified distance functions."},"StatementOptionType":"V"},{"StatementOptionName":"BLOCKS","StatementOptionHelp":{"#cdata":"Syntax: BLOCKS(NX, NY) \n          \nSpecifies the block size that is required for calculating the confidence intervals of distance functions, \nwhere NX specifies the number of horizontal blocks and NY specifies the number of vertical blocks. The block \nsize should be neither too small nor too large for this option to behave reasonably."},"StatementOptionType":"S"}]}},{"StatementName":"TREND","StatementHelp":{"#cdata":"Syntax: TREND name = FIELD(field-definition); \n\nThe TREND statement enables you to define a spatial trend covariate, where name is a standard SAS variable \nname that names the trend and the FIELD suboption describes the field as follows: \n\nFIELD (X-variable, Y-variable, field-variable ) \n  specifies a spatial field variable as a trend by using any spatial field covariates that are available \n  in the DATA= data set, where X-variable specifies the X coordinate and Y-variable specifies the Y coordinate \n  of the spatial field. The third argument is the field-variable, which is a numeric variable in the DATA= data set."},"StatementOptions":null}]}}}