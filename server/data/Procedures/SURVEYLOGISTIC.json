{"Procedure":{"Name":"SURVEYLOGISTIC","#comment":{},"ProductGroup":"SAS/STAT","ProcedureHelp":{"#cdata":"Syntax: PROC SURVEYLOGISTIC  <options> ; \n    BY variables ; \n    CLASS variable <(v-options)> <variable <(v-options)> ...> </ v-options> ; \n    CLUSTER variables ; \n    CONTRAST \u2019label\u2019   effect values <,...effect values> </ options> ; \n    DOMAIN variables <variable*variable variable*variable*variable ...> ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    ESTIMATE <'label'> estimate-specification < / options> ; \n    FREQ variable ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification < / options> ; \n    MODEL events/trials = <effects < / options>> ; \n    MODEL variable <(v-options)> = <effects> < / options> ; \n    OUTPUT <OUT=SAS-data-set> <options> < / option> ; \n    REPWEIGHTS variables < / options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name</LABEL='label'> ; \n    STRATA variables </ option> ; \n    <label:> TEST equation1 < , ... , equationk> </ options> ; \n    UNITS independent1 = list1 <... independentk = listk> < / option> ; \n    WEIGHT variable ; \n  \nCategorical responses arise extensively in sample survey. Common examples of responses \ninclude the following: \n\n    o binary: for example, attended graduate school or not \n    o ordinal: for example, mild, moderate, and severe pain \n    o nominal: for example, ABC, NBC, CBS, FOX TV network viewed at a certain hour \n\nLogistic regression analysis is often used to investigate the relationship between such \ndiscrete responses and a set of explanatory variables."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"ALPHA=","ProcedureOptionHelp":{"#cdata":"[Syntax: ALPHA=\u03b1] \n      \nSets the confidence level for confidence limits. The value of the ALPHA= option must \nbe between 0 and 1, and the default value is 0.05. A confidence level of \u03b1 produces \n100(1-\u03b1)% confidence limits. The default of ALPHA=0.05 produces 95% confidence limits."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"[Syntax: DATA=SAS-data-set] \n      \nSpecifies the SAS data set to be analyzed by PROC SURVEYREG. If you omit the DATA= \noption, the procedure uses the most recently created SAS data set."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"MISSING","ProcedureOptionHelp":{"#cdata":"Treats missing values as a valid (nonmissing) category for all categorical variables, \nwhich include CLASS, STRATA, CLUSTER, and DOMAIN variables. By default, if you do not \nspecify the MISSING option, an observation is excluded from the analysis if it has a \nmissing value."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NOMCAR","ProcedureOptionHelp":{"#cdata":"Requests that the procedure treat missing values in the variance computation as not \nmissing completely at random (NOMCAR) for Taylor series variance estimation. When \nyou specify the NOMCAR option, PROC SURVEYREG computes variance estimates by \nanalyzing the nonmissing values as a domain or subpopulation, where the entire \npopulation includes both nonmissing and missing domains.]"},"ProcedureOptionType":"S"},{"ProcedureOptionName":"ORDER=","ProcedureOptionHelp":{"#cdata":"Specifies the order in which to sort the levels of the classification variables \n(which are specified in the CLASS statement). This option applies to the levels \nfor all classification variables, except when you use the (default) ORDER=FORMATTED \noption with numeric classification variables that have no explicit format. With this \noption, the levels of such variables are ordered by their internal value."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"ProcedureOptionToolTips":{"@ToolTip1":"Levels sorted by the order of appearance in the input data set.","@ToolTip2":"Levels sorted by the external formatted value, except for numeric variables with  no explicit format, which are sorted by their unformatted (internal) value.","@ToolTip3":"Levels sorted by the descending frequency count; levels with the most observations  come first in the order.","@ToolTip4":"Levels sorted by the unformatted value."}},{"ProcedureOptionName":"RATE=|R=","ProcedureOptionHelp":{"#cdata":"[Syntax: RATE=value | SAS-data-set] \n      \nSpecifies the sampling rate as a nonnegative value, or identifies an input data set \nthat gives the stratum sampling rates in a variable named _RATE_. The procedure \nuses this information to compute a finite population correction for Taylor series \nvariance estimation. The procedure does not use the RATE= option for BRR or jackknife \nvariance estimation, which you request with the VARMETHOD=BRR or VARMETHOD=JACKKNIFE \noption."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"TOTAL=|N=","ProcedureOptionHelp":{"#cdata":"[Syntax: TOTAL=value | SAS-data-set] \n      \nSpecifies the total number of primary sampling units (PSUs) in the study population \nas a positive value, or identifies an input data set that gives the stratum population \ntotals in a variable named _TOTAL_. The procedure uses this information to compute \na finite population correction for Taylor series variance estimation. The procedure \ndoes not use the TOTAL= option for BRR or jackknife variance estimation, which you \nrequest with the VARMETHOD=BRR or VARMETHOD=JACKKNIFE option."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"TRUNCATE","ProcedureOptionHelp":{"#cdata":"Specifies that class levels should be determined using no more than the first 16 \ncharacters of the formatted values of the CLASS, STRATA, and CLUSTER variables. \nWhen formatted values are longer than 16 characters, you can use this option in \norder to revert to the levels as determined in releases before SAS 9."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"VARMETHOD=","ProcedureOptionHelp":{"#cdata":"[Syntax: VARMETHOD=BRR < (method-options) > | JACKKNIFE <(method-options) > | TAYLOR] \n      \nSpecifies the variance estimation method."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"BRR","@Value2":"JACKKNIFE","@Value3":"TAYLOR"},"ProcedureOptionToolTips":{"@ToolTip1":"Requests variance estimation by balanced repeated replication (BRR).                                  You can specify the following method-options in parentheses after the VARMETHOD=BRR option:     FAY <=value>    requests Fay\u2019s method, which is a modification of the BRR method.      HADAMARD=SAS-data-set    H=SAS-data-set    names a SAS data set that contains the Hadamard matrix for BRR replicate construction.     OUTWEIGHTS=SAS-data-set    names an output SAS data set to store the replicate weights that PROC SURVEYPHREG creates    for BRR variance estimation. The OUTWEIGHTS= method-option is not available when you provide    replicate weights with a REPWEIGHTS statement.     PRINTH    displays the Hadamard matrix used to construct replicates for BRR. When you provide the    Hadamard matrix in the HADAMARD= method-option, PROC SURVEYPHREG displays only the rows    and columns that are actually used to construct replicates.     REPS=number    specifies the number of replicates for BRR variance estimation. The value of number must    be an integer greater than 1.","@ToolTip2":"Requests variance estimation by the delete-1 jackknife method.                                  You can specify the following method-options in parentheses following VARMETHOD=JACKKNIFE:     OUTWEIGHTS=SAS-data-set    names an output SAS data set that contains replicate weights.     The OUTWEIGHTS= method-option is not available when you provide replicate weights    with the REPWEIGHTS statement.     OUTJKCOEFS=SAS-data-set    names an output SAS data set that contains jackknife coefficients.","@ToolTip3":"Requests Taylor series variance estimation. This is the default method if you do not  specify the VARMETHOD= option or a REPWEIGHTS statement."},"SubOptionsKeywords":"OUTJKCOEFS=|OUTWEIGHTS=|REPS=|PRINTH|OUTWEIGHTS=|HADAMARD=|FAY|FAY="}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"BY","StatementHelp":{"#cdata":"Syntax: BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>; \n      \nYou can specify a BY statement with PROC SURVEYLOGISTIC to obtain separate analyses  \non observations in groups that are defined by the BY variables. When a BY statement \nappears, the procedure expects the input data set to be sorted in order of the BY \nvariables. If you specify more than one BY statement, only the last one specified \nis used."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING","StatementOptionHelp":{"#cdata":"Specifies that the observations are sorted in descending order by the variable that \nimmediately follows the word DESCENDING in the BY statement."},"StatementOptionType":"S"},{"StatementOptionName":"NOTSORTED","StatementOptionHelp":{"#cdata":"Specifies that observations are not necessarily sorted in alphabetic or numeric order."},"StatementOptionType":"S"}]}},{"StatementName":"CLASS","StatementHelp":{"#cdata":"Syntax: CLASS variable <(v-options)> <variable <(v-options)> ...> </ v-options> ; \n      \nThe CLASS statement names the classification variables to be used in the analysis. The \nCLASS statement must precede the MODEL statement. You can specify various v-options for \neach variable by enclosing them in parentheses after the variable name. You can also \nspecify global v-options for the CLASS statement by placing them after a slash (/). \nGlobal v-options are applied to all the variables specified in the CLASS statement. \nHowever, individual CLASS variable v-options override the global v-options."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CPREFIX=","StatementOptionHelp":{"#cdata":"[Syntax: CPREFIX=n] \n          \nSpecifies that, at most, the first n characters of a CLASS variable name be used \nin creating names for the corresponding dummy variables."},"StatementOptionType":"V"},{"StatementOptionName":"DESCENDING|DESC","StatementOptionHelp":{"#cdata":"Reverses the sorting order of the classification variable."},"StatementOptionType":"S"},{"StatementOptionName":"LPREFIX=","StatementOptionHelp":{"#cdata":"[Syntax: LPREFIX=n] \n          \nSpecifies that, at most, the first n characters of a CLASS variable label be used \nin creating labels for the corresponding design variables."},"StatementOptionType":"V"},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"Specifies the order in which to sort the levels of the classification variables \n(which are specified in the CLASS statement). This option applies to the levels \nfor all classification variables, except when you use the (default) ORDER=FORMATTED \noption with numeric classification variables that have no explicit format. With \nthis option, the levels of such variables are ordered by their internal value."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"StatementOptionToolTips":{"@ToolTip1":"Levels are sorted by the order of appearance in the input data set","@ToolTip2":"Levels are sorted by the external formatted value, except for numeric variables  with no explicit format, which are sorted by their unformatted (internal) value.","@ToolTip3":"Levels are sorted by the descending frequency count; levels with the most observations  come first in the order","@ToolTip4":"Levels are sorted by the unformatted value."}},{"StatementOptionName":"PARAM=","StatementOptionHelp":{"#cdata":"Specifies the parameterization method for the classification variable or variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EFFECT","@Value2":"GLM","@Value3":"ORDINAL","@Value4":"POLYNOMIAL","@Value5":"REFERENCE","@Value6":"ORTHEFFECT","@Value7":"ORTHORDINAL","@Value8":"ORTHPOLY","@Value9":"ORTHREF"},"StatementOptionToolTips":{"@ToolTip1":"Specifies effect coding","@ToolTip2":"Specifies less-than-full-rank, reference-cell coding; this option can be used only as a global option.","@ToolTip3":"Specifies the cumulative parameterization for an ordinal CLASS variable.","@ToolTip4":"Specifies polynomial coding.","@ToolTip5":"Specifies reference-cell coding.","@ToolTip6":"Orthogonalizes PARAM=EFFECT coding.","@ToolTip7":"Orthogonalizes PARAM=ORDINAL coding.","@ToolTip8":"Orthogonalizes PARAM=POLYNOMIAL coding.","@ToolTip9":"Orthogonalizes PARAM=REFERENCE coding."}},{"StatementOptionName":"REF=","StatementOptionHelp":{"#cdata":"[Syntax: REF=\u2019level\u2019 | FIRST | LAST] \n          \nSpecifies the reference level for PARAM=EFFECT, or PARAM=REFERENCE. For an individual \n(but not a global) variable REF= option, you can specify the level of the variable to \nuse as the reference level. For a global or individual variable REF= option, you can \nuse the FIRST or LAST keyword. The default is REF=LAST."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"<\u2019level\u2019>","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"For an individual (but not a global) variable, you can specify the level of the variable to use as  the reference level. Specify the formatted value of the variable if a format is assigned.","@ToolTip2":"For a global or individual variable, designates the first ordered level as reference.","@ToolTip3":"For a global or individual variable, designates the last ordered level as reference."}}]}},{"StatementName":"CLUSTER|CLUSTERS","StatementHelp":{"#cdata":"Syntax: CLUSTER variables ; \n      \nThe CLUSTER statement names variables that identify the clusters in a clustered sample \ndesign. The combinations of categories of CLUSTER variables define the clusters in the \nsample. If there is a STRATA statement, clusters are nested within strata. \n\nIf you provide replicate weights for BRR or jackknife variance estimation with the \nREPWEIGHTS statement, you do not need to specify a CLUSTER statement. \n\nIf your sample design has clustering at multiple stages, you should identify only the \nfirst-stage clusters (primary sampling units (PSUs)), in the CLUSTER statement. \n\nThe CLUSTER variables are one or more variables in the DATA= input data set. These \nvariables can be either character or numeric, but the procedure treats them as categorical \nvariables. The formatted values of the CLUSTER variables determine the CLUSTER variable \nlevels. Thus, you can use formats to group values into levels."},"StatementOptions":null},{"StatementName":"DOMAIN","StatementHelp":{"#cdata":"Syntax: DOMAIN variables <variable*variable variable*variable*variable ... > ; \n      \nThe DOMAIN statement requests analysis for domains (subpopulations), in addition to \nanalysis for the entire study population. The DOMAIN statement names the variables \nthat identify domains, which are called domain variables. \n\nIt is common practice to compute statistics for domains. The formation of these domains \nmight not be known at the design stage. Therefore, the sample sizes for the domains are \noften random. Use a DOMAIN statement to incorporate this variability into the variance \nestimation. \n\nNote that a DOMAIN statement is different from a BY statement. In a BY statement, you \ntreat the sample sizes as fixed in each subpopulation, and you perform analysis within \neach BY group independently."},"StatementOptions":null},{"StatementName":"EFFECT","StatementHelp":{"#cdata":"Syntax: EFFECT effect-name = effect-type (var-list < / effect-options >) ; \n\nThe name of the effect is specified after the EFFECT keyword. This name can appear \nin only one EFFECT statement and cannot be the name of a variable in the input data \nset. The effect-type is specified after an equal sign, followed by a list of variables \nwithin parentheses which are used in constructing the effect. Effect-options that are \nspecific to an effect-type can be specified after a slash (/) following the variable list. \n\nThe EFFECT statement enables you to construct special collections of columns for design \nmatrices. These collections are referred to as constructed effects to distinguish them \nfrom the usual model effects formed from continuous or classification variables."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"EFFECT-NAME=","StatementOptionHelp":{"#cdata":"Replace 'EFFECT-NAME' with the name of the effect, specified after the EFFECT keyword. \nThis name can appear in only one EFFECT statement and cannot be the name of a \nvariable in the input data set."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"COLLECTION","@Value2":"LAG","@Value3":"MULTIMEMBER|MM","@Value4":"POLYNOMIAL|POLY","@Value5":"SPLINE"},"StatementOptionToolTips":{"@ToolTip1":"Is a collection effect that defines one or more variables as a single effect with  multiple degrees of freedom. The variables in a collection are considered as a  unit for estimation and inference.  Option(s) available (specified after a slash (/) following the variable list):   DETAILS  Displays the constituents of the collection effect","@ToolTip2":"Is a classification effect in which the level that is used for a given period  corresponds to the level in the preceding period.   Options available (specified after a slash (/) following the variable list):    DESIGNROLE=    Names a variable that controls to which lag design an observation is assigned     DETAILS    Displays the lag design of the lag effect     NLAG=    Specifies the number of periods in the lag     PERIOD=    Names the variable that defines the period     WITHIN=    Names the variable or variables that define the group within which each period is defined","@ToolTip3":"Is a multimember classification effect whose levels are determined by one or  more variables that appear in a CLASS statement.   Options available (specified after a slash (/) following the variable list):     NOEFFECT    Specifies that observations with all missing levels for the multimember variables should    have zero values in the corresponding design matrix columns     WEIGHT=    Specifies the weight variable for the contributions of each of the classification effects","@ToolTip4":"Is a multivariate polynomial effect in the specified numeric variables.                                      Options available (specified after a slash (/) following the variable list):     DEGREE=    Specifies the degree of the polynomial     MDEGREE=    Specifies the maximum degree of any variable in a term of the polynomial     STANDARDIZE=    Specifies centering and scaling suboptions for the variables that define the polynomial","@ToolTip5":"Is a regression spline effect whose columns are univariate spline expansions of  one or more variables. A spline expansion replaces the original variable with  an expanded or larger set of new variables.   Options available (specified after a slash (/) following the variable list):     BASIS=    Specifies the type of basis (B-spline basis or truncated power function basis) for the spline expansion     DEGREE=    Specifies the degree of the spline transformation     KNOTMETHOD=    Specifies how to construct the knots for spline effects"},"SubOptionsKeywords":"DETAILS|DESIGNROLE=|NLAG=|WITHIN=|NOEFFECT|WEIGHT=|DEGREE=|MDEGREE=|STANDARDIZE=|BASIS=|KNOTMETHOD="},{"StatementOptionName":"PERIOD=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only]\n          \n[Syntax: PERIOD=variable] \n          \nSpecifies the period variable of the LAG design. The number of periods is the number \nof unique formatted values of the PERIOD= variable, and the ordering of the period is \nformed by sorting these formatted values in ascending order. You must specify a PERIOD= \nvariable."},"StatementOptionType":"V"},{"StatementOptionName":"WITHIN=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: WITHIN=(variables) | WITHIN=variable] \n\nSpecifies a variable (or a list of variables within parentheses) that defines the \nsubject grouping of the lag design. If there is only one WITHIN= variable, then the \nparentheses are not required. Each subject is defined by the unique set of formatted \nvalues of the variables in the WITHIN= list. The subjects are sorted in ascending \nlexicographic order. You must specify a WITHIN= variable."},"StatementOptionType":"V"},{"StatementOptionName":"DESIGNROLE=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: DESIGNROLE=variable] \n\nSpecifies a numeric variable that is used to subset observations into a fitting group \nin which the value of the DESIGNROW= variable is nonzero and a second group in which \nthe value of the specified variable is zero. The observations in the fitting group are \nused to form the LAG design matrix that is used in fitting the model. The LAG design \nthat corresponds to the non-fitting group is used when scoring observations in the \ninput data set that do not belong to the fitting group. This option is useful when \nyou want to obtain predicted values in an output data set for observations that are \nnot used in fitting the model. If you do not specify a DESIGNROLE= variable, then all \nobservations are assigned to the fitting group."},"StatementOptionType":"V"},{"StatementOptionName":"DETAILS","StatementOptionHelp":{"#cdata":"[For the LAG | COLLECTION | MULTIMEMBER | POLYNOMIAL |SPLINE effect-type] \n          \nRequests a table that shows the (1) lag design matrix of the lag effect, or (2) constituents \nof the collection effect, or (3) levels of the multimember effect, or (4) details of the specified \npolynomial, or (5) knot locations and the knots associated with each spline basis function."},"StatementOptionType":"S"},{"StatementOptionName":"NLAG=","StatementOptionHelp":{"#cdata":"[For the LAG effect-type only] \n          \n[Syntax: NLAG= n] \n\nSpecifies the number of lags. By default NLAG=1."},"StatementOptionType":"V"},{"StatementOptionName":"NOEFFECT","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \nSpecifies that, for observations with all missing levels of the multimember variables, \nthe values in the corresponding design matrix columns be set to zero."},"StatementOptionType":"S"},{"StatementOptionName":"STDIZE","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \nSpecifies that for each observation, the entries in the design matrix that corresponds \nto the multimember effect be scaled to have a sum of one."},"StatementOptionType":"S"},{"StatementOptionName":"WEIGHT=","StatementOptionHelp":{"#cdata":"[For the MULTIMEMBER effect-type only] \n          \n[Syntax: WEIGHT=wght-list] \n\nSpecifies numeric variables used to weigh the contributions of each of the classification \neffects that define the constructed multimember effect. The number of variables in wght-list \nmust match the number of classification variables that define the effect."},"StatementOptionType":"V"},{"StatementOptionName":"DEGREE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL and SPLINE effect-type only] \n          \n[Syntax: DEGREE=n] \n\nSpecifies the (1) degree of the polynomial, or (2) degree of the spline transformation. \nThe degree must be a positive integer. The n degree is typically a small integer, such as \n1, 2, or 3. The default for polynomial effect is DEGREE=1, and DEGREE=3 for spline \ntransformation."},"StatementOptionType":"V"},{"StatementOptionName":"LABELSTYLE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: LABELSTYLE=(style-opts) | LABELSTYLE=style-opt] \n\nSpecifies how the terms in the polynomial are labeled. By default, powers are shown \nwith ^ as the exponentiation operator and * as the multiplication operator."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EXPAND","@Value2":"EXPONENT","@Value3":"INCLUDENAME","@Value4":"PRODUCTSYMBOL="},"StatementOptionToolTips":{"@ToolTip1":"Specifies that each variable with an exponent greater than 1 be written as products of that variable.","@ToolTip2":"Syntax: EXPONENT <=quoted string>                                      Specifies that each variable with an exponent greater than 1 be written using exponential  notation. By default, the symbol ^ is used as the exponentiation operator. If you supply the  optional quoted string after an equal sign, then that string is used as the exponentiation  operator.","@ToolTip3":"Specifies that the name of the effect followed by an underscore be used as a prefix  for term labels.","@ToolTip4":"Syntax: PRODUCTSYMBOL=NONE | quoted string                                      Specifies that the supplied string be used as the product symbol."}},{"StatementOptionName":"MDEGREE=","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: MDEGREE=n] \n\nSpecifies the maximum degree of any variable in a term of the polynomial. This degree \nmust be a positive integer. The default is the degree of the specified polynomial."},"StatementOptionType":"V"},{"StatementOptionName":"NOSEPARATE","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \nSpecifies that the polynomial be treated as a single effect with multiple degrees \nof freedom. The effect name that you specify is used as the constructed effect name, \nand the labels of the terms are used as labels of the corresponding parameters."},"StatementOptionType":"S"},{"StatementOptionName":"STANDARDIZE","StatementOptionHelp":{"#cdata":"[For the POLYNOMIAL effect-type only] \n          \n[Syntax: STANDARDIZE <(centerscale-opts)> <= standardize-opt>] \n\nSpecifies that the variables that define the polynomial be standardized. By default, \nthe standardized variables receive prefix \"s_\" in the variable names. \n\nYou can use the following centerscale-opts to specify how the center and scale are estimated: \n\n  METHOD=MOMENTS \n  specifies that the center be estimated by the variable mean and the scale be estimated by the standard deviation. \n\n  METHOD=RANGE \n  specifies that the center be estimated by the midpoint of the variable range and the scale be estimated as half the variable range.\n\n  METHOD=WMOMENTS \n  is the same as METHOD=MOMENTS except that weighted means and weighted standard deviations are used. \n\n  PREFIX=NONE | quoted-string \n  specifies the prefix that is appended to standardized variables when forming the term labels."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"CENTER","@Value2":"CENTERSCALE","@Value3":"NONE","@Value4":"SCALE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies that variables be centered but not scaled.","@ToolTip2":"Specifies that variables be centered and scaled. This is the default if you do not  specify a standardization-opt.","@ToolTip3":"Specifies that no standardization be performed.","@ToolTip4":"Specifies that variables be scaled but not centered."}},{"StatementOptionName":"BASIS=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies a basis for the spline expansion."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BSPLINE","@Value2":"TPF"},"StatementOptionToolTips":{"@ToolTip1":"Specifies a B-spline basis for the spline expansion.","@ToolTip2":"Syntax: TPF(options)                                      Specifies a truncated power function basis for the spline expansion.   You can modify the number of columns when you request BASIS=TPF with the following options:     NOINT    excludes the intercept column.     NOPOWERS    excludes the intercept and polynomial columns."}},{"StatementOptionName":"DATABOUNDARY","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only]\n          \nSpecifies that the extremes of the data be used as boundary knots when building a B-spline basis."},"StatementOptionType":"S"},{"StatementOptionName":"KNOTMAX=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only]\n          \n[Syntax: KNOTMAX=value] \n\nSpecifies that, for each variable in the EFFECT statement, the right-side boundary \nknots be equally spaced starting at the maximum of the variable and ending at the \nspecified value. This option is ignored for variables whose maximum value is greater \nthan the specified value or if the DATABOUNDARY option is also specified."},"StatementOptionType":"V"},{"StatementOptionName":"KNOTMETHOD=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies how to construct the knots for spline effects."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"EQUAL","@Value2":"LIST","@Value3":"LISTWITHBOUNDARY","@Value4":"MULTISCALE","@Value5":"PERCENTILES","@Value6":"RANGEFRACTIONS"},"StatementOptionToolTips":{"@ToolTip1":"Syntax: EQUAL<(n)>               Specifies that n equally spaced knots be positioned between the extremes of the data.  The default is n=3. For a B-spline basis, any needed boundary knots continue to be  equally spaced unless the DATABOUNDARY option has also been specified. KNOTMETHOD=EQUAL  is the default if no knot-method is specified.","@ToolTip2":"Syntax: LIST(number-list)                                      Specifies the list of internal knots to be used in forming the spline basis columns.  For a B-spline basis, the data extremes are used as boundary knots.","@ToolTip3":"Syntax: LISTWITHBOUNDARY(number-list)                                      Specifies the list of all knots that are used in forming the spline basis columns.","@ToolTip4":"Syntax: MULTISCALE<(multiscale-options)>                                      Specifies that multiple B-spline bases be generated, corresponding to sets with an  increasing number of internal knots.   You can control which scales are included with the following multiscale-options:     STARTSCALE=n    specifies the start scale, where n is a positive integer. The default is STARTSCALE=0.     ENDSCALE=n    specifies the end scale, where n is a positive integer. The default is ENDSCALE=7.","@ToolTip5":"Syntax: PERCENTILES(n)                                      Requests that internal knots be placed at n equally spaced percentiles of the variable  or variables named in the EFFECT statement.","@ToolTip6":"Syntax: RANGEFRACTIONS(fraction-list)                                      Requests that internal knots be placed at each fraction of the ranges of the variables  in the EFFECT statement."}},{"StatementOptionName":"KNOTMIN=","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \n[Syntax: KNOTMIN=value] \n\nSpecifies that for each variable in the EFFECT statement, the left-side boundary knots be \nequally spaced starting at the specified value and ending at the minimum of the variable. \nThis option is ignored for variables whose minimum value is less than the specified value \nor if the DATABOUNDARY option is also specified."},"StatementOptionType":"V"},{"StatementOptionName":"SEPARATE","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies that when multiple variables are specified in the EFFECT statement, \nthe spline basis for each variable be treated as a separate effect. The names \nof these separated effects are formed by appending an underscore followed by \nthe name of the variable to the name that you specify in the EFFECT statement."},"StatementOptionType":"S"},{"StatementOptionName":"SPLIT","StatementOptionHelp":{"#cdata":"[For the SPLINE effect-type only] \n          \nSpecifies that each individual column in the design matrix that corresponds to the spline \neffect be treated as a separate effect that can enter or leave the model independently. \nNames for these split effects are generated by appending the variable name and an index \nfor each column to the name that you specify in the EFFECT statement."},"StatementOptionType":"S"}]}},{"StatementName":"ESTIMATE","StatementHelp":{"#cdata":"Syntax: ESTIMATE <'label'> estimate-specification <(divisor=n)>\n  <, ...<'label'> estimate-specification <(divisor=n)> >\n  < / options> ; \n  \nThe ESTIMATE statement provides a mechanism for obtaining custom hypothesis tests. \nEstimates are formed as linear estimable functions of the form L\u03b2. You can perform \nhypothesis tests for the estimable functions, construct confidence limits, and obtain \nspecific nonlinear transformations. \n\nThe basic element of the ESTIMATE statement is the estimate-specification, which consists \nof model effects and their coefficients. A estimate-specification takes the general form \n\n  effect name <effect values ...> \n  \nThe following variables can appear in the ESTIMATE statement: \n\n  label \n  is an optional label that identifies the particular row of the estimate in the output. \n\n  effect \n  identifies an effect that appears in the MODEL statement. The keyword INTERCEPT can be \n  used as an effect when an intercept is fitted in the model. You do not need to include \n  all effects that are in the MODEL statement. \n\n  values \n  are constants that are elements of the L matrix and are associated with the fixed and random effects."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \n  limits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator    degrees of freedom for the final effect listed in the ESTIMATE statement from the 'Type    III' table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees    of freedom are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the estimates."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE<(simoptions)>","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum    or maximum absolute value of a multivariate t random vector.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."}},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed with confidence level 1-number.  \nThe value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F or chi-square tests with the JOINT option. \n\nThe category-options are used to indicate how response variable levels are treated in \nconstructing the estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row ESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row ESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed. If the procedure shows the degrees \nof freedom in the \"Estimates\" table as infinite, then the confidence limits are z intervals. \nThe confidence level is 0.95 by default, and you can change the confidence level with the \nALPHA= option. The confidence intervals are adjusted for multiplicity when you specify the \nADJUST= option. However, if a step-down p-value adjustment is requested with the STEPDOWN \noption, only the p-values are adjusted for multiplicity."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. This option \nis not supported by the procedures that perform chi-square-based inference (LOGISTIC, \nPHREG, and SUVEYLOGISTIC)."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0. \n\nIf the number of elements in value-list exceeds the number of rows of the estimate, the \nextra values are ignored. If the number of elements in value-list is less than the number \nof rows of the estimate, the last value in value-list is copied forward. \n\nIf you specify a row-specific divisor as part of the specification of the estimate row, \nthis value multiplies the corresponding divisor that is implied by the value-list. For \nexample, the following statement divides the coefficients in the first row by 8, and the \ncoefficients in the third and fourth row by 3: \n\n  estimate 'One vs. two'   A 2 -2  (divisor=2),\n           'One vs. three' A 1  0 -1         ,\n           'One vs. four'  A 3  0  0 -3      ,\n           'One vs. five'  A 1  0  0  0  -1  / divisor=4,.,3;\n\nCoefficients in the second row are not altered."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the estimate. When you model data with the logit, cumulative \nlogit, or generalized logit link functions, and the estimate represents a log odds ratio \nor log cumulative odds ratio, the EXP option produces an odds ratio. In proportional hazards \nmodel, this option produces estimates of hazard ratios. If you specify the CL or ALPHA= option, \nthe (adjusted) confidence bounds are also exponentiated. \n\nThe EXP option is supported only by PROC PHREG, PROC SURVEYPHREG, the procedures that support \ngeneralized linear modeling (LOGISTIC and SURVEYLOGISTIC), and by PROC PLM when it is used to \nperform statistical analyses on item stores created by these procedures."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the mean \n(the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \nThe JOINT option in the ESTIMATE statement essentially replaces the CONTRAST statement. \n\nWhen the LOWERTAILED or the UPPERTAILED options are in effect, or if the BOUNDS option \ndescribed below is in effect, the JOINT option produces the chi-bar-square statistic \naccording to Silvapulle and Sen (2004). This statistic uses a simulation-based approach \nto compute p-values in situations where the alternative hypotheses of the estimable \nfunctions are not simple two-sided hypotheses. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004).   \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option. "},"StatementOptionType":"S"},{"StatementOptionName":"NOFILL","StatementOptionHelp":{"#cdata":"Suppresses the automatic fill-in of coefficients of higher-order effects."},"StatementOptionType":"V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Produces all possible plots with their default settings.","@ToolTip2":"Syntax: BOXPLOT<(boxplot-options)>                                      Produces box plots of the distribution of the estimable function across the posterior  sample. A separate box is generated for each estimable function, and all boxes appear  on a single graph by default. You can affect the appearance of the box plot graph with  the following options:     ORIENTATION=VERTICAL|HORIZONTAL    ORIENT=VERT|HORIZ    specifies the orientation of the boxes. The default is vertical orientation of the box plots.     NPANELPOS=number    specifies how to break the series of box plots across multiple panels. If the NPANELPOS option    is not specified, or if number equals zero, then all box plots are displayed in a single graph;    this is the default.","@ToolTip3":"Syntax: DISTPLOT<(distplot-options)>                                      Generates panels of histograms with a kernel density overlaid. A separate plot in each  panel contains the results for each estimable function. You can specify the following  distplot-options in parentheses:     BOX|NOBOX    controls the display of a horizontal box plot of the estimable function\u2019s distribution    across the posterior sample below the graph. The BOX option is enabled by default.     HIST|NOHIST    controls the display of the histogram of the estimable function\u2019s distribution across the    posterior sample. The HIST option is enabled by default.     NORMAL|NONORMAL    controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.     KERNEL|NOKERNEL    controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.     NROWS=number    specifies the highest number of rows in a panel. The default is 3.     NCOLS=number    specifies the highest number of columns in a panel. The default is 3.     UNPACK    unpacks the panel into separate graphics.","@ToolTip4":"Does not produce any plots."},"SubOptionsKeywords":"BOX|NOBOX|HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK"},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the \nESTIMATE statement (for example, chi-bar-square statistics and simulated p-values). \nnumber specifies an integer that is used to start the pseudo-random number generator \nfor the simulation. If you do not specify a seed, or if you specify a value less than \nor equal to zero, the seed is generated from reading the time of day from the computer \nclock. There could be multiple ESTIMATE statements with SEED= specifications and there \ncould be other statements that can supply a random number seed. Since the procedure has \nonly one random number stream, the initial seed is shown in the SAS log."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant. \n\nYou can specify the following step-down-options in parentheses after the STEPDOWN option: \n\n  MAXTIME=n \n  specifies the time (in seconds) to be spent computing the maximal logically consistent \n  sequential subsets of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60. \n\n  ORDER=PVALUE | ORDER=ROWS   \n  specifies the order in which the step-down tests to be performed. ORDER=PVALUE is the default, \n  with estimates being declared significant only if all estimates with smaller (unadjusted) \n  p-values are significant. If you specify ORDER=ROWS, then significances are evaluated in the \n  order in which they are specified in the syntax. \n\n  REPORT \n  specifies that a report on the step-down adjustment be displayed, including a listing of the \n  sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n  TYPE=LOGICAL<(n)> | TYPE=FREE \n  specifies how step-down adjustment are made. If you specify TYPE=LOGICAL, the step-down \n  adjustments are computed by using maximal logically consistent sequential subsets of equality \n  hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, sequential subsets are \n  computed ignoring logical constraints. The TYPE=FREE results are more conservative than those \n  for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. For example, \n  it is not feasible to take logical constraints between all pairwise comparisons of more than about \n  10 groups. For this reason, TYPE=FREE is the default."},"StatementOptionType":"S"},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nESTIMATE statement. The rules for specifying the value-list are very similar to those for \nspecifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"FREQ|FREQUENCY","StatementHelp":{"#cdata":"Syntax: FREQ variable ; \n      \nThe variable in the FREQ statement identifies a variable that contains the frequency \nof occurrence of each observation. PROC SURVEYLOGISTIC treats each observation as if \nit appears n times, where n is the value of the FREQ variable for the observation. If \nit is not an integer, the frequency value is truncated to an integer. If the frequency \nvalue is less than 1 or missing, the observation is not used in the model fitting. \nWhen the FREQ statement is not specified, each observation is assigned a frequency \nof 1. \n\nIf you use the events/trials syntax in the MODEL statement, the FREQ statement is not \nallowed because the event and trial variables represent the frequencies in the data set."},"StatementOptions":null},{"StatementName":"LSMEANS","StatementHelp":{"#cdata":"Syntax: LSMEANS <model-effects> </ options> ; \n      \nThe LSMEANS statement computes and compares least squares means (LS-means) of fixed \neffects. LS-means are predicted population margins\u2014that is, they estimate the marginal \nmeans over a balanced population. In a sense, LS-means are to unbalanced designs as \nclass and subclass arithmetic means are to balanced designs."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified LSMEANS effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the LSMEANS effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the LSMEANS statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the LSMEANS \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="}]}},{"StatementName":"LSMESTIMATE","StatementHelp":{"#cdata":"Syntax: LSMESTIMATE model-effect <'label'> values <divisor=> \n  <, ...<'label'> values <divisor=>>\n  < / options> ; \n  \nThe LSMESTIMATE statement provides a mechanism for obtaining custom hypothesis \ntests among least squares means."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees of  freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across estimates."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the \nLS-mean estimates. The adjusted quantities are produced in addition to the unadjusted \np-values and confidence limits. Adjusted confidence limits are produced if the CL or \nALPHA= option is in effect."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"SCHEFFE","@Value3":"SIDAK","@Value4":"SIMULATE","@Value5":"T"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Scheffe's adjustment","@ToolTip3":"Sidak adjustment","@ToolTip4":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip5":"The default, which really signifies no adjustment for multiple comparisons."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means with \nconfidence level 1-number. The value of number must be between 0 and 1; the default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates used in computing LS-means. By default, all \ncovariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that the procedure compute separate margins for each level of the LSMEANS effect."},"StatementOptionType":"S"},{"StatementOptionName":"CATEGORY=","StatementOptionHelp":{"#cdata":"Specifies how to construct estimates and multiplicity corrections for models with \nmultinomial data (ordinal or nominal). This option is also important for constructing \nsets of estimable functions for F tests with the JOINT option. \n\nThe category-options indicate how response variable levels are treated in constructing \nthe estimable functions."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"JOINT","@Value2":"SEPARATE","@Value3":"<quoted-value-list>"},"StatementOptionToolTips":{"@ToolTip1":"Computes the estimable functions for every nonredundant category and treats them as a set.  For example, a three-row LSESTIMATE statement in a model with three response categories  leads to six estimable functions.","@ToolTip2":"Computes the estimable functions for every nonredundant category in turn. For example,  a three-row LSESTIMATE statement in a model with three response categories leads to two  sets of three estimable functions.","@ToolTip3":"Computes the estimable functions only for the list of values given. The list must consist  of formatted values of the response categories."}},{"StatementOptionName":"CHISQ","StatementOptionHelp":{"#cdata":"Requests that chi-square tests be performed in addition to F tests, when you request \nan F test with the JOINT option. This option has no effect in procedures that produce \nchi-square statistics by default."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. \nThe confidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the linear combination of the least \nsquares means."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits."},"StatementOptionType":"V"},{"StatementOptionName":"DIVISOR=","StatementOptionHelp":{"#cdata":"[Syntax: DIVISOR=value-list] \n          \nSpecifies a list of values by which to divide the coefficients so that fractional \ncoefficients can be entered as integer numerators. If you do not specify value-list, \na default value of 1.0 is assumed. Missing values in the value-list are converted to 1.0."},"StatementOptionType":"V"},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L coefficients of the estimable function be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"ELSM","StatementOptionHelp":{"#cdata":"Requests that the K matrix coefficients be displayed. These are the coefficients \nthat apply to the LS-means. This option is useful to ensure that you assigned the \ncoefficients correctly to the LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the least squares means estimate. When you model data \nwith the logit link function and the estimate represents a log odds ratio, the \nEXP option produces an odds ratio. If you specify the CL or ALPHA= option, the \n(adjusted) confidence limits for the estimate are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that the estimate and its standard error are also reported on the scale of the \nmean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"JOINT","StatementOptionHelp":{"#cdata":"[Syntax: JOINT<(joint-test-options)>] \n          \nRequests that a joint F or chi-square test be produced for the rows of the estimate. \n\nYou can specify the following joint-test-options in parentheses: \n\n  ACC=\u03b3 \n  specifies the accuracy radius for determining the necessary sample size in the simulation-based \n  approach of Silvapulle and Sen (2004) for tests with order restrictions. The value of \u03b3 must be \n  strictly between 0 and 1; the default value is 0.005. \n\n  EPS=\u0454\n  specifies the accuracy confidence level for determining the necessary sample size in the \n  simulation-based approach of Silvapulle and Sen (2004) for tests with order restrictions. \n  The value of \u0454 must be strictly between 0 and 1; the default value is 0.01. \n\n  LABEL='label' \n  assigns an identifying label to the joint test. If you do not specify a label, the first \n  non-default label for the ESTIMATE rows is used to label the joint test. \n\n  NOEST | ONLY \n  performs only the F or chi-square test and suppresses other results from the ESTIMATE statement. \n  This option is useful for emulating the CONTRAST statement that is available in other procedures. \n\n  NSAMP=n \n  specifies the number of samples for the simulation-based method of Silvapulle and Sen (2004). \n\n  CHISQ --  adds a chi-square test if the procedure produces an F test by default. \n\n  BOUNDS=value-list --  specifies boundary values for the estimable linear function."},"StatementOptionType":"V","SubOptionsKeywords":"ACC=|EPS=|LABEL=|NOEST|ONLY|NSAMP=|CHISQ|BOUNDS="},{"StatementOptionName":"LOWER|LOWERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values less than the test \nstatistic. A two-tailed test is the default. A lower-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to \nthose found in the OM-data-set. This adjustment is reasonable when you want your \ninferences to apply to a population that is not necessarily balanced but has the \nmargins observed in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PLOTS=","StatementOptionHelp":{"#cdata":"Syntax: PLOTS=plot-options \n          \nProduces ODS statistical graphics of the distribution of estimable functions if the \nprocedure performs the analysis in a sampling-based mode."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"BOXPLOT","@Value3":"DISTPLOT|DIST","@Value4":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this LSMEANS statement be produced.","@ToolTip2":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip3":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip4":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|HIST|NOHIST|\n            NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking as documented for the ESTIMATE statement."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down-options)>] \n          \nRequests that multiplicity adjustments for the p-values of estimates be further adjusted \nin a step-down fashion. Step-down methods increase the power of multiple testing procedures \nby taking advantage of the fact that a p-value is never declared significant unless all \nsmaller p-values are also declared significant.\n\nYou can specify the following step-down-options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential subsets \n    of equality hypotheses for TYPE=LOGICAL. The default is MAXTIME=60.\n\n    ORDER=PVALUE \n    ORDER=ROWS \n    specifies the order in which the step-down tests are performed. ORDER=PVALUE is the default, with LS-mean\n    estimates being declared significant only if all LS-mean estimates with smaller (unadjusted) p-values are\n    significant. If you specify ORDER=ROWS, then significances are evaluated in the order in which they are specified. \n\n    REPORT \n    specifies that a report on the step-down adjustment be displayed, including a listing of the sequential \n    subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results. \n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically consistent \n    sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, for TYPE=FREE, \n    sequential subsets are computed ignoring logical constraints. The TYPE=FREE results are more conservative \n    than those for TYPE=LOGICAL, but they can be much more efficient to produce for many estimates. Default: TYPE=FREE."},"StatementOptionType":"S"},{"StatementOptionName":"TESTVALUE=|TESTMEAN=","StatementOptionHelp":{"#cdata":"[Syntax: TESTVALUE=value-list] \n          \nSpecifies the value under the null hypothesis for testing the estimable functions in the \nLSMESTIMATE statement. The rules for specifying the value-list are very similar to those  \nfor specifying the divisor list in the DIVISOR= option. If no TESTVALUE= is specified, all \ntests are performed as H: L\u03b2=0. Missing values in the value-list also are translated to zeros. \nIf you specify fewer values than rows in the ESTIMATE statement, the last value in value-list \nis carried forward. \n\nThe TESTVALUE= option affects only p-values from individual, joint, and multiplicity-adjusted \ntests. It does not affect confidence intervals. \n\nThe TESTVALUE option is not available for the multinomial distribution, and the values are \nignored when you perform a sampling-based (Bayesian) analysis."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER|UPPERTAILED","StatementOptionHelp":{"#cdata":"Requests that the p-value for the t test be based only on values greater than the test \nstatistic. A two-tailed test is the default. An upper-tailed confidence limit is also \nproduced if you specify the CL or ALPHA= option."},"StatementOptionType":"S"}]}},{"StatementName":"MODEL","StatementHelp":{"#cdata":"Syntax: MODEL events/trials = <effects < / options>> ; \n  \n  MODEL variable <(v-options)> = <effects> < / options> ; \n\nThe MODEL statement names the response variable and the explanatory effects, including covariates, \nmain effects, interactions, and nested effects. Model options can be specified after a slash (/). \n\nTwo forms of the MODEL statement can be specified. The first form, referred to as single-trial \nsyntax, is applicable to binary, ordinal, and nominal response data. The second form, referred \nto as events/trials syntax, is restricted to the case of binary response data. The single-trial \nsyntax is used when each observation in the DATA= data set contains information about only a \nsingle trial, such as a single subject in an experiment. When each observation contains information \nabout multiple binary-response trials, such as the counts of the number of subjects observed and \nthe number responding, then events/trials syntax can be used. \n\nIn the events/trials syntax, you specify two variables that contain count data for a binomial \nexperiment. These two variables are separated by a slash. The value of the first variable, events, \nis the number of positive responses (or events), and it must be nonnegative. The value of the \nsecond variable, trials, is the number of trials, and it must not be less than the value of events. \n\nIn the single-trial syntax, you specify one variable (on the left side of the equal sign) as the \nresponse variable. This variable can be character or numeric. Options specific to the response \nvariable can be specified immediately after the response variable with parentheses around them. \n\nFor both forms of the MODEL statement, explanatory effects follow the equal sign. Variables can \nbe either continuous or classification variables. Classification variables can be character or \nnumeric, and they must be declared in the CLASS statement. When an effect is a classification \nvariable, the procedure enters a set of coded columns into the design matrix instead of directly \nentering a single column containing the values of the variable."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DESCENDING|DESC","StatementOptionHelp":{"#cdata":"[response variable option] \n          \nReverses the order of the response categories."},"StatementOptionType":"RS"},{"StatementOptionName":"EVENT=","StatementOptionHelp":{"#cdata":"[response variable option] \n          \n[Syntax: EVENT=\u2019category\u2019|FIRST|LAST] \n\nSpecifies the event category for the binary response model."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"<\u2019category\u2019>","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"Replace \u2019category\u2019 with an actual event category.","@ToolTip2":"Designates the first ordered category as the event.","@ToolTip3":"Designates the last ordered category as the event. This is the default."}},{"StatementOptionName":"ORDER=","StatementOptionHelp":{"#cdata":"[response variable option] \n          \nSpecifies the sorting order for the levels of the response variable."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"DATA","@Value2":"FORMATTED","@Value3":"FREQ","@Value4":"INTERNAL"},"StatementOptionToolTips":{"@ToolTip1":"Levels are sorted by the order of appearance in the input data set.","@ToolTip2":"Levels are sorted by the external formatted value, except for numeric variables with no  explicit format, which are sorted by their unformatted (internal) value.","@ToolTip3":"Levels are sorted by the Descending frequency count; levels with the most observations  come first in the order.","@ToolTip4":"Levels are sorted by the unformatted value."}},{"StatementOptionName":"REFERENCE=|REF=","StatementOptionHelp":{"#cdata":"[response variable option] \n          \nSyntax: REFERENCE=\u2019category\u2019 | keyword \n\nSpecifies the reference category for the generalized logit model and the binary \nresponse model. The default is REF=LAST."},"StatementOptionType":"RV","StatementOptionValues":{"@Value1":"\u2019category\u2019","@Value2":"FIRST","@Value3":"LAST"},"StatementOptionToolTips":{"@ToolTip1":"Replace <\u2019category\u2019> with an actual value (formatted if a format is applied) of the   reference category in quotes.","@ToolTip2":"Designates the first ordered category as the reference category.","@ToolTip3":"Designates the last ordered category as the reference category. This is the default."}},{"StatementOptionName":"ABSFCONV=","StatementOptionHelp":{"#cdata":"[Syntax: ABSFCONV=value] \n          \nSpecifies the absolute function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nSets the level of significance \u03b1 for 100(1 - \u03b1)% confidence intervals for regression \nparameters or odds ratios. The value \u03b1 must be between 0 and 1. By default, \u03b1 is equal \nto the value of the ALPHA= option in the PROC SURVEYLOGISTIC statement, or \u03b1=0.05 if \nthe ALPHA= option is not specified. This option has no effect unless confidence limits \nfor the parameters or odds ratios are requested."},"StatementOptionType":"V"},{"StatementOptionName":"CLODDS","StatementOptionHelp":{"#cdata":"Requests confidence intervals for the odds ratios. Computation of these confidence \nintervals is based on individual Wald tests. The confidence coefficient can be \nspecified with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CLPARM","StatementOptionHelp":{"#cdata":"Requests confidence intervals for the parameters."},"StatementOptionType":"S"},{"StatementOptionName":"CORRB","StatementOptionHelp":{"#cdata":"Displays the correlation matrix of the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"COVB","StatementOptionHelp":{"#cdata":"Displays the covariance matrix of the parameter estimates."},"StatementOptionType":"S"},{"StatementOptionName":"EXPB|EXPEST","StatementOptionHelp":{"#cdata":"Displays the exponentiated values of the parameter estimates in the \"Analysis of \nMaximum Likelihood Estimates\" table for the logit model."},"StatementOptionType":"S"},{"StatementOptionName":"FCONV=","StatementOptionHelp":{"#cdata":"[Syntax: FCONV=value] \n          \nSpecifies the relative function convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"GCONV=","StatementOptionHelp":{"#cdata":"[Syntax: GCONV=value] \n          \nSpecifies the relative gradient convergence criterion."},"StatementOptionType":"V"},{"StatementOptionName":"ITPRINT","StatementOptionHelp":{"#cdata":"Displays the iteration history of the maximum-likelihood model fitting. The ITPRINT \noption also displays the last evaluation of the gradient vector and the final change \nin the -2logL."},"StatementOptionType":"S"},{"StatementOptionName":"LINK=|L=","StatementOptionHelp":{"#cdata":"Specifies the link function that links the response probabilities to the linear predictors."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"CLOGLOG","@Value2":"GLOGIT","@Value3":"LOGIT","@Value4":"PROBIT"},"StatementOptionToolTips":{"@ToolTip1":"Specifies the complementary log-log function.","@ToolTip2":"Specifies the generalized logit function.","@ToolTip3":"Specifies the cumulative ogit function.","@ToolTip4":"Specifies the inverse standard normal distribution function."}},{"StatementOptionName":"MAXITER=","StatementOptionHelp":{"#cdata":"[Syntax: MAXITER=n] \n          \nSpecifies the maximum number of iterations to perform. By default, MAXITER=25. \nIf convergence is not attained in n iterations, the displayed output created by \nthe procedure contains results that are based on the last maximum likelihood \niteration."},"StatementOptionType":"V"},{"StatementOptionName":"NOCHECK","StatementOptionHelp":{"#cdata":"Disables the checking process to determine whether maximum likelihood estimates of the \nregression parameters exist. If you are sure that the estimates are finite, this option \ncan reduce the execution time when the estimation takes more than eight iterations."},"StatementOptionType":"S"},{"StatementOptionName":"NODUMMYPRINT","StatementOptionHelp":{"#cdata":"Suppresses the \"Class Level Information\" table, which shows how the design matrix \ncolumns for the CLASS variables are coded."},"StatementOptionType":"S"},{"StatementOptionName":"NOINT","StatementOptionHelp":{"#cdata":"Suppresses the intercept for the binary response model or the first intercept for \nthe ordinal response model."},"StatementOptionType":"S"},{"StatementOptionName":"OFFSET=","StatementOptionHelp":{"#cdata":"[Syntax: OFFSET=name] \n          \nNames the offset variable. The regression coefficient for this variable is fixed at 1."},"StatementOptionType":"V"},{"StatementOptionName":"PARMLABEL","StatementOptionHelp":{"#cdata":"Displays the labels of the parameters in the \"Analysis of Maximum Likelihood Estimates\" table."},"StatementOptionType":"S"},{"StatementOptionName":"RIDGING=","StatementOptionHelp":{"#cdata":"Specifies the technique used to improve the log-likelihood function when its value in the current \niteration is less than that in the previous iteration."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ABSOLUTE","@Value2":"RELATIVE","@Value3":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"The diagonal elements of the negative (expected) Hessian are inflated by adding the ridge value.","@ToolTip2":"The diagonal elements are inflated by a factor of 1 plus the ridge value. This is the default.","@ToolTip3":"The crude line search method of taking half a step is used instead of ridging."}},{"StatementOptionName":"RSQUARE","StatementOptionHelp":{"#cdata":"Requests a generalized R\u00b2 measure for the fitted model."},"StatementOptionType":"S"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=value] \n          \nSpecifies the tolerance for testing the singularity of the Hessian matrix (Newton-Raphson \nalgorithm) or the expected value of the Hessian matrix (Fisher scoring algorithm)."},"StatementOptionType":"V"},{"StatementOptionName":"STB","StatementOptionHelp":{"#cdata":"Displays the standardized estimates for the parameters for the continuous explanatory variables \nin the \"Analysis of Maximum Likelihood Estimates\" table."},"StatementOptionType":"S"},{"StatementOptionName":"TECHNIQUE=","StatementOptionHelp":{"#cdata":"Specifies the optimization technique for estimating the regression parameters."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"FISHER","@Value2":"NEWTON"},"StatementOptionToolTips":{"@ToolTip1":"Fisher scoring algorithm","@ToolTip2":"Newton-Raphson algorithm"}},{"StatementOptionName":"VADJUST=","StatementOptionHelp":{"#cdata":"Specifies an adjustment to the variance estimation for the regression coefficients."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"DF","@Value2":"VADJUST=","@Value3":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Specifies to use the degrees of freedom adjustment.","@ToolTip2":"Syntax: VADJUST=MOREL <(Morel-options)>                                     Specifies to use the variance adjustment proposed by Morel (1989).   You can specify the following Morel-options within parentheses after the VADJUST=MOREL option:     ADJBOUND=\u03c6    sets the upper bound coefficient \u03c6 in the variance adjustment. This upper bound must be positive.    By default, the procedure uses \u03c6=0.5.      DEFFBOUND=\u03b4   sets the lower bound of the estimated design effect in the variance adjustment. This lower bound    must be positive. By default, the procedure uses \u03b4=1.","@ToolTip3":"Specifies not to use any variance adjustment."}},{"StatementOptionName":"XCONV=","StatementOptionHelp":{"#cdata":"[Syntax: XCONV=value] \n          \nSpecifies the relative parameter convergence criterion."},"StatementOptionType":"V"}],"#comment":{}}},{"StatementName":"OUTPUT","StatementHelp":{"#cdata":"Syntax: OUTPUT <OUT=SAS-data-set> <options> < / option> ; \n      \nThe OUTPUT statement creates a new SAS data set that contains all the variables in the \ninput data set and, optionally, the estimated linear predictors and their standard error \nestimates, the estimates of the cumulative or individual response probabilities, and the \nconfidence limits for the cumulative probabilities."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"LOWER=|L=","StatementOptionHelp":{"#cdata":"[Syntax: LOWER=name] \n          \nNames the variable that contains the lower confidence limits for \u03c0, where \u03c0 is the \nprobability of the event response if events/trials syntax or single-trial syntax \nwith binary response is specified."},"StatementOptionType":"V"},{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"[Syntax: OUT=SAS-data-set] \n          \nNames the output data set. If you omit the OUT= option, the output data set is created \nand given a default name by using the DATAn convention. The statistic options in the \nOUTPUT statement specify the statistics to be included in the output data set and name \nthe new variables that contain the statistics."},"StatementOptionType":"DV"},{"StatementOptionName":"PREDICTED=|P=","StatementOptionHelp":{"#cdata":"Names the variable that contains the predicted probabilities. For the events/trials \nsyntax or the single-trial syntax with binary response, it is the predicted event \nprobability. For a cumulative model, it is the predicted cumulative probability \n(that is, the probability that the response variable is less than or equal to the \nvalue of _LEVEL_); and for the generalized logit model, it is the predicted individual \nprobability (that is, the probability of the response category represented by the \nvalue of _LEVEL_)."},"StatementOptionType":"V"},{"StatementOptionName":"PREDPROBS=","StatementOptionHelp":{"#cdata":"Requests individual, cumulative, or cross validated predicted probabilities."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"(INDIVIDUAL CUMULATIVE)|(I C)","@Value2":"(INDIVIDUAL CROSSVALIDATE)|(I X)","@Value3":"(CUMULATIVE CROSSVALIDATE)|(C X)","@Value4":"(INDIVIDUAL CUMULATIVE CROSSVALIDATE)|(I C X)"},"StatementOptionToolTips":{"@ToolTip1":"Requests the predicted probability and cumulative predicted probability of each response level.","@ToolTip2":"Requests the predicted probability and cross validated individual predicted probability of each  response level.","@ToolTip3":"Requests the cumulative predicted probability and cross validated individual predicted probability  of each response level.","@ToolTip4":"Requests the predicted probability, cumulative predicted probability, and cross validated individual  predicted probability of each response level."}},{"StatementOptionName":"STDXBETA=","StatementOptionHelp":{"#cdata":"[Syntax: STDXBETA=name] \n          \nNames the variable that contains the standard error estimates of XBETA."},"StatementOptionType":"V"},{"StatementOptionName":"UPPER=|U=","StatementOptionHelp":{"#cdata":"[Syntax: UPPER=name] \n          \nNames the variable containing the upper confidence limits for \u03c0, where \u03c0 is the probability of the event response if events/trials syntax \nor single-trial syntax with binary response is specified."},"StatementOptionType":"V"},{"StatementOptionName":"XBETA=","StatementOptionHelp":{"#cdata":"[Syntax: XBETA=name] \n          \nNames the variable that contains the estimates of the linear predictor \u03b1i + \u03b2'x, \nwhere i is the corresponding ordered value of _LEVEL_."},"StatementOptionType":"V"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=\u03b1] \n          \nSets the level of significance \u03b1 for 100(1-\u03b1)% limits for the appropriate response \nprobabilities. The value \u03b1 must be between 0 and 1. By default, \u03b1 is equal to the \nvalue of the ALPHA= option in the PROC SURVEYLOGISTIC statement, or 0.05 if the \nALPHA= option is not specified."},"StatementOptionType":"V"}]}},{"StatementName":"REPWEIGHTS","StatementHelp":{"#cdata":"Syntax: REPWEIGHTS variables < / options > ; \n      \nThe REPWEIGHTS statement names variables that provide replicate weights for BRR or jackknife \nvariance estimation, which you request with the VARMETHOD=BRR or VARMETHOD=JACKKNIFE option \nin the PROC SURVEYREG statement. If you do not provide replicate weights for these methods \nby using a REPWEIGHTS statement, then the procedure constructs replicate weights for the \nanalysis.  \n\nEach REPWEIGHTS variable should contain the weights for a single replicate, and the number \nof replicates equals the number of REPWEIGHTS variables. The REPWEIGHTS variables must be \nnumeric, and the variable values must be nonnegative numbers."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=df] \n          \nSpecifies the degrees of freedom for the analysis. The value of df must be a positive number. \nPROC SURVEYPHREG also use the DF= value in computing the denominator degrees of freedom for \nthe F statistics in Wald type tests and confidence intervals."},"StatementOptionType":"V"},{"StatementOptionName":"JKCOEFS=","StatementOptionHelp":{"#cdata":"[Syntax: JKCOEFS=jackknife-coefficient-specification] \n          \nSpecifies jackknife coefficients for VARMETHOD=JACKKNIFE. The default value for the \njackknife coefficient is (R-1)/R, where R is the total number of replicates. You can \nspecify an alternative value with one of the following three forms: \n\n  JKCOEFS=value \n  specifies a single jackknife coefficient for all replicates. The coefficient value must \n  be a nonnegative number. \n\n  JKCOEFS=(values) \n  specifies jackknife coefficients for VARMETHOD=JACKKNIFE, where each coefficient corresponds \n  to an individual replicate identified by a REPWEIGHTS variable. You can separate values with \n  blanks or commas. The coefficient values must be nonnegative numbers. The number of values must \n  equal the number of replicate weight variables named in the REPWEIGHTS statement. List these \n  values in the same order in which you list the corresponding replicate weight variables in the \n  REPWEIGHTS statement. \n\n  JKCOEFS=SAS-data-set \n  names a SAS data set that contains the jackknife coefficients for VARMETHOD=JACKKNIFE. You \n  provide the jackknife coefficients in the JKCOEFS= data set variable JKCoefficient. Each \n  coefficient value must be a nonnegative number."},"StatementOptionType":"V"}]}},{"StatementName":"SLICE","StatementHelp":{"#cdata":"Syntax: SLICE model-effect </ options> ; \n      \nThe SLICE statement provides a general mechanism for performing a partitioned analysis \nof the LS-means for an interaction. This analysis is also known as an analysis of simple \neffects. \n\nThe SLICE statement uses the same options as the LSMEANS statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"ADJDFE=","StatementOptionHelp":{"#cdata":"Specifies how denominator degrees of freedom are determined when p-values and confidence \nlimits are adjusted for multiple comparisons with the ADJUST= option."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"SOURCE","@Value2":"ROW"},"StatementOptionToolTips":{"@ToolTip1":"The denominator degrees of freedom for multiplicity-adjusted results are the denominator degrees  of freedom for the LS-mean effect in the \"Type III Tests of Fixed Effects\" table.","@ToolTip2":"Useful if you want multiplicity adjustments to take into account that denominator degrees of freedom  are not constant across LS-mean differences."}},{"StatementOptionName":"ADJUST=","StatementOptionHelp":{"#cdata":"Requests a multiple comparison adjustment for the p-values and confidence limits for the differences \nof LS-means."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"BON","@Value2":"DUNNETT","@Value3":"NELSON","@Value4":"SCHEFFE","@Value5":"SIDAK","@Value6":"SIMULATE","@Value7":"SMM|GT2","@Value8":"TUKEY"},"StatementOptionToolTips":{"@ToolTip1":"Bonferroni adjustment","@ToolTip2":"Dunnett adjustment (in which the procedure analyzes all differences with a control level)","@ToolTip3":"Nelson adjustment (in which ANOM differences are taken)","@ToolTip4":"Scheffe's adjustment","@ToolTip5":"Sidak adjustment","@ToolTip6":"Computes adjusted p-values and confidence limits from the simulated distribution of the maximum or  maximum absolute value of a multivariate t random vector.  Syntax: SIMULATE<(simoptions)>  You can specify the following simoptions in parentheses after the ADJUST=SIMULATE option.       ACC=value      specifies the target accuracy radius \u03b3 of a 100(1-\u03b5)% confidence interval for the true      probability content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.           EPS=value      specifies the value \u03b5 for a 100(1-\u03b5)% confidence interval for the true probability      content of the estimated (1-\u03b1)th quantile. The default value is ACC=0.005.      NSAMP=n      specifies the sample size for the simulation.       SEED=number      specifies an integer that is used to start the pseudo-random number generator for the simulation.          THREADS      specifies that the computational work for the simulation be divided into parallel threads,      where the number of threads is the value of the SAS system option CPUCOUNT=.           NOTHREADS      specifies that the computational work for the simulation be performed in sequence rather than in      parallel. NOTHREADS is the default. This option overrides the SAS system option THREADS|NOTHREADS.","@ToolTip7":"SMM adjustment","@ToolTip8":"If your data are unbalanced, PROC GLIMMIX uses the approximation described in Kramer (1956)  and identifies the adjustment as \"Tukey-Kramer\" in the results."},"SubOptionsKeywords":"ACC=|EPS=|NSAMP=|SEED=|THREADS|NOTHREADS"},{"StatementOptionName":"ALPHA=","StatementOptionHelp":{"#cdata":"[Syntax: ALPHA=number] \n          \nRequests that a t-type confidence interval be constructed for each of the LS-means \nwith confidence level (1-number)x100%. The value of number must be between 0 and 1; \nthe default is 0.05."},"StatementOptionType":"V"},{"StatementOptionName":"AT","StatementOptionHelp":{"#cdata":"[Syntax: AT variable=value | AT(variable-list)=(value-list) | AT MEANS] \n          \nModifies the values of the covariates that are used in computing LS-means. By default, \nall covariate effects are set equal to their mean values for computation of standard \nLS-means. The AT option enables you to assign arbitrary values to the covariates. \nAdditional columns in the output table indicate the values of the covariates. \n\nIf there is an effect that contains two or more covariates, the AT option sets the \neffect equal to the product of the individual means rather than the mean of the product \n(as with standard LS-means calculations). The AT MEANS option sets covariates equal to \ntheir mean values (as with standard LS-means) and incorporates this adjustment to \ncrossproducts of covariates."},"StatementOptionType":"S|V","SubOptionsKeywords":"MEANS"},{"StatementOptionName":"BYLEVEL","StatementOptionHelp":{"#cdata":"Requests that separate margins be computed for each level of the SLICE model-effect."},"StatementOptionType":"S"},{"StatementOptionName":"CL","StatementOptionHelp":{"#cdata":"Requests that t-type confidence limits be constructed for each of the LS-means. The \nconfidence level is 0.95 by default; this can be changed with the ALPHA= option."},"StatementOptionType":"S"},{"StatementOptionName":"CORR","StatementOptionHelp":{"#cdata":"Displays the estimated correlation matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"COV","StatementOptionHelp":{"#cdata":"Displays the estimated covariance matrix of the least squares means as part of the \n\"Least Squares Means\" table."},"StatementOptionType":"S"},{"StatementOptionName":"DF=","StatementOptionHelp":{"#cdata":"[Syntax: DF=number] \n          \nSpecifies the degrees of freedom for the t test and confidence limits. The default is the \ndenominator degrees of freedom taken from the \"Type III Tests\" table that corresponds to \nthe LS-means effect."},"StatementOptionType":"V"},{"StatementOptionName":"DIFF=|PDIFF=","StatementOptionHelp":{"#cdata":"[Syntax: DIFF<=difftype>] \n          \nRequests that differences of the LS-means be displayed."},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOM","@Value3":"CONTROL","@Value4":"CONTROLL","@Value5":"CONTROLU"},"StatementOptionToolTips":{"@ToolTip1":"Requests all pairwise differences; this is the default.","@ToolTip2":"Requests differences between each LS-mean and the average LS-mean, as in the analysis  of means (Ott 1967).","@ToolTip3":"Requests the differences with a control, which, by default, is the first level of each of the  specified SLICE effects.","@ToolTip4":"Tests whether the noncontrol levels are significantly smaller than the control; the  upper confidence limits for the control minus the noncontrol levels are considered  to be infinity and are displayed as missing.","@ToolTip5":"Tests whether the noncontrol levels are significantly larger than the control; the  upper confidence limits for the noncontrol levels minus the control are considered  to be infinity and are displayed as missing."}},{"StatementOptionName":"E","StatementOptionHelp":{"#cdata":"Requests that the L matrix coefficients for the SLICE effects be displayed."},"StatementOptionType":"S"},{"StatementOptionName":"EXP","StatementOptionHelp":{"#cdata":"Requests exponentiation of the LS-means or LS-mean differences. When you model \ndata with the logit, cumulative logit, or generalized logit link functions, and \nthe estimate represents a log odds ratio or log cumulative odds ratio, the EXP \noption produces an odds ratio. In proportional hazards model, the exponentiation \nof the LS-mean differences produces estimates of hazard ratios. If you specify the \nCL or ALPHA= option, the (adjusted) confidence bounds are also exponentiated."},"StatementOptionType":"S"},{"StatementOptionName":"ILINK","StatementOptionHelp":{"#cdata":"Requests that estimates and their standard errors in the \"Least Squares Means\" \ntable also be reported on the scale of the mean (the inverse linked scale)."},"StatementOptionType":"S"},{"StatementOptionName":"LINES","StatementOptionHelp":{"#cdata":"Presents results of comparisons between all pairs of least squares means by listing \nthe means in descending order and indicating nonsignificant subsets by line segments \nbeside the corresponding LS-means."},"StatementOptionType":"S"},{"StatementOptionName":"MEANS","StatementOptionHelp":{"#cdata":"Specifies to produce the table of least squares means."},"StatementOptionType":"S"},{"StatementOptionName":"NOMEANS","StatementOptionHelp":{"#cdata":"Specifies not to produce the table of least squares means. This is the default."},"StatementOptionType":"S"},{"StatementOptionName":"ODDSRATIO|OR","StatementOptionHelp":{"#cdata":"Requests that LS-mean differences (DIFF, ADJUST= options) are also reported in terms \nof odds ratios. The ODDSRATIO option is ignored unless you use either the logit, \ncumulative logit, or generalized logit link function. If you specify the CL or \nALPHA= option, confidence intervals for the odds ratios are also computed. These \nintervals are adjusted for multiplicity when you specify the ADJUST= option."},"StatementOptionType":"S"},{"StatementOptionName":"OBSMARGINS=|OM=","StatementOptionHelp":{"#cdata":"Syntax: OBSMARGINS<=OM-data-set> \n          \nSpecifies a potentially different weighting scheme for the computation of LS-means \ncoefficients. The standard LS-means have equal coefficients across classification \neffects; however, the OM option changes these coefficients to be proportional to those \nfound in the OM-data-set. This adjustment is reasonable when you want your inferences \nto apply to a population that is not necessarily balanced but has the margins that are \nobserved in OM-data-set."},"StatementOptionType":"S|V"},{"StatementOptionName":"PDIFF","StatementOptionHelp":{"#cdata":"Is the same as the DIFF option."},"StatementOptionType":"S"},{"StatementOptionName":"PLOT=|PLOTS=","StatementOptionHelp":{"#cdata":"Requests that least squares means related graphics are produced via ODS Graphics, provided \nthat the ODS GRAPHICS statement has been specified and the plot request does not conflict \nwith other options in the SLICE statement.\n\nSyntax:\n(1) PLOT | PLOTS<=plot-request<(options)>> \n(2) PLOT | PLOTS<=(plot-request<(options)> <...plot-request<(options)> >)>"},"StatementOptionType":"S|V","StatementOptionValues":{"@Value1":"ALL","@Value2":"ANOMPLOT|ANOM","@Value3":"BOXPLOT","@Value4":"CONTROLPLOT|CONTROL","@Value5":"DIFFPLOT|DIFFOGRAM|DIFF","@Value6":"DISTPLOT|DIST","@Value7":"MEANPLOT","@Value8":"NONE"},"StatementOptionToolTips":{"@ToolTip1":"Requests that the default plots corresponding to this SLICE statement be produced.","@ToolTip2":"Requests an analysis of means display in which least squares means are compared to an  average least squares mean.","@ToolTip3":"Syntax: BOXPLOT<boxplot-options>>                                       Produces box plots of the distribution of the least squares mean or least squares mean  differences across a posterior sample. For example, this plot is available in procedures  that support a Bayesian analysis through the BAYES statement.   A separate box is generated for each estimable function, and all boxes appear on a single  graph by default. You can affect the appearance of the box plot graph with the following options:       ORIENTATION=VERTICAL|HORIZONTAL      ORIENT=VERT|HORIZ      specifies the orientation of the boxes. The default is vertical orientation of the box plots.       NPANELPOS=number      specifies how to break the series of box plots across multiple panels. If the NPANELPOS option      is not specified, or if number equals zero, then all box plots are displayed in a single graph;      this is the default.","@ToolTip4":"Requests a display in which least squares means are visually compared against a reference level.","@ToolTip5":"Requests a display of all pairwise least squares mean differences and their significance.  Syntax: DIFFPLOT<(diffplot-options)>  You can specify the following diffplot-options:       ABS     all line segments are shown on the same side of the reference line.       NOABS      separates comparisons according to the sign of the difference.       CENTER      marks the center point for each comparison.       NOLINES     suppresses the display of the line segments that represent the confidence bounds for the differences     of the least squares means. The NOLINES option implies the CENTER option.","@ToolTip6":"Syntax: DISTPLOT<distplot-options>                                        Generates panels of histograms with a kernel density overlaid if the analysis has access  to a set of posterior parameter estimates. You can sepcify the following distplot-options  in parentheses:       BOX|NOBOX      controls the display of a horizontal box plot of the estimable function\u2019s distribution      across the posterior sample below the graph. The BOX option is enabled by default.       HIST|NOHIST      controls the display of the histogram of the estimable function\u2019s distribution across the      posterior sample. The HIST option is enabled by default.       NORMAL|NONORMAL      controls the display of a normal density estimate on the graph. The NONORMAL option is enabled by default.       KERNEL|NOKERNEL      controls the display of a kernel density estimate on the graph. The KERNEL option is enabled by default.       NROWS=number      specifies the highest number of rows in a panel. The default is 3.       NCOLS=number      specifies the highest number of columns in a panel. The default is 3.       UNPACK      unpacks the panel into separate graphics.","@ToolTip7":"Syntax: MEANPLOT<(meanplot-options)>  Requests displays of the least squares means. The following meanplot-options control  the display of the least squares means:      ASCENDING      displays the least squares means in ascending order. This option has no effect if means are sliced      or displayed in separate plots.       CL      displays upper and lower confidence limits for the least squares means. By default, 95% limits are drawn.      CLBAND      displays confidence limits as bands. This option implies the JOIN option.       DESCENDING      displays the least squares means in descending order. This option has no effect if means are sliced     or displayed in separate plots.       ILINK      requests that means (and confidence limits) are displayed on the inverse linked scale.       JOIN | CONNECT      connects the least squares means with lines. This option is implied by the CLBAND option.          SLICEBY=fixed-effect      specifies an effect by which to group the means in a single plot.      PLOTBY=fixed-effect      specifies an effect by which to break interaction plots into separate displays.","@ToolTip8":"Requests that no plots be produced."},"SubOptionsKeywords":"\n            ABS|NOABS|CENTER|NOLINES|ASCENDING|CL|CLBAND|DESCENDING|ILINK|JOIN|\n            CONNECT|SLICEBY=|PLOTBY=|ORIENTATION=|ORIENT=|NPANELPOS=|BOX|NOBOX|\n            HIST|NOHIST|NORMAL|NONORMAL|KERNEL|NOKERNEL|NROWS=|NCOLS=|UNPACK\n          "},{"StatementOptionName":"SEED=","StatementOptionHelp":{"#cdata":"[Syntax: SEED=number] \n          \nSpecifies the seed for the sampling-based components of the computations for the SLICE \nstatement (for example, chi-bar-square statistics and simulated p-values). number specifies \nan integer that is used to start the pseudo-random-number generator for the simulation. If \nyou do not specify a seed, or if you specify a value less than or equal to zero, the seed \nis generated from reading the time of day from the computer clock."},"StatementOptionType":"V"},{"StatementOptionName":"SINGULAR=","StatementOptionHelp":{"#cdata":"[Syntax: SINGULAR=number] \n          \nTunes the estimability checking. The value for number must be between 0 and 1; \nthe default is 1E-4."},"StatementOptionType":"V"},{"StatementOptionName":"STEPDOWN","StatementOptionHelp":{"#cdata":"[Syntax: STEPDOWN<(step-down options)>] \n          \nRequests that multiple comparison adjustments for the p-values of LS-mean differences \nbe further adjusted in a step-down fashion. Step-down methods increase the power of \nmultiple comparisons by taking advantage of the fact that a p-value is never declared \nsignificant unless all smaller p-values are also declared significant.\n\nYou can specify the following step-down options in parentheses: \n\n    MAXTIME=n \n    specifies the time (in seconds) to spend computing the maximal logically consistent sequential \n    subsets of equality hypotheses for TYPE=LOGICAL.\n\n    REPORT \n    specifies that a report on the step-down adjustment should be displayed, including a listing of \n    the sequential subsets (Westfall 1997) and, for ADJUST=SIMULATE, the step-down simulation results.\n\n    TYPE=LOGICAL<(n)> \n    TYPE=FREE \n    If you specify TYPE=LOGICAL, the step-down adjustments are computed by using maximal logically \n    consistent sequential subsets of equality hypotheses (Shaffer 1986, Westfall 1997). Alternatively, \n    for TYPE=FREE, sequential subsets are computed ignoring logical constraints. The TYPE=FREE results \n    are more conservative than those for TYPE=LOGICAL, but they can be much more efficient to produce \n    for many comparisons."},"StatementOptionType":"S","SubOptionsKeywords":"MAXTIME=|REPORT|TYPE="},{"StatementOptionName":"SLICEBY=","StatementOptionHelp":{"#cdata":"Determines how to construct the partition of the least squares means for the model-effect.\n          \nSyntax: \nSLICEBY <=> slice-specification \nSIMPLE <=> slice-specification \nSLICEBY(slice-specification <, slice-specification <, >>) \nSIMPLE(slice-specification <, slice-specification <, >>) \n\nA slice-specification consists of an effect name followed by an optional list of formatted \nvalues. For example, the following statements creates partitions of the A*B interaction effect \nfor all levels of variable A: \n\n  class a b;\n  model y = a b a*b;\n  slice a*b / sliceby=a;"},"StatementOptionType":"S|V"},{"StatementOptionName":"NOF","StatementOptionHelp":{"#cdata":"Suppresses the F test for testing the mutual equality of the estimable functions \nin the partition."},"StatementOptionType":"S"}]}},{"StatementName":"STORE|ITEMSTORE","StatementHelp":{"#cdata":"Syntax: STORE <OUT=>item-store-name </ LABEL='label'> ; \n      \nThe STORE statement requests that the procedure save the context and results of the \nstatistical analysis. The resulting item store is a binary file format that cannot \nbe modified. The contents of the item store can be processed with the PLM procedure. \n\nThe item-store-name is a usual one- or two-level SAS name, like the names that are used \nfor SAS data sets. If you specify a one-level name, then the item store resides in the \nWORK library and is deleted at the end of the SAS session. Since item stores usually are \nused to perform postprocessing tasks, typical usage specifies a two-level name of the form \nlibname.membername. \n\nIf an item store by the same name as specified in the STORE statement already exists, \nthe existing store is replaced."},"StatementOptions":{"StatementOption":{"StatementOptionName":"LABEL=","StatementOptionHelp":{"#cdata":"[Syntax: LABEL='label'] \n          \nAdds a custom label. When the PLM procedure processes an item store, the label appears \nin the PROC PLM output along with other identifying information."},"StatementOptionType":"V"}}},{"StatementName":"STRATA|STRATUM","StatementHelp":{"#cdata":"Syntax: STRATA variables < / option > ; \n      \nThe STRATA statement specifies variables that form the strata in a stratified sample design. \nThe combinations of categories of STRATA variables define the strata in the sample. \n\nIf your sample design has stratification at multiple stages, you should identify only the \nfirst-stage strata in the STRATA statement. \n\nIf you provide replicate weights for BRR or jackknife variance estimation with a REPWEIGHTS \nstatement, you do not need to specify a STRATA statement. \n\nThe STRATA variables are one or more variables in the DATA= input data set. These variables \ncan be either character or numeric, but the procedure treats them as categorical variables. \nThe formatted values of the STRATA variables determine the STRATA variable levels. Thus, you \ncan use formats to group values into levels."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"LIST","StatementOptionHelp":{"#cdata":"Displays a \"Stratum Information\" table, which includes values of the STRATA variables \nand the number of observations, number of clusters, population total, and sampling \nrate for each stratum."},"StatementOptionType":"S"},{"StatementOptionName":"NOCOLLAPSE","StatementOptionHelp":{"#cdata":"Prevents the procedure from collapsing (combining) strata that have only one sampling \nunit for the Taylor series variance estimation. By default, the procedure collapses \nstrata that contain only one sampling unit for the Taylor series method."},"StatementOptionType":"S"}]}},{"StatementName":"TEST","StatementHelp":{"#cdata":"Syntax: <label:> TEST equation1 <, equation2, > </ option> ; \n      \nThe TEST statement tests linear hypotheses about the regression coefficients. The Wald test \nis used to jointly test the null hypotheses (Ho: L\u03b8=c) specified in a single TEST statement. \nWhen c=0 you should specify a CONTRAST statement instead. \n\nEach equation specifies a linear hypothesis (a row of the L matrix and the corresponding \nelement of the c vector); multiple equations are separated by commas. The label, which must \nbe a valid SAS name, is used to identify the resulting output and should always be included. \nYou can submit multiple TEST statements. \n\nThe form of an equation is as follows: \n\n  term < \u00b1 term ...> < = \u00b1 term < \u00b1 term ... >> \n\nwhere term is a parameter of the model, or a constant, or a constant times a parameter. \nFor a binary response model, the intercept parameter is named INTERCEPT; for an ordinal \nresponse model, the intercept parameters are named INTERCEPT, INTERCEPT2, INTERCEPT3, and \nso on. When no equal sign appears, the expression is set to 0."},"StatementOptions":{"StatementOption":{"StatementOptionName":"PRINT","StatementOptionHelp":{"#cdata":"Displays intermediate calculations in the testing of the null hypothesis Ho: L\u03b8=c."},"StatementOptionType":"S"}}},{"StatementName":"UNITS","StatementHelp":{"#cdata":"Syntax: UNITS independent1 = list1 <... independentk = listk></ option> ; \n      \nThe UNITS statement enables you to specify units of change for the continuous explanatory \nvariables so that customized odds ratios can be estimated. An estimate of the corresponding \nodds ratio is produced for each unit of change specified for an explanatory variable. The \nUNITS statement is ignored for CLASS variables. If the CLODDS option is specified in the \nMODEL statement, the corresponding confidence limits for the odds ratios are also displayed. \n\nThe term independent is the name of an explanatory variable, and list represents a list of \nunits of change, separated by spaces, that are of interest for that variable. Each unit of \nchange in a list has one of the following forms: \n\n  o number \n  o SD or SD \n  o number * SD \n\nwhere number is any nonzero number and SD is the sample standard deviation of the corresponding \nindependent variable."},"StatementOptions":{"StatementOption":{"StatementOptionName":"DEFAULT=|DEF=","StatementOptionHelp":{"#cdata":"[Syntax: DEFAULT=list] \n          \nGives a list of units of change for all explanatory variables that are not specified in \nthe UNITS statement. Each unit of change can be in any of the forms described previously. \nIf the DEFAULT= option is not specified, PROC SURVEYLOGISTIC does not produce customized \nodds ratio estimates for any explanatory variable that is not listed in the UNITS statement."},"StatementOptionType":"V"}}},{"StatementName":"WEIGHT|WGT","StatementHelp":{"#cdata":"Syntax: WEIGHT variable;\n      \nThe WEIGHT statement names the variable that contains the sampling weights. This variable \nmust be numeric, and the sampling weights must be positive numbers. If an observation has \na weight that is nonpositive or missing, then the procedure omits that observation from the \nanalysis. \n\nIf you do not specify a WEIGHT statement but provide replicate weights with a REPWEIGHTS \nstatement, PROC SURVEYLOGISTIC uses the average of each observation\u2019s replicate weights as the \nobservation\u2019s weight. \n\nIf you do not specify a WEIGHT statement or a REPWEIGHTS statement, PROC SURVEYLOGISTIC assigns \nall observations a weight of one."},"StatementOptions":null}]}}}