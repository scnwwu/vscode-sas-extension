{"Procedure":{"Name":"TREESPLIT","ProductGroup":"CAS","ProcedureHelp":{"#cdata":"Syntax: PROC TREESPLIT <options>;\n    AUTOTUNE < options > ;\n    CLASS variables;\n    CODE FILE=filename ;\n    FREQ variable ;\n    GROW criterion < options > ;\n    MODEL response = variable. . . ;\n    OUTPUT OUT=CAS-libref.data-table output-options ;\n    PARTITION < partition-options > ;\n    PRUNE prune-method < (prune-options) > ;\n    WEIGHT variable;\n    INPUT variables </ option>;\n    TARGET variable </ options>;\n    \nThe TREESPLIT procedure builds tree-based statistical models for classification and regression in SAS Viya.\nThe procedure produces a classification tree, which models a categorical response, or a regression tree, which\nmodels a continuous response. Both types of trees are referred to as decision trees, because the model is\nexpressed as a series of if-then statements. For each type of tree, you specify a response variable (also called\na target variable), whose values you want PROC TREESPLIT to predict, and one or more input variables\n(called predictor variables), whose values the procedure uses to predict the values of the target variable."},"ProcedureOptions":{"ProcedureOption":[{"ProcedureOptionName":"ASSIGNMISSING=","ProcedureOptionHelp":{"#cdata":"Syntax: ASSIGNMISSING= BRANCH|MACSMALL|POPULAR|SIMILAR|USEINSEARCH|NONE  \n      \nSpecifies how to handle missing values of predictor variables during training and how to handle missing\nvalues and unknown levels of predictor variables after all surrogate rules have been applied during\nscoring. An unknown level of a categorical predictor variable is a level that does not exist in the\ntraining data but is encountered during scoring. During scoring, unknown levels are treated as missing\nvalues."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"BRANCH","@Value2":"MACSMALL","@Value3":"POPULAR","@Value4":"SIMILAR","@Value5":"USEINSEARCH","@Value6":"NONE"},"ProcedureOptionToolTips":{"@ToolTip1":"During the training phase, assigns any observation that has a missing value for the predictor variable to a specially created child node (branch). If all observations have nonmissing values for a predictor variable, then no branch is created to contain observations with missing values.","@ToolTip2":"During the training phase, treats a missing value in a categorical predictor variable as a separate, legitimate value. If all observations have nonmissing values for a categorical predictor variable, then no branch is selected to contain observations with missing values.","@ToolTip3":"During the training phase, assigns any observation that has a missing value in the predictor variable to the child node that has the most training observations","@ToolTip4":"During the training phase, assigns any observation that has a missing value in the predictor variable to the child node whose observations are most similar to it. This similarity is determined using the chi-square criterion for categorical responses or the F-test criterion for continuous responses. If all observations have nonmissing values for a predictor variable, then no branch is selected to contain observations with missing values.","@ToolTip5":"During the training phase, treats a missing value in a predictor variable as a separate, legitimate value. If all observations have nonmissing values for a predictor variable, then no branch is selected to contain observations with missing values.","@ToolTip6":"During the training phase, excludes any observation that has a missing value for any predictor variable. In the scoring phase, if an observation has a missing value or an unknown level for a predictor variable, then the observation is assigned to the child node that contains the most training observations."}},{"ProcedureOptionName":"BINMETHOD=","ProcedureOptionHelp":{"#cdata":"Syntax: BINMETHOD=BUCKET | QUANTILE \n      \nSpecifies how to bin interval input variables prior to growing the decision tree. The number of bins \nthat are created is determined by the NUMBIN= option."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"BUCKET","@Value2":"QUANTILE"},"ProcedureOptionToolTips":{"@ToolTip1":"Bins interval input variables into fixed-width bins.","@ToolTip2":"Bins interval input variables into bins according to their quantile. "}},{"ProcedureOptionName":"CLUSTERSPLIT","ProcedureOptionHelp":{"#cdata":"Determines the splits at each node using clustering on each input variable, and then chooses the \nsplitting variable on the basis of which variable and split optimize the criterion that is \nspecified in the GROW statement."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"CVCC|CVCOSTCOMPLEXITY","ProcedureOptionHelp":{"#cdata":"Requests a table of the results of cost-complexity pruning based on cross validation. For each penalty \nparameter in the cross validation, the table provides the penalty parameter, the minimum, the maximum, \nand the average error. The error is the misclassification rate when the response variable is categorical \nand is the average square error (ASE) when the response variable is continuous. You can use the PLOTS=CVCC \noption to request a plot of the information in this table."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"DATA=","ProcedureOptionHelp":{"#cdata":"Syntax: DATA=CAS-libref.data-table\n      \nNames the input data table for PROC TREESPLIT to use. CAS-libref.data-table is a two-level name,\nwhere\n\n  CAS-libref refers to a collection of information that is defined in the LIBNAME statement and\n    includes the caslib, which includes a path to the data, and a session identifier, which\n    defaults to the active session but which can be explicitly defined in the LIBNAME\n    statement.\n    \n  data-table specifies the name of the input data table."},"ProcedureOptionType":"DV"},{"ProcedureOptionName":"INMODEL=","ProcedureOptionHelp":{"#cdata":"Syntax: INMODEL=< CAS-libref. >data-table\n      \nSpecifies the data table that you have previously saved as a tree model by using the OUTMODEL= option \nin a previous run of PROC TREESPLIT.  CAS-libref.data-table is a two-level name, where CASlibref\nrefers to the caslib and session identifier, and data-table specifies the name of the input data table."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MAXBRANCH=","ProcedureOptionHelp":{"#cdata":"Syntax: MAXBRANCH=b\n      \nSpecifies the maximum number of child nodes per parent node in the tree. PROC TREESPLIT tries to\ncreate this number of children unless it is impossible (for example, if a split variable does not have\nenough levels).\nBy default, MAXBRANCH=2."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MAXDEPTH=","ProcedureOptionHelp":{"#cdata":"Syntax: MAXDEPTH= integer >= 1  \n      \nSpecifies the maximum depth to which you wish to grow your decision tree.  \n\nDefault Changed to Log2(10/MaxBranch) 12/15/2015  maxdepth=10 on the proc corresponds to maxlevel=11 \non the action (add 1)."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MINLEAFSIZE=","ProcedureOptionHelp":{"#cdata":"Syntax: MINLEAFSIZE=number\n      \nSpecifies the minimum number of observations in the training data that each child of a split must\ncontain in order for the split to be considered.\nBy default, MINLEAFSIZE=1."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"MINUSEINSEARCH=","ProcedureOptionHelp":{"#cdata":"Syntax: MINUSEINSEARCH=number\n      \nSpecifies a threshold for using missing values in the split search when ASSIGNMISSING=\nUSEINSEARCH as the missing value policy. If the number of observations that have\nmissing values for the splitting variable is greater than or equal to number, then PROC TREESPLIT\nuses the USEINSEARCH policy for missing values.\n\nBy default, MINUSERINSEARCH=1."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NOPRINT","ProcedureOptionHelp":{"#cdata":"Specifies to turn off all printing of ODS tables and graphics."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"NUMBIN=","ProcedureOptionHelp":{"#cdata":"Syntax: NUMBIN=number\n      \nSpecifies the number of bins to use for binning interval predictor variables. PROC TREESPLIT bins\ncontinuous predictors to a fixed bin size. This option controls the number of bins and thereby also the\nsize of the bins.\n\nBy default, NUMBIN=1. This option is ignored if you use the AUTOTUNE statement."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"NSURROGATES=","ProcedureOptionHelp":{"#cdata":"Syntax: NSURROGATES=number\n      \nSpecifies the number of surrogate rules to create for each splitting rule, where number is an integer\ngreater than 0. Surrogate rules are backup splitting rules that are used when the variable that corresponds\nto the primary splitting rule is missing.\nBoth this option and the ASSIGNMISSING= affect training and scoring."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"OUTMODEL=","ProcedureOptionHelp":{"#cdata":"Syntax: OUTMODEL=CAS-libref.data-table\n      \nNames the output data table to which you want to save the decision tree model. CAS-libref.data-table is\na two-level name, where\n\n  CAS-libref refers to a collection of information that is defined in the LIBNAME statement and\n    includes the caslib, which includes a path to the data, and a session identifier, which\n    defaults to the active session but which can be explicitly defined in the LIBNAME\n    statement. \n    \n  data-table specifies the name of the input data table."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"PLOTS=","ProcedureOptionHelp":{"#cdata":"Syntax: PLOTS < (global-plot-option) > < = plot-request < (options) > >\nSyntax: PLOTS < (global-plot-option) > < = (plot-request < (options) > < . . . plot-request < (options) > >) >\n\nControls the plots that are produced through ODS Graphics. When you specify only one plot-request,\nyou can omit the parentheses around it. \n      \nglobal-plot-option: ONLY suppresses the default plots. Only plots that you specifically request are displayed.\n\nYou can specify the following plot-requests:\nALL produces all appropriate plots.\nNONE suppresses the default plots. Only plots that you specifically request are displayed.\nPRUNEUNTIL plots the metric that is used to select the final subtree. \nWHOLETREE \n  LINKSTYLE - specifies the style of the links between nodes \n    CURVED - requests curved links between parent and child nodes \n    ORTHOGONAL - requests that the link goes down from the parent, then horizontal, then down again to the child node \n    STRAIGHT - requests that the links go straight from the parent to child nodes \n  LINKWIDTH - species how the user wants the link thickness defined \n    CONSTANT - requests that all links have the same thickness \n    PROPORTIONAL - requests that the links have a thickness proportional to the total number of observations \n  NOLEGEND - turns off the legend \nZOOMEDTREE \n  DEPTH=depth - creates a plot down to depth for each node-id specified in the NODES= option.\n  LINKSTYLE - specifies the style of the links between nodes \n    CURVED - requests curved links between parent and child nodes \n    ORTHOGONAL - requests that the link goes down from the parent, then horizontal, then down again to the child node \n    STRAIGHT - requests that the links go straight from the parent to child nodes \n  LINKWIDTH - species how the user wants the link thickness defined \n    CONSTANT - requests that all links have the same thickness \n    PROPORTIONAL - requests that the links have a thickness proportional to the total number of observations \n  NODES - requests plots for the subtree that is root at nodes at node-id. The default node ID is \"0\", the root of \n    the entire tree. The values of node-id are alphanumeric strings that are displayed within the nodes that is created \n    by the WHOLETREE option.  \n  NOLEGEND - turns off the legend "},"ProcedureOptionType":"S|V","SubOptionsKeywords":"LINKSTYLE|CURVED|ORTHOGONAL|STRAIGHT|LINKWIDTH|CONSTANT|PROPORTIONAL|NOLEGEND|DEPTH|NODES|ONLY"},{"ProcedureOptionName":"PRINTTARGET","ProcedureOptionHelp":{"#cdata":"Outputs tables that indicate generated columns in the OUT= table from the OUTPUT statement."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"PRUNINGTABLE","ProcedureOptionHelp":{"#cdata":"Outputs a table of the pruning results."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"RBAIMP","ProcedureOptionHelp":{"#cdata":"Creates a variable importance table by using random branch assignment (RBA). This table is created \nin addition to the normal variable importance table that is calculated using the residual sum of \nsquares (RSS) error."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"SEED=","ProcedureOptionHelp":{"#cdata":"Syntax: SEED=number\n      \nSpecifies the initial seed for random number generation for cross validation. The value of number must\nbe an integer. By default, the seed is generated by reading the time of day from the computer\u2019s clock."},"ProcedureOptionType":"V"},{"ProcedureOptionName":"SPLITONCE","ProcedureOptionHelp":{"#cdata":"Specifies the that an input variable should only be split once."},"ProcedureOptionType":"S"},{"ProcedureOptionName":"VII=|INTERACTIONIMP=|","ProcedureOptionHelp":{"#cdata":"Syntax: VII=2|3 | INTERACTIONIMP=2|3 \n      \nCalculates the variable interaction importance, which is described in the section Variable \nnteraction Importance."},"ProcedureOptionType":"V","ProcedureOptionValues":{"@Value1":"2","@Value2":"3"},"ProcedureOptionToolTips":{"@ToolTip1":"Calculates the importance of all two-way variable interactions. ","@ToolTip2":"Calculates the importance of all three-way and all two-way variable interactions."}}]},"ProcedureStatements":{"ProcedureStatement":[{"StatementName":"AUTOTUNE","StatementHelp":{"#cdata":"Syntax: AUTOTUNE < options > ;\n      \nThe AUTOTUNE statement searches for the best growing parameters based on the problem and the options.\nWhen you specify the AUTOTUNE statement, the NUMBIN= and MAXDEPTH= options in the PROC\nTREESPLIT statement and the GROW statement are ignored, because PROC TREESPLIT searches for the\nbest of these parameters for tree growth. Trees created as a result of using autotuning are not pruned. You\ncannot specify the AUTOTUNE statement in conjunction with the PARTITION statement."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"EVALHISTORY=","StatementOptionHelp":{"#cdata":"Syntax: EVALHISTORY=ALL |LOG |NONE |TABLE \n          \nSpecifies how to report the evaluation history of the tuner."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ALL","@Value2":"LOG","@Value3":"NOE","@Value4":"TABLE"},"StatementOptionToolTips":{"@ToolTip1":"Reports each evaluation in the log and creates the EvaluationHistory ODS table. ","@ToolTip2":"Prints the following information to the log for each evaluation: evaluation number, objective value, best objective value up to that point, evaluation time, and elapsed time since the beginning of the  tuning process.","@ToolTip3":"Suppresses reporting of evaluations in the log and does not create the EvaluationHistory ODS table.","@ToolTip4":"Creates the EvaluationHistory ODS table, which contains all evaluated points. The table contains columns  for the evaluation number, all tuning parameters, and the objective function value."}},{"StatementOptionName":"FRACTION=","StatementOptionHelp":{"#cdata":"Syntax: FRACTION=number\n          \nSpecifies the fraction of all data to be used for validation, where number must be between 0.01 and\n0.99, inclusive. If you specify this option, the tuner uses a single partition validation for finding the\nobjective value (validation error estimate). This option might not be advisable for small or unbalanced\ndata tables where the random assignment of the validation subset might not provide a good estimate of\nerror. For large, balanced data tables, a single validation partition is usually sufficient for estimating\nerror; a single partition is more efficient than cross validation in terms of the total execution time.\nBy default, FRACTION=0.3. You cannot specify this option in combination with the KFOLD= option."},"StatementOptionType":"V"},{"StatementOptionName":"KFOLD=","StatementOptionHelp":{"#cdata":"Syntax: KFOLD=number\n          \nSpecifies the number of partition folds in the cross validation process, where number must be between\n2 and 20, inclusive. If you specify this option, the tuner uses cross validation to find the objective value.\nIn cross validation, each model evaluation requires number of training executions (on number\u20131 data\nfolds) and number of scoring executions (on 1 hold-out fold). Thus, the evaluation time is increased by\napproximately number. For small to medium data tables or for unbalanced data tables, cross validation\nprovides on average a better representation of error across the entire data table (a better generalization\nerror).\nBy default, KFOLD=5. You cannot specify this option in combination with the FRACTION= option."},"StatementOptionType":"V"},{"StatementOptionName":"MAXEVALS=","StatementOptionHelp":{"#cdata":"Syntax: MAXEVALS=number \n          \nSpecifies the maximum number of configuration evaluations allowed for the tuner, where number\nmust be an integer greater than or equal to 3. When the number of evaluations is reached, the tuner\nterminates the search and returns the results. To produce a single objective function value (validation\nerror estimate), each configuration evaluation requires either a single model training and scoring\nexecution on a validation partition, or a number of training and scoring executions equal to the value of\nthe KFOLD= option for cross validation. The MAXEVALS= option might lead to termination before\nthe value of the MAXITER= option or the MAXTIME= option is reached.\nBy default, MAXEVALS=50."},"StatementOptionType":"V"},{"StatementOptionName":"MAXITER=","StatementOptionHelp":{"#cdata":"Syntax: MAXITER=number\n          \nSpecifies the maximum number of iterations of the optimization tuner, where number must be greater\nthan or equal to 1. Each iteration normally involves a number of objective evaluations up to the value\nof the POPSIZE= option. The MAXITER= option might lead to termination before the value of the\nMAXEVALS= option or the MAXTIME= option is reached.\nBy default, MAXITER=5."},"StatementOptionType":"V"},{"StatementOptionName":"MAXTIME=","StatementOptionHelp":{"#cdata":"Syntax: MAXTIME=number\n          \nSpecifies the maximum time (in seconds) allowed for the tuner, where number must be greater than or\nequal to 1. When this value is reached, the tuner terminates the search and returns results. The actual\nrun time for optimization might be longer because it includes the remaining time needed to finish\nthe current evaluation. For long-running model training (large data tables), the actual run time might\nsignificantly exceed number. The MAXTIME= option might lead to termination before the value of\nthe MAXEVALS= option or the MAXITER= option is reached.\nBy default, MAXTIME=36000."},"StatementOptionType":"V"},{"StatementOptionName":"NPARALLEL=","StatementOptionHelp":{"#cdata":"Syntax: NPARALLEL=number \n          \nSpecifies the number of evaluations to be performed in parallel, where number must be greater than or \nequal to 0. When SEARCHMETHOD=GA is specified, the value of number is equal to the value of the POPSIZE= \noption minus one. When SEARCHMETHOD=LHS or SEARCHMETHOD=RANDOM is specified, the value of number is equal \nto the value of SAMPLESIZE= option."},"StatementOptionType":"V"},{"StatementOptionName":"OBJECTIVE=","StatementOptionHelp":{"#cdata":"Syntax: OBJECTIVE=function \n          \nSpecifies which measure of model performance the tuner uses as the objective function.\n\nBy default, OBJECTIVE=MISC for nominal targets, and OBJECTIVE=MSE for interval targets."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"ASE","@Value2":"AUC","@Value3":"F05","@Value4":"F1","@Value5":"GAMMA","@Value6":"GINI","@Value7":"KS","@Value8":"MAE","@Value9":"MCE","@Value10":"MCLL","@Value11":"MISC","@Value12":"MSE","@Value13":"MSLE","@Value14":"RASE","@Value15":"RMAE","@Value16":"RMSLE","@Value17":"TAU"},"StatementOptionToolTips":{"@ToolTip1":"Uses average squared error as the objective function.","@ToolTip2":"Uses area under the curve as the objective function (nominal type only).","@ToolTip3":"Uses the F0.5 coefficient as the objective function (nominal type only). ","@ToolTip4":"Uses the F1 coefficient as the objective function (nominal type only).","@ToolTip5":"Uses the gamma coefficient as the objective function (nominal type only).","@ToolTip6":"Uses the Gini coefficient as the objective function (nominal type only). ","@ToolTip7":"Uses the Kolmogorov-Smirnov coefficient as the objective function (nominal type only).","@ToolTip8":"Uses the mean absolute error as the objective function (interval type only).","@ToolTip9":"Uses the misclassification rate as the objective function (nominal type only).","@ToolTip10":"Uses the multiclass log loss as the objective function (nominal type only).","@ToolTip11":"Uses the misclassification error percentage as the objective function (nominal type only).","@ToolTip12":"Uses the mean squared error as the objective function (interval type only).","@ToolTip13":"Uses the mean squared logarithmic error as the objective function (interval type only).","@ToolTip14":"Uses the root average squared error as the objective function.","@ToolTip15":"Uses the root mean absolute error as the objective function (interval type only).","@ToolTip16":"Uses the root mean squared logarithmic error as the objective function (interval type only).","@ToolTip17":"Uses the tau coefficient as the objective function (nominal type only)."}},{"StatementOptionName":"POPSIZE=","StatementOptionHelp":{"#cdata":"Syntax: POPSIZE=number\n          \nSpecifies the maximum number of evaluations in one iteration (population), where number must\nbe greater than or equal to 1. In some cases, the tuner algorithm might generate a number of new\nconfigurations smaller than number.\nBy default, POPSIZE=10."},"StatementOptionType":"V"},{"StatementOptionName":"SAMPLESIZE=","StatementOptionHelp":{"#cdata":"Syntax: SAMPLESIZE=number \n          \nSpecifies the total number of evaluations, where number must be greater than or equal to 1. \nYou can specify this option when SEARCHMETHOD=RANDOM or SEARCHMETHOD=LHS. This option is \nignored when SEARCHMETHOD=GA. \n\nBy default, SAMPLESIZE=50."},"StatementOptionType":"V"},{"StatementOptionName":"SEARCHMETHOD=","StatementOptionHelp":{"#cdata":"Syntax: SEARCHMETHOD=GA |LHS |RANDOM \n          \nSpecifies the search method to use for tuning.\n\nBy default, SEARCHMETHOD=GA."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"GA","@Value2":"LHS","@Value3":"RANDOM"},"StatementOptionToolTips":{"@ToolTip1":"Uses an initial Latin hypercube sample that seeds a genetic algorithm to generate a new population  of alternative configurations at each iteration.","@ToolTip2":"Uses a Latin hypercube to generate a single sample of configurations that is uniform in each tuning  parameter, but random in combinations.","@ToolTip3":"Generates a single sample of purely random configurations. "}},{"StatementOptionName":"TARGETEVENT=","StatementOptionHelp":{"#cdata":"Syntax: TARGETEVENT=string \n          \nSpecifies the target event to use for calculating the selected objective function. This option \nis ignored when the value of the OBJECTIVE= option is not AUC, F1, F05, GINI, GAMMA, TAU, or KS."},"StatementOptionType":"V"},{"StatementOptionName":"CRITERION","StatementOptionHelp":{"#cdata":"Syntax: CRITERION (VALUES=value-list INIT=value EXCLUDE) \n          \nSpecifies information about the splitting criteria to use for tuning the decision tree. \n\nYou can specify the following additional suboptions: \n\n VALUES=value-list \n    specifies a list of splitting criteria to consider during tuning, where value-list is a space separated \n    list that can include one or more of the following values: CHAID, CHISQUARE, FTEST, GAIN, GINI, and VARIANCE. \n INIT=value \n    specifies the initial splitting criterion for the tuner to use. You can specify the following values: CHAID, \n    CHISQUARE, FTEST, GAIN, GINI, IGR, RSS, or VARIANCE. \n\n    By default, INIT=IGR for nominal targets and INIT=VARIANCE for interval targets. \n EXCLUDE \n    excludes the splitting criterion from the tuning process. \n"},"StatementOptionType":"S","SubOptionsKeywords":"VALUES=|INIT=|EXCLUDE"},{"StatementOptionName":"MAXDEPTH","StatementOptionHelp":{"#cdata":"Syntax: MAXDEPTH (LB=number UB=number VALUES=value-list INIT=number EXCLUDE) \n          \nSpecifies information about the maximum depth to grow the decision tree to use for tuning the decision tree. \n\nYou can specify the following additional suboptions: \n\n LB=number \n    specifies the minimum depth to consider during tuning. If you specify this suboption, you cannot specify the \n    VALUES= suboption. \n\n    By default, LB=1. \n UB=number \n    specifies the maximum depth to consider during tuning. If you specify this suboption, you cannot specify the \n    VALUES= suboption. \n\n    By default, UB=19. \n VALUES=value-list \n    specifies a list of depth values to consider during tuning, where value-list is a space-separated list of \n    positive integers. If you specify this suboption, you cannot specify either the LB= or UB= suboption. \n  INIT=number \n    specifies the initial depth for the tuner to use. \n\n    By default, INIT=10. \n  EXCLUDE \n    excludes depth from the tuning process. \n\n"},"StatementOptionType":"S","SubOptionsKeywords":"LB=|UB=|VALUES=|INIT=|EXCLUDE"},{"StatementOptionName":"NUMBIN","StatementOptionHelp":{"#cdata":"Syntax: NUMBIN (LB=number UB=number VALUES=value-list INIT=number EXCLUDE) \n          \nSpecifies information about the number of bins in which to bin the interval inputs while tuning the decision tree. \n\nYou can specify the following additional suboptions: \n\n LB=number \n    specifies the minimum number of bins to consider during tuning. If you specify this suboption, you cannot \n    specify the VALUES= suboption. \n\n    By default, LB=20. \n UB=number \n    specifies the maximum number of bins to consider during tuning. If you specify this suboption, you cannot \n    specify the VALUES= suboption. \n\n    By default, UB=200. \n VALUES=value-list \n    specifies a list of numbers of bins to consider during tuning, where value-list is a space-separated list \n    of positive integers. If you specify this suboption, you cannot specify either the LB= or UB= suboption. \n  INIT=number \n    specifies the initial number of bins for the tuner to use. \n\n    By default, INIT=20. \n   EXCLUDE \n    excludes the number of bins from the tuning process."},"StatementOptionType":"S","SubOptionsKeywords":"LB=|UB=|VALUES=|INIT=|EXCLUDE"},{"StatementOptionName":"USEPARAMETERS=","StatementOptionHelp":{"#cdata":"Syntax: USEPARAMETERS=tuning-parameter-option \n          \nSpecifies which set of parameters to tune."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"STANDARD","@Value2":"CUSTOM","@Value3":"COMBINED"},"StatementOptionToolTips":{"@ToolTip1":"Tunes using the default bounds and initial values for all parameters.","@ToolTip2":"Tunes only the parameters that are specified in the TUNINGPARAMETERS= option.","@ToolTip3":"Tunes the parameters that are specified in the TUNINGPARAMETERS= option and uses default bounds  and initial values to tune all other parameters."}}]}},{"StatementName":"CLASS","StatementHelp":{"#cdata":"Syntax: CLASS variables;\n\nThe CLASS statement causes the specified variables to be treated as categorical variables in the analysis. \nThese variables enter the analysis not through their values but through levels to which the unique values \nare mapped. \nYou can specify only one CLASS statement. \n\nNote: All classification levels are padded or truncated to 32 characters."},"StatementOptions":null},{"StatementName":"CODE","StatementHelp":{"#cdata":"Syntax: CODE FILE=filename ;\n      \nThe CODE statement converts the final tree to SAS DATA step code that you can use for scoring.\n\nIf you do not specify this statement, no SAS DATA step code is output."},"StatementOptions":{"StatementOption":{"StatementOptionName":"FILE=","StatementOptionHelp":{"#cdata":"Syntax: FILE=filename \n          \nSpecifies the name of the file to write the SAS score code to."},"StatementOptionType":"V"}}},{"StatementName":"FREQ","StatementHelp":{"#cdata":"Syntax: FREQ variable ; \n      \nThe variable in the FREQ statement identifies a numeric variable in the data set that contains the frequency\nof occurrence of each observation. PROC TREESPLIT treats each observation as if it appears f times, where\nf is the value of the FREQ variable for the observation. If f is not an integer, it is truncated to an integer.\nIf f is less than 1 or missing, the observation is not used in the analysis. When the FREQ statement is not\nspecified, each observation is assigned a frequency of 1."},"StatementOptions":null},{"StatementName":"GROW","StatementHelp":{"#cdata":"Syntax: GROW criterion < (options) > ;\n      \nThe GROW statement specifies the criterion by which to split a parent node into child nodes. As it grows the\ntree, PROC TREESPLIT calculates the specified criterion for each predictor variable and then splits on the\npredictor variable whose criterion is closest to the value specified for that criterion."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"CHAID","StatementOptionHelp":{"#cdata":"Syntax: CHAID < (options) >\n          \nFor categorical predictor variables, CHAID uses the value (as specified in the ALPHA= option) of a\nchi-square statistic (for a classification tree) or an F statistic (for a regression tree) to merge similar\nlevels of the predictor variable until the number of children in the proposed split reaches the number\nthat you specify in the MAXBRANCH= option. The p-values for the final split determine the variable\non which to split.\n\nFor continuous predictor variables, CHAID chooses the best single split until the number of children\nin the proposed split reaches the value that you specify in the MAXBRANCH= option.\n\nYou can specify the following options:\n  ALPHA=value\n    specifies the maximum p-value for a split to be considered.\n    By default, ALPHA=0.3.\n  BONFERRONI\n    requests a Bonferroni adjustment to the p-value for a variable after the split has been determined.\n    By default, no adjustment is made."},"StatementOptionType":"S","SubOptionsKeywords":"ALPHA=|BONFERRONI"},{"StatementOptionName":"CHISQUARE","StatementOptionHelp":{"#cdata":"Syntax: CHISQUARE < (options) >\n          \nUses a chi-square statistic to split each variable and then uses the p-values that correspond to the\nresulting splits to determine the splitting variable.\n\nYou can specify the following options:\n  ALPHA=value\n    specifies the maximum p-value for a split to be considered.\n    By default, ALPHA=0.3.\n  BONFERRONI\n    requests a Bonferroni adjustment to the p-value for a variable after the split has been determined.\n    By default, no adjustment is made."},"StatementOptionType":"S","SubOptionsKeywords":"ALPHA=|BONFERRONI"},{"StatementOptionName":"ENTROPY|GAIN","StatementOptionHelp":{"#cdata":"Syntax: ENTROPY (<options>)  | GAIN < option >\n          \nUses the gain in information (decrease in entropy) to split each variable and then to determine the split.\n\nYou can specify the following option:\n  MINENTROPY=number\n  MINGAIN=number\n   specifies the minimum gain value to validate a split."},"StatementOptionType":"S","SubOptionsKeywords":"MINENTROPY=|MINGAIN="},{"StatementOptionName":"GINI","StatementOptionHelp":{"#cdata":"Uses the decrease in the Gini index to split each variable and then to determine the split."},"StatementOptionType":"S"},{"StatementOptionName":"IGR","StatementOptionHelp":{"#cdata":"Uses the entropy metric to split each variable and then uses the information gain ratio to determine the\nsplit."},"StatementOptionType":"S"},{"StatementOptionName":"FTEST","StatementOptionHelp":{"#cdata":"Syntax: FTEST < (options) >\n          \nUses an F statistic to split each variable and then uses the resulting p-value to determine the split\nvariable.\n\nYou can specify the following options:\n  ALPHA=value\n    specifies the maximum p-value for a split to be considered.\n    By default, ALPHA=0.3.\n  BONFERRONI\n    requests a Bonferroni adjustment to the p-value for a variable after the split has been determined.\n    By default, no adjustment is made."},"StatementOptionType":"S","SubOptionsKeywords":"ALPHA=|BONFERRONI"},{"StatementOptionName":"RSS|VARIANCE","StatementOptionHelp":{"#cdata":"Uses the change in response variance to split each variable and then to determine the split."},"StatementOptionType":"S"}]}},{"StatementName":"MODEL","StatementHelp":{"#cdata":"Syntax: MODEL response = variable ;\n      \nThe MODEL statement causes PROC TREESPLIT to create a tree model by using response as the response\nvariable and one or more variables as predictors. By default, variables are treated as a continuous predictors\nif they are numeric variables, or as categorical variables if they also appear in a CLASS statement.\n\nNOTE: Specifying a character variable in a MODEL statement without previously declaring it in a CLASS\nstatement results in an error."},"StatementOptions":null},{"StatementName":"OUTPUT","StatementHelp":{"#cdata":"Syntax: OUTPUT OUT=CAS-libref.data-table < option > ;\n      \nThe OUTPUT statement creates an output data table that contains the results of PROC TREESPLIT."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"Syntax: OUT=CAS-libref.data-table\n          \nNames the output data table for PROC TREESPLIT to use. CAS-libref.data-table is a two-level name,\nwhere\n\n  CAS-libref refers to a collection of information that is defined in the LIBNAME statement and\n    includes the caslib, which includes a path to where the data table is to be stored, and\n    a session identifier, which defaults to the active session but which can be explicitly\n    defined in the LIBNAME statement. \n    \n  data-table specifies the name of the output data table."},"StatementOptionType":"V"},{"StatementOptionName":"COPYVAR=|COPYVARS=","StatementOptionHelp":{"#cdata":"Syntax:COPYVAR=variable | COPYVARS=(variables)\n          \nLists one or more variables from the input data table to be transferred to the output data table."},"StatementOptionType":"V"}]}},{"StatementName":"PARTITION","StatementHelp":{"#cdata":"Syntax: PARTITION partition-option ;\n      \nThe PARTITION statement specifies how observations in the input data set are logically partitioned into\ndisjoint subsets for model training, validation, and testing."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"FRACTION","StatementOptionHelp":{"#cdata":"Syntax: FRACTION(< TEST=fraction > < VALIDATE=fraction > < SEED=number >)\n          \nRandomly assigns specified proportions of the observations in the input data table to the roles. You\nspecify the proportions for testing and validation by using the TEST= and VALIDATE= suboptions.\nIf you specify both the TEST= and VALIDATE= suboptions, then the sum of the specified fractions\nmust be less than 1 and the remaining fraction of the observations are assigned to the training role. The\nSEED= option specifies an integer that is used to start the pseudorandom number generator for random\npartitioning of data for training, testing, and validation. If you do not specify SEED=number or if\nnumber is less than or equal to 0, the seed is generated by reading the time of day from the computer\u2019s \nclock."},"StatementOptionType":"V","SubOptionsKeywords":"VALIDATE=|TEST=|SEED="},{"StatementOptionName":"ROLE=|ROLEVAR=","StatementOptionHelp":{"#cdata":"Syntax: ROLE=|ROLEVAR=variable (< TEST='value' > < TRAIN='value' > < VALIDATE='value' >)  \n\nNames the variable in the input data table whose values are used to assign roles to each observation.\nThis variable cannot also appear as an analysis variable in other statements or options. The TEST=,\nTRAIN=, and VALIDATE= suboptions specify the formatted values of this variable that are used to\nassign observation roles. If you do not specify the TRAIN= suboption, then all observations whose\nrole is not determined by the TEST= or VALIDATE= suboption are assigned to the training role."},"StatementOptionType":"V","SubOptionsKeywords":"TRAIN=|VALIDATE=|TEST="}]}},{"StatementName":"PRUNE","StatementHelp":{"#cdata":"Syntax: PRUNE < prune-method >< (prune-options) > ;\n      \nThe PRUNE statement specifies the pruning method and related options."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"C45","StatementOptionHelp":{"#cdata":"Syntax: C45 < (CONFIDENCE=confidence-level) >\n          \nRequests C4.5 pruning (Quinlan 1993), which is based on the upper confidence limit for the error rate.\nFor more information, see the section \u201cPruning\u201d on page 499. This pruning method is available only\nfor classification trees (which have a categorical response). PROC TREESPLIT uses the error rate\nfrom the training data only.\n\nYou can specify the following prune-option:\n\n  CONFIDENCE=confidence-level\n    specifies the pruning confidence level, which must be a positive number in the range of [0, 1].\n    The default confidence level is 0.25."},"StatementOptionType":"S","SubOptionsKeywords":"CONFIDENCE="},{"StatementOptionName":"COSTCOMPLEXITY|CC","StatementOptionHelp":{"#cdata":"Syntax: COSTCOMPLEXITY < (prune-options) > | CC < (prune-options) >\n          \nRequests cost-complexity pruning (Breiman et al. 1984; Quinlan 1987; Zhang and Singer 2010). You\ncan specify this pruning method for both classification trees (which have a categorical response) and\nregression trees (which have a continuous response).\n\nYou can specify the following prune-options:\n  ALPHA=number\n    selects the subtree whose cost-complexity value \u03b1 is equal to number.\n  KFOLD=number \n    specifies the number of folds for k-fold cross validation.\n  LEAVES=number | ALL|SE\n    selects the subtree that has the requested number of leaves, or if no subtree with exactly that\n    number of leaves is available, selects the subtree whose number of leaves is less than and closest\n    to number. When LEAVES=ALL, the largest tree is selected. SE selects the subtree by performing k-fold \n    cross validation and using the Breiman\u2019s 1-SE rule instead of the minimum error rate."},"StatementOptionType":"S","SubOptionsKeywords":"ALPHA=|KFOLD=|LEAVES="},{"StatementOptionName":"OFF|NONE","StatementOptionHelp":{"#cdata":"Turns off pruning completely. No pruning is performed, and no pruning plots are generated."},"StatementOptionType":"S"},{"StatementOptionName":"REDUCEDERROR|REP","StatementOptionHelp":{"#cdata":"Syntax: REDUCEDERROR < (prune-options) > | REP < (prune-options) >\n          \nRequests reduced-error pruning (Quinlan 1986). Reduced-error pruning has two stages: subtree sequence\ngeneration and subtree selection. The validation data are used for both stages. The PARTITION\nstatement is required. \n\nYou can specify the following prune-options:\n\n  LEAVES=number | ALL\n    selects the subtree that has the requested number of leaves, or if no subtree with exactly that\n    number of leaves is available, selects the subtree whose number of leaves is less than and closest\n    to number. When LEAVES=ALL, the largest tree is selected."},"StatementOptionType":"S","SubOptionsKeywords":"LEAVES="}]}},{"StatementName":"WEIGHT","StatementHelp":{"#cdata":"Syntax: WEIGHT variable; \n\nThe variable in the WEIGHT statement is used as a weight to perform a weighted analysis of the data. \nObservations that have nonpositive or missing weights are not included in the analysis. If a WEIGHT \nstatement is not included, all observations that are used in the analysis are assigned a weight of 1."},"StatementOptions":null},{"StatementName":"TARGET","StatementHelp":{"#cdata":"Syntax: TARGET variable </ options>;\n\nThe TARGET statement names the variable whose values PROC TREESPLIT predicts. Missing values \nin the target are ignored except during scoring. \n\nYou cannot use a TARGET statement with a MODEL or CLASS statement."},"StatementOptions":{"StatementOption":{"StatementOptionName":"LEVEL=","StatementOptionHelp":{"#cdata":"Syntax: LEVEL=INTERVAL | NOMINAL\n          \nSpecifies whether the specified response variable is interval or nominal. \n\nBy default, LEVEL=INTERVAL for numeric variables and LEVEL=NOMINAL for categorical variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"INTERVAL","@Value2":"NOMINAL"},"StatementOptionToolTips":{"@ToolTip1":"Treats the response as an interval variable and creates a regression tree.","@ToolTip2":"Treats the response as a nominal variable and creates a decision tree."}}}},{"StatementName":"INPUT","StatementHelp":{"#cdata":"Syntax: INPUT variables </ option>;\n\nThe INPUT statement specifies predictor variables for the decision tree or regression tree. \nThe value of variable can be a range such as \"var_1\u2013var_1000\" or the special \"_ALL_\" value \nto include all variables in the data tables. As with CLASS variables, all nominal INPUT \nvariables are padded or truncated to 32 characters. \n\nYou cannot use an INPUT statement with a MODEL or CLASS statement."},"StatementOptions":{"StatementOption":{"StatementOptionName":"LEVEL=","StatementOptionHelp":{"#cdata":"Syntax: LEVEL=INTERVAL | NOMINAL\n          \nSpecifies whether the specified predictor variables are interval or nominal. \n\nBy default, LEVEL=INTERVAL for numeric variables and LEVEL=NOMINAL for categorical variables."},"StatementOptionType":"V","StatementOptionValues":{"@Value1":"INTERVAL","@Value2":"NOMINAL"},"StatementOptionToolTips":{"@ToolTip1":"Treats all numeric variables as interval predictors.","@ToolTip2":"Treats all variables as nominal predictors."}}}},{"StatementName":"SCORE","StatementHelp":{"#cdata":"Syntax: SCORE OUT=CAS-libref.data-table < option > ;\n      \nThe SCORE statement creates a new data table that is the result of prediction from using the input data and\nthe model."},"StatementOptions":{"StatementOption":[{"StatementOptionName":"OUT=","StatementOptionHelp":{"#cdata":"Syntax: OUT=CAS-libref.data-table\n          \nNames the output data table for PROC NNET to use. CAS-libref.data-table is a two-level name, where\n\nCAS-libref refers to a collection of information that is defined in the LIBNAME statement and\n  includes the caslib, which includes a path to where the data table is to be stored, and\n  a session identifier, which defaults to the active session but which can be explicitly\n  defined in the LIBNAME statement.\n  \n  data-table specifies the name of the output data table."},"StatementOptionType":"V"},{"StatementOptionName":"COPYVAR=|COPYVARS=","StatementOptionHelp":{"#cdata":"Syntax: COPYVAR=variable | COPYVARS=(variables)\n          \nLists one or more variables from the input data table to be transferred to the output data table."},"StatementOptionType":"V"}]}}],"#comment":{}}}}