{"Keywords":{"Keyword":[{"Name":"ACCESS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ACCESS options;  \n\nCreate and Update Statements:  \n  CREATE libref.member-name.ACCESS|VIEW ; \n  \n  UPDATE libref.member-name.ACCESS|VIEW ;  \n \nDatabase-Description Statements:\n  PATH= 'path-and-filename<.PC-filename-extension>' | <'>filename<'> | fileref;  \n \n...Editing Statements\nRUN; \n\nSAS still supports this legacy procedure. However, to access your relational DBMS data more directly, \nit is recommended that you use the SAS/ACCESS LIBNAME statement or the SQL pass-through facility."}},{"Name":"ACECLUS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ACECLUS PROPORTION=p | THRESHOLD=t <options> ; \n    BY variables ; \n    FREQ variable ; \n    VAR variables ; \n    WEIGHT variable ; \n\nThe ACECLUS (approximate covariance estimation for clustering) procedure obtains \napproximate estimates of the pooled within-cluster covariance matrix when the \nclusters are assumed to be multivariate normal with equal covariance matrices.\nNeither cluster membership nor the number of clusters needs to be known. PROC \nACECLUS is useful for preprocessing data to be subsequently clustered by the \nCLUSTER or FASTCLUS procedure."}},{"Name":"ADAPTIVEREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ADAPTIVEREG <options> ; \n    BY variables ; \n    CLASS variables </ options> ; \n    FREQ variable ; \n    MODEL dependent <(options)> = <effects></ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword <(keyword-options )> <=name>> \u2026<keyword <(keyword-options )> <=name>> ; \n    PARTITION <options> ; \n    SCORE <DATA=SAS-data-set> <OUT=SAS-data-set><keyword <=name>>\u2026<keyword <=name>> ; \n    WEIGHT variable ; \n\n[SAS/STAT 12.1 Experimental Procedure]\n\nThe ADAPTIVEREG procedure fits multivariate adaptive regression splines as defined by Friedman (1991b). \nThe method is a nonparametric regression technique that combines both regression splines and model \nselection methods. It does not assume parametric model forms and does not require specification of \nknot values for constructing regression spline terms. Instead, it constructs spline basis functions \nin an adaptive way by automatically selecting appropriate knot values for different variables and \nobtains reduced models by applying model selection techniques."}},{"Name":"ALLELE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ALLELE <options> ; \n    BY variables ; \n    POP variable </ options> ; \n    VAR variables ; \n    WITH variables ;      \n  \nThe ALLELE procedure performs preliminary analyses on genetic marker data. These \nanalyses serve to characterize the markers themselves or the population from which \nthey were sampled, and can also serve as the basis for joint analyses on markers and \ntraits. A genetic marker is any heritable unit that obeys the laws of transmission \ngenetics, and the analyses presented here assume the marker genotypes are determined \nwithout error. With an underlying assumption of random sampling, the analyses rest on \nthe multinomial distribution of marker alleles, and many standard statistical techniques \ncan be invoked with little modification. The ALLELE procedure uses the notation and \nconcepts described by Weir (1996); this is the reference for all equations and methods \nnot otherwise cited."}},{"Name":"ANOVA","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC ANOVA <options> ; \n    CLASS variables </ option> ; \n    MODEL dependents=effects </ options> ; \n    ABSORB variables ; \n    BY variables ; \n    FREQ variable ; \n    MANOVA <test-options></ detail-options> ; \n    MEANS effects </ options> ; \n    REPEATED factor-specification </ options> ; \n    TEST <H=effects> E=effect ;\n    \nThe ANOVA procedure performs analysis of variance (ANOVA) for balanced data from a wide \nvariety of experimental designs. In analysis of variance, a continuous response variable, \nknown as a dependent variable, is measured under experimental conditions identified by \nclassification variables, known as independent variables. The variation in the response \nis assumed to be due to effects in the classification, with random error accounting for \nthe remaining variation."}},{"Name":"APPEND","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC APPEND BASE=<libref.>SAS-data-set <DATA=<libref.>SAS-data-set> \n    <FORCE> <APPENDVER=V6> <GETSORT>;\n    \nThe APPEND procedure adds the observations from one SAS data set to the end of another \nSAS data set. \n\nGenerally, the APPEND procedure functions the same as the APPEND statement in the \nDATASETS procedure. The only difference between the APPEND procedure and the APPEND \nstatement in PROC DATASETS is the default for libref in the BASE= and DATA= arguments. \nFor PROC APPEND, the default is either WORK or USER. For the APPEND statement, the \ndefault is the libref of the procedure input library."}},{"Name":"AUTHLIB","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC AUTHLIB <option(s)>; \n    CREATE <option(s)>;\n    MODIFY <option(s)>;\n    REMOVE <option(s)>;\n    REPAIR ADD | UPDATE | DELETE LOCATION | METADATA <option(s)>;\n    REPORT <LIBRARY=libref>;\n    TABLES <option(s)>;\n    \n  \nThe AUTHLIB procedure is a utility procedure that manages metadata-bound libraries. With PROC AUTHLIB, \nyou can do the following: \n  \u2022 create a metadata-bound library by binding a physical library to metadata within a SAS Metadata Repository\n  \u2022 modify password values for a metadata-bound library\n  \u2022 repair metadata-bound libraries by recovering security information, secured library objects, \n    and secured table objects\n  \u2022 remove the physical security information and metadata objects that protect a metadata-bound library\n  \u2022 report inconsistencies between physical library contents and corresponding metadata objects within \n    a specified metadata-bound library"}},{"Name":"BCHOICE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC BCHOICE <options>;\n    BY variables;\n    CLASS variable <(options)> <\u2026variable <(options)> > </ options>;\n    MODEL response <(response-options)> = <fixed-effects> </ model-options>;\n    RANDOM random-effects </ options>;\n    PREDDIST OUTPRED=SAS-data-set <options>;    \n    RESTRICT <'label'> fixed-effect operand operator <value> ; \n    RESTRICT <'label'> fixed-effect constraint-list; \n\nThe BCHOICE (Bayesian choice) procedure performs Bayesian analysis for discrete choice models. Discrete \nchoice models are used in marketing research to model decision makers' choices among alternative products \nand services. The decision maker might be people, households, companies and so on, and the alternatives might \nbe products, services, actions, or any other options or items about which choices must be made (Train 2009). \nThe collection of alternatives that are available to the decision makers is called a choice set."}},{"Name":"BOXPLOT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC BOXPLOT options ; \n    BY variables ; \n    ID variables ; \n    INSET keywords </options> ; \n    INSETGROUP keywords </ options> ; \n    PLOT analysis-variable*group-variable <(block-variables)> <=symbol-variable> </ options > ; \n\nThe BOXPLOT procedure creates side-by-side box-and-whiskers plots of measurements \norganized in groups. A box-and-whiskers plot displays the mean, quartiles, and minimum \nand maximum observations for a group."}},{"Name":"BTL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC BTL <options> ; \n    BY variables ; \n    CLASS variables ; \n    MARKER variables </ options> ; \n    MODEL dependent <= fixed-effects> </ options> ; \n    PARMEST <options> ; \n    PARMS (value-list) ...</ options> ; \n    RANDOM random-effects </ options> ; \n    REPEATED <repeated-effect> </ options> ; \n    WEIGHT variable ; \n\nThe BTL procedure analyzes marker and trait data in order to find and characterize \nbinary trait loci (BTL). Mixed model analysis of variance is used to find a locus or \nloci associated with a trait, and a maximum likelihood model is used to estimate the \nrecombination and penetrance parameters for a given set of BTL. "}},{"Name":"CASECONTROL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CASECONTROL <options> ; \n    BY variables ; \n    STRATA variables </ options> ; \n    TRAIT variable ; \n    VAR variables ; \n    \nMarker information can be used to help locate the genes that affect susceptibility \nto a disease. The CASECONTROL procedure is designed for the interpretation of marker \ndata when random samples are available from the populations of unrelated individuals \nwho are either affected or unaffected by the disease. Several tests are available in \nPROC CASECONTROL that compare marker allele and/or genotype frequencies in the two \npopulations, with frequency differences indicating an association of the marker with \nthe disease. Although such an association can point to the proximity of the marker \nand disease genes in the genome, it can also reflect population structure, so care \nis needed in interpreting the results; association does not necessarily imply linkage."}},{"Name":"CALENDAR","Type":"SAS_PROCEDURE","Help":{"#cdata":"[Syntax: PROC CALENDAR <option(s)>;  \n    START variable;  \n    BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n    CALID variable </ OUTPUT=COMBINE|MIX|SEPARATE>;  \n    DUR variable;  \n    FIN variable;  \n    HOLISTART variable;  \n    HOLIDUR variable;  \n    HOLIFIN variable;  \n    HOLIVAR variable;\n    MEAN variable(s) </ FORMAT=format-name>;  \n    OUTSTART day-of-week;  \n    OUTDUR number-of-days;  \n    OUTFIN day-of-week;  \n    SUM variable(s) </ FORMAT=format-name>;  \n    VAR variable(s); ]\n    \nThe CALENDAR procedure displays data from a SAS data set in a monthly calendar format."}},{"Name":"CALIS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CALIS <options> ; \n    ...CALIS statements\n    ...SAS Programming statements\n    RUN;\n    QUIT;\n    \nThe CALIS procedure deals with structural equation modeling, an important statistical tool in social \nand behavioral sciences. Structural equations express relationships among a system of variables that \ncan be either observed variables (manifest variables) or unobserved hypothetical variables (latent \nvariables). You can use the CALIS procedure to estimate parameters and test hypotheses for constrained \nand unconstrained problems in various situations."}},{"Name":"CALLRFC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CALLRFC<options>;  \n    CALL <FUNCTION> 'function-name' <EXPORTING parameter-1|parameter-1.field-1=value-1 \n      < ... parameter-n=value-n>> \n      <IMPORTING parameter-1=SAS-dataset-name-1 < ... parameter-n=SAS-dataset-name-n>> \n      <INTABLES table-parameter-1=SAS-dataset-name-1 <... table-parameter-n=SAS-dataset-name-n>> \n      <TABLES table-parameter-1=SAS-dataset-name-1 <... table-parameter-n=SAS-dataset-name-n>> \n      <CALLBACK <callback-parameter-1=SAS-dataset-name-1 <... table-parameter-n=SAS-dataset-name-n>>> \n      </ default = SAS-library>;  \n \n    DESCRIBE <FUNCTION> 'function-name' <SHORT>; \n  \nThe CALLRFC procedure executes Remote Function Calls (RFC) or RFC-compatible functions \non an SAP System. \n\nAny Advanced Business Applications Programming (ABAP) function modules called by the \nCALLRFC procedure must be:\n\n  o RFC enabled \n  o have no dialog boxes \n  o synchronous"}},{"Name":"CANCORR","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CANCORR <options> ; \n    WITH variables ; \n    BY variables ; \n    FREQ variable ; \n    PARTIAL variables ; \n    VAR variables ; \n    WEIGHT variable ; \n    \nThe CANCORR procedure performs canonical correlation, partial canonical correlation, \nand canonical redundancy analysis. \n\nCanonical correlation is a generalization of multiple correlation for analyzing the \nrelationship between two sets of variables. In multiple correlation, you examine the \nrelationship between a linear combination of a set of explanatory variables, X, and \na single response variable, Y. In canonical correlation, you examine the relationship \nbetween linear combinations of the set of X variables and linear combinations of a set \nof Y variables. These linear combinations are called canonical variables or canonical \nvariates. Either set of variables can be considered explanatory or response variables, \nsince the statistical model is symmetric in the two sets of variables. Simple and \nmultiple correlation are special cases of canonical correlation in which one or both \nsets contain a single variable."}},{"Name":"CANDISC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CANDISC <options> ; \n    CLASS variable ; \n    BY variables ; \n    FREQ variable ; \n    VAR variables ; \n    WEIGHT variable ; \n\nCanonical discriminant analysis is a dimension-reduction technique related to principal \ncomponent analysis and canonical correlation. The methodology used in deriving the canonical \ncoefficients parallels that of a one-way MANOVA. MANOVA tests for equality of the mean \nvector across class levels. Canonical discriminant analysis finds linear combinations of \nthe quantitative variables that provide maximal separation between classes or groups. \nGiven a classification variable and several quantitative variables, the CANDISC procedure \nderives canonical variables, linear combinations of the quantitative variables that summarize \nbetween-class variation in much the same way that principal components summarize total variation."}},{"Name":"CATALOG","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC CATALOG CATALOG=<libref.>catalog <ENTRYTYPE=etype> <FORCE> <KILL>;  \n    CONTENTS <OUT=SAS-data-set> <FILE=fileref>;  \n    COPY OUT=<libref.>catalog <options>;  \n      SELECT entry-1 <...entry-n> </ ENTRYTYPE=etype>;  \n      EXCLUDE entry-1 <...entry-n> </ ENTRYTYPE=etype>;  \n \n    CHANGE old-name-1=new-name-1 <...old-name-n=new-name-n> </ ENTRYTYPE=etype>;  \n    EXCHANGE name-1=other-name-1 <...name-n=other-name-n> </ ENTRYTYPE=etype>;  \n    DELETE entry-1 <...entry-n> </ ENTRYTYPE=etype>;  \n    MODIFY entry (DESCRIPTION=<<'>entry-description<'>>)</ ENTRYTYPE=etype>;  \n    SAVE entry-1 <...entry-n> </ ENTRYTYPE=etype>; \n    \nPROC CATALOG is an interactive, statement-driven procedure that enables you to do \nthe following:\n\n  o create a listing of the contents of a catalog \n  o copy a catalog or selected entries within a catalog \n  o rename, exchange, or delete entries within a catalog \n  o change the name of a catalog entry \n  o modify, by changing or deleting, the description of a catalog entry"}},{"Name":"CATMOD","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC CATMOD <options> ; \n    DIRECT <variables> ; \n    MODEL response-effect=design-effects </ options> ; \n    CONTRAST 'label' row-description <, , row-description></ options> ; \n    BY variables ; \n    FACTORS factor-description <, , factor-description></ options> ; \n    LOGLIN effects</ option> ; \n    POPULATION variables ; \n    REPEATED factor-description <, , factor-description></ options> ; \n    RESPONSE <function></ options> ; \n    RESTRICT parameter=value < parameter=value> ; \n    WEIGHT variable ; \n    \nThe CATMOD procedure performs categorical data modeling of data that can be \nrepresented by a contingency table. PROC CATMOD fits linear models to functions \nof response frequencies, and it can be used for linear modeling, log-linear \nmodeling, logistic regression, and repeated measurement analysis. PROC CATMOD \nuses the following estimation methods: \n\n  o weighted least squares (WLS) estimation of parameters for a wide range of \n    general linear models \n\n  o maximum likelihood (ML) estimation of parameters for log-linear models and \n    the analysis of generalized logits"}},{"Name":"CHART","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CHART <option(s)>;  \n    BLOCK variable(s) </ option(s)>;  \n    BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n    HBAR variable(s) </ option(s)>;  \n    PIE variable(s) </ option(s)>;  \n    STAR variable(s) </ option(s)>;  \n    VBAR variable(s) </ option(s)>;\n  \nThe CHART procedure produces vertical and horizontal bar charts, block charts, \npie charts, and star charts. These types of charts graphically display values \nof a variable or a statistic associated with those values. The charted variable \ncan be numeric or character.\n\nPROC CHART is a useful tool that lets you visualize data quickly, but if you need \nto produce presentation-quality graphics that include color and various fonts, then \nuse SAS/GRAPH software. The GCHART procedure in SAS/GRAPH software produces the same \ntypes of charts as PROC CHART does. In addition, PROC GCHART can produce donut charts."}},{"Name":"CIMPORT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CIMPORT destination=libref | <libref.>member-name <option(s)>;\n    EXCLUDE SAS file(s) | catalog entry(s)</ MEMTYPE=mtype></ ENTRYTYPE=entry-type>;  \n    SELECT SAS file(s) | catalog entry(s)</ MEMTYPE=mtype></ ENTRYTYPE=entry-type>;  \n  \nThe CIMPORT procedure imports a transport file that was created (exported) by the \nCPORT procedure. PROC CIMPORT restores the transport file to its original form as \na SAS catalog, SAS data set, or SAS library. Transport files are sequential files \nthat each contain a SAS library, a SAS catalog, or a SAS data set in transport format. \nThe transport format that PROC CPORT writes is the same for all environments and for \nmany releases of SAS."}},{"Name":"CLUSTER","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CLUSTER METHOD = name <options> ; \n    BY variables ; \n    COPY variables ; \n    FREQ variable ; \n    ID variable ; \n    RMSSTD variable ; \n    VAR variables ;\n    \nThe CLUSTER procedure hierarchically clusters the observations in a SAS data set \nby using one of 11 methods. The data can be coordinates or distances.  If the data \nare coordinates, PROC CLUSTER computes (possibly squared) Euclidean distances. If \nyou want non-Euclidean distances, use the DISTANCE procedure to compute an appropriate \ndistance data set that can then be used as input to PROC CLUSTER."}},{"Name":"COMPARE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC COMPARE <option(s)>;\n    BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n    ID <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n    VAR variable(s);  \n    WITH variable(s);  \n\nThe COMPARE procedure compares the contents of two SAS data sets, selected variables \nin different data sets, or variables within the same data set."}},{"Name":"CONTENTS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CONTENTS <option-1 <...option-n>>;\n    \nThe CONTENTS procedure shows the contents of a SAS data set and prints the directory \nof the SAS library. \n\nGenerally, the CONTENTS procedure functions the same as the CONTENTS statement in the \nDATASETS procedure. The differences between the CONTENTS procedure and the CONTENTS \nstatement in PROC DATASETS are as follows:\n\nThe default for libref in the DATA= option in PROC CONTENTS is WORK. For the CONTENTS \nstatement, the default is the libref of the procedure input library.\n\nPROC CONTENTS can read sequential files. The CONTENTS statement cannot."}},{"Name":"CONVERT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CONVERT product-specification <option(s)> ;\n    \nThe CONVERT procedure converts a BMDP or OSIRIS system file or an SPSS export\nfile to a SAS data set. It produces one output data set, but no printed output.\nThe new data set contains the same information as the input system file;\nexceptions are noted in Output Data Sets. The BMDP, OSIRIS and SPSS engines\nprovide more extensive capabilities.\n\nBecause the BMDP, OSIRIS and SPSS products are maintained by other companies or\norganizations, changes can be made that make the system files incompatible with\nthe current version of PROC CONVERT. SAS upgrades PROC CONVERT only to support\nchanges that are made to these products when a new version of SAS is available."}},{"Name":"COPY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC COPY OUT=libref-1 IN=libref-2 <CLONE|NOCLONE> \n    <CONSTRAINT=YES|NO> <DATECOPY> <INDEX=YES|NO> \n    <MEMTYPE=(mtype-1 <...mtype-n>)> <MOVE <ALTER=alter-password>>;\n        EXCLUDE SAS-file-1 <...SAS-file-n> </ MEMTYPE=mtype>;  \n        SELECT SAS-file-1 <...SAS-file-n> </ <MEMTYPE=mtype> <ALTER=alter-password>>; \n\nThe COPY procedure copies one or more SAS files from a SAS library."}},{"Name":"CORR","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CORR <options> ; \n    BY variables ; \n    FREQ variable ; \n    ID variables ; \n    PARTIAL variables ; \n    VAR variables ; \n    WEIGHT variable ; \n    WITH variables ;\n    \nThe CORR procedure computes Pearson correlation coefficients, three nonparametric \nmeasures of association, and the probabilities associated with these statistics. \nThe correlation statistics include the following:  \n\n  o Pearson product-moment correlation \n  o Spearman rank-order correlation \n  o Kendall's tau-b coefficient \n  o Hoeffding's measure of dependence, D\n  o Pearson, Spearman, and Kendall partial correlation"}},{"Name":"CORRESP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CORRESP <options> ; \n    TABLES <row-variables,> column-variables ; \n    VAR variables ; \n    BY variables ; \n    ID variable ; \n    SUPPLEMENTARY variables ; \n    WEIGHT variable ;\n\nThe CORRESP procedure performs simple correspondence analysis and multiple correspondence \nanalysis (MCA). You can use correspondence analysis to find a low-dimensional graphical \nrepresentation of the rows and columns of a crosstabulation or contingency table. Each \nrow and column is represented by a point in a plot determined from the cell frequencies. \nPROC CORRESP can also compute coordinates for supplementary rows and columns. \n\nPROC CORRESP can read two kinds of input: raw categorical responses on two or more \nclassification variables or a two-way contingency table. The correspondence analysis \nplot is displayed with ODS Graphics."}},{"Name":"CPORT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CPORT source-type=libref | <libref.>member-name<option(s)>;\n      EXCLUDE SAS file(s) | catalog entry(s)</ MEMTYPE=mtype></ ENTRYTYPE=entry-type>;  \n      SELECT SAS file(s) | catalog entry(s) </ MEMTYPE=mtype></ ENTRYTYPE=entry-type>;  \n      TRANTAB NAME=translation-table-name <option(s)>;\n  \nThe CPORT procedure writes SAS data sets, SAS catalogs, or SAS libraries to sequential \nfile formats (transport files). Use PROC CPORT with the CIMPORT procedure to move files \nfrom one environment to another. Transport files are sequential files that each contain \na SAS library, a SAS catalog, or a SAS data set in transport format. The transport format \nthat PROC CPORT writes is the same for all environments and for many releases of SAS. In \nPROC CPORT, export means to put a SAS library, a SAS catalog, or a SAS data set into \ntransport format. PROC CPORT exports catalogs and data sets, either singly or as a SAS \nlibrary. PROC CIMPORT restores (imports) the transport file to its original form as a \nSAS catalog, SAS data set, or SAS library."}},{"Name":"DATASETS","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"The DATASETS procedure is a utility procedure that manages your SAS files. \n  \nWith PROC DATASETS, you can do the following:\n\n  o copy SAS files from one SAS library to another \n  o rename SAS files \n  o repair SAS files \n  o delete SAS files \n  o list the SAS files that are contained in a SAS library \n  o list the attributes of a SAS data set, such as: \n      o the date when the data was last modified \n      o whether the data is compressed \n      o whether the data is indexed \n  o manipulate passwords on SAS files \n  o append SAS data sets \n  o modify attributes of SAS data sets and variables within the data sets \n  o create and delete indexes on SAS data sets \n  o create and manage audit files for SAS data sets \n  o create and delete integrity constraints on SAS data sets"}},{"Name":"DBF","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DBF <option(s)>;      \n      \nNames the input SAS data set. Use this option if you are creating a DBF file\nfrom a SAS data set. If you use the DATA= option, do not use the OUT= option.\nIf you omit the DATA= option, SAS software creates an output SAS data set\nfrom the DBF file."}},{"Name":"DBLOAD","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DBLOAD <options>;\n  CREATE;  \n  DBN= database-name;  \n  ACCDESC= libref.access-descriptor;  \n  DELETE variable-identifier <...variable-identifier-n>;  \n  INDEX variable-identifier = Y|N <...variable-identifier-n= Y|N>;  \n  LABEL;  \n  LEVEL variable-identifier = n <...variable-identifier-n= n>;  \n  LIST list-selection;  \n  LOAD;  \n  QUIT;  \n  RENAME variable-identifier = name <...variable-identifier-n = name-n>;  \n  RESET ALL|variable-identifier <...variable-identifier-n>;  \n  S2KLEN variable-identifier = n <...variable-identifier-n = n>;  \n  S2KLOAD;  \n  S2KMODE= M|S;  \n  S2KPW= password;  \n  VIEWDESC= libref.view-descriptor;  \n  WHERE SAS-where-expression;  \n\nThe DBLOAD procedure enables you to create and load a SYSTEM 2000 database\nusing data from a SAS data file, from a view created with the SQL procedure, or\nfrom a SYSTEM 2000 database or another DBMS (using a view descriptor created by\nusing the ACCESS procedure)."}},{"Name":"DELETE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DELETE <LIBRARY=libref> DATA=SAS-file-1 <SAS-file-2 \u2026> \n    (<GENNUM=ALL | HIST | REVERT | integer> \n    <MEMTYPE=member-type> \n    <ENCRYPTKEY=key-value> \n    <ALTER=alter-password>);\n    \nThe DELETE procedure deletes SAS files from the disk or tape on which it is stored. Use PROC DELETE \nto do the following: \n\n  \u2022delete either permanent or temporary SAS files\n  \u2022delete a list of data sets with a numeric suffix, such as\n    proc delete data=x1-x3;\n    run;\n  \u2022delete all SAS files of the same type using MEMTYPE=\n  \u2022delete generation data sets using GENNUM=\n  \u2022delete AES encrypted data sets when using GENNUM=ALL and ENCRYPTKEY= options \n  \nOne of the benefits of using PROC DELETE instead of the DELETE statement in the DATASETS procedure \nis that it does not use the in-memory directory to delete SAS data sets. \n\nThe DELETE procedure produces no printed output. As a result, the DELETE procedure is faster."}},{"Name":"DIF","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DIF options;\n\nConverts a DIF file to SAS data set or a SAS data set to a DIF file."}},{"Name":"DISCRIM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DISCRIM <options> ; \n    CLASS variable ; \n    BY variables ; \n    FREQ variable ; \n    ID variable ; \n    PRIORS probabilities ; \n    TESTCLASS variable ; \n    TESTFREQ variable ; \n    TESTID variable ; \n    VAR variables ; \n    WEIGHT variable ; \n\nFor a set of observations containing one or more quantitative variables and a classification \nvariable defining groups of observations, the DISCRIM procedure develops a discriminant criterion\nto classify each observation into one of the groups. The derived discriminant criterion from this \ndata set can be applied to a second data set during the same execution of PROC DISCRIM. The data \nset that PROC DISCRIM uses to derive the discriminant criterion is called the training or \ncalibration data set."}},{"Name":"DISPLAY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DISPLAY CATALOG=libref.catalog.entry.type <BATCH>;\n    \nThe DISPLAY procedure executes SAS/AF applications. These applications are composed \nof a variety of entries that are stored in a SAS catalog and that have been built with \nthe BUILD procedure in SAS/AF software. For complete documentation on building SAS/AF \napplications, see SAS Guide to Applications Development.\n\nYou can use the DISPLAY procedure to execute an application that runs in NODMS batch mode. \nBe aware that any SAS programming statements that you submit with the DISPLAY procedure \nthrough the SUBMIT block in SCL are not submitted for processing until PROC DISPLAY has \nexecuted.\n\nIf you use the SAS windowing environment, you can use the AF command to execute an \napplication. SUBMIT blocks execute immediately when you use the AF command. You can \nuse the AFA command to execute multiple applications concurrently."}},{"Name":"DISTANCE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DISTANCE <options> ; \n    BY variables ; \n    COPY variables ; \n    FREQ variable ; \n    ID variable ; \n    VAR level(variables </ opt-list>) ; \n    WEIGHT variable ; \n\nThe DISTANCE procedure computes various measures of distance, dissimilarity, or \nsimilarity between the observations (rows) of a SAS data set. These proximity \nmeasures are stored as a lower triangular matrix or a square matrix in an output \ndata set (depending on the SHAPE= option) that can then be used as input to the \nCLUSTER, MDS, and MODECLUS procedures. The input data set might contain numeric \nor character variables, or both, depending on which proximity measure is used."}},{"Name":"DOCUMENT","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC DOCUMENT <options>;  \n  COPY path<(where-expression)> <, path-2<(where-expression-2)>> \n    <, ...path-n<(where-expression-n)>> TO path </ option(s)>;  \n  DELETE path<(where-expression)> <, path-2<(where-expression-2)>> \n    <, ...path-n<(where-expression-n)>> < / LEVELS= ALL | value>;  \n  DIR <path>;  \n  DOC <options>;  \n  DOC CLOSE;  \n  HIDE path <, path-2, ...path-n>;  \n  IMPORT DATA= data-set-name | GRSEG=grseg TO path </options>;  \n  LINK path TO path </ options>;  \n  LIST path<(where-expression)> <, path-2<(where-expression-2)>> \n    <, ...path-n<(where-expression-n)>> </option(s)>;  \n  MAKE path <, path-2, ...path-n> </ options>;  \n  MOVE path<(where-expression)> <, path-2<(where-expression-2)>> \n    <, ...path-n<(where-expression-n)>> TO path </ option(s) >;  \n  NOTE path <'text'> </ option(s)>;  \n  OBANOTE<n> output-object <'text'> </option>;  \n  OBBNOTE<n> output-object <'text'> </ option>;  \n  OBFOOTN<n> output-object <'text'>;  \n  OBPAGE output-object </ option(s)>;  \n  OBSTITLE<n> output-object <'text'> </ options>;  \n  OBTEMPL output-object;  \n  OBTITLE<n> output-object <'text'>;  \n  RENAME path-1 TO path-2;  \n  REPLAY path<(where-expression)> <, path-2<(where-expression-2)>> \n    <, ...path-n<(where-expression-n)>> </ options>;  \n  SETLABEL path 'label';  \n  UNHIDE path <, path-2, ...path-n>;  \nQUIT;  \n\nIn ODS documents, the DOCUMENT procedure enables you to rearrange, duplicate, or remove \noutput from the results of a procedure or a database."}},{"Name":"DSTRANS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DSTRANS DSI_TO_DS2 | IN=data-step-file OUT=ds2-filename OUTDIR=ds2-pathname; \n    SUBMIT; \n    ENDSUBMIT; \n    \n The DSTRANS procedure translates a subset of SAS DATA step code into DS2 language statements. \n Then, if necessary, you can revise your program to take advantage of DS2 functionality and \n submit your program in a Base SAS session using the DS2 procedure."}},{"Name":"EXPORT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC EXPORT DATA=<libref.>SAS-data-set <(SAS-data-set-options)> \n    OUTFILE=\"filename\" | OUTTABLE=\"tablename\" <DBMS=identifier> <REPLACE><LABEL>;  \n    <data-source-statement(s);>\n      \nThe EXPORT procedure reads data from a SAS data set and writes it to an external data source. \nExternal data sources can include such files as Microsoft Access Database, Excel files, Lotus \nspreadsheets, and delimited external files. In delimited files, a delimiter--such as a blank, \ncomma, or tab--separates columns of data values. \n\nWhen you run PROC EXPORT, it reads the input data set and writes the data to the external data \nsource. PROC EXPORT uses one of these methods to export data:\n\n  o generated DATA step code \n  o generated SAS/ACCESS code \n  o translation engines"}},{"Name":"EXPLODE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC EXPLODE;\n    PARMCARDS|PARMCARDS4;\n    message-line(s)\n    ;|;;;; \n    \nThe EXPLODE procedure produces printed output with oversized text by expanding \neach letter into a matrix of characters. You can use the EXPLODE procedure to \ngenerate posters, flip charts, and header pages for computer output. \n\nNote: PROC EXPLODE with a PARMCARDS statement cannot be included in a macro."}},{"Name":"FACTOR","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FACTOR <options> ; \n    VAR variables ; \n    PRIORS communalities ; \n    PARTIAL variables ; \n    FREQ variable ; \n    WEIGHT variable ; \n    BY variables ; \n\nThe FACTOR procedure performs a variety of common factor and component analyses \nand rotations. Input can be multivariate data, a correlation matrix, a covariance \nmatrix, a factor pattern, or a matrix of scoring coefficients. The procedure can \nfactor either the correlation or covariance matrix, and you can save most results \nin an output data set."}},{"Name":"FAMILY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PROC FAMILY <options> ; \n    BY variables ; \n    ID variables ; \n    TRAIT variable </ AFFECTED= value> ; \n    VAR variables ; \n    XLVAR variables ; \n  \nFamily genotype data, though more difficult to collect, often provide a more effective way \nof testing markers for association with disease status than case-control data. Case-control \ndata can uncover significant associations between markers and a disease that could be caused \nby factors other than linkage, such as population structure. Analyzing family data by using \nthe FAMILY procedure ensures that any significant associations found between a marker and \ndisease status are due to linkage between the marker and disease locus. This is accomplished \nby using the transmission/disequilibrium test (TDT) and several variations of it that can \naccommodate different types of family data. One type of family consists of parents, at least \none heterozygous, and an affected child who have all been genotyped. This family structure is \nsuitable for the original TDT. Families having at least one affected and one unaffected sibling \nfrom a sibship that have both been genotyped can be analyzed using the sibling tests: the sib \nTDT (S-TDT) or the nonparametric sibling disequilibrium test (SDT). Both types of families can \nbe jointly analyzed using the combined versions of the S-TDT and SDT and the reconstruction-\ncombined TDT (RC-TDT). The RC-TDT can additionally accommodate families with no unaffected \nchildren and missing parental genotypes in certain situations."}},{"Name":"FASTCLUS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FASTCLUS <DATA=SAS-data-set> MAXCLUSTERS=n | RADIUS=t <options> ; \n    VAR variables ; \n    ID variables ; \n    FREQ variable ; \n    WEIGHT variable ; \n    BY variables ;\n\nThe FASTCLUS procedure performs a disjoint cluster analysis on the basis of distances \ncomputed from one or more quantitative variables. The observations are divided into \nclusters such that every observation belongs to one and only one cluster; the clusters \ndo not form a tree structure as they do in the CLUSTER procedure. If you want separate \nanalysis for different numbers of clusters, you can run PROC FASTCLUS once for each \nanalysis. Alternatively, to do hierarchical clustering on a large data set, use PROC \nFASTCLUS to find initial clusters, and then use those initial clusters as input to \nPROC CLUSTER."}},{"Name":"FCMP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FCMP option(s); \n    ABORT;  \n    ARRAY array-name[dimensions] </NOSYMBOLS | variable(s) | constant(s) | (initial-values)>; \n    ATTRIB variable(s) <FORMAT=format-name ><LABEL='label'>< LENGTH=length>;  \n    DELETEFUNC function-name; \n    DELETESUBR subroutine-name; \n    FUNCTION function-name(argument(s)) <VARARGS> <$> <length>\n      <KIND | GROUP='string' <LABEL='string-2'>>; \n    LABEL variable='label'; \n    LISTFUNC function-name;  \n    LISTSUBR subroutine-name; \n    STRUCT structure-name variable; \n    SUBROUTINE subroutine-name (argument(s)) <VARARGS>\n      <LABEL='label'> <KIND | GROUP='string'>;  \n    OUTARGS out-argument(s);\n      \nThe SAS Function Compiler (FCMP) procedure enables you to create, test, and store \nSAS functions and CALL routines before you use them in other SAS procedures or DATA \nsteps. PROC FCMP provides the ability to build functions and CALL routines using DATA \nstep syntax that is stored in a data set. The procedure accepts slight variations of \nDATA step statements, and you can use most features of the SAS programming language \nin functions and CALL routines that are created by PROC FCMP. You can call PROC FCMP \nfunctions and CALL routines from the DATA step just as you would any other SAS function \nor CALL routine. This feature enables programmers to more easily read, write, and maintain \ncomplex code with independent and reusable subroutines. You can reuse the PROC FCMP routines \nin any DATA step or SAS procedure that has access to their storage location."}},{"Name":"FEDSQL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FEDSQL <option(s)>; \n  \u2026FedSQL statements \n  QUIT; \n  \nSAS FedSQL is a SAS proprietary implementation of ANSI SQL:1999 core standard. It provides support \nfor new data types and other ANSI 1999 core compliance features and proprietary extensions. FedSQL \nprovides a scalable, threaded, high-performance way to access, manage, and share relational data in \nmultiple data sources. When possible, FedSQL queries are optimized with multi-threaded algorithms \nin order to resolve large-scale operations. \n\nFor applications, FedSQL provides a common SQL syntax across all data sources. That is, FedSQL \nis a vendor-neutral SQL dialect that accesses data from various data sources without having to \nsubmit queries in the SQL dialect that is specific to the data source. In addition, a single \nFedSQL query can target data in several data sources and return a single result table."}},{"Name":"FMM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FMM <options> ; \n  BAYES bayes-options ; \n  BY variables ; \n  CLASS variables </ TRUNCATE> ; \n  FREQ variable ; \n  ID variables ; \n  MODEL response<(response-options)> = <effects> </ model-options> ; \n  MODEL events/trials = <effects> </ model-options> ; \n  MODEL + <effects> </ model-options> ; \n  OUTPUT <OUT=SAS-data-set> <keyword<(keyword-options)> <=name>>...\n    <keyword<(keyword-options)> <=name>> </ options> ; \n  PERFORMANCE performance-options ; \n  PROBMODEL <effects> </ probmodel-options> ; \n  RESTRICT <'label'> constraint-specification <, ..., constraint-specification>\n    <operator <value>> </ option> ; \n  WEIGHT variable ; \n    \nThe FMM procedure estimates the parameters in univariate finite mixture models and \nproduces various statistics to evaluate parameters and model fit."}},{"Name":"FONTREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FONTREG <option(s)>;  \n    FONTFILE 'file' <...'file'> || 'file-1, pfm-file-1, afm-file-1' <...'file-n'>;  \n    FONTPATH 'directory' <...'directory'>;  \n    REMOVE 'family-name' | 'alias' | family-type | _ALL_;  \n    TRUETYPE 'directory' <...'directory'>;  \n    TYPE1 'directory' <...'directory'>;\n    OPENTYPE <fileref> 'directory' <\u2026'directory'>;\n      \nThe FONTREG procedure enables you to update the SAS registry to include system fonts, \nwhich can then be used in SAS output. PROC FONTREG uses FreeType font-rendering to \nrecognize and incorporate various types of font definitions. Fonts of any type that \ncan be incorporated and used by SAS are known collectively in this documentation as \nfonts in the FreeType library."}},{"Name":"FORMAT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FORMAT <option(s)>;\n    EXCLUDE entry(s);  \n    INVALUE <$>name <(informat-option(s))> value-range-set(s);  \n    PICTURE name <(format-option(s))> value-range-set-1 <(picture-1-option(s) )> \n      <...value-range-set-n <(picture-n-option(s))>>;  \n    SELECT entry(s);  \n    VALUE <$>name <(format-option(s))> value-range-set(s);  \n\nThe FORMAT procedure enables you to define your own informats and formats for variables. \nIn addition, you can print the parts of a catalog that contain informats or formats, store \ndescriptions of informats or formats in a SAS data set, and use a SAS data set to create \ninformats or formats."}},{"Name":"FORMS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FORMS <option(s)>;\n    BY <DESCENDING> variable-1\n      <\u2026<DESCENDING> variable-n>\n      <NOTSORTED>;\n    FREQ variable;\n    LINE line-number variable(s) </ option(s)>; \n    \nThe FORMS procedure produces labels for envelopes, mailing labels, external tape labels, \nfile cards, and any other printer forms that have a regular pattern. For each observation \nin the input SAS data set, PROC FORMS prints data in a rectangular block called a form unit. \nFor example, a mailing label is a form unit."}},{"Name":"FREQ","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FREQ <options> ; \n    BY variables ; \n    EXACT statistic-options </ computation-options> ; \n    OUTPUT <OUT=SAS-data-set> options ; \n    TABLES requests </ options> ; \n    TEST options ; \n    WEIGHT variable </ option> ; \n\nThe FREQ procedure produces one-way to n-way frequency and contingency (crosstabulation) tables. \nFor two-way tables, PROC FREQ computes tests and measures of association. For n-way tables, PROC \nFREQ provides stratified analysis by computing statistics across, as well as within, strata."}},{"Name":"FSLIST","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FSLIST FILEREF=file-specification|UNIT=nn <option(s)>;\n  \nThe FSLIST procedure enables you to browse external files that are not SAS data sets within \na SAS session."}},{"Name":"FSLETTER","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FSLETTER LETTER=SAS-catalog<.catalog-entry>  <DATA=data-set>  \n    <NOBORDER>  \n    <PRINTFILE=fileref | 'actual-filename'>;   \n    WHERE expression;  \n    \nThe FSLETTER procedure enables you to create, edit, and print letters and other documents. \nWhen creating and editing documents in the FSLETTER window, you can use all the features of \nthe SAS text editor, including the spelling checker."}},{"Name":"FSVIEW","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FSVIEW <DATA=data-set> | <NEW=data-set <LIKE=data-set>>  \n    <FORMULA=SAS-catalog<.formula-entry>> <options>;  \n     \n    FORMAT variable-list format <... variable-list-n format-n>;  \n    ID variable <... variable-n>;  \n    INFORMAT variable-list informat <... variable-list-n informat-n>;  \n    VAR variable <... variable-n>;  \n    WHERE expression;  \n\nThe FSVIEW procedure enables you to browse or edit a SAS data set, displaying the data set \nas a table of rows and columns. You can also use it to create a new SAS data set.\n\nThe procedure provides tools for customizing an FSVIEW application. For example, you can \nredesign the display by changing the size, position, and colors of the FSVIEW window. You \ncan also add computed variables, which display values that are calculated from other variables \nin the data set."}},{"Name":"FSBROWSE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FSBROWSE <DATA=data-set>  <KEYS=keys-entry>  \n    <SCREEN=SAS-catalog <.screen-entry>> | <display-options>  \n    <procedure-options>  \n    <letter-options>;  \n    \n    FORMAT variable-list format <... variable-list-n format-n>;  \n    INFORMAT variable-list informat <... variable-list-n informat-n>;  \n    LABEL variable='label' <... variable-n='label-n'>;  \n    VAR variable <... variable-n>;  \n    WHERE expression;     \n\nThe FSBROWSE procedure opens the FSBROWSE window, from which you can browse the contents \nof a SAS data set one observation at a time. The FSBROWSE procedure is identical to the \nFSEDIT procedure, except that the FSBROWSE window does not allow you to make changes to \nthe displayed data set."}},{"Name":"FSEDIT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FSEDIT <DATA=data-set | NEW=data-set <LIKE=data-set>>  <KEYS=keys-entry>  \n    <SCREEN=SAS-catalog<.screen-entry>> | <display-options>  \n    <procedure-options>  \n    <letter-options>;  \n    \n    FORMAT variable-list format <... variable-list-n format-n>;  \n    INFORMAT variable-list informat <... variable-list-n informat-n>;  \n    LABEL variable='label' <... variable-n='label-n'>;  \n    VAR variable <... variable-n>;  \n    WHERE expression;     \n\nThe FSEDIT procedure enables you to edit a SAS data set one observation at a time. \nYou can also use it to create a new SAS data set.\n\nThe procedure provides the tools for building applications for entering and editing data. \nAn FSEDIT application provides a custom display in which each data entry field has a set \nof attributes that can \n  o assign an initial value to the field \n  o restrict the range of values that can be entered in the field \n  o protect the field from editing \n  o require that a value be entered in the field."}},{"Name":"G3D","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC G3D <DATA=input-data-set> <ANNOTATE=annotate-data-set> \n    <GOUT=<libref.>output-catalog>;  \n    PLOT plot-request</option(s)>;  \n    SCATTER plot-request</option(s)>;  \n\nThe G3D procedure enables you to produce three-dimensional surface plots (using the PLOT statement) \nand scatter plots (using the SCATTER statement). \n\nSurface plots represent the shape of the surface that is described by the values of three \nvariables, X, Y, and Z. The values of the X and Y variables are plotted to form a horizontal \nplane. The values of the Z variable, create a vertical axis that is perpendicular to the X-Y \nplane. Combined, these three axes, form a three-dimensional surface."}},{"Name":"G3GRID","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC G3GRID <DATA=input-data-set> <OUT=output-data-set>\n    <OUTTRI=output-data-set>;  \n    GRID grid-request </option(s)>;  \n\nThe G3GRID procedure processes an existing SAS data set to create a data set that the G3D \nprocedure or the GCONTOUR procedure can use to produce a three-dimensional surface plot or \na contour plot. The procedure creates a data set whose horizontal X-Y variable values form \na complete grid, and it interpolates the values of the vertical Z variable for each point \non the X-Y plane."}},{"Name":"GAM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GAM <options> ; \n    CLASS variable<(options)><variable<(options)>></options> ; \n    MODEL dependent</options> = <PARAM(effects)> <smoothing effects></options> ; \n    SCORE data=SAS-data-set out=SAS-data-set ; \n    OUTPUT <out=SAS-data-set> keyword=prefix < keyword=prefix> ; \n    BY variables ; \n    FREQ variable ; \n\nThe GAM procedure fits generalized additive models as those models are defined by Hastie and \nTibshirani (1990). This procedure provides an array of powerful tools for data analysis, based \non nonparametric regression and smoothing techniques."}},{"Name":"GAMPL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GAMPL <options>;\n    CLASS variable <(options)>$\\ldots $ <variable <(options)>> </ global-options>;\n    MODEL response <(response-options)> = <PARAM(effects)> <spline-effects> </ model-options>;\n    MODEL events / trials = <PARAM(effects)> <spline-effects> </ model-options>;\n    OUTPUT <OUT=SAS-data-set> <keyword <=name>>\u2026<keyword <=name>> </ options>;\n    PERFORMANCE performance-options;\n    FREQ variable;\n    ID variables;\n    WEIGHT variable;\n    \nThe GAMPL procedure is a high-performance procedure that fits generalized additive models that are based on \nlow-rank regression splines (Wood 2006). This procedure provides powerful tools for nonparametric regression \nand smoothing."}},{"Name":"GANNO","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GANNO ANNOTATE=Annotate-data-set \n    <DATASYS> \n    <DESCRIPTION='description'> \n    <GOUT=<libref.>output-catalog> \n    <IMAGEMAP=output-data-set> \n    <LONGNAME='entry-name'> \n    <NAME= 'entry-name' | variable-name>; \n\nThe GANNO procedure displays graphs created by Annotate data sets. The procedure can also be \nused to scale data-dependent graphics to fit the graphics output area. Note that the GANNO \nprocedure ignores all currently defined title and footnote statements and some graphics option \nspecifications, including BORDER=. To include titles, footnotes, and graphics options along with \nyour Annotate data set, use the GSLIDE procedure instead of the GANNO procedure."}},{"Name":"GAREABAR","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GAREABAR <DATA=input-data-set;>  \n    HBAR | HBAR3D | VBAR | VBAR3D chart-variable*width-variable/SUMVAR=numeric-variable<(option(s)> ; \n\nThe GAREABAR procedure produces an area bar chart displaying two statistics for each \ncategory of data."}},{"Name":"GENESELECT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GENESELECT <options> ; \n    FREQ variable ; \n    PERFORMANCE <options> ; \n    TRAIT variable </ options> ; \n    VAR variables </ options> ; \n    IMPORTANCE <options> ; \n    PARTIALDEP <options> ; \n    SAVE <options> ; \n    SCORE <options> ; \n\nThe GENESELECT procedure identifies influential genetic and environmental variables \nand their interactions by fitting a model to predict a trait and then evaluating the \ninfluence that the predictor variables and their interactions have on the model."}},{"Name":"GBARLINE","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GBARLINE <DATA=input-data-set> \n    <ANNOTATE=Annotate-data-set> <IMAGEMAP=output-data-set>;  \n    BAR bar-variable </option(s)>;  \n    <PLOT </option(s)>;>...  \n    <PLOT </option(s)>;>  \n\nThe GBARLINE procedure produces bar-line charts. Bar-line charts are vertical bar \ncharts with one or more plot overlays. These charts graphically represent the value \nof a statistic calculated for one or more variables in an input SAS data set. The \ncharted variables can be either numeric or character.\n\nThe procedure calculates these statistics: \n  o sum\n  o mean\n  o frequency or cumulative frequency\n  o percentage or cumulative percentage."}},{"Name":"GCHART","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GCHART <DATA=input-data-set> \n      <ANNOTATE=Annotate-data-set> \n      <GOUT=<libref.>output-catalog> \n      <IMAGEMAP=output-data-set>;  \n      BLOCK chart-variable(s) </ option(s)>;  \n      HBAR | HBAR3D | VBAR | VBAR3D chart-variable(s) </ option(s)>;  \n      PIE | PIE3D | DONUT chart-variable(s) </ option(s)>;  \n      STAR chart-variable(s) </ option(s)>;  \n\nThe GCHART procedure produces six types of charts: block charts, horizontal and vertical \nbar charts, pie and donut charts, and star charts. These charts graphically represent the \nvalue of a statistic calculated for one or more variables in an input SAS data set. The \ncharted variables can be either numeric or character."}},{"Name":"GCONTOUR","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GCONTOUR <DATA=input-data-set> \n    <ANNOTATE=Annotate-data-set> <GOUT=<libref.>output-catalog> <INCOMPLETE>;  \n    PLOT y*x=z </option(s)>;  \n\nThe GCONTOUR procedure enables you to generate two-dimensional plots representing \nthree-dimensional relationships. \n\nWith PROC GCONTOUR, you can do the following actions:\n\n  o use AXIS statements to customize the axes \n  o use line styles and patterns to emphasize the contour levels \n  o use reference lines to see how (x,y) combinations align to z values \n  o use SYMBOL statements to customize labels or highlight data trends"}},{"Name":"GDEVICE","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GDEVICE <CATALOG=<libref.>SAS-catalog> <BROWSE> <NOFS>; \n    ADD new-device-entry required-parameters <optional-parameters>;  \n    COPY device-entry <FROM=<libref.>SAS-catalog> <NEWNAME=new-device-entry>;  \n    DELETE device-entry;  \n    FS;  \n    LIST device-entry | _ALL_ | _NEXT_ | _PREV_ | DUMP>;  \n    MODIFY device-entry parameter(s);\n    QUIT | END | STOP;  \n    RENAME device-entry NEWNAME=entry-name;  \n\nThe GDEVICE procedure is a tool for examining and changing the parameters of the graphics \ndevice driver catalog entries used with SAS/GRAPH software. With the GDEVICE procedure, you \ncan use either the GDEVICE windows or GDEVICE procedure statements to:\n\n  o list the device entries stored in any DEVICES catalog \n  o view the parameters for any device entry \n  o create and modify new device entries \n  o copy, modify, rename, or delete existing device entries."}},{"Name":"GEE","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GEE <options>; \n    BY variables; \n    CLASS variable <(options)> \u2026<variable <(options)>> </ options>; \n    ESTIMATE <'label'> estimate-specification </ options>; \n    FREQ | FREQUENCY variable; \n    LSMEANS <model-effects> </ options>; \n    MISSMODEL <effects> </ options>; \n    MODEL response = <effects > </ options>; \n    OUTPUT <OUT=SAS-data-set> <keyword=name \u2026keyword=name>; \n    REPEATED SUBJECT=subject-effect </ options>; \n    WEIGHT variable; \n    \nThe GEE procedure implements the generalized estimating equations (GEE) approach (Liang and Zeger 1986), \nwhich extends the generalized linear model to handle longitudinal data (Stokes, Davis, and Koch 2012; \nFitzmaurice, Laird, and Ware 2011; Diggle et al. 2002). For longitudinal studies, missing data are common, \nand they can be caused by dropouts or skipped visits. If missing responses depend on previous responses, \nthe usual GEE approach can lead to biased estimates. So the GEE procedure also implements the weighted \nGEE method to handle missing responses that are caused by dropouts in longitudinal studies (Robins and \nRotnitzky 1995; Preisser, Lohman, and Rathouz 2002). The GEE procedure in SAS/STAT 14.1 does not support \nthe weighted GEE method for the multinomial distribution for polytomous responses."}},{"Name":"GENMOD","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GENMOD <options> ; \n    ASSESS | ASSESSMENT VAR=(effect) | LINK </ options> ; \n    BAYES <options> ; \n    BY variables ; \n    CLASS variable <(options)><variable <(options)>> </ options> ; \n    CONTRAST 'label' contrast-specification </ options> ; \n    DEVIANCE variable = expression ; \n    EFFECTPLOT <plot-type <(plot-definition-options)>> </ options> ; \n    ESTIMATE 'label' effect values <,...effect values> </ options> ; \n    EXACT <'label'> <INTERCEPT> <effects> </ options> ; \n    EXACTOPTIONS options ; \n    FREQ | FREQUENCY variable ; \n    FWDLINK variable = expression ; \n    INVLINK variable = expression ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect <'label'> values <divisor=> <, ...<'label'> values <divisor=>> < / options> ; \n    MODEL response = <effects > </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name...keyword=name> ; \n    Programming statements ; \n    REPEATED SUBJECT=subject-effect </ options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    STRATA variable <(option)>  <variable <(option)>> </ options> ; \n    WEIGHT | SCWGT variable ; \n    VARIANCE variable = expression ; \n    ZEROMODEL <effects > </ options> ; \n\nThe GENMOD procedure fits generalized linear models, as defined by Nelder and Wedderburn \n(1972). The class of generalized linear models is an extension of traditional linear models \nthat allows the mean of a population to depend on a linear predictor through a nonlinear \nlink function and allows the response probability distribution to be any member of an \nexponential family of distributions."}},{"Name":"GEOCODE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GEOCODE <option(s)>; \n    \nGeocoding is the process of adding geographic coordinates (latitude and longitude values) \nto an address. \n\nThe coordinates typically represent the center of a ZIP code, a city, an address, or any \ngeographic region. After geocoding, the coordinates can be used to display a point on a map \nor to calculate distances. Geocoding also enables you to add attributes values such as census \nblocks to an address."}},{"Name":"GFONT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GFONT NAME=SAS/GRAPH font| device-resident font | system font mode \n      <display-option(s)> <creation-option(s)>; \n\nThe GFONT procedure displays fonts and creates SAS/GRAPH fonts for use in SAS/GRAPH \nprograms. These fonts can contain standard Roman alphabet characters, foreign language \ncharacters, symbols, logos, or figures. \n\nYou can use the GFONT procedure output when you want to do the following tasks:\n\n  o review the characters that are available in SAS/GRAPH fonts \n  o examine the default device-resident font for your device \n  o see the character codes associated with font characters \n  o view the hexadecimal values associated with font characters \n  o modify the color and height of font characters \n  o draw reference lines around font characters"}},{"Name":"GINSIDE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GINSIDE \n    DATA=points-data-set\n    MAP=map-data-set \n    <OUT=output-data-set > \n    <DROPMAPVARS>\n    <INSIDEONLY>\n    <INCLUDEBORDER>\n    <KEEPMAPVARS>; \n    ID d-variable(s); \n\nThe GINSIDE procedure compares a data set of X and Y coordinates to a map dataset containing \nmap polygons. The procedure determines whether the X and Y coordinates for each point fall \ninside of or outside of the map polygons. If the point falls inside of a polygon, then the \nID variable is set to the ID value of that polygon. For example, if a map contains states, \nthen the ID variable of the output data set is set to the state that contains the point. The \nGINSIDE procedure can be used with the SAS/GRAPH map data sets and the results can be used to \nannotate onto a map with the GMAP procedure."}},{"Name":"GKPI","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GKPI <MODE= BASIC | RAISED>;  \n    DIAL|HBULLET|HSLIDER|HTRAFFICLIGHT|SPEEDOMETER| VTRAFFICLIGHT|VBULLET|VSLIDER \n    ACTUAL=data-value BOUNDS=bound-value-list </ options>;  \n\nThe GKPI procedure creates graphical key performance indicator (KPI) charts. KPIs \nare metrics that help a business monitor its performance and measure its progress \ntoward specific goals. \n\nThe procedure produces five KPI chart types:\n\n  o slider (vertical or horizontal) \n  o bullet graph (vertical or horizontal) \n  o dial \n  o speedometer \n  o traffic light (vertical or horizontal).\n\nThe GKPI procedure produces a two or three-dimensional KPI chart based on a series \nof segment boundaries and an actual KPI value that you specify. If you specify a \ntarget value, the KPI chart also displays the target value. The procedure uses a \nset of default colors for the KPI chart, but you can specify your own colors."}},{"Name":"GLIMMIX","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GLIMMIX <options> ; \n    BY variables ; \n    CLASS variables ; \n    CODE <options>; \n    CONTRAST 'label' contrast-specification <, contrast-specification> <, ...> </ options> ; \n    COVTEST <'label'> <test-specification> </ options> ; \n    EFFECT effect-specification ; \n    ESTIMATE 'label' contrast-specification <(divisor=n)>\n      <, 'label' contrast-specification <(divisor=n)>> <, ...> </ options> ; \n    FREQ variable ; \n    ID variables ; \n    LSMEANS fixed-effects </ options> ; \n    LSMESTIMATE fixed-effect <'label'> values <divisor=>\n      <, <'label'> values <divisor=n>> <, ...> </ options> ; \n    MODEL response<(response-options)> = <fixed-effects> </ model-options> ; \n    MODEL events/trials = <fixed-effects> </ model-options> ; \n    NLOPTIONS <options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword<(keyword-options)> <=name>>...\n      <keyword<(keyword-options)> <=name>> </ options> ; \n    PARMS (value-list) ...</ options> ; \n    RANDOM random-effects </ options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    WEIGHT variable ; \n    Programming statements ;  \n\nThe GLIMMIX procedure fits statistical models to data with correlations or nonconstant variability \nand where the response is not necessarily normally distributed. These models are known as generalized \nlinear mixed models (GLMM)."}},{"Name":"GLM","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GLM <options> ; \n    CLASS variables </ option> ; \n    MODEL dependent-variables=independent-effects </ options> ; \n    ABSORB variables ; \n    BY variables ; \n    FREQ variable ; \n    ID variables ; \n    WEIGHT variable ; \n    CONTRAST 'label' effect values <...effect values> </ options> ; \n    ESTIMATE 'label' effect values <...effect values> </ options> ; \n    LSMEANS effects </ options> ; \n    MANOVA <test-options></ detail-options> ; \n    MEANS effects </ options> ; \n    OUTPUT <OUT=SAS-data-set> keyword=names <...keyword=names> </ option> ; \n    RANDOM effects </ options> ; \n    REPEATED factor-specification </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    TEST <H=effects> E=effect </ options> ; \n\nThe GLM procedure uses the method of least squares to fit general linear models. Among \nthe statistical methods available in PROC GLM are regression, analysis of variance, analysis \nof covariance, multivariate analysis of variance, and partial correlation."}},{"Name":"GLMMOD","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GLMMOD <options> ; \n    BY variables ; \n    CLASS variables ; \n    FREQ variable ; \n    MODEL dependents=independents / <options> ; \n    WEIGHT variable ; \n\nThe GLMMOD procedure constructs the design matrix for a general linear model; it \nessentially constitutes the model-building front end for the GLM procedure. You can \nuse the GLMMOD procedure in conjunction with other SAS/STAT software regression \nprocedures or with SAS/IML software to obtain specialized analyses for general \nlinear models that you cannot obtain with the GLM procedure."}},{"Name":"GLMPOWER","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GLMPOWER <options> ; \n    BY variables ; \n    CLASS variables ; \n    CONTRAST 'label' effect values <...effect values> </ options> ; \n    MODEL dependents = independents ; \n    PLOT <plot-options> </ graph-options> ; \n    POWER <options> ; \n    WEIGHT variable ; \n\nPower and sample size analysis optimizes the resource usage and design of a study, \nimproving chances of conclusive results with maximum efficiency. The GLMPOWER procedure \nperforms prospective power and sample size analysis for linear models, with a variety of \ngoals: \n\n  o determining the sample size required to get a significant result with adequate \n    probability (power) \n\n  o characterizing the power of a study to detect a meaningful effect \n\n  o conducting what-if analyses to assess sensitivity of the power or required sample \n    size to other factors"}},{"Name":"GLMSELECT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GLMSELECT <options> ; \n    BY variables ; \n    CLASS variable <(v-options)> <variable <(v-options ...)> > </ v-options> <options> ; \n    CODE <options>; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    FREQ variable ; \n    MODEL variable = <effects> </ options> ; \n    MODELAVERAGE <options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword <=name> > <...keyword=name> ; \n    PARTITION <options> ; \n    PERFORMANCE <options> ; \n    SCORE <DATA=SAS-data-set> <OUT=SAS-data-set> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    WEIGHT variable ; \n\nA variety of model selection methods are available, including the LASSO method of Tibshirani (1996) \nand the related LAR method of Efron et al. (2004). The procedure offers extensive capabilities for \ncustomizing the selection with a wide variety of selection and stopping criteria, from traditional \nand computationally efficient significance-level-based criteria to more computationally intensive \nvalidation-based criteria. The procedure also provides graphical summaries of the selection search."}},{"Name":"GMAP","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GMAP <MAP=map-data-set> \n      DATA=response-data-set | feature-table \n      <ALL> \n      <ANNOTATE=Annotate-data-set> \n      <DENSITY=0...6 | LOW | MEDIUM | HIGH> \n      <GOUT=<libref.>output-catalog> \n      <IMAGEMAP=output-data-set> \n      <STRETCH> \n      <UNIFORM>;  ID id-variable(s) | geo-variable; \n    AREA response-variable </ option(s)>; \n    BLOCK response-variable(s) </ option(s)>; \n    CHORO response-variable(s) </ option(s)>; \n    PRISM response-variable(s)</ option(s)>; \n    SURFACE response-variable(s) </ option(s)>;  \n\nThe GMAP procedure produces two-dimensional (choropleth) or three-dimensional (block, \nprism, and surface) maps that show variations of a variable value with respect to an \narea. A wide assortment of map data sets is available with SAS/GRAPH software."}},{"Name":"GOPTIONS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GOPTIONS <option(s)>; \n    \nThe GOPTIONS procedure provides information about the values of graphics options \nand the global statement definitions that are currently in effect in your session. \nThe values displayed are either the defaults of the current device driver or user-\ndefined values that have been assigned in your SAS session. You can use the GOPTIONS \nprocedure to do the following tasks:\n\n  o list the current values of all of the graphics options or of one specified option\n  o display the values of all of the AXIS, FOOTNOTE, LEGEND, PATTERN, SYMBOL, and TITLE \n    definitions that are currently in effect\n  o list the current values of all of the graphics options or of one specified option\n  o display the values of all of the AXIS, FOOTNOTE, LEGEND, PATTERN, SYMBOL, and TITLE \n    definitions that are currently in effect"}},{"Name":"GPLOT","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GPLOT <DATA=input-data-set> \n    <ANNOTATE=Annotate-data-set> <GOUT=<libref.>output-catalog> \n    <IMAGEMAP=output-data-set > <UNIFORM>;  \n    BUBBLE plot-request(s) </option(s)>;  \n    BUBBLE2 plot-request(s) </option(s)>;  \n    PLOT plot-request(s) </option(s)>;  \n    PLOT2 plot-request(s) </option(s)>;  \n \nThe GPLOT procedure plots the values of two or more variables on a set of coordinate axes \n(X and Y). The coordinates of each point on the plot correspond to two variable values in \nan observation of the input data set. The procedure can also generate a separate plot for \neach value of a third (classification) variable. It can also generate bubble plots in which \ncircles of varying proportions representing the values of a third variable are drawn at the \ndata points."}},{"Name":"GPROJECT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GPROJECT <option(s)>;  \n    ID id-variable(s); \n  \nThe GPROJECT procedure processes traditional map data sets by converting spherical coordinates \n(longitude and latitude) into Cartesian coordinates for use by the GMAP procedure.  The process \nof converting coordinates from spherical to Cartesian is called projecting. Many of the map data \nsets that are available with SAS/GRAPH contain unprojected longitude and latitude coordinates. \nWhen these coordinates are plotted by the GMAP procedure, which is designed to plot points on a \ntwo-dimensional plane, the resulting map is often reversed and distorted as a result of forcing \nthe spherical map coordinates onto a flat plane."}},{"Name":"GRADAR","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GRADAR <DATA=input-data-set> <GOUT=<libref.>output-catalog> \n    <ANNOTATE=Annotate-data-set>;  \n    CHART chart-variable </ option(s)>;  \n\nThe GRADAR procedure creates radar charts that show the relative frequency of data measures \nin quality control or market research problems. Radar charts are sometimes also called star \ncharts."}},{"Name":"GREDUCE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GREDUCE <option(s)>;  \n    ID id-variable(s);  \n\nThe GREDUCE procedure processes map data sets so that they can draw simpler maps with fewer \nboundary points. It creates an output map data set that contains all of the variables in the \ninput map data set plus a new variable named DENSITY. For each observation in the input map \ndata set, the procedure determines the significance of that point for maintaining a semblance \nof the original shape and gives the observation a corresponding DENSITY value."}},{"Name":"GREMOVE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GREMOVE <DATA=input-map-data-set> \n    <FUZZ=fuzz-factor> <OUT=output-map-data-set> <NODECYCLE>;  \n    BY <DESCENDING>variable-l <...<DESCENDING>variable-n> <NOTSORTED>;  \n    ID variable(s);  \n\nThe GREMOVE procedure processes a map data set that is used as input. It does not produce any \ngraphics output. Instead, it produces an output data set that typically becomes the input map \ndata set for the GMAP procedure (see The GMAP Procedure). The GREMOVE procedure combines unit \nareas defined in a map data set into larger unit areas by removing shared borders between the \noriginal unit areas. For example, Map before Removing Borders (GRMUSMAP(a)) and Map after\nRemoving Borders (GRMUSMAP(b)) show combined unit areas in a typical map data set by removing \nstate boundaries to create regional census divisions."}},{"Name":"GREPLAY","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GREPLAY <BYLINE> <CC=color-map-catalog> <CMAP=color-map-entry> \n    <FS> <GOUT=<libref.>output-catalog> <IGOUT=<libref.>input-catalog> \n    <IMAGEMAP=output-data-set> <NOBYLINE> <NOFS> <PRESENTATION> \n    <TC=template-catalog> <TEMPLATE=template-entry>; \n    BYLINE;  \n    CC color-map-catalog;  \n    CCOPY <color-map-catalog.>color-map-entry<.CMAP>;  \n    CDEF color-map-entry <color-definition(s)> <DES=\"description\">;  \n    CDELETE color-map-entry(s) | _ALL_ ;  \n    CMAP color-map-entry;  \n    COPY entry-id(s) | _ALL_ ;  \n    DELETE entry-id(s) | _ALL_ ;  \n    DEVICE device-name;  \n    FS;  \n    GOUT <libref.>output-catalog;  \n    GROUP entry-id(s);  \n    IGOUT <libref.>input-catalog ;  \n    LIST required-argument;  \n    MODIFY modify-pair(s);  \n    MOVE entry-id-1 AFTER | BEFORE entry-id-2;  \n    NOBYLINE;  \n    PREVIEW template-entry(s) | _ALL_ ;  \n    QUIT | END | STOP;  \n    REPLAY entry-id(s) | _FIRST_ | _LAST_ | _ALL_ ;  \n    TC template-catalog;  \n    TCOPY <template-catalog.>template-entry<.TEMPLATE>;  \n    TDEF template-entry < panel definition(s)> \n    <DES=\"description\">;  \n    TDELETE template-entry(s) | _ALL_ ;  \n    TEMPLATE template-entry;  \n    TREPLAY select-pair(s);  \n\nThe GREPLAY procedure displays and manages graphics output that is stored in SAS catalogs. \nThe GREPLAY procedure also creates templates and color maps that you can use when you replay \nyour graphics output. The GREPLAY procedure operates in line mode, batch mode, and in the SAS \nwindowing environments."}},{"Name":"GROOVY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GROOVY <classpath options>; \n  ADD classpath options; \n  EVALUATE <(LOAD | PARSEONLY | NORUN)> \u201cGroovy statement string\u201d <arguments>; \n  EXECUTE <(LOAD | PARSEONLY | NORUN)> Groovy file name | fileref <arguments>; \n  SUBMIT <(LOAD | PARSEONLY | NORUN)> <arguments>; \n  Groovy statements\n  ENDSUBMIT;\n  CLEAR;\nQUIT;\n\nGroovy is a dynamic language that runs on the Java Virtual Machine (JVM). PROC GROOVY \nenables SAS code to execute Groovy code on the JVM. PROC GROOVY can run Groovy statements \nthat are written as part of your SAS code, and it can run statements that are in files that \nyou specify with PROC GROOVY commands. It can parse Groovy statements into Groovy Class \nobjects, and run these objects or make them available to other PROC GROOVY statements or \nJava DATA Step Objects. You can also use PROC GROOVY to update your CLASSPATH environment \nvariable with additional CLASSPATH strings or filerefs to jar files."}},{"Name":"GSLIDE","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC GSLIDE <option(s)>; \n  \nThe GSLIDE procedure is useful for creating text slides for presentations. You can overlay \ntext slides on other graphics output with the GREPLAY procedure. The GSLIDE procedure produces \ngraphics output that consists of text and straight lines that are generated by TITLE, FOOTNOTE, \nand NOTE statements. In addition, the procedure provides an easy way to add titles, notes, and \nfootnotes to output that is produced entirely with an Annotate data set."}},{"Name":"GTILE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GTILE <DATA=input-data-set>;  \n    FLOW | TILE | TOGGLE size-variable TILEBY=(variable) | (variable-list) </option(s)>;  \n\nThe GTILE procedure creates charts that consist of a rectangle or a square divided into \ntile-shaped segments. These charts represent the relative sizes of tiles to one another \nand to the whole. The GTILE procedure provides three statements you can use to define the \nlayout in order to visualize your data. The statements require one numeric variable. This \nvariable defines the top level of the chart.\n\nThe TILEBY= statement is followed by any number of numeric or character variables that \nare delineated by a comma or a blank space. By providing multiple TILEBY variables, and \nspecifying either a JAVA or ACTIVEX device with the DEVICE= option, you can use the GTILE \nprocedure to create interactive charts.These charts enable you to display subsets (or levels) \nof your data. You can assign an additional numeric variable as a color variable using the \nCOLORVAR= option."}},{"Name":"GIMPORT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GIMPORT FILEREF=cgm-fileref | 'external-file' \n  FILETYPE=CGM \n  FORMAT=BINARY | CHARACTER | CLEARTEXT \n  <GOUT=<libref.>output-catalog>; \n    \nIdentifies the input file to be processed, and specifies its file type and format. \nOptionally specifies an output catalog."}},{"Name":"HPCANDISC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPCANDISC <options> ;     \n    BY variables ; \n    CLASS variable ; \n    FREQ variable ;\n    ID variables; \n    PERFORMANCE performance-options; \n    VAR variables ; \n    WEIGHT variable ; \n\nThe HPCANDISC procedure is a high-performance procedure that performs canonical discriminant analysis. \nIt is a high-performance version of the CANDISC procedure in SAS/STAT software. PROC HPCANDISC runs in \neither single-machine mode or distributed mode. \n\nNote: Distributed mode requires SAS High-Performance Statistics."}},{"Name":"HPCLUS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPCLUS < options > ;\n    INPUT variables < options > ;\n    ID variables ;\n    FREQ variable ;\n    SCORE < options > ;\n    CODE < options > ;\n    PERFORMANCE performance-options ; \n    \nThe HPCLUS procedure executes high-performance clustering. Clustering is a common step in the data\nexploration stage. The HPCLUS procedure takes only numeric variables. \n\nThe HPCLUS procedure performs an cluster analysis on the basis of distances computed from one or more\nvariables. The observations are divided into clusters such that every observation belongs to one and only one\ncluster."}},{"Name":"HPF","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPF options ; \n    BY variables ; \n    FORECAST variable-list / options ; \n    ID variable INTERVAL= interval options ; \n    IDM options ; \n\nThe HPF (High-Performance Forecasting) procedure provides a quick and automatic\nway to generate forecasts for many time series or transactional data in one\nstep. The procedure can forecast millions of series at a time, with the series\norganized into separate variables or across BY groups."}},{"Name":"HPFARIMASPEC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFARIMASPEC options ; \n    FORECAST options ; \n    INPUT options ; \n    ESTIMATE options ; \n\nThe HPFARIMASPEC procedure is used to create an ARIMA (autoregressive\nintegrated moving average) model specification file. The output of this\nprocedure is an XML file that stores the intended ARIMA model specification."}},{"Name":"HPFDIAGNOSE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFDIAGNOSE options ; \n    ADJUST variable = ( variable-list ) / options ; \n    ARIMAX options ; \n    BY variables ; \n    ESM option ; \n    EVENT event-names ; \n    FORECAST variables ; \n    ID variable INTERVAL=interval options ; \n    IDM options ; \n    INPUT variables ; \n    TRANSFORM options ; \n    TREND options ; \n    UCM options ; \n\nThe HPFDIAGNOSE procedure provides a comprehensive set of tools for automated\nunivariate time series model identification. Time series data can have\noutliers, structural changes, and calendar effects. In the past, finding a good\nmodel for time series data usually required experience and expertise in time\nseries analysis."}},{"Name":"HPFENGINE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFENGINE options ; \n    ADJUST variable = ( variable-list ) / options ; \n    BY variables ; \n    CONTROL variable-list / options ; \n    EXTERNAL variable-list / options ; \n    FORECAST variable-list / options ; \n    ID variable INTERVAL= interval options ; \n    INPUT variable-list / options ; \n    SCORE ; \n    STOCHASTIC variable-list / options ; \n\nThe HPFENGINE procedure provides an automatic way to generate forecasts for\nmany time series or transactional data in one step. The procedure can\nautomatically choose the best forecast model from a user-defined model list \nor a default model list. Specifications for the candidate forecast models are\nindependent of any data series. You can generate the specifications or choose\nthem from a default set."}},{"Name":"HPFESMSPEC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFESMSPEC options ; \n    ESM options ;  \n\nThe HPFESMSPEC procedure creates model specifications files for exponential\nsmoothing models (ESM). \n\nYou can specify many types of exponential models with this procedure. In\nparticular, any model that can be analyzed using the HPF procedure can be\nspecified."}},{"Name":"HPFEVENTS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFEVENTS <options> ; \n    BY variables ; \n    EVENTCOMB variable= variable-list / options ; \n    EVENTDATA options ; \n    EVENTDEF variable= do-list / options ; \n    EVENTDUMMY options ; \n    EVENTGROUP variable=( list ) ; \n    EVENTKEY <variable=> event-keyword < / options > ; \n    ID variable INTERVAL= interval options ; \n    VAR variables ;\n\nThe HPFEVENTS procedure provides a way to create and manage events associated\nwith time series for the purpose of analysis. The procedure can create events,\nread events from an events data set, write events to an events data set, and\ncreate dummy variables based on those events if date information is provided."}},{"Name":"HPFEXMSPEC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFEXMSPEC options ; \n    EXM options ; \n\nThe HPFEXMSPEC procedure creates model specifications files for external models\n(EXM). External model specifications are used for forecasts that are provided\nexternal to the system. These external forecasts might have originated from an\nexternal statistical model from another software package, might have been\nprovided by an outside organization (for example, a marketing organization or\ngovernment agency), or might be based on judgment."}},{"Name":"HPFIDMSPEC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFIDMSPEC options ; \n    IDM options ;\n\nThe HPFIDMSPEC procedure creates model specifications files for intermittent\ndemand models (IDM)."}},{"Name":"HPFMM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFMM <options> ; \n    BAYES bayes-options ; \n    BY variables ; \n    CLASS variable <(options)>... <variable <(options)>> </ global-options>; \n    FREQ variable ; \n    ID variables ; \n    MODEL response<(response-options)> = <effects> </ model-options> ; \n    MODEL events/trials = <effects> </ model-options> ; \n    MODEL + <effects> </ model-options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword<(keyword-options)> <=name>>...\n      <keyword<(keyword-options)> <=name>> </ options> ; \n    PERFORMANCE performance-options ; \n    PROBMODEL <effects> </ probmodel-options> ; \n    RESTRICT <'label'> constraint-specification <, ..., constraint-specification>\n      <operator <value>> </ option> ; \n    WEIGHT variable ; \n    \nThe HPFMM procedure is a high-performance counterpart of the FMM procedure that fits statistical models to \ndata for which the distribution of the response is a finite mixture of univariate distributions\u2014that is, \neach response comes from one of several random univariate distributions that have unknown probabilities.\nYou can use PROC HPFMM to model the component distributions in addition to the mixing probabilities."}},{"Name":"HPFSELECT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFSELECT options ; \n    DELETE specification-list ; \n    DIAGNOSE options ; \n    FORECASTOPTIONS options ; \n    SELECT options ; \n    SPECIFICATION specification-list </ options> ; \n\nThe HPFSELECT procedure enables you to control the forecasting model selection\nprocess by defining lists of candidate forecasting models. Using model\nselection lists created by the HPFSELECT procedure, you can control which\nforecasting model or models SAS High-Performance Forecasting software uses to\nforecast particular time series."}},{"Name":"HPFUCMSPEC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFUCMSPEC options ; \n    AUTOREG options ; \n    BLOCKSEASON options ; \n    CYCLE options ; \n    DEPLAG options ; \n    FORECAST options ; \n    INPUT options ; \n    IRREGULAR options ; \n    LEVEL options ; \n    SEASON options ; \n    SLOPE options ; \n\nThe HPFUCMSPEC procedure is used to create an unobserved component model (UCM)\nspecification file. The output of this procedure is an XML file that stores the\nintended UCM specification. This XML specification file can be used for\ndifferent purposes\u2014for example, it can be used to populate the model repository\nused by the HPFENGINE procedure (see Chapter 5, The HPFENGINE Procedure ). You\ncan specify any UCM that can be analyzed by using the UCM procedure; see\nChapter 29, The UCM Procedure (SAS/ETS User's Guide). Moreover, the model\nspecification can include series transformations such as  or Box-Cox\ntransformations. Apart from minor modifications to accommodate series\ntransformations, the model specification syntax of the HPFUCMSPEC procedure is\nsimilar to that of the UCM procedure."}},{"Name":"HPGENSELECT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPGENSELECT < options > ;\n    CLASS variable < (options) >: : : < variable < (options) > > < / global-options > ;\n    CODE < options > ;\n    MODEL response< (response-options) > = < effects > < / model-options > ;\n    MODEL events/trials< (response-options) > = < effects > < / model-options > ;\n    OUTPUT <OUT=SAS-data-set >\n    < keyword < =name > >. . .\n    < keyword < =name > > < / options > ;\n    PERFORMANCE performance-options ;\n    SELECTION selection-options ;\n    FREQ variable ;\n    ID variables ;\n    WEIGHT variable ; \n    \nThe HPGENSELECT procedure is a high-performance procedure that fits generalized linear models on the\nSAS appliance. \n\nThe HPGENSELECT procedure fits a broader class of regression models than exponential family generalized\nlinear models; the procedure permits several link functions and can handle zero-modified models for count\ndata as well as ordinal and nominal data with more than two response categories (multinomial data)."}},{"Name":"HPMIXED","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPMIXED <options> ; \n    BY variables ; \n    CLASS variables ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    ID variables ; \n    MODEL dependent = <fixed-effects> </ options> ; \n    RANDOM random-effects </ options> ; \n    REPEATED repeated-effect </ options> ;\n    PARMS <(value-list) ...> </ options> ; \n    TEST fixed-effects </ options> ; \n    CONTRAST 'label' contrast-specification <, contrast-specification> <, ...> </ options> ; \n    ESTIMATE 'label' contrast-specification <(divisor=n)>\n      <, 'label' contrast-specification <(divisor=n)>> <, ...> </options> ; \n    LSMEANS fixed-effects </ options> ; \n    NLOPTIONS <options> ; \n    OUTPUT <OUT=SAS-data-set>\n      <keyword<(keyword-options)><=name>>...\n      <keyword<(keyword-options)><=name>> </ options> ; \n    WEIGHT variable ; \n\nThe HPMIXED procedure uses a number of specialized high-performance techniques to fit linear \nmixed models with variance component structure. The HPMIXED procedure is specifically designed \nto cope with estimation problems involving a large number of fixed effects, a large number of \nrandom effects, or a large number of observations."}},{"Name":"HPPLS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPPLS <options> ; \n    BY variables ; \n    CLASS variables </ option> ;    \n    MODEL response-variables = predictor-effects </ options>; \n    OUTPUT <OUT=SAS-data-set><keyword <=prefix>>\u2026<keyword <=prefix>> ;\n    PARTITION <partition-options>;\n    PERFORMANCE <performance-options>;\n    ID variables ; \n\nThe HPPLS procedure is a high-performance version of the PLS procedure in SAS/STAT software, which fits \nmodels by using any one of a number of linear predictive methods, including partial least squares (PLS).\nOrdinary least squares regression, as implemented in SAS/STAT procedures such as the GLM and REG procedures, \nhas the single goal of minimizing sample response prediction error, and it seeks linear functions of the\npredictors that explain as much variation in each response as possible. The HPPLS procedure implements \ntechniques that have the additional goal of accounting for variation in the predictors,  under the \nassumption that directions in the predictor space that are well sampled should provide better prediction \nfor new observations when the predictors are highly correlated. All the techniques that the HPPLS procedure \nimplements work by extracting successive linear combinations of the predictors, called factors (also called \ncomponents, latent vectors, or latent variables), which optimally address one or both of these two \ngoals: explaining response variation and explaining predictor variation. In particular, the method of \npartial least squares balances the two objectives by seeking factors that explain both response and \npredictor variation."}},{"Name":"HPPRINCOMP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPPRINCOMP <options> ; \n    BY variables ; \n    CODE <options>;\n    FREQ variable ; \n    ID variables ; \n    OUTPUT <OUT=SAS-data-set> <keyword <=prefix>>\u2026<keyword <=prefix>> ; \n    PARTIAL variables ; \n    PERFORMANCE performance-options;\n    VAR variables ; \n    WEIGHT variable ; \n\nThe HPPRINCOMP procedure is a high-performance procedure that performs principal component analysis. \nIt is a high-performance version of the PRINCOMP procedure in SAS/STAT software, but it provides \nadditional iterative methods to calculate the principal components."}},{"Name":"HPQUANTSELECT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPQUANTSELECT <options> ; \n    BY variables ; \n    CLASS variable <(v-options)> <variable <(v-options \u2026)> > </ v-options> <options> ; \n    CODE <options>; \n    EFFECT name = effect-type (variables </ options> ) ; \n    MODEL variable = <effects> </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword <=name> > <\u2026keyword<=name>> ; \n    PARTITION <options> ; \n    WEIGHT variable ; \n\nThe QUANTSELECT procedure compares most closely to the GLMSELECT and QUANTREG procedures. PROC GLMSELECT \nperforms effect selection in the framework of general linear models. PROC QUANTREG supports a variety of \nestimation and inference methods for quantile regression but does not directly provide effect selection \nfacilities. The QUANTSELECT procedure, as a counterpart of PROC GLMSELECT for quantile regression, fills \nthis gap."}},{"Name":"HPTMINE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPTMINE < options > ;\n    VARIABLE variable ;\n    DOC_ID variable ;\n    PARSE < parse-options > ;\n    SVD < svd-options > ;\n    PERFORMANCE performance-options ;\n    \nThe HPTMINE procedure is a high-performance procedure that analyzes large-scale textual\ndata. PROC HPTMINE provides the SAS High-Performance Analytics platform an essential capability\nfor text mining and supports a wide range of fundamental text analysis features, which include tokenizing,\nstemming, part-of-speech tagging, noun group extraction, default or customized stop or start lists, entity\nparsing, multiword tokens, synonym lists, term weighting, term-by-document matrix creation, and dimension\nreduction by term filtering and singular value decomposition (SVD)."}},{"Name":"HPTMSCORE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPTMSCORE < options > ;\n    VARIABLE variable ;\n    DOC_ID variable ;\n    PERFORMANCE performance-options ;\n    \nFor high-performance text mining, scoring is the process of applying the parsing and SVD projections to\nnew textual data. The HPTMSCORE procedure performs this scoring of new documents, and its primary\noutput is a document data set Outdocpro, which holds the reduced dimensional representation of the score\ncollection. PROC HPTMSCORE uses some of the output data sets of the HPTMINE procedure as input\ndata to ensure consistency between scoring and training. During scoring, the new textual data must be\nparsed with the same settings that the training data were parsed with, indexed using only the subset of terms\nthat were used during training, and projected onto the reduced dimensional subspace of the singular value\ndecomposition that was derived from the training data. The three data sets, Outconfig, Outterms and Svdu,\nwhich were created with PROC HPTMINE facilitate this process and serve as input to PROC HPTMSCORE\nwith the CONFIG=, TERMS=, and SVDU= options, respectively. The purpose of these three data sets are\nsummarized below under their respective options."}},{"Name":"HAPLOTYPE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HAPLOTYPE <options> ; \n    BY variables ; \n    ID variables ; \n    TRAIT variable </ options> ; \n    VAR variables ; \n\nA haplotype is a combination of alleles at multiple loci on a single chromosome. A pair \nof haplotypes constitutes the multilocus genotype. Haplotype information has to be inferred \nbecause data are usually collected at the genotypic, not haplotype pair, level. For homozygous \nmarkers, there is no problem. If one locus has alleles A and a, and a second locus has alleles  \nB and b, the observed genotype AaBB must contain two haplotypes of type AB; genotype AaBB must \ncontain haplotypes AB and aB, and so on. Haplotypes and their frequencies can be obtained directly. \nWhen both loci are heterozygous, however, there is ambiguity; a variety of combinations of haplotypes \ncan generate the genotype, and it is not possible to determine directly which two haplotypes constitute \nany individual genotype. For example, the genotype AaBb might be of type AB/ab with haplotypes AB and\nab, or of type Ab/aB with haplotypes Ab and aB. The HAPLOTYPE procedure uses the expectation-maximization \n(EM) algorithm to generate maximum likelihood estimates of haplotype frequencies given a multilocus \nsample of genetic marker genotypes under the assumption of Hardy-Weinberg equilibrium (HWE). These \nestimates can then be used to assign the probability that each individual possesses a particular \nhaplotype pair. A Bayesian approach for haplotype frequency estimation is also implemented in \nPROC HAPLOTYPE."}},{"Name":"HTSNP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HTSNP <options> ; \n    BY variables ; \n    FREQ variable ; \n    VAR variables ; \n  \nSingle nucleotide polymorphism (SNP) is the most abundant form of genetic variation \nand accounts for about 90% of human DNA polymorphism. There is roughly one SNP per 1 \nkilobase in the human genome. Studies of human haplotype variations that use SNPs over \nlarge genomic regions suggest the presence of discrete blocks with limited haplotype \ndiversity punctuated by recombination hot spots. The intrablock linkage disequilibrium \n(LD) decreases only gradually with distance, while the interblock LD decays much more \nrapidly. Within each block, because of high LD, some allele(s) might always be coexistent \nwith a particular allele at another locus such that (1) little haplotype diversity exists \nin the block, and (2) not all SNPs will be essential in characterizing the haplotype \nstructure in the block. Therefore, the most common haplotypes could usually be captured \nby a small subset of SNPs, termed haplotype tagging SNPs (htSNPs) by Johnson et al. (2001)."}},{"Name":"HTTP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HTTP options;\n    \nPROC HTTP issues HTTP requests. PROC HTTP reads as input the entire body from a fileref and \nwrites output to a fileref. PROC HTTP can also read custom request headers from a fileref \nand write response headers to a fileref."}},{"Name":"ICPHREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ICPHREG <options>; \n    BASELINE <OUT=SAS-data-set> <COVARIATES=SAS-data-set><TIMELIST=list><keyword=name \u2026keyword=name> </ options>; \n    BY variables; \n    CLASS variable <(options)> \u2026<variable <(options)>> </ global-options>; \n    FREQ variable </ option>; \n    HAZARDRATIO <'label'> variable </ options>; \n    MODEL (t1, t2)= effects </ options>; \n    OUTPUT <OUT=SAS-data-set> <keyword=name \u2026keyword=name>; \n    TEST  <model-effects> </ options>; \n    STRATA variable; \n\nThe ICPHREG procedure is designed to fit proportional hazards regression models to interval-censored data. \nIt can also fit proportional hazards regression models to failure time data that are uncensored, right \ncensored, or left censored. \n\nThe ICPHREG procedure enables you to use a variety of configurations with respect to the baseline function \nto fit a proportional hazards model; these configurations include a piecewise constant model (Friedman 1982) \nand a cubic spline model (Royston and Parmar 2002). To estimate the regression coefficients and the baseline \nparameters, the ICPHREG procedure maximizes the full likelihood instead of the Cox partial likelihood. Standard\nerrors of the estimates are obtained by inverting the observed information matrix, which is derived from the \nfull likelihood."}},{"Name":"ICLIFETEST","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ICLIFETEST <options>; \n    BY variables; \n    FREQ variable; \n    STRATA variables; \n    TEST variable </options>; \n    TIME (variable,variable ); \n    \nThe ICLIFETEST procedure performs nonparametric survival analysis for interval-censored data. You can use \nthe ICLIFETEST procedure to compute nonparametric estimates of the survival functions and to examine the \nequality of the survival functions through statistical tests."}},{"Name":"IMPORT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC IMPORT DATAFILE=\"filename\" | TABLE=\"tablename\" \n    OUT=<libref.>SAS-data-set <(SAS-data-set-options)> \n    <DBMS=identifier><REPLACE> ;  <data-source-statement(s);>  \n  \nThe IMPORT procedure reads data from an external data source and writes it to a SAS \ndata set. Base SAS can import delimited files. In delimited files, a delimiter--such \nas a blank, comma, or tab--separates columns of data values. If you license SAS/ACCESS \nInterface to PC Files, additional external data sources can include such files as \nMicrosoft Access Database, Excel files, and Lotus spreadsheets. See the SAS/ACCESS \nInterface to PC Files for more information."}},{"Name":"IMSTAT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC IMSTAT <options>; \n    AGGREGATE variable-name (aggregate-variable-options) </ options>;\n    ARM ITEM=item-variable TRAN=transaction-variable </ options>;\n    ASSESS <variable-list> / Y=response-variable <options>; \n    BOXPLOT <variable-list> </ options>;\n    CLUSTER <variable-list> </ options>;\n    CORR <variable-list> </ options>;\n    CROSSTAB row*column </ options>;\n    DECISIONTREE target-variable </ options>;\n    DISTINCT <variable-list> </ options>;\n    FORECAST timestamp-variable </ options>;\n    FREQUENCY variable-list </ options>;\n    GENMODEL dependent-variable <(class-variables)> = model-effects </ options>;\n    GLM dependent-variable <(class-variables)> = model-effects </ options>;\n    GROUPBY <variable-list> </ options>;\n    HISTOGRAM <variable-list> </ options>;\n    HYPERGROUP <variable-list> </ options>;\n    KDE variable-list </ options>;\n    LOGISTIC dependent-variable <(class-variables)> = model-effects </ options>;\n    MDSUMMARY variable-list </ <set-specification,...> options>;\n    NEURAL <target-variable> </ options>;\n    OPTIMIZE <options>;\n    PERCENTILE <variable-list> </ options>;\n    RANDOMWOODS target-variable </ options>;\n    REGCORR <variable-list> </ options>;\n    SUMMARY <variable-list> </ options>;\n    TEXTPARSE TXT=text-variable ID=document-ID <options>;\n    TOPK <variable-list> </ options>;\n    TRANSFORM (request1) <(request2) ...> </ options>;\n    \nThe analytic statements of the IMSTAT procedure are used to perform in-memory analytics \nwith a SAS LASR Analytic Server. All analyses are performed on in-memory tables."}},{"Name":"INBREED","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC INBREED <options> ; \n    BY variables ; \n    CLASS variable ; \n    GENDER variable ; \n    MATINGS individual-list1 / mate-list1 <,..., individual-listn / mate-listn> ; \n    VAR variables ; \n\nThe INBREED procedure calculates the covariance or inbreeding coefficients for a pedigree. \nPROC INBREED is unique in that it handles very large populations."}},{"Name":"INFOMAPS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC INFOMAPS <options> ;\n  DELETE INFOMAP \"information-map-name\" <options> ;\n  EXPORT FILE=fileref | \"physical-location\" <options> ; \n  IMPORT FILE=fileref |\"physical-location\"; \n  INSERT DATAITEM \n  COLUMN=\"data-source-ID\".\"column-name\" | EXPRESSION=\"expression-text\" | \n    HIERARCHY=\"dimension\".\"hierarchy\" | MEASURE=\"OLAP-measure\" <options> ;\n  INSERT DATASOURCE SASSERVER=\"application-server-name\" TABLE=\"library\".\"table\" <options> ; \n  | INSERT DATASOURCE SASSERVER=\"application-server-name\" CUBE=<\"schema\".>\"cube\" <_ALL_> <options> ; \n  INSERT FILTER CONDITION=\"conditional-expression\" <options> ; \n  INSERT FOLDER \"folder-name\" <options> ; \n  INSERT IDENTITY_PROPERTY PROPERTY=property-keyword <ID=\"identity_property-ID\">; \n  INSERT RELATIONSHIP CONDITION=\"conditional-expression\" LEFT_TABLE=\"data-source-ID-1\" \n    RIGHT_TABLE=\"data-source-ID-2\" <options> ;\n  LIST <DATAITEMS | DATASOURCES | FILTERS |RELATIONSHIPS | _ALL_>; \n  MOVE DATAITEM \"data-item-ID\" | ID_LIST=(\"data-item-ID-1\" <... \"data-item-ID-n\">) \n    NEW_LOCATION=\"new-folder-location\" </CREATE>; \n  MOVE FILTER \"filter-ID\" | ID_LIST=(\"filter-ID-1\" <... \"filter-ID-n\">) \n    NEW_LOCATION=\"new-folder-location\" </CREATE>; \n  MOVE FOLDER \"folder-name\" NEW_LOCATION=\"new-folder-location\" </CREATE> \n    <LOCATION=\"current-folder-location\">; \n  NEW INFOMAP \"information-map-name\" <options> ; \n  SAVE <INFOMAP \"information-map-name\"> <MAPPATH=\"location\" </CREATE>>; \n  SET STORED_PROCESS NAME=\"stored-process-name\" <LOCATION=\"stored-process-location\">; \n  UPDATE DATAITEM \"data-item-ID\" <options> ;\n  UPDATE DATASOURCE \"data-source-ID\" <options> ; \n  UPDATE FILTER \"filter-ID\" <options> ; \n  UPDATE FOLDER \"folder-name\" <options> ;\n  UPDATE INFOMAP \"information-map-name\" <options> ;\n  UPDATE RELATIONSHIP \"relationship-ID\" <options> ;\n  \nThe INFOMAPS procedure enables you to create information maps programmatically. You can \nalso use the procedure to modify an existing information map by adding new data sources, \ndata items, filters, folders, or relationships. Or you can change the definitions of any \nexisting data item, filter, data source, folder, or relationship within an information map."}},{"Name":"IRT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC IRT <options>; \n    BY variables;\n    COV covariance parameters; \n    EQUALITY equality-constraints; \n    FACTOR factor-variables-relations; \n    FREQ variable; \n    GROUP variable; \n    MODEL model-specification; \n    VAR variables; \n    VARIANCE variance parameters; \n    WEIGHT variable;\n    \nThe item response theory (IRT) model was first proposed in the field of psychometrics for the purpose of ability \nassessment. It is most widely used in education to calibrate and evaluate items in tests, questionnaires, and other \ninstruments and to score subjects on their abilities, attitudes, or other latent traits. Today, all major psychological \nand educational tests are built using IRT, because the methodology can significantly improve measurement accuracy and \nreliability while providing potential significant reductions in assessment time and effort, especially via computerized \nadaptive testing. In a computerized adaptive test, items are optimally selected for each subject. Different subjects \nmight receive entirely different items during the test. IRT plays an essential role in selecting the most appropriate \nitems for each subject and equating scores for subjects who receive different subsets of items. Notable examples of \nthese tests include the Scholastic Aptitude Test (SAT), Graduate Record Examination (GRE), and Graduate Management \nAdmission Test (GMAT)."}},{"Name":"KDE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC KDE <options> ; \n    BIVAR variable-list </ options> ; \n    UNIVAR variable-list </ options> ; \n    BY variables ; \n    FREQ variable ; \n    WEIGHT variable ;\n\nThe KDE procedure performs univariate and bivariate kernel density estimation. Statistical \ndensity estimation involves approximating a hypothesized probability density function from \nobserved data. Kernel density estimation is a nonparametric technique for density estimation \nin which a known density function (the kernel) is averaged across the observed data points \nto create a smooth approximation. PROC KDE uses a Gaussian density as the kernel, and its \nassumed variance determines the smoothness of the resulting estimate. Refer to Silverman \n(1986) for a thorough review and discussion."}},{"Name":"HADOOP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HADOOP <hadoop-server-option(s)>; \n  HDFS <hadoop-server-option(s)> <hdfs-command-option(s)>; \n  MAPREDUCE <hadoop-server-option(s)> <mapreduce-option(s)>; \n  PIG <hadoop-server-option(s)> <pig-code-option(s)>; \n  PROPERTIES <configuration-properties>;\n\nThe HADOOP procedure enables SAS to interact with Hadoop data by running Apache Hadoop code. \nApache Hadoop is an open-source framework, written in Java, that provides distributed data \nstorage and processing of large amounts of data."}},{"Name":"ISHIKAWA","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ISHIKAWA options ;\n  \nThe Ishikawa diagram, also known as a cause-and-effect diagram or fishbone diagram, \nis one of the seven basic tools for quality improvement in Japanese industry. It is \nused to display the factors that affect a particular quality characteristic or problem. \n\nAn Ishikawa diagram is typically the result of a brainstorming session to improve a \nproduct, process, or service. The main goal is represented by a main arrow or trunk, \nand primary factors are represented as sub-arrows or branches. Secondary factors are \nthen added as stems, tertiary factors as leaves, and so on."}},{"Name":"IML","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC IML <SYMSIZE=n1 > <WORKSIZE=n2 >;\n  ...IML statements/functions/call-routines \n  RUN;\n\nwhere n1 and n2 are specified in kilobytes. \n\nThe SYMSIZE= and WORKSIZE= options in the PROC IML statement give you control over \nthe size of memory allocated to the symbol space and the size of each extent of \nworkspace. If you do not specify these options, PROC IML uses host dependent defaults. \n \nSAS/IML software gives you access to a powerful and flexible programming language \n(Interactive Matrix Language) in a dynamic, interactive environment. The fundamental \nobject of the language is a data matrix. You can use SAS/IML software interactively \n(at the statement level) to see results immediately, or you can store statements in \na module and execute them later. The programming is dynamic because necessary \nactivities such as memory allocation and dimensioning of matrices are performed \nautomatically."}},{"Name":"JSON","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC JSON OUT=fileref | \"external-file\" <option(s)>; \n  EXPORT <libref.>SAS-data-set <(SAS-data-set-option(s))> </option(s)>; \n  WRITE VALUES value(s) </option(s)>; \n  WRITE OPEN type; \n  WRITE CLOSE;\n  \nThe JSON procedure reads data from a SAS data set and writes it to an external file in JSON1 \nrepresentation. You can control the exported data with several options that remove content \nand affect the format. In addition to exporting data from a SAS data set, PROC JSON provides \nstatements that enable you to write additional data to the external file and control JSON \ncontainers."}},{"Name":"KRIGE2D","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC KRIGE2D options ; \n    BY variables ; \n    COORDINATES | COORD coordinate-variables ; \n    GRID grid-options ; \n    PREDICT | PRED | P predict-options ; \n    MODEL model-options ; \n    RESTORE restore-options ; \n\nPROC KRIGE2D can handle anisotropic and nested semivariogram models. Eight semivariogram \nmodels are supported: the Gaussian, exponential, spherical, power, cubic, pentaspherical, \nsine hole effect, and Mat\u00e9rn models. A single nugget effect is also supported. You can \nspecify the correlation model by naming the form and supplying the associated parameters, \nor by using the contents of an item store file that was previously created by PROC VARIOGRAM."}},{"Name":"LATTICE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LATTICE <options> ; \n    BY variables ; \n    VAR variables \n\nThe LATTICE procedure computes the analysis of variance and analysis of simple covariance \nfor data from an experiment with a lattice design. PROC LATTICE analyzes balanced square \nlattices, partially balanced square lattices, and some rectangular lattices. \n\nIn balanced square lattices, the number of treatments is equal to the square of the number \nof units per block. Incomplete blocks are grouped to form mutually orthogonal replications. \nThe number of replicates in the basic plan is always 1 plus the number of units per block."}},{"Name":"LIFEREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LIFEREG <options> ; \n    BAYES <options> ; \n    BY variables ; \n    CLASS variables ; \n    ESTIMATE <'label'> estimate-specification <(divisor=n)>\n      <, \u2026<'label'> estimate-specification <(divisor=n)>> </ options> ; \n    EFFECTPLOT <plot-type <(plot-definition-options)>> </ options> ; \n    INSET <keyword-list> </ options> ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect <'label'> values <(divisor=n)>\n      <, \u2026<'label'> values <(divisor=n)>> </ options> ; \n    MODEL response = <effects> </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name \u2026keyword=name> ; \n    PROBPLOT </ options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    TEST <model-effects> </ options> ; \n    WEIGHT variable ;   \n\nThe LIFEREG procedure fits parametric models to failure time data that can be uncensored, \nright censored, left censored, or interval censored. The models for the response variable \nconsist of a linear effect composed of the covariates and a random disturbance term. The \ndistribution of the random disturbance can be taken from a class of distributions that \nincludes the extreme value, normal, logistic, and, by using a log transformation, the \nexponential, Weibull, lognormal, log-logistic, and three-parameter gamma distributions.."}},{"Name":"LIFETEST","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LIFETEST <options> ; \n    BY variables ; \n    FREQ variable ; \n    ID variables ; \n    STRATA variable <(list)> <...variable <(list)>> </options> ; \n    TEST variables ; \n    TIME variable <*censor(list)> ; \n\nThe LIFETEST procedure deals with lifetime or survival data analysis. \n\nA common feature of lifetime or survival data is the presence of right-censored observations \ndue either to withdrawal of experimental units or to termination of the experiment. For such \nobservations, you know only that the lifetime exceeded a given value; the exact lifetime remains\nunknown. Such data cannot be analyzed by ignoring the censored observations because, among other \nconsiderations, the longer-lived units are generally more likely to be censored. The analysis \nmethodology must correctly use the censored observations as well as the uncensored observations."}},{"Name":"LOESS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LOESS <DATA=SAS-data-set> ; \n    MODEL dependents=regressors </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword <=name>> <\u2026keyword <=name>> </ options> ; \n    ID variables ; \n    BY variables ; \n    WEIGHT variable ; \n    SCORE DATA=SAS-data-set <ID=(variable list)> </ options> ; \n\nThe LOESS procedure implements a nonparametric method for estimating regression surfaces pioneered \nby Cleveland, Devlin, and Grosse (1988), Cleveland and Grosse (1991), and Cleveland, Grosse, and \nShyu (1992)."}},{"Name":"LOGISTIC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LOGISTIC <options> ; \n    BY variables ; \n    CLASS variable <(options)> <variable <(options)> \u2026> </ options>;  \n    CODE <options>; \n    CONTRAST 'label' effect values<, effect values, \u2026> </ options>; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    EFFECTPLOT <plot-type<(plot-definition-options)>></ options> ; \n    ESTIMATE <'label'> estimate-specification </ options> ; \n    EXACT <'label'><INTERCEPT><effects></ options> ; \n    EXACTOPTIONS options ; \n    FREQ variable ;    \n    ID variable<variable,...> ;\n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification </ options> ;     \n    <label:> MODEL variable <(variable_options)> = <effects> </ options>; \n    <label:> MODEL events/trials = <effects> </ options>;\n    NLOPTIONS options;\n    ODDSRATIO <'label'> variable </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name <keyword=name \u2026>> </ option>;\n    ROC <'label'> <specification> </ options> ; \n    ROCCONTRAST <'label'><contrast></ options> ; \n    SCORE <options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    STRATA effects </ options> ; \n    <label:> TEST equation1 <,equation2, \u2026> </ option>;\n    UNITS <independent1=list1 <independent2=list2 \u2026>> </ option>; \n    WEIGHT variable </ option> ; \n\nBinary responses (for example, success and failure), ordinal responses (for example, normal, \nmild, and severe), and nominal responses (for example, major TV networks viewed at a certain \nhour) arise in many fields of study. Logistic regression analysis is often used to investigate \nthe relationship between these discrete responses and a set of explanatory variables."}},{"Name":"MAPIMPORT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MAPIMPORT OUT= map-data-set DATAFILE= 'path-to-shapefile' <CONTENTS> <CREATE_ID_>;  \n      EXCLUDE 'field-identifier(s)';  \n      ID 'field-identifier(s)';  \n      RENAME 'field-identifier-1' = variable-name-1 < ... 'field-identifier-n' = variable-name-n>;  \n      SELECT 'field-identifier(s)';  \n\nThe MAPIMPORT procedure enables you to import ESRI shapefiles (spatial data formats) and \nprocess the SHP files into SAS/GRAPH traditional map data sets. \n\nThe MAPIMPORT procedure does not produce any graphics output. Instead, it produces an output \nmap data set, which can be used with the GMAP procedure."}},{"Name":"MCMC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MCMC <options> ;   \n    ARRAY arrayname [ dimensions ] <$> <variables-and-constants>; \n    BEGINCNST/ENDCNST ; \n    BEGINNODATA/ENDNODATA ; \n    BY variables ; \n    MODEL variable ~distribution <options>;  \n    PARMS parameter <=> number </options> ; \n    PREDDIST <'label'> OUTPRED=SAS-data-set <options> ; \n    PRIOR/HYPERPRIOR parameter ~ distribution ; \n    Programning statements ; \n    RANDOM random-effects-specification </ options>; \n    UDS subroutine-name ( subroutine-argument-list) ;   \n\nThe MCMC procedure is a general purpose Markov chain Monte Carlo (MCMC) simulation procedure \nthat is designed to fit Bayesian models. Bayesian statistics is different from traditional \nstatistical methods such as frequentist or classical methods."}},{"Name":"MDS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MDS <options> ; \n    VAR variables ; \n    INVAR variables ; \n    ID | OBJECT variable ; \n    MATRIX | SUBJECT variable ; \n    WEIGHT variables ; \n    BY variables ; \n\nMultidimensional scaling (MDS) refers to a class of methods. These methods estimate coordinates \nfor a set of objects in a space of specified dimensionality. The input data are measurements of \ndistances between pairs of objects."}},{"Name":"MEANS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MEANS <option(s)> <statistic-keyword(s)>;\n    BY <DESCENDING> variable-1 <... <DESCENDING> variable-n><NOTSORTED>;  \n    CLASS variable(s) </ option(s)>;  \n    FREQ variable;  \n    ID variable(s);  \n    OUTPUT <OUT=SAS-data-set> <output-statistic-specification(s)> <id-group-specification(s)> \n      <maximum-id-specification(s)> \n      <minimum-id-specification(s)> </ option(s)> ;  \n    TYPES request(s);  \n    VAR variable(s) < / WEIGHT=weight-variable>;  \n    WAYS list;  \n    WEIGHT variable;\n  \nThe MEANS procedure provides data summarization tools to compute descriptive statistics for \nvariables across all observations and within groups of observations. For example, PROC MEANS \n\n  o calculates descriptive statistics based on moments \n  o estimates quantiles, which includes the median \n  o calculates confidence limits for the mean \n  o identifies extreme values \n  o performs a t test."}},{"Name":"METADATA","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC METADATA <server-connection-arguments>\n    IN = \"XML-formatted-method-call\" | fileref  <OUT = fileref>  \n    <HEADER = NONE | SIMPLE | FULL>  <VERBOSE>;  \n\nThe METADATA procedure sends an XML string to the SAS Metadata Server."}},{"Name":"MI","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MI <options> ; \n    BY variables ; \n    CLASS variables ; \n    EM <options> ; \n    FCS <options> ; \n    FREQ variable ; \n    MCMC <options> ; \n    MNAR options ;\n    MONOTONE <options> ; \n    TRANSFORM transform ( variables </ options>) <...transform ( variables </ options>) > ; \n    VAR variables ;\n    \nThe MI procedure performs multiple imputation of missing data. Missing values are an issue in a \nsubstantial number of statistical analyses. Most SAS statistical procedures exclude observations \nwith any missing variable values from the analysis."}},{"Name":"MIANALYZE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MIANALYZE <options> ; \n    BY variables ; \n    CLASS variables ; \n    MODELEFFECTS effects ; \n    <label:> TEST  <, ..., <> > </ > ; \n    STDERR variables ; \n\nThe MIANALYZE procedure combines the results of the analyses of imputations and generates valid \nstatistical inferences. Multiple imputation provides a useful strategy for analyzing data sets \nwith missing values."}},{"Name":"MIGRATE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MIGRATE IN=libref-2 OUT=libref-1 <BUFSIZE=n> <MOVE> \n    <SLIBREF=libref> <KEEPNODUPKEY>;\n  \nThe MIGRATE procedure migrates members in a SAS library to the current SAS version. \n\nThe procedure migrates a library from most SAS 6, SAS 7, SAS 8, and SAS 9 operating \nenvironments to the current release of SAS. The migration must occur within the same \nengine family; for example, V6, V7, or V8 can migrate to V9, but V6TAPE must migrate \nto V9TAPE. \n\nThe procedure migrates the following library members:\n\ndata sets with alternate collating sequence, audit trails, compression, created and \nmodified datetimes, deleted observations, encryption, generations, indexes, integrity \nconstraints, and passwords\n\nin many cases, views, catalogs, item stores, and MDDBs (see What Are the Specific \nConsiderations for Each Member Type?)"}},{"Name":"MIXED","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MIXED <options> ; \n    BY variables ; \n    CLASS variables ; \n    CODE <options>;\n    ID variables ; \n    MODEL dependent = <fixed-effects> </ options> ; \n    RANDOM random-effects </ options> ; \n    REPEATED <repeated-effect></ options> ; \n    PARMS (value-list) ...</ options> ; \n    PRIOR <distribution >< / options> ; \n    CONTRAST 'label' <fixed-effect values ...> \n      <| random-effect values ...>, ...</ options> ; \n    ESTIMATE 'label' <fixed-effect values ...> \n      <| random-effect values ...></ options> ; \n    LSMEANS fixed-effects </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification < / options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    WEIGHT variable ;\n\nThe MIXED procedure fits a variety of mixed linear models to data and enables you to \nuse these fitted models to make statistical inferences about the data. A mixed linear \nmodel is a generalization of the standard linear model used in the GLM procedure, the \ngeneralization being that the data are permitted to exhibit correlation and nonconstant \nvariability. The mixed linear model, therefore, provides you with the flexibility of \nmodeling not only the means of your data (as in the standard linear model) but their \nvariances and covariances as well."}},{"Name":"MODEL","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC MODEL options ; \n    programming Statements...   \n    PROC-MODEL-specific statements...\n    ...\n\nThe MODEL procedure analyzes models in which the relationships among the variables comprise \na system of one or more nonlinear equations. Primary uses of the MODEL procedure are estimation, \nsimulation, and forecasting of nonlinear simultaneous equation models."}},{"Name":"MODECLUS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MODECLUS <options> ; \n    BY variables ; \n    FREQ variable ; \n    ID variable ; \n    VAR variables ; \n\nThe MODECLUS procedure clusters observations in a SAS data set by using any of several algorithms \nbased on nonparametric density estimates."}},{"Name":"MULTTEST","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MULTTEST <options> ; \n    BY variables ; \n    CLASS variable ; \n    CONTRAST 'label' values ; \n    FREQ variable ; \n    ID variables ;\n    STRATA variable ; \n    TEST name (variables </ options>) ; \n\nThe MULTTEST procedure addresses the multiple testing problem. This problem arises when you perform \nmany hypothesis tests on the same data set. Carrying out multiple tests is often reasonable because \nof the cost of obtaining data, the discovery of new aspects of the data, and the many alternative \nstatistical methods."}},{"Name":"NESTED","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NESTED <options> ; \n    CLASS variables </ option> ; \n    VAR variables ; \n    BY variables ; \n\nThe NESTED procedure performs random-effects analysis of variance for data from an \nexperiment with a nested (hierarchical) structure. \n\nNote that PROC NESTED is appropriate for models with only classification effects; \nit does not handle models that contain continuous covariates. For random effects \nmodels with covariates, use either the GLM or MIXED procedure."}},{"Name":"NLIN","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NLIN <options> ; \n    BOUNDS inequality <, ..., inequality> ; \n    BY variables ; \n    CONTROL variable <=values> <...variable <=values>> ; \n    DER. parameter=expression ; \n    DER. parameter.parameter=expression ; \n    ID variables ; \n    MODEL dependent=expression ; \n    OUTPUT OUT=SAS-data-set keyword=names <...keyword=names> ; \n    PARAMETERS <parameter-specification> <,..., parameter-specification> \n      < / PDATA=SAS-data-set> ; \n    PROFILE parameter < . . . parameter > < / options > ;\n    RETAIN variable <=values> <...variable <=values>> ; \n    Programming Statements ; \n\nThe NLIN procedure fits nonlinear regression models and estimates the parameters \nby nonlinear least squares or weighted nonlinear least squares. You specify the \nmodel with programming statements. This gives you great flexibility in modeling \nthe relationship between the response variable and independent (regressor) variables. \nIt does, however, require additional coding compared to model specifications in \nlinear modeling procedures such as the REG, GLM, and MIXED procedures."}},{"Name":"NLMIXED","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NLMIXED <options> ; \n    ARRAY array specification ; \n    BOUNDS boundary constraints ; \n    BY variables ; \n    CONTRAST 'label' expression <,expression><options> ; \n    ESTIMATE 'label' expression <options> ; \n    ID names ; \n    MODEL model specification ; \n    PARMS parameters and starting values ; \n    PREDICT expression OUT=SAS-data-set <options> ; \n    RANDOM random effects specification ; \n    REPLICATE variable ; \n    Program statements ; \n\nThe NLMIXED procedure fits nonlinear mixed models\u2014-that is, models in which both fixed and \nrandom effects enter nonlinearly. These models have a wide variety of applications, two of \nthe most common being pharmacokinetics and overdispersed binomial data. PROC NLMIXED enables \nyou to specify a conditional distribution for your data (given the random effects) having \neither a standard form (normal, binomial, Poisson) or a general distribution that you code \nusing SAS programming statements."}},{"Name":"NPAR1WAY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PROC NPAR1WAY <options> ; \n    BY variables ; \n    CLASS variable ; \n    EXACT statistic-options </ computation-options> ; \n    FREQ variable ; \n    OUTPUT  < OUT=SAS-data-set > < output-options > ;  \n    STRATA  variables < options > ; \n    VAR variables ; \n\nPROC NPAR1WAY performs tests for location and scale differences based on the following \nscores of a response variable: Wilcoxon, median, Van der Waerden (normal), Savage, \nSiegel-Tukey, Ansari-Bradley, Klotz, Mood, and Conover. Additionally, PROC NPAR1WAY \nprovides tests that use the raw input data as scores. When the data are classified \ninto two samples, tests are based on simple linear rank statistics. When the data are \nclassified into more than two samples, tests are based on one-way ANOVA statistics. \nBoth asymptotic and exact p-values are available for these tests. PROC NPAR1WAY also \nprovides Hodges-Lehmann estimation, including exact confidence limits for the location \nshift."}},{"Name":"OPERATE","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC OPERATE <options>;\n    Library Management Commands  \n    Server Management Commands  \n    User Management Commands  \n\nYou can use the OPERATE procedure in any SAS method of processing\n(noninteractive mode, interactive-line mode, batch mode, or windowing\nenvironment) to manage a server, the server libraries, and the server users."}},{"Name":"OPTGRAPH","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTGRAPH options ; \n    DATA_ADJ_MATRIX_VAR column1 <,column2,...> ; \n    DATA_LINKS_VAR < options > ; \n    DATA_MATRIX_VAR column1 <,column2,...> ; \n    DATA_NODES_VAR < options > ; \n    BICONCOMP < options > ; \n    CENTRALITY < options > ; \n    CLIQUE < options > ; \n    COMMUNITY < options > ; \n    CONCOMP < options > ; \n    CORE < options > ; \n    CYCLE < options > ; \n    EIGENVECTOR < options > ; \n    LINEAR_ASSIGNMENT < options > ; \n    MINCUT < options > ; \n    MINSPANTREE < options > ; \n    NETFLOW_MINCOST < options > ; \n    REACH < options > ; \n    SHORTPATH < options > ; \n    SUMMARY < options > ; \n    TRANSITIVE_CLOSURE < options > ; \n    TSP < option > ; \n    PERFORMANCE < options > ; \n\nThe OPTGRAPH procedure can be used to analyze relationships between entities. These relationships \nare typically defined by using a graph. A graph, G = (N,A), is defined over a set N of nodes and \na set A of arcs. A node is an abstract representation of some entity (or object), and an arc defines \nsome relationship (or connection) between two nodes. The terms node and vertex are often interchanged \nwhen describing an entity. The term arc is often interchanged with the term edge or link when describing \na connection."}},{"Name":"OPTIONS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTIONS <option(s)>;\n  \nThe OPTIONS procedure lists the current settings of SAS system options in the SAS log. \n\nSAS system options control how SAS formats output, handles files, processes data sets, \n'interacts with the operating environment, and does other tasks that are not specific \nto a single SAS program or data set. You can change the settings of SAS system options \nby using one of the following methods:\n\n  o the SAS command \n  o the option in a configuration or autoexec file \n  o the SAS OPTIONS statement \n  o the OPTLOAD and OPTSAVE procedures \n  o the SAS System Options window \n  o the DMOPTSAVE and DMOPTLOAD commands \n  o in other ways, depending on your operating environment."}},{"Name":"OPTLOAD","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTLOAD <options>;\n    \nThe OPTLOAD procedure reads SAS system option settings that are stored in the SAS \nregistry or a SAS data set and puts them into effect. \n\nYou can load SAS system option settings from a SAS data set or registry key by using \none of these methods:\n\n  o the DMOPTLOAD command from a command line in the SAS windowing environment. \n    For example, DMOPTLOAD key= \"core\\options\".\n\n  o the PROC OPTLOAD statement"}},{"Name":"OPTSAVE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTSAVE <options >;\n    \nPROC OPTSAVE saves the current SAS system option settings in the SAS registry or in a \nSAS data set. \n\nSAS system options can be saved across SAS sessions. You can save the settings of the \nSAS system options in a SAS data set or registry key by using one of these methods:\n\n  o the DMOPTSAVE command from a command line in the SAS windowing environment. Use the \n    command like this: DMOPTSAVE <save-location>.\n\n  o the PROC OPTSAVE statement."}},{"Name":"ORTHOREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ORTHOREG <options> ; \n    CLASS variables </ option> ; \n    MODEL dependent-variable=independent-effects </ option> ; \n    BY variables ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    EFFECTPLOT <plot-type <(plot-definition-options)>></ options> ; \n    ESTIMATE <'label'> estimate-specification < / options> ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification < / options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    TEST <model-effects> </ options> ; \n    WEIGHT variable ; \n\nThe ORTHOREG procedure fits general linear models by the method of least squares. Other \nSAS/STAT software procedures, such as GLM and REG, fit the same types of models, but PROC \nORTHOREG can produce more accurate estimates than other regression procedures when your data \nare ill conditioned. Instead of collecting crossproducts, PROC ORTHOREG uses Gentleman-Givens \ntransformations to update and compute the upper triangular matrix R of the QR decomposition of \nthe data matrix, with special care for scaling (Gentleman; 1972, 1973). This method has the \nadvantage over other orthogonalization methods (for example, Householder transformations) of \nnot requiring the data matrix to be stored in memory."}},{"Name":"PHREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PHREG <options> ; \n    ASSESS keyword </ options> ; \n    BASELINE <OUT=SAS-data-set> <COVARIATES=SAS-data-set> <keyword=name ...keyword=name > </ options> ; \n    BAYES <options> ; \n    BY variables ; \n    CLASS variable <(options)> <...variable <(options)> > </ options> ; \n    CONTRAST <'label'> effect values <,..., effect values> </ options> ; \n    FREQ variable ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    ESTIMATE <'label'> estimate-specification </ options> ; \n    HAZARDRATIO <'label'> variable </options> ; \n    ID variables ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification </ options> ; \n    MODEL response <*censor(list)> = <effects> </options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name ...keyword=name > </ options> ; \n    programming statements ; \n    \n    RANDOM variable </ options> ;\n    SLICE model-effect </ options> ; \n    STORE <OUT=> item-store-name </ LABEL='label'> ; \n    STRATA variable <(list)> <...variable <(list)>> < / option> ; \n    <label:>TEST equation <,..., equation >< / options> ; \n    WEIGHT variable </ option> ; \n\nThe analysis of survival data requires special techniques because the data are almost always \nincomplete and familiar parametric assumptions might be unjustifiable. Investigators follow \nsubjects until they reach a prespecified endpoint (for example, death). However, subjects \nsometimes withdraw from a study, or the study is completed before the endpoint is reached. \nIn these cases, the survival times (also known as failure times) are censored; subjects \nsurvived to a certain time beyond which their status is unknown. The uncensored survival \ntimes are sometimes referred to as event times. Methods of survival analysis must account \nfor both censored and uncensored data."}},{"Name":"PLAN","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC PLAN <options> ; \n    FACTORS factor-selections </ NOPRINT> ; \n    OUTPUT OUT=SAS-data-set <factor-value-settings> ; \n    TREATMENTS factor-selections ;\n\nThe PLAN procedure constructs designs and randomizes plans for factorial experiments, \nespecially nested and crossed experiments and randomized block designs."}},{"Name":"PLOT","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC PLOT <option(s)>;\n    BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n    PLOT plot-request(s) </ option(s)>;  \n      \nThe PLOT procedure plots the values of two variables for each observation in an input \nSAS data set. The coordinates of each point on the plot correspond to the two variables' \nvalues in one or more observations of the input data set."}},{"Name":"PLS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PLS <options> ; \n    BY variables ; \n    CLASS variables </ option> ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    ID variables ; \n    MODEL dependent-variables = effects </ options> ; \n    OUTPUT OUT=SAS-data-set <options> ;\n\nThe PLS procedure fits models by using any one of a number of linear predictive \nmethods, including partial least squares (PLS). Ordinary least squares regression, \nas implemented in SAS/STAT procedures such as PROC GLM and PROC REG, has the single \ngoal of minimizing sample response prediction error, seeking linear functions of the \npredictors that explain as much variation in each response as possible. The techniques \nimplemented in the PLS procedure have the additional goal of accounting for variation \nin the predictors, under the assumption that directions in the predictor space that are \nwell sampled should provide better prediction for new observations when the predictors \nare highly correlated. All of the techniques implemented in the PLS procedure work by \nextracting successive linear combinations of the predictors, called factors (also called \ncomponents, latent vectors, or latent variables), which optimally address one or both \nof these two goals\u2014explaining response variation and explaining predictor variation. \nIn particular, the method of partial least squares balances the two objectives, seeking \nfactors that explain both response and predictor variation."}},{"Name":"PLM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PLM SOURCE=item-store-specification <options> ; \n    EFFECTPLOT <plot-type <(plot-definition-options)>> </ options> ; \n    ESTIMATE <'label'> estimate-specification <(divisor=n)>\n      <, ...<'label'> estimate-specification <(divisor=n)>> </ options> ; \n    FILTER expression ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect <'label'> values <divisor=>\n      <, ...<'label'> values <divisor=n>> </ options> ; \n    SCORE DATA=SAS-data-set <OUT=SAS-data-set>\n      <keyword<=name>>...<keyword<=name>> </ options> ; \n    SHOW options ; \n    SLICE model-effect </ options> ; \n    TEST <model-effects> </ options> ; \n    WHERE expression ; \n\n(New in SAS/STAT 9.22!)\n\nThe PLM procedure performs postfitting statistical analyses for the contents of a SAS item \nstore that was previously created with the STORE statement in some other SAS/STAT procedure. \nAn item store is a special SAS-defined binary file format used to store and restore information \nwith a hierarchical structure."}},{"Name":"PMENU","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC PMENU <CATALOG=<libref.>catalog> <DESC 'entry-description'>;  \n    MENU menu-bar;  ITEM command <option(s)>;  \n    ITEM 'menu-item' <option(s)>;  \n    DIALOG dialog-box 'command-string field-number-specification';  \n    CHECKBOX <ON> #line @column 'text-for-selection' <COLOR=color> <SUBSTITUTE='text-for-substitution'>;  \n    RADIOBOX DEFAULT=button-number;  RBUTTON <NONE> #line @column 'text-for-selection' \n      <COLOR=color> <SUBSTITUTE='text-for-substitution'>; \n    TEXT #line @column field-description <ATTR=attribute> <COLOR=color>;   \n    MENU pull-down-menu;  \n    SELECTION selection 'command-string';  \n    SEPARATOR;  \n    SUBMENU submenu-name SAS-file; \n  \n The PMENU procedure defines menus that can be used in DATA step windows, macro windows, \n both SAS/AF and SAS/FSP windows,  or in any SAS application that enables you to specify \n customized menus."}},{"Name":"PRINCOMP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PRINCOMP <options> ; \n    BY variables ; \n    FREQ variable ; \n    ID variables ; \n    PARTIAL variables ; \n    VAR variables ; \n    WEIGHT variable ; \n\nThe PRINCOMP procedure performs principal component analysis. As input you can use raw data, \na correlation matrix, a covariance matrix, or a sum-of-squares-and-crossproducts (SSCP) matrix. \nYou can create output data sets containing eigenvalues, eigenvectors, and standardized or \nunstandardized principal component scores."}},{"Name":"PRINQUAL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PRINQUAL <options> ; \n    TRANSFORM transform(variables </ t-options>)\n    <transform(variables </ t-options>) ...> ; \n    ID variables ; \n    FREQ variable ; \n    WEIGHT variable ; \n    BY variables ; \n\nThe PRINQUAL procedure performs principal component analysis (PCA) of qualitative, quantitative, \nor mixed data."}},{"Name":"PRINT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PRINT <option(s)>;  \n    BY <DESCENDING> variable-1 <...<DESCENDING> variable-n><NOTSORTED>;  \n        PAGEBY BY-variable;  \n        SUMBY BY-variable;  \n\n    ID variable(s) <option>;  \n    SUM variable(s) <option>;  \n    VAR variable(s) <option>;\n  \nThe PRINT procedure prints the observations in a SAS data set, using all or some \nof the variables. You can create a variety of reports ranging from a simple listing \nto a highly customized report that groups the data and calculates totals and subtotals \nfor numeric variables."}},{"Name":"PRINTTO","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PRINTTO <option(s)>; \n\nThe PRINTTO procedure defines destinations, other than ODS destinations, for SAS procedure \noutput and for the SAS log. By default, SAS procedure output and the SAS log are routed to \nthe default procedure output file and the default SAS log file for your method of operation. \nThe PRINTTO procedure does not define ODS destinations. See the following table. \n\nYou can store the SAS log or procedure output in an external file or in a SAS catalog entry. \nWith additional programming, you can use SAS output as input data within the same job."}},{"Name":"PROBIT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PROBIT < options > ;\n    BY variables ;\n    CDFPLOT <VAR=variable > < options > ;\n    CLASS variables ;\n    ESTIMATE < 'label' > estimate-specification < (divisor=n) >\n      < , . . . < 'label' > estimate-specification < (divisor=n) > > < / options > ;\n    EFFECTPLOT < plot-type < (plot-definition-options) > > < / options > ;\n    INSET < keyword-list > < / options > ;\n    IPPPLOT <VAR=variable > < options > ;\n    LPREDPLOT < VAR=variable > < options > ;\n    LSMEANS < model-effects > < / options > ;\n    LSMESTIMATE model-effect < 'label' > values < (divisor=n) >\n      < , . . . < 'label' > values < (divisor=n) > > < / options > ;\n    MODEL response = independents < / options > ;\n    OUTPUT <OUT=SAS-data-set > < options > ;\n    PREDPPLOT < VAR=variable > < options > ;\n    SLICE model-effect < / options > ;\n    STORE <OUT=>item-store-name < / LABEL='label' > ;\n    TEST < model-effects > < / options > ;\n    WEIGHT variable ;\n\nThe PROBIT procedure calculates maximum likelihood estimates of regression parameters \nand the natural (or threshold) response rate for quantal response data from biological \nassays or other discrete event data. This includes probit, logit, ordinal logistic, and \nextreme value (or gompit) regression models. \n\nProbit analysis developed from the need to analyze qualitative (dichotomous or polytomous) \ndependent variables within the regression framework. Many response variables are binary by \nnature (yes/no), while others are measured ordinally rather than continuously (degree of \nseverity). Collett (2003) and Agresti (2002), for example, have shown ordinary least squares \n(OLS) regression to be inadequate when the dependent variable is discrete. Probit or logit \nanalyses are more appropriate in this case."}},{"Name":"POWER","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PROC POWER <options> ; \n    COXREG <options>; \n    LOGISTIC <options> ; \n    MULTREG <options> ; \n    ONECORR <options> ; \n    ONESAMPLEFREQ <options> ; \n    ONESAMPLEMEANS <options> ; \n    ONEWAYANOVA <options> ; \n    PAIREDFREQ <options> ; \n    PAIREDMEANS <options> ; \n    PLOT <plot-options> </ graph-options> ; \n    TWOSAMPLEFREQ <options> ; \n    TWOSAMPLEMEANS <options> ; \n    TWOSAMPLESURVIVAL <options> ; \n    TWOSAMPLEWILCOXON <options> ; \n\nPower and sample size analysis optimizes the resource usage and design of a study, improving \nchances of conclusive results with maximum efficiency. The POWER procedure performs prospective \npower and sample size analyses for a variety of goals, such as the following: \n  o determining the sample size required to get a significant result with adequate probability (power) \n  o characterizing the power of a study to detect a meaningful effect \n  o conducting what-if analyses to assess sensitivity of the power or required sample size to other factors"}},{"Name":"PRESENV","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PRESENV PERMDIR=libref SASCODE=fileref <SHOW_COMMENTS>; \n  \nThe PRESENV procedure preserves all global statements and macro variables in your SAS code \nfrom one SAS session to another. When this procedure is invoked at the end of a SAS session, \nall of the global statements and macro variables are written to a file. The Work data sets \nand the macro catalog are written to an auxiliary directory. You can then terminate the SAS \nsession. You can restart the session at a later time, and the saved global statements and \nmacro variable settings can be re-executed. The Work data sets can be copied back to the \ncurrent Work directory, thereby allowing the session to resume. \n\nThe PRESENV procedure works with the PRESENV system option to preserve your SAS program and \ndata sets. You can turn the option on or off at any time. When the PRESENV system option is \nturned off, the global statements collection is suspended. When turned back on, the collection \nresumes. At no point is the collection discarded. However, the collection does not begin until \nthe first time the option is turned on."}},{"Name":"PROTO","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PROTO PACKAGE=catalog-entry <options>;  \n    MAPMISS type1=value1 type2=value2 ...;  \n    LINK load-module <NOUNLOAD>;  \n\nThe PROTO procedure enables you to register, in batch mode, external functions that are written \nin the C or C++ programming languages."}},{"Name":"PRTDEF","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PRTDEF <option(s)>;\n    \nThe PRTDEF procedure creates printer definitions in batch mode either for an individual \nuser or for all SAS users at your site. Your system administrator can create printer \ndefinitions in the SAS registry and make these printers available to all SAS users at \nyour site by using PROC PRTDEF with the USESASHELP option. An individual user can create \npersonal printer definitions in the SAS registry by using PROC PRTDEF."}},{"Name":"PRTEXP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PRTEXP<option(s)>;\n    <SELECT printer_1 ...< printer_n>>;  \n    <EXCLUDE printer_1 ... <printer_n>>; \n      \nThe PRTEXP procedure enables you to extract printer attributes from the SAS registry \nfor replication and modification. PROC PRTEXP then writes these attributes to the SAS \nlog or to a SAS data set. You can specify that PROC PRTEXP search for these attributes \nin the SASHELP portion of the registry or the entire SAS registry."}},{"Name":"PSMOOTH","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PSMOOTH <options> ; \n    BY variables ; \n    ID variables ; \n    VAR variables ; \n\nIn the search for complex disease genes, linkage and/or association tests are often \nperformed on markers from a genome-wide scan or SNPs from a finely scaled map. This \nmeans hundreds or even thousands of hypotheses are being simultaneously tested. \nPlotting the negative log p-values of all the marker tests will reveal many peaks \nthat indicate significant test results, some of which are false positives. In order \nto reduce the number of false positives or improve power, smoothing methods can be \napplied that take into account p-values from neighboring, and possibly correlated, \nmarkers. That is, the peak length can be used to indicate significance in addition \nto the peak height. The PSMOOTH procedure offers smoothing methods that implement \nSimes' method (1986), Fisher's method (1932), and/or the truncated product method \n(TPM) (Zaykin et al. 2002) for multiple hypothesis testing. These methods modify \nthe p-value from each marker test by using a function of its original p-value and \nthe p-values of the tests on the nearest markers. Since the number of hypothesis \ntests being performed is not reduced, adjustments to correct the smoothed p-values \nfor multiple testing are available as well."}},{"Name":"PWENCODE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PWENCODE IN='password' <OUT=fileref> <METHOD=encoding-method>;\n  \nThe PWENCODE procedure enables you to encode passwords. Encoded passwords can be used \nin place of plaintext passwords in SAS programs that access relational database management \nsystems (RDBMSs) and various servers, such as SAS/CONNECT servers, SAS/SHARE servers, and \nSAS Integrated Object Model (IOM) servers (such as the SAS Metadata Server)."}},{"Name":"QDEVICE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC QDEVICE \n  <REPORT = GENERAL | FONT | DEVOPTION | LINESTYLE | RECTANGLE | SYMBOL >\n  <OUT=SAS-data-set>\n  <DEVLOC = GDEVICE0...GDEVICE9 | SASHELP>\n  <REGISTRY = SASHELP | SASUSER>\n  <SUPPORT = YES | NO | ALL>\n  <UNITS = IN | CM>; \n  DEVICE device-name-1<...device-name-n>\n  <_ALL_> <_HTML_> <_LISTING_> <_RTF_>; \n  PRINTER printer-name-1 <...printer-name-n>\n  <_ALL_> <_PCL_> <_PDF_> <_PRINTER_> <_PS_>; \n  VAR variable-1<...variable-n>; \n\nThe QDEVICE procedure produces reports about graphics devices and universal printers. \nYou can use the information in these reports to determine the best device or printer \nto use for a specific application. \n\nSix different reports are available. These reports summarize information such as color \nsupport, default output sizes, margin sizes, resolution, supported fonts, hardware \nsymbols, hardware fill types, hardware line styles, and device options."}},{"Name":"QUANTREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC QUANTREG <options> ; \n    BY variables ; \n    CLASS variables ; \n    ESTIMATE < 'label' > estimate-specification < (divisor=n) >\n      < , . . . < 'label' > estimate-specification < (divisor=n) > >\n      < / options > ;\n    EFFECT name = effect-type ( variables </ options> ) ; \n    ID variables ; \n    MODEL response = independents </ options> ; \n    OUTPUT <OUT= SAS-data-set> <options> ; \n    PERFORMANCE <options> ; \n    TEST effects </ options> ; \n    WEIGHT variable ; \n\nThe QUANTREG procedure models the effects of covariates on the conditional \nquantiles of a response variable by means of quantile regression. \n\nOrdinary least squares (OLS) regression models the relationship between one \nor more covariates X and the conditional mean of the response variable Y given \nX=x. Quantile regression, which was introduced by Koenker and Bassett (1978), \nextends the regression model to conditional quantiles of the response variable, \nsuch as the median or the 90th percentile. Quantile regression is particularly \nuseful when the rate of change in the conditional quantile, expressed by the \nregression coefficients, depends on the quantile."}},{"Name":"QUANTLIFE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC QUANTLIFE <options> ; \n    BASELINE <options> ; \n    BY variables ; \n    CLASS variables ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    MODEL response <*censor(list)> = <effects> </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name \u2026keyword=name> ; \n    TEST effects </ options> ; \n    WEIGHT variable ; \n\n[SAS/STAT 12.1 Experimental Procedure]\n\nThe QUANTLIFE procedure performs quantile regression analysis for survival data, where observations \nare not always directly observed. \n\nQuantile regression (Koenker and Bassett, 1978) is a type of regression analysis that explores how \nthe conditional quantile of a response variable depends on its covariates. By estimating a set of \nconditional quantiles, you can gain more insight about the conditional distribution of the response \ngiven its covariates."}},{"Name":"QUANTSELECT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PROC QUANTSELECT <options> ; \n    BY variables ; \n    CLASS variable <(v-options)> <variable <(v-options \u2026)> > </ v-options> <options> ; \n    EFFECT name = effect-type (variables </ options> ) ; \n    MODEL variable = <effects> </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword <=name> > <\u2026keyword<=name>> ; \n    PARTITION <options> ; \n    WEIGHT variable ; \n\n[SAS/STAT 12.1 Experimental Procedure]\n\nQuantile regression, which was introduced by Koenker and Bassett (1978), is a modern method that models \nthe effects of covariates on the conditional quantiles of a response variable. The QUANTSELECT procedure \nperforms effect selection in the framework of quantile regression. A variety of effect selection methods \nare available, including greedy methods and penalty methods. The QUANTSELECT procedure offers extensive \ncapabilities for customizing the effect selection processes with a variety of candidate selecting, \neffect-selection stopping, and final-model choosing criteria. PROC QUANTSELECT also provides graphical \nsummaries for the effect selection processes."}},{"Name":"RANK","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC RANK <option(s)>;  \n      BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n      VAR data-set-variables(s);  \n      RANKS new-variables(s);\n\nThe RANK procedure computes ranks for one or more numeric variables across the observations \nof a SAS data set and outputs the ranks to a new SAS data set. PROC RANK by itself produces \nno printed output."}},{"Name":"REG","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC REG <options> ; \n    <label:>MODEL dependents=<regressors> </ options> ; \n    BY variables ; \n    FREQ variable ; \n    ID variables ; \n    VAR variables ; \n    WEIGHT variable ; \n    ADD variables ; \n    DELETE variables ; \n    <label:>MTEST <equation, ...,equation> </ options> ; \n    OUTPUT <OUT=SAS-data-set>< keyword=names> <...keyword=names> ; \n    PAINT <condition | ALLOBS> </ options > | < STATUS | UNDO> ; \n    RESTRICT equation, ...,equation ; \n    REWEIGHT <condition | ALLOBS> </ options > | < STATUS | UNDO> ; \n    PRINT <options> <ANOVA> <MODELDATA> ; \n    REFIT ; \n    RESTRICT equation, ...,equation ; \n    REWEIGHT <condition | ALLOBS> </ options > | < STATUS | UNDO> ; \n    <label:>TEST equation,<,...,equation> </ option> ; \n\nThe REG procedure is one of many regression procedures in the SAS System. It is a general-purpose \nprocedure for regression, while other SAS regression procedures provide more specialized applications. "}},{"Name":"REGISTRY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC REGISTRY <option(s)>;\n  \nThe REGISTRY procedure maintains the SAS registry. The registry consists of two parts. One part \nis stored in the SASHELP library, and the other part is stored in the SASUSER library."}},{"Name":"REPORT","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC REPORT <option(s)>;  \n      BREAK location break-variable</ option(s)>;  \n      BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n      COLUMN column-specification(s);  \n      COMPUTE location <target> </ STYLE=<style-element-name> <[style-attribute-specification(s)]>>;  \n        LINE specification(s);  \n        ... select SAS language elements ...  \n        ENDCOMP;   \n        COMPUTE report-item </ type-specification>;  \n          CALL DEFINE (column-id, 'attribute-name', value);  \n          ... select SAS language elements ...  \n          ENDCOMP;  \n      DEFINE report-item / <usage> <attribute(s)> <option(s)> \n        <justification> <COLOR=color> <'column-header-1' <...'column-header-n'>> <style>;  \n      FREQ variable;  \n      RBREAK location </ option(s)>;  \n      WEIGHT variable; \n  \nThe REPORT procedure combines features of the PRINT, MEANS, and TABULATE procedures with \nfeatures of the DATA step in a single report-writing tool that can produce a variety of \nreports."}},{"Name":"ROBUSTREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ROBUSTREG <options> ; \n    BY variables ; \n    CLASS variables ; \n    EFFECT name=effect-type ( variables </options>) ; \n    ID variables ; \n    MODEL response=<effects> </ options> ; \n    OUTPUT <OUT=SAS-data-set> <options> ; \n    PERFORMANCE <options> ; \n    TEST effects ; \n    WEIGHT variable ; \n\nThe main purpose of robust regression is to detect outliers and provide resistant (stable) \nresults in the presence of outliers. In order to achieve this stability, robust regression \nlimits the influence of outliers. Historically, three classes of problems have been addressed \nwith robust regression techniques: \n\n  o problems with outliers in the -direction (response direction) \n\n  o problems with multivariate outliers in the -space (that is, outliers in the covariate space, \n    which are also referred to as leverage points) \n\n  o problems with outliers in both the -direction and the x-space"}},{"Name":"RSREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC RSREG <options> ; \n    MODEL responses= independents </ options> ; \n    RIDGE <options> ; \n    WEIGHT variable ; \n    ID variables ; \n    BY variables ; \n\nThe RSREG procedure uses the method of least squares to fit quadratic response surface regression \nmodels. Response surface models are a kind of general linear model in which attention focuses on \ncharacteristics of the fit response function and in particular, where optimum estimated response \nvalues occur."}},{"Name":"SCAPROC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SCAPROC;  \n    <statements>;  \n\nThe SCAPROC procedure implements the SAS Code Analyzer, which captures information \nabout input, output, and the use of macro symbols from a SAS job while it is running. \nThe SAS Code Analyzer can write this information and the information that is in the \noriginal SAS file to a file that you specify. The SCAPROC procedure can also generate \na grid-enabled job that can concurrently run independent pieces of the job. You can \nissue the SCAPROC procedure on your operating system's command line or in SAS code \nin the SAS Editor window."}},{"Name":"SCORE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SCORE DATA=SAS-data-set<options> ; \n    BY variables ; \n    ID variables ; \n    VAR variables ;\n\nThe SCORE procedure multiplies values from two SAS data sets, one containing coefficients (for example, \nfactor-scoring coefficients or regression coefficients) and the other containing raw data to be scored \nusing the coefficients from the first data set."}},{"Name":"SEQDESIGN","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SEQDESIGN <options> ; \n    <label:> DESIGN options ; \n    SAMPLESIZE <MODEL= option> ; \n\nThe purpose of the SEQDESIGN procedure is to design interim analyses for clinical trials. \nClinical trials are experiments on human subjects to demonstrate the efficacy and safety \nof new drugs or treatments. A simple example is a trial to test the effectiveness of a new \ndrug in humans by comparing the outcomes in a group of patients who receive the new drug \nwith the outcomes in a comparable group of patients who receive a placebo."}},{"Name":"SEQTEST","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SEQTEST <options> ;\n    \nThe purpose of the SEQTEST procedure is to perform interim analyses for clinical trials. \nClinical trials are experiments on human beings to demonstrate the efficacy and safety \nof new drugs or treatments. A simple example is a trial to test the effectiveness of a \nnew drug in humans by comparing the outcomes in a group of patients who receive the new \ndrug with the outcomes in a comparable group of patients who receive a placebo. \n\nA clinical trial is conducted according to a plan called a protocol. A protocol details \nthe objectives of the trial, the data collection process, and the analyses of the data. \nThe protocol contains information such as a null hypothesis and an alternative hypothesis, \na test statistic, the probability \u03b1 of a Type I error (incorrectly rejecting the null \nhypothesis), the probability \u03b2 of a Type II error (incorrectly accepting the null hypothesis), \nthe sample size needed to attain a specified power (probability of correctly rejecting the \nnull hypothesis) of 1-\u03b2 at an alternative reference, and critical values that are associated \nwith the test statistic for hypothesis testing."}},{"Name":"SERVER","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC SERVER <options>;\n    ALLOCATE SASFILE SAS-data-set1 <(data-set-options) >  \n      <SAS-data-set2> <(data-set-options) ... SAS-data-set8 <(data-set-options)>>  \n    ALLOCATE LIBRARY libref <engine> 'SAS-data-library' <LIBTYPE=library-type>\n  <CATCACHELIMIT=n><engine/system-options>;  \n  \nThe SERVER procedure is the core of SAS/SHARE. It is the component that enables\ntwo or more clients to write concurrently to the same SAS file. To start a\nSAS/SHARE server, invoke the SERVER procedure. Specify an ID for that server\nwith a set of optional parameters that define the server behavior."}},{"Name":"SGDESIGN","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SGDESIGN SGD=\"SGD-file-specification\" <option(s)>;\n    DYNAMIC dynamic-var\u20131=\"assigned-value\u20131\" <...dynamic-var\u2013n=\"assigned-value-n\">;\n\nThe SGDESIGN procedure produces a graph from one or more input SAS data sets and a user-defined \nODS Graphics Designer (SGD) file. The SGD file is created with the SAS ODS Graphics Designer \napplication."}},{"Name":"SGPANEL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PROC SGPANEL < option(s)>;\n    ...SGPANEL statements\n    RUN;\n    QUIT;\n\nThe SGPANEL procedure creates a panel of graph cells for the values of one or more classification \nvariables. For example, if a data set contains three variables (A, B and C) and you want to compare \nthe scatter plots of B*C for each value of A, then you can use the SGPANEL to create this panel. The \nSGPANEL procedure creates a layout for you automatically and splits the panel into multiple graphs \nif necessary.\n\nThe SGPANEL procedure can create a wide variety of plot types, and overlay multiple plots together \nin each graph cell in the panel. It can also produce several types of layout."}},{"Name":"SGPLOT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SGPLOT < option(s)>; \n    ...SGPPLOT statements\n    RUN;\n    QUIT;\n\nThe SGPLOT procedure creates one or more plots and overlays them on a single set of axes. \nYou can use the SGPLOT procedure to create statistical graphics such as histograms and \nregression plots, in addition to simple graphics such as scatter plots and line plots. \nStatements and options enable you to control the appearance of your graph and add additional \nfeatures such as legends and reference lines.\n\nThe SGPLOT procedure can create a wide variety of plot types, and can overlay plots together \nto produce many different types of graphs."}},{"Name":"SPP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SPP options; \n    BY variables; \n    PROCESS name = (variables </pattern-options>)</process-options <distance-function-options>>; \n    TREND name = FIELD(field-definition ); \n    COVTEST process-name = trend-name <trend-name, \u2026></options>; \n    MODEL process-name = <trend-name, \u2026></model-options>; \n    PARMS value-list </ PARMSDATA=SAS-data set>; \n    NLOPTIONS <options>;\n    \nThe SPP procedure performs analysis for spatial point patterns in two dimensions. You can specify the \npoint process rectangular window or rely on the input data set coordinates. Summary descriptions are \navailable through the F, G, J, K functions, which compare the empirical function distributions to the \ntheoretical homogeneous Poisson functions. \n\nThe SPP procedure uses ODS Graphics to create graphs as part of its output."}},{"Name":"SSM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SSM <options>;\n    BY variables;\n    COMPONENT name = (variables)* state </ options>;\n    DEPLAG name(response-variable) lag-term1 <lag-term2 \u2026> ;\n    EVAL name = expression </ options>;\n    ID variable <option>;\n    IRREGULAR name <options>;\n    MODEL response = variables </ options>;\n    OUTPUT <options>;\n    PARMS variables </ options> ;\n    STATE name(dim)<options>;\n    TREND name(type)<options>;    \n    Programming statements ;\n    \nState space models (SSMs) are used for analyzing continuous response variables that are recorded \nsequentially according to a numeric indexing variable. In many cases, the indexing variable is time \nand the observations are collected at regular time intervals\u2014for example, hourly, weekly, or monthly. \nIn such cases, the resulting data are called time series data. In other cases, the indexing variable \nmight not be time or the observations might not be equally spaced according to the indexing variable. \nThese more general types of sequential data are called longitudinal data. Because of their sequential \nnature, these types of data exhibit some characteristic features. For example, chronologically closer \nmeasurements tend to be highly correlated while measurements farther apart are essentially uncorrelated. \nData can be trending in a particular direction and can have seasonal or other periodic patterns. SSMs \nare specially designed to model such sequential data. They apply to both univariate and multivariate \nresponse situations and can easily incorporate predictor (independent variable) information when it \nis available."}},{"Name":"STREAM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC STREAM OUTFILE= fileref <option(s)>; \n    BEGIN \n    text-1\n    <text-n> \n    ;;;;\n    \nwhere:\ntext \n  specifies the SAS statements or macros to use with PROC STREAM.\n  \nThe STREAM procedure enables you to process an input stream that consists of arbitrary text that \ncan contain SAS macro specifications. The macros are executed and expanded while the other text \nin the input stream is preserved. The text stream is not validated as SAS syntax. The output stream \nis sent to an external file that is referenced by a fileref, and that can be defined to use any \ntraditional SAS output destination."}},{"Name":"SURVEYIMPUTE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SURVEYIMPUTE <options>;\n    BY variables;\n    CELLS variables ;\n    CLASS variable <(options)> <\u2026variable <(options)>> </ options>;\n    CLUSTER variables;\n    ID variable;\n    IMPJOINT <variables>;\n    OUTPUT <OUT=SAS-data-set><OUTJKCOEFS=SAS-data-set><keyword=name \u2026keyword=name>;\n    REPWEIGHTS variables;\n    STRATA variables ;\n    VAR variables;\n    WEIGHT variable; \n    \nThe SURVEYIMPUTE procedure imputes missing values of an item in a data set by replacing them with observed \nvalues from the same item. The principles by which the imputation is performed are particularly useful for \nsurvey data. PROC SURVEYIMPUTE also computes replicate weights (such as jackknife weights) that account for \nthe imputation and that can be used for replication-based variance estimation for complex surveys. The procedure \nimplements a fractional hot-deck imputation technique (Kim and Fuller 2004; Fuller 2009; Kim and Shao 2014) \nin addition to some traditional hot-deck imputation techniques (Andridge and Little 2010)."}},{"Name":"SURVEYPHREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SURVEYPHREG <options> ; \n    BY variables ; \n    CLASS variable <(options)> <...variable <(options)> > </options> ; \n    CLUSTER variables ; \n    DOMAIN variables <variable*variable variable*variable*variable ... > ; \n    ESTIMATE <'label'> estimate-specification < / options> ; \n    FREQ variable ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification < / options> ; \n    MODEL response <*censor(list)> = effects </options> ; \n    NLOPTIONS <options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword=name ...keyword=name > </options> ; \n    REPWEIGHTS variables </ options> ; \n    SLICE model-effect </ options> ; \n    STRATA variables </option> ; \n    STORE <OUT=>item-store-name </ LABEL='label'> ; \n    TEST <model-effects> </ options> ; \n    WEIGHT variable ; \n\nThe SURVEYPHREG procedure performs regression analysis based on the Cox proportional \nhazards model for sample survey data. Cox's semiparametric model is widely used in the \nanalysis of survival data to estimate hazard rates when adequate explanatory variables \nare available. The procedure provides design-based variance estimates, confidence intervals, \nand hypothesis tests concerning the parameters and model effects."}},{"Name":"SURVEYREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SURVEYREG  <options> ; \n    BY variables ; \n    CLASS variables ; \n    CLUSTER variables ; \n    CONTRAST 'label' effect values < ... effect values> </ options> ; \n    DOMAIN variables <variable*variable variable*variable*variable ... > ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    ESTIMATE <'label'> estimate-specification < / options> ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification < / options> ; \n    MODEL dependent = <effects> </ options> ; \n    OUTPUT <keyword <=variable-name> ... keyword <=variable-name>> </ option> ; \n    REPWEIGHTS variables < / options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name</LABEL='label'> ; \n    STRATA variables </ option> ; \n    TEST <model-effects> </ options> ; \n    WEIGHT variable ; \n  \nThe SURVEYREG procedure performs regression analysis for sample survey data. This procedure \ncan handle complex survey sample designs, including designs with stratification, clustering, \nand unequal weighting. The procedure fits linear models for survey data and computes regression \ncoefficients and their variance-covariance matrix. The procedure also provides significance \ntests for the model effects and for any specified estimable linear functions of the model \nparameters. Using the regression model, the procedure can compute predicted values for the \nsample survey data."}},{"Name":"SURVEYLOGISTIC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SURVEYLOGISTIC  <options> ; \n    BY variables ; \n    CLASS variable <(v-options)> <variable <(v-options)> ...> </ v-options> ; \n    CLUSTER variables ; \n    CONTRAST 'label'   effect values <,...effect values> </ options> ; \n    DOMAIN variables <variable*variable variable*variable*variable ...> ; \n    EFFECT name = effect-type ( variables </ options> ) ; \n    ESTIMATE <'label'> estimate-specification < / options> ; \n    FREQ variable ; \n    LSMEANS <model-effects> </ options> ; \n    LSMESTIMATE model-effect lsmestimate-specification < / options> ; \n    MODEL events/trials = <effects < / options>> ; \n    MODEL variable <(v-options)> = <effects> < / options> ; \n    OUTPUT <OUT=SAS-data-set> <options> < / option> ; \n    REPWEIGHTS variables < / options> ; \n    SLICE model-effect </ options> ; \n    STORE <OUT=>item-store-name</LABEL='label'> ; \n    STRATA variables </ option> ; \n    <label:> TEST equation1 < , ... , equationk> </ options> ; \n    UNITS independent1 = list1 <... independentk = listk> < / option> ; \n    WEIGHT variable ; \n  \nCategorical responses arise extensively in sample survey. Common examples of responses \ninclude the following: \n\n    o binary: for example, attended graduate school or not \n    o ordinal: for example, mild, moderate, and severe pain \n    o nominal: for example, ABC, NBC, CBS, FOX TV network viewed at a certain hour"}},{"Name":"SURVEYMEANS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SURVEYMEANS <options> <statistic-keywords> ; \n    BY variables ; \n    CLASS variables ; \n    CLUSTER variables ; \n    DOMAIN variables <variablevariable variablevariablevariable ...> < / option> ; \n    RATIO <'label'> variables / variables ; \n    REPWEIGHTS variables < / options> ; \n    STRATA variables < / option> ; \n    VAR variables ; \n    WEIGHT variable \n  \nThe SURVEYMEANS procedure estimates characteristics of a survey population by using \nstatistics computed from a survey sample. You can estimate statistics such as means, \ntotals, proportions, quantiles, and ratios. PROC SURVEYMEANS also provides domain \nanalysis, which computes estimates for subpopulations or domains. The procedure also \nestimates variances and confidence limits and performs t tests for these statistics. \nPROC SURVEYMEANS uses either the Taylor series (linearization) method or replication \n(subsampling) methods to estimate sampling errors of estimators based on complex sample \ndesigns. The sample design can be a complex survey sample design with stratification, \nclustering, and unequal weighting."}},{"Name":"SGRENDER","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SGRENDER < option(s)>;  \n    DATTRVAR variable-assignment(s);\n    DYNAMIC variable-assignment(s);  \n\nThe SGRENDER procedure produces graphical output from templates that are created with the Graph Template \nLanguage (GTL). The templates are referred to as StatGraph templates. The GTL is a comprehensive language \nfor creating statistical graphics, which can be used to create customized layouts and graphs that are beyond \nthe scope of the ODS Graphics procedures."}},{"Name":"SGSCATTER","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SGSCATTER < options>;  \n      COMPARE X= variable | (variable-1 ... variable-n) Y= variable | (variable-1 ... variable-n)</options>;  \n      MATRIX variable-1 < ... variable-n> </options>;  \n      PLOT plot-request(s) </options>;  \n\nThe SGSCATTER procedure creates a paneled graph of scatter plots for multiple combinations \nof variables, depending on the plot statement that you use. You can use options to overlay \nfit plots and ellipses on your scatter plots."}},{"Name":"SIM2D","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SIM2D options ; \n      BY variables ; \n      COORDINATES coordinate-variables ; \n      GRID grid-options ; \n      ID variable ; \n      RESTORE store-options ; \n      SIMULATE simulate-options ; \n      MEAN mean-options ; \n\nThe SIM2D procedure uses an LU decomposition technique to produce a spatial simulation for \na Gaussian random field with a specified mean and covariance structure in two dimensions. \n\nThe simulation can be conditional or unconditional. If it is conditional, a set of coordinates \nand associated field values are read from a SAS data set. The resulting simulation honors these \ndata values. \n\nYou can specify the mean structure as a quadratic function in the coordinates. Specify the \nsemivariance by naming the form and supplying the associated parameters, or by using the \ncontents of an item store file that was previously created by PROC VARIOGRAM."}},{"Name":"SIMNORMAL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SIMNORMAL DATA=SAS-data-set ; \n    VAR variables ; \n    BY variables ; \n    CONDITION variables ; \n\nThe SIMNORMAL procedure can perform conditional and unconditional simulation for a set \nof correlated normal or Gaussian random variables. \n\nThe means, variances, and covariances (or correlations) are read from an input TYPE=CORR \nor TYPE=COV data set. This data set is typically produced by the CORR procedure. Conditional \nsimulations are performed by appending a special observation, identified by the value of \n'COND' for the _TYPE_ variable, which contains the conditioning value."}},{"Name":"SOAP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SOAP option(s) <properties>;\n  \nPROC SOAP reads XML input from a file that has a fileref and writes XML output \nto another file that has a fileref. The envelope and headings are part of the \ncontent of the fileref. They are defined in the IN option of PROC SOAP. The input \nXML is either a SOAPEnvelope element, or an element inside the SOAPEnvelope that \nis required to invoke the Web service. \n\nOperating Environment Information:   PROC SOAP can run on any platform; however, \nWS-Security features are not available in the z/OS operating environment. The \nmessage component is an XML document that corresponds to a service request."}},{"Name":"SORT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SORT <collating-sequence-option> <other option(s)>;  \n    BY <DESCENDING> variable-1 <...<DESCENDING> variable-n>; \n      \nThe SORT procedure orders SAS data set observations by the values of one or more \ncharacter or numeric variables. The SORT procedure either replaces the original \ndata set or creates a new data set. PROC SORT produces only an output data set."}},{"Name":"STP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC STP PROGRAM=\u201cmetadata-path-of-stored-process\u201d <ODSOUT=STORE | REPLAY>; \n  INPUTDATA stored-process-data-file=member-name | \u201cdata-set-path\u201d; \n  INPUTFILE stored-process-file<=local-fileref | \u201clocal-file-path\u201d> ...; \n  INPUTPARAM parameter-name<=\u201dparameter-value\u201d> \n  <parameter-name<=\u201dparameter-value\u201d>>; \n  LIST< GROUP=level | (level1...leveln)>; \n  LOG FILE=local-fileref | local-file-path\n  OUTPUTDATA stored-process-data-file=member-name | \u201cdata-set-path\u201d; \n  OUTPUTFILE stored-process-file<=local-fileref | \u201clocal-file-path\u201d> ...; \n  OUTPUTPARAM parameter-name<=local-variable-name>; \n    \nThe STP procedure enables stored process execution from a SAS program. PROC STP \ncan be executed in an interactive, batch, or server SAS session and can also be \nexecuted by another stored process."}},{"Name":"SQL","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC SQL <option(s)>; \n      ...statements;\n    <QUIT;>\n    \nThe SQL procedure implements Structured Query Language (SQL) for SAS. SQL is a \nstandardized, widely used language that retrieves data from and updates data in \ntables and the views that are based on those tables. \n\nThe SAS SQL procedure enables you to:\n\n  o retrieve and manipulate data that is stored in tables or views. \n  o create tables, views, and indexes on columns in tables. \n  o create SAS macro variables that contain values from rows in a query's result. \n  o add or modify the data values in a table's columns or insert and delete rows. \n    You can also modify the table itself by adding, modifying, or dropping columns.\n  o send DBMS-specific SQL statements to a database management system (DBMS) and \n    retrieve DBMS data."}},{"Name":"STANDARD","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC STANDARD <option(s)>;\n    \nThe STANDARD procedure standardizes variables in a SAS data set to a given mean and \nstandard deviation, and it creates a new SAS data set containing the standardized \nvalues."}},{"Name":"STDIZE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC STDIZE <options> ; \n    BY variables ; \n    FREQ variable ; \n    LOCATION variables ; \n    SCALE variables ; \n    VAR variables ; \n    WEIGHT variable ; \n\nThe STDIZE procedure standardizes one or more numeric variables in a SAS data set by \nsubtracting a location measure and dividing by a scale measure."}},{"Name":"STDRATE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC STDRATE <options> ; \n    BY variables ; \n    POPULATION options ; \n    REFERENCE options ; \n    STRATA variables \u2002 </ option> ;\n\n[New procedure in SAS/STAT 12.1]\n\nThe STDRATE procedure computes directly standardized rates and risks for study populations. For two \nstudy populations with the same reference population, PROC STDRATE compares directly standardized \nrates or risks from these two populations. For homogeneous effects across strata, PROC STDRATE computes \nMantel-Haenszel estimates. The STDRATE procedure also computes indirectly standardized rates and \nrisks, including SMR."}},{"Name":"SEVERITY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SEVERITY options ;\n    BY variable-list ;\n    LOSS < response-variable > < / censoring-truncation-options > ;\n    WEIGHT weight-variable ;\n    CLASS variable < (options) > . . . < variable < (options) > > < / global-options > ;\n    SCALEMODEL regression-effect-list < / scalemodel-options > ;\n    DIST distribution-name-or-keyword < (distribution-option) < distribution-name-or-keyword\n      < (distribution-option) > > . . . > < / preprocess-options > ;\n    OUTSCORELIB < OUTLIB= > fcmp-library-name options ;\n    NLOPTIONS options ;\n    Programming statements ;\n  \nThe SEVERITY procedure estimates parameters of any arbitrary continuous probability \ndistribution that is used to model magnitude (severity) of a continuous-valued event \nof interest. Some examples of such events are loss amounts paid by an insurance company \nand demand of a product as depicted by its sales. PROC SEVERITY is especially useful \nwhen the severity of an event does not follow typical distributions, such as the normal \ndistribution, that are often assumed by standard statistical methods."}},{"Name":"STEPDISC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC STEPDISC <options> ; \n    CLASS variable ; \n    BY variables ; \n    FREQ variable ; \n    VAR variables ; \n    WEIGHT variable ; \n\nGiven a classification variable and several quantitative variables, the STEPDISC procedure \nperforms a stepwise discriminant analysis to select a subset of the quantitative variables \nfor use in discriminating among the classes."}},{"Name":"SUMMARY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SUMMARY <option(s)> <statistic-keyword(s)>;\n    BY <DESCENDING> variable-1<...<DESCENDING> variable-n> <NOTSORTED>;  \n    CLASS variable(s) </ option(s)>;  \n    FREQ variable;  \n    ID variable(s);  \n    OUTPUT <OUT=SAS-data-set><output-statistic-specification(s)> <id-group-specification(s)> \n        <maximum-id-specification(s)> <minimum-id-specification(s)></ option(s)> ;  \n    TYPES request(s);  \n    VAR variable(s)</ WEIGHT=weight-variable>;  \n    WAYS list;  \n    WEIGHT variable; \n    \nThe SUMMARY procedure provides data summarization tools that compute descriptive statistics \nfor variables across all observations or within groups of observations. The SUMMARY procedure \nis very similar to the MEANS procedure."}},{"Name":"SURVEYFREQ","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SURVEYFREQ <options> ; \n    BY variables ; \n    CLUSTER variables ; \n    REPWEIGHTS variables </ options> ; \n    STRATA variables </ option> ; \n    TABLES requests </ options> ; \n    WEIGHT variable ; \n\nThe SURVEYFREQ procedure produces one-way to n-way frequency and crosstabulation tables \nfrom sample survey data. These tables include estimates of population totals, population \nproportions, and their standard errors. Confidence limits, coefficients of variation, and \ndesign effects are also available. The procedure provides a variety of options to customize \nthe table display."}},{"Name":"SURVEYSELECT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SURVEYSELECT options ;\n    CONTROL variables ;\n    FREQ variable ;\n    ID variables ;\n    SAMPLINGUNIT | CLUSTER variables < / options > ;\n    SIZE variable ;\n    STRATA variables < / options > ;\n\nThe SURVEYSELECT procedure provides a variety of methods for selecting probability-based \nrandom samples. The procedure can select a simple random sample or can sample according to \na complex multistage sample design that includes stratification, clustering, and unequal \nprobabilities of selection. With probability sampling, each unit in the survey population \nhas a known, positive probability of selection. This property of probability sampling avoids \nselection bias and enables you to use statistical theory to make valid inferences from the \nsample to the survey population. \n\nPROC SURVEYSELECT provides the following equal probability sampling methods: \n  o simple random sampling (without replacement) \n  o unrestricted random sampling (with replacement) \n  o systematic random sampling \n  o sequential random sampling \n  o Bernoulli sampling"}},{"Name":"TABULATE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TABULATE <option(s)>;  \n    BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n    CLASS variable(s) </ options>;  \n    CLASSLEV variable(s) / STYLE=<style-element-name | PARENT> <[style-attribute-specification(s)] >;  \n    FREQ variable;  \n    KEYLABEL keyword-1='description-1' <...keyword-n='description-n'>;  \n    KEYWORD keyword(s) / STYLE=<style-element-name | PARENT> <[style-attribute-specification(s)] >;  \n    TABLE <<page-expression,> row-expression,> column-expression</ table-option(s)>;  \n    VAR analysis-variable(s)</ options>;  \n    WEIGHT variable; \n    \nThe TABULATE procedure displays descriptive statistics in tabular format, using some \nor all of the variables in a data set. You can create a variety of tables ranging from \nsimple to highly customized."}},{"Name":"TEMPLATE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TEMPLATE;  \n    DEFINE COLUMN column-path </ STORE=libref.template-store>;  <column-attribute-1; <...column-attribute-n;>>  \n    statements  \n    END; \n    DEFINE FOOTER footer-path </ STORE=libref.template-store>;  <footer-attribute-1; <...footer-attribute-n;>>  \n    statements  \n    END; \n    DEFINE HEADER template-name </ STORE=libref.template-store>;  <header-attribute-1; <...header-attribute-n;>>  \n    statements  \n    END;\n    DEFINE STYLE style-path </ STORE=libref.template-store>;  <PARENT=style-path;>  \n    statements  \n    END;\n    DEFINE TABLE table-path </ STORE=libref.template-store>;  <table-attribute-1; <...table-attribute-n;>>  \n    statements  \n    END;\n    DEFINE TAGSET tagset-path </ STORE=libref.template-store>;  DEFINE EVENT event-name;  \n    <event-attribute-1; <...event-attribute-n;>>  \n    statements  \n    END;\n    DEFINE CROSSTABS table-path </ STORE=libref.template-store>;  statements  \n    END;\n    DEFINE STATGRAPH graph-path </ STORE=libref.template-store>;  statements  \n    END; \n    DELETE template-path </ STORE=libref.template-store >;  \n    EDIT template-path-1 <AS template-path-2> </ STORE=libref.template-store > ;  statements-and-attributes  \n    END; \n    LINK template-path-1 TOtemplate-path-2 </ option(s)>;  \n    LIST <starting-path></ option(s)>;  \n    PATH location(s);  \n    SOURCE template-path </ option(s)>;  \n    TEST DATA=data-set </ STORE=libref.template-store>;  \n\nThe TEMPLATE procedure enables you to customize the appearance of your SAS output."}},{"Name":"TCALIS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TCALIS <options> ; \n    BASEMODEL model number </ options> ; \n    BOUNDS boundary constraints ; \n    BY variables ; \n    COV covariance parameters ; \n    DETERM variables <label> ; \n    EFFPART effects ; \n    FACTOR <factor options> ; \n    FITINDEX <options> ; \n    FREQ variable ; \n    GROUP group number </ group options> ; \n    LINCON linear constraints ; \n    LINEQS model equations ; \n    LISMOD variable lists ; \n    LMTESTS <options> ; \n    MATRIX matrix-name parameters-in-matrix ; \n    MEAN mean parameters ; \n    MODEL model number </ model options> ; \n    MSTRUCT variable list ; \n    NLINCON nonlinear constraints ; \n    NLOPTIONS optimization options ; \n    OUTFILES output files organization ; \n    PARAMETERS parameters ; \n    PARTIAL variables ; \n    PATH path list ; \n    PCOV partial covariance parameters ; \n    PVAR partial variance parameters ; \n    RAM ram list ; \n    REFMODEL model number </ options> ; \n    RENAMEPARM parameter renaming ; \n    SIMTEST simultaneous tests definitions ; \n    STD variance parameters ; \n    STRUCTEQ set of variables <label> ; \n    TESTFUNC parametric functions ; \n    VAR variables ; \n    WEIGHT variable ; \n    SAS Programming statements ; \n\nThe TCALIS procedure deals with structural equation modeling, an important statistical tool in social\nand behavioral sciences. Structural equations express relationships among a system of variables that\ncan be either observed variables (manifest variables) or unobserved hypothetical variables\n(latent variables)."}},{"Name":"TIMEPLOT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TIMEPLOT <option(s)>; \n    \nThe TIMEPLOT procedure plots one or more variables over time intervals. A listing of \nvariable values accompanies the plot. Although the plot and the listing are similar \nto the ones produced by the PLOT and PRINT procedures, PROC TIMEPLOT output has these \ndistinctive features: \n\n  o The vertical axis always represents the sequence of observations in the data set; \n    thus, if the observations are in order of date or time, then the vertical axis \n    represents the passage of time.\n\n  o The horizontal axis represents the values of the variable that you are examining. \n    Like PROC PLOT, PROC TIMEPLOT can overlay multiple plots on one set of axes so that \n    each line of the plot can contain values for more than one variable.\n\n  o A plot produced by PROC TIMEPLOT can occupy more than one page.\n\n  o Each observation appears sequentially on a separate line of the plot; PROC TIMEPLOT \n    does not hide observations as PROC PLOT sometimes does.\n\n  O The listing of the plotted values can include variables that do not appear in the plot."}},{"Name":"TPSPLINE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TPSPLINE <option> ; \n    MODEL dependents = <variables> (variables) </options> ; \n    SCORE data=SAS-data-set out=SAS-data-set ; \n    OUTPUT <out=SAS-data-set> keyword ... keyword ; \n    BY variables ; \n    FREQ variable ; \n    ID variables ; \n\nThe TPSPLINE procedure uses the penalized least squares method to fit a nonparametric regression \nmodel. It computes thin-plate smoothing splines to approximate smooth multivariate functions observed \nwith noise. The TPSPLINE procedure allows great flexibility in the possible form of the regression \nsurface. In particular, PROC TPSPLINE makes no assumptions of a parametric form for the model. The \ngeneralized cross validation (GCV) function can be used to select the amount of smoothing. \n\nThe TPSPLINE procedure uses the penalized least squares method to fit the data with a flexible \nmodel in which the number of effective parameters can be as large as the number of unique design \npoints. Hence, as the sample size increases, the model space also increases, enabling the thin-plate \nsmoothing spline to fit more complicated situations."}},{"Name":"TRANSPOSE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TRANSPOSE <DATA=input-data-set> <DELIMITER=delimiter> <LABEL=label> <LET> \n      <NAME=name> <OUT=output-data-set> <PREFIX=prefix> <SUFFIX=suffix>;\n    BY <DESCENDING> variable-1 <...<DESCENDING> variable-n> <NOTSORTED>;  \n    COPY variable(s);  \n    ID variable;  \n    IDLABEL variable; \n      VAR variable(s); \n    \nThe TRANSPOSE procedure creates an output data set by restructuring the values in \na SAS data set, transposing selected variables into observations. The TRANSPOSE \nprocedure can often eliminate the need to write a lengthy DATA step to achieve the \nsame result. Further, the output data set can be used in subsequent DATA or PROC \nsteps for analysis, reporting, or further data manipulation.\n\nPROC TRANSPOSE does not produce printed output. To print the output data set from \nthe PROC TRANSPOSE step, use PROC PRINT, PROC REPORT, or another SAS reporting tool."}},{"Name":"TRANTAB","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TRANTAB TABLE=table-name <NLS>;  \n    CLEAR <ONE|TWO|BOTH>;  \n    INVERSE;  \n    LIST <ONE|TWO|BOTH>;  \n    LOAD TABLE=table-name <NLS>;  \n    REPLACE position value-1<...value-n>;  \n    SAVE <TABLE=table-name> <ONE|TWO|BOTH>;  \n    SWAP;\n  \nThe TRANTAB procedure creates, edits, and displays customized translation tables. \nIn addition, you can use PROC TRANTAB to view and modify translation tables that \nare supplied by SAS. These SAS supplied tables are stored in the SASHELP.HOST catalog. \nAny translation table that you create or customize is stored in your SASUSER.PROFILE \ncatalog. Translation tables have an entry type of TRANTAB.\n\nTranslation tables are operating environment-specific SAS catalog entries that are \nused to translate the values of one (coded) character set to another. A translation \ntable has two halves: table one provides a translation, such as ASCII to EBCDIC; table \ntwo provides the inverse (or reverse) translation, such as EBCDIC to ASCII. Each half \nof a translation table is an array of 256 two-digit positions, each of which contains \na one-byte unsigned number that corresponds to a coded character."}},{"Name":"TREE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TREE <options> ; \n    NAME variables ; \n    HEIGHT variable ; \n    PARENT variables ; \n    BY variables ; \n    COPY variables ; \n    FREQ variable ; \n    ID variable ; \n\nThe TREE procedure produces a tree diagram, also known as a dendrogram or phenogram, from a data \nset created by the CLUSTER or VARCLUS procedure that contains the results of hierarchical clustering \nas a tree structure."}},{"Name":"TSPL","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC TSPL | DS2 <table-server-connection-options> \n      <ANSIMODE> <AUTHDOMAIN=auth-domain> <CONN=\"connection-string\"|macrovar>  \n      <DSN=dsn-definition> <DSNPASSWORD=\"password\"> <DSNUSER=\"user-name\">  \n      <ERRORSTOP|NOERRORSTOP> <EXEC|NOEXEC> <IPTRACE> <LABEL|NOLABEL>  \n      <NOAUTOCOMMIT> <NOLIBNAMES> <NOPRINT> <NUMBER> <STIMER>  \n      <TRACEFILE=>LOG | \"filename\"  \n      <TRACEFLAGS=flag | (flag, flag ...)>  \n      <TSID=\"logical-name\"> ;  \n\n    <TSPL statements>\n    RUN | RUN CANCEL;\n    QUIT;\n    \nData Step 2 (DS2) is the new name for the Table Server Programming Language (TSPL). \"DS2\" and\n\"TSPL\" can be used interchangeably.\n\nDS2 is a new SAS proprietary programming language that is appropriate for advanced data manipulation \nand data modeling applications. The DS2 language combines traditional SAS DATA step processing \nwith the standard operations of SQL:1999 by integrating the two languages into one. DS2 supports \nthe ability to create, bulk load, and manipulate tables, create and execute stored routines."}},{"Name":"DS2","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC DS2 | TSPL <table-server-connection-options> \n      <ANSIMODE> <AUTHDOMAIN=auth-domain> <CONN=\"connection-string\"|macrovar>  \n      <DSN=dsn-definition> <DSNPASSWORD=\"password\"> <DSNUSER=\"user-name\">  \n      <ERRORSTOP|NOERRORSTOP> <EXEC|NOEXEC> <IPTRACE> <LABEL|NOLABEL>  \n      <NOAUTOCOMMIT> <NOLIBNAMES> <NOPRINT> <NUMBER> <STIMER>  \n      <TRACEFILE=>LOG | \"filename\"  \n      <TRACEFLAGS=flag | (flag, flag ...)>  \n      <TSID=\"logical-name\"> ;  \n\n    <DS2 statements>\n    RUN | RUN CANCEL;\n    QUIT;\n\nData Step 2 (DS2) is the new name for the Table Server Programming Language (TSPL). \"DS2\" and\n\"TSPL\" can be used interchangeably.\n\nDS2 is a new SAS proprietary programming language that is appropriate for advanced data manipulation \nand data modeling applications. The DS2 language combines traditional SAS DATA step processing \nwith the standard operations of SQL:1999 by integrating the two languages into one. DS2 supports \nthe ability to create, bulk load, and manipulate tables, create and execute stored routines."}},{"Name":"TTEST","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TTEST <options> ; \n    CLASS variable ; \n    PAIRED variables ; \n    BY variables ; \n    VAR variables </ options> ; \n    FREQ variable ; \n    WEIGHT variable ; \n\n\nThe TTEST procedure performs t tests and computes confidence limits for one sample, paired \nobservations, two independent samples, and the AB/BA crossover design."}},{"Name":"UNIVARIATE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC UNIVARIATE <options> ; \n    BY variables ; \n    CDFPLOT <variables> < / options> ; \n    CLASS variable-1 <(v-options)> <variable-2 <(v-options)>> </ KEYLEVEL= value1 | ( value1 value2 )> ; \n    FREQ variable ; \n    HISTOGRAM <variables> < / options> ; \n    ID variables ; \n    INSET keyword-list </ options> ; \n    OUTPUT <OUT=SAS-data-set> <keyword1=names ...keywordk=names> <percentile-options> ; \n    PPPLOT <variables> < / options> ; \n    PROBPLOT <variables> < / options> ; \n    QQPLOT <variables> < / options> ; \n    VAR variables ; \n    WEIGHT variable ; \n    \nThe UNIVARIATE procedure provides the following: \n  o descriptive statistics based on moments (including skewness and kurtosis), quantiles \n    or percentiles (such as the median), frequency tables, and extreme values \n  o histograms that optionally can be fitted with probability density curves for various \n    distributions and with kernel density estimates \n  o cumulative distribution function plots (cdf plots). Optionally, these can be superimposed \n    with probability distribution curves for various distributions. \n  o quantile-quantile plots (Q-Q plots), probability plots, and probability-probability plots \n    (P-P plots). These plots facilitate the comparison of a data distribution with various \n    theoretical distributions. \n  o goodness-of-fit tests for a variety of distributions including the normal \n  o the ability to inset summary statistics on plots \n  o the ability to analyze data sets with a frequency variable \n  o the ability to create output data sets containing summary statistics, histogram intervals, \n    and parameters of fitted curves"}},{"Name":"VARCLUS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC VARCLUS <options> ; \n    VAR variables ; \n    SEED variables ; \n    PARTIAL variables ; \n    WEIGHT variables ; \n    FREQ variables ; \n    BY variables ; \n\nThe VARCLUS procedure divides a set of numeric variables into disjoint or hierarchical clusters."}},{"Name":"VARCOMP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC VARCOMP <options> ; \n    CLASS variables ; \n    MODEL dependent = <effects> </ options> ; \n    BY variables ; \n\nThe VARCOMP procedure handles general linear models that have random effects. Random \neffects are classification effects with levels that are assumed to be randomly selected \nfrom an infinite population of possible levels. PROC VARCOMP estimates the contribution \nof each of the random effects to the variance of the dependent variable."}},{"Name":"VARIOGRAM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC VARIOGRAM options ; \n    BY variables ; \n    COMPUTE computation-options ; \n    COORDINATES coordinate-variables ; \n    DIRECTIONS directions-list ; \n    ID variable ; \n    MODEL model-options ; \n    PARMS parameters-list < / parameters-options> ; \n    NLOPTIONS <options> ; \n    STORE store-options ; \n    VAR analysis-variables-list ; \n\nThe VARIOGRAM procedure computes empirical measures of spatial continuity for two-dimensional \nspatial data. These measures are a function of the distances between the sample data pairs. \nWhen the data are free of nonrandom (or systematic) surface trends, the estimated continuity \nmeasures are the empirical semivariance and covariance. The procedure also fits permissible \ntheoretical models to the empirical semivariograms, so that you can use them in subsequent \nanalysis to perform spatial prediction. You can produce plots of the empirical semivariograms \nin addition to plots of the fitted models. Both isotropic and anisotropic continuity measures \nare available."}},{"Name":"DQMATCH","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DQMATCH\n    <DATA=input-data-set>\n    <DELIMITER | NODELIMITER>\n    <CLUSTER=output-variable-name>\n    <CLUSTER_BLANKS | NO_CLUSTER_BLANKS>\n    <CLUSTERS_ONLY>\n    <LOCALE=locale-name>\n    <MATCHCODE=output-variable-name>\n    <OUT=data-set-name> ;\n    <CRITERIA1 options\n    ...\n    CRITERIAn options\n    >; \n\nThe DQMATCH procedure creates match codes in an output data set for specified input \ncharacter variables. The procedure can also generate cluster numbers for input values \nthat generate identical match codes. Cluster numbers are not assigned to input values \nthat generate unique match codes. Input values that generate a unique match code (no \ncluster number) can be excluded from the output data set. Blank values can be retained \nin the output data set. Blank values can receive a cluster number."}},{"Name":"DQSCHEME","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DQSCHEME\n    <DATA=input-data-set>\n    <BFD | NOBFD>\n    <OUT=output-data-set>;\n\n    <CREATE options;>\n    <APPLY options;>\n    <CONVERT options;>\n\nThe DQSCHEME procedure creates scheme data sets and analysis data sets and applies schemes to input data sets. \nYou can also apply schemes with the DQSCHEMEAPPLY function or CALL routine."}},{"Name":"DQSRVADM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DQSRVADM\n    <HOST=host-name>\n    <PORT=job-port-number>\n    <OUT=output-data-set>; \n\nThe DQSRVADM procedure creates a data set that provides the name, type, and description of all \ndfPower Architect and dfPower Profile jobs that ran or that are running on a specified port on \na DataFlux Integration Server. Status information is provided for all jobs that have a log file \non the server."}},{"Name":"DQSRVSVC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DQSRVSVC\n    SERVICE=service-name\n    <HOST=host-name>\n    <PORT=port-number>\n    <TIMEOUT=message-processing-limit>\n    <DATA=input-data-set>\n    <OUT=output-data-set>\n    <BLOCKSIZE=rows-per-message>\n    <USERID=user-name-on-server>\n    <PASSWORD=password-on-server>\n    <TRIM>\n    <MISSINGVARSOK>;\n\nThe DQSRVSVC procedure runs a dfPower Architect real-time service on a DataFlux \nIntegration Server. dfPower Architect real-time services are batch processes that \nare intended to cleanse smaller amounts of data at the point of data entry. Data \nprocessing is intended to be synchronous, when a client application requests the \nservice and awaits a response. DQSRVSVC procedure authenticates the user on the \nserver, requests a service, delivers input data to the server, and delivers output \ndata to a SAS data set."}},{"Name":"ANOM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ANOM < options > ; \n    < BY variables; >\n    < ID variables; >\n    XCHART (responses)/*group-variable < (block-variables) > < =symbol-variable > < / options >; \n    PCHART (responses)/*group-variable < (block-variables) > < =symbol-variable > < / options >; \n    UCHART (responses)/*group-variable < (block-variables) > < =symbol-variable > < / options >; \n    BOXCHART (responses)/*group-variable < (block-variables) > < =symbol-variable > < / options >; \n    INSET keyword-list < / options >; \n  \nAnalysis of means (ANOM) is a graphical and statistical method for simultaneously \ncomparing k treatment means with their overall mean at a specified significance \nlevel \u03b1. You can use the ANOM procedure to create ANOM charts for various types \nof response data, including continuous measurements, proportions, and rates."}},{"Name":"CAPABILITY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CAPABILITY < options >; \n    < BY variables;  FREQ variable; WEIGHT variable; ID variable; >\n    VAR variables; \n    CLASS variable-1 <variable-2> </ options> ; \n    SPEC <options >; \n    CDFPLOT <variables > < / options >; \n    COMPHISTOGRAM <variables > / CLASS=(class-variables) <options >; \n    HISTOGRAM <variables > < / options >; \n    PPPLOT <variables > < / options >; \n    PROBPLOT <variables > < / options >; \n    QQPLOT <variables > < / options >; \n    INSET keyword-list < / options >; \n    INTERVALS <variables > < / options >; \n    OUTPUT <OUT=SAS-data-set> keyword=names<...keyword=names >;\n    \nA process capability analysis compares the distribution of output from an in-control process \nto its specification limits to determine the consistency with which the specifications can be \nmet."}},{"Name":"CUSUM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CUSUM < options >;\n    XCHART statement...\n    INSET statement...\n  \nThe CUSUM procedure creates cumulative sum control charts, also known as cusum charts, \nwhich display cumulative sums of the deviations of measurements or subgroup means from \na target value."}},{"Name":"FACTEX","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC FACTEX <options> ; \n    FACTORS factor-names < / option> ; \n    SIZE size-specification ; \n    MODEL model-specification <MINABS<(d)>; \n    BLOCKS block-specification ; \n    UNITEFFECTS uniteffect / < WHOLE=() > < SUB=() > ; \n    EXAMINE <options> ; \n    OUTPUT OUT=SAS-data-set <options> ; \n\nThe FACTEX procedure constructs orthogonal factorial experimental designs. These designs \ncan be either full or fractional factorial designs, and they can be with or without blocks."}},{"Name":"MACONTROL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MACONTROL < options >; \n    EWMACHART (processes)*subgroup-variable <( block-variables ) > \n    < =symbol-variable  'character' > / WEIGHT=value < options >; \n    MACHART (processes)*subgroup-variable <( block-variables ) > \n    < =symbol-variable  'character' > / SPAN=value < options > ; \n    INSET keyword-list < / options >; \n\nThe MACONTROL procedure creates moving average control charts, which are tools for deciding whether\na process is in a state of statistical control and for detecting shifts in a process average."}},{"Name":"OPTEX","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTEX < options > ;\n    CLASS class-variables ;\n    MODEL effects < / options> ;\n    BLOCKS block-specification <options> ;\n    EXAMINE <options> ;\n    GENERATE <options> ;\n    ID variables ;\n    OUTPUT OUT= SAS-data-set <options> ;\n\nThe OPTEX procedure searches for optimal experimental designs. You specify a set of candidate design\npoints and a linear model, and the procedure chooses points so that the terms in the model can be\nestimated as efficiently as possible."}},{"Name":"PARETO","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PARETO < options >; \n    VBAR (variable-list) < / options > ; \n    HBAR (variable-list) < / options > ;\n    INSET (keyword-list) < / options > ;\n    < BY variables ; >\n  \nThe PARETO procedure creates Pareto charts, which display the relative frequency of quality-related \nproblems in a process or operation. The frequencies are represented by bars that are ordered in decreasing \nmagnitude. Thus, a Pareto chart can be used to decide which subset of problems should be solved first or \nwhich problem areas deserve the most attention. Pareto charts provide a tool for visualizing the Pareto \nprinciple, which states that a small subset of problems tend to occur much more frequently than the remaining \nproblems. In Japanese industry, the Pareto chart is one of the \"seven basic QC tools\" heavily used by workers \nand engineers."}},{"Name":"RELIABILITY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC RELIABILITY <options>; \n    <label:>ANALYZE variable<censor-variable(values)> <=(group-variables)> </ options>; \n    <label:>MCFPLOT variable<cost/censor-variable(values)> <=(group-variables)> </ options>; \n    MODEL variable<censor-variable(values)> =<independent-variables> </ options>; \n    <label:>PROBPLOT variable<censor-variable(values)> <=(group-variables)> </ options>; \n    <label:>RELATIONPLOT variable<censor-variable(values)> <=(group-variables)> </ options>; \n    \n    BY variables; CLASS variables; DISTRIBUTION distribution-name; \n    FMODE keyword = variable('value1' ... 'valuen');\n    FREQ variable; INSET keyword-list< options>; \n    MAKE 'table' OUT=SAS-data-set < / options>;\n    NENTER variable; \n    UNITID variable; \n\n The RELIABILITY procedure provides tools for reliability and survival data analysis \nand for recurrence data analysis. You can use this procedure to:\n\no construct probability plots and fitted life distributions with left-censored, right-censored, \n  and interval-censored lifetime data \no fit regression models, including accelerated life test models, to combinations of left-censored, \n  right-censored, and interval-censored data \no analyze recurrence data from repairable systems"}},{"Name":"SHEWHART","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SHEWHART < options >; \n    < BY variables; >\n    < ID variables; >\n    BOXCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    CCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    IRCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    MCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    MRCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    NPCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    PCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    RCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    SCHART (processes)*subgroup-variable <(block-variables ) > \n    < =symbol-variable  'character' > < / options >; \n    UCHART (processes)*subgroup-variable <(block-variables ) > \n    < =symbol-variable  'character' > < / options >; \n    XCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    XRCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    XSCHART (processes)*subgroup-variable <(block-variables ) > \n      < =symbol-variable  'character' > < / options >; \n    INSET keyword-list < / options >; \n    INSET2 keyword-list < / options >; \n  \nThe Shewhart control chart is a graphical and analytical tool for deciding whether \na process is in a state of statistical control. You can use the SHEWHART procedure \nto display many different types of control charts, including all commonly used charts \nfor variables and attributes."}},{"Name":"BOM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC BOM options ; \n    STRUCTURE / options ;\n\nThe BOM procedure performs bill-of-material processing."}},{"Name":"CLP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CLP options ; \n    ACTIVITY activity specifications ; \n    ALLDIFF alldiff constraints ; \n    ARRAY array specifications ; \n    ELEMENT element constraints ; \n    FOREACH foreach constraints ; \n    GCC global cardinality constraints ; \n    LINCON linear constraints ; \n    REIFY reify constraints ; \n    REQUIRES resource requirement constraints ; \n    RESOURCE resource specifications ; \n    SCHEDULE schedule options ; \n    VARIABLE variable specifications ; \n\nThe CLP procedure is a finite-domain constraint programming solver for constraint \nsatisfaction problems (CSPs) with linear, logical, global, and scheduling constraints. \nIn addition to having an expressive syntax for representing CSPs, the solver features \npowerful built-in consistency routines and constraint propagation algorithms, a choice \nof nondeterministic search strategies, and controls for guiding the search mechanism \nthat enable you to solve a diverse array of combinatorial problems."}},{"Name":"GA","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GA options ; \n    ContinueFor Call; \n    Cross Call; \n    Dynamic_array Call; \n    EvaluateLC Call; \n    GetDimensions Call; \n    GetObjValues Call; \n    GetSolutions Call; \n    Initialize Call; \n    MarkPareto Call; \n    Mutate Call; \n    Objective Call; \n    PackBits Call; \n    Program Statements; \n    ReadChild Call; \n    ReadCompare Call; \n    ReadMember Call; \n    ReadParent Call; \n    ReEvaluate Call; \n    SetBounds Call; \n    SetCross Call; \n    SetCrossProb Call; \n    SetCrossRoutine Call; \n    SetElite Call; \n    SetEncoding Call; \n    SetFinalize Call; \n    SetMut Call; \n    SetMutProb Call; \n    SetMutRoutine Call; \n    SetObj Call; \n    SetObjFunc Call; \n    SetProperty Call; \n    SetSel Call; \n    SetUpdateRoutine Call;\n    \nGenetic algorithms are a family of local search algorithms that seek optimal solutions \nto problems by applying the principles of natural selection and evolution."}},{"Name":"INTPOINT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC INTPOINT options ; \n    CAPACITY variable ; \n    COEF variables ; \n    COLUMN variable ; \n    COST variable ; \n    DEMAND variable ; \n    HEADNODE variable ; \n    ID variables ; \n    LO variable ; \n    NAME variable ; \n    NODE variable ; \n    QUIT; \n    RHS variable ; \n    ROW variables ; \n    RUN; \n    SUPDEM variable ; \n    SUPPLY variable ; \n    TAILNODE variable ; \n    TYPE variable ; \n    VAR variables ;\n\nThe INTPOINT procedure solves the Network Program with Side Constraints (NPSC) problem and the \nmore general Linear Programming (LP) problem. NPSC and LP models can be used to describe a wide \nvariety of real-world applications ranging from production, inventory, and distribution problems \nto financial applications."}},{"Name":"LP","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC LP options ; \n    COEF variables ; \n    COL variable ; \n    ID variable(s) ; \n    IPIVOT; \n    PIVOT; \n    PRINT options ; \n    QUIT options ; \n    RANGE variable ; \n    RESET options ; \n    RHS variables ; \n    RHSSEN variables ; \n    ROW variable(s) ; \n    RUN; \n    SHOW options ; \n    TYPE variable ; \n    VAR variables ; \n\nThe LP procedure solves linear programs, integer programs, and mixed-integer programs. It also\nperforms parametric programming, range analysis, and reports on solution sensitivity to changes\nin the right-hand-side constants and price coefficients."}},{"Name":"NLP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NLP options ; \n    ARRAY function names ; \n    BOUNDS boundary constraints ; \n    BY variables ; \n    CRPJAC variables ; \n    DECVAR function names ; \n    GRADIENT variables ; \n    HESSIAN variables ; \n    INCLUDE model files ; \n    JACNLC variables ; \n    JACOBIAN function names ; \n    LABEL decision variable labels ; \n    LINCON linear constraints ; \n    MATRIX matrix specification ; \n    MIN, MAX, or LSQ function names ; \n    MINQUAD or MAXQUAD matrix, vector, or number ; \n    NLINCON nonlinear constraints ; \n    PROFILE profile specification ; \n    Program Statements ; \n\nThe NLP procedure (NonLinear Programming) offers a set of optimization techniques for minimizing \nor maximizing a continuous nonlinear function f(x) of n decision variables, with lower and upper \nbound, linear and nonlinear, equality and inequality constraints."}},{"Name":"OPTQP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTQP < options > ;\n    PERFORMANCE < performance-options > ;\n\nThe OPTQP procedure solves quadratic programs - problems with quadratic objective function and a\ncollection of linear constraints, including lower and/or upper bounds on the decision variables."}},{"Name":"OPTLP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTLP < options > ;\n  DECOMP < options > ;\n  DECOMPMASTER < options > ;\n  DECOMPSUBPROB < options > ;\n  PERFORMANCE < performance-options > ; \n\nThe OPTLP procedure provides three methods for solving linear programs (LPs). \n\nThe following LP solvers are available in the OPTLP procedure: \n\n  o primal simplex solver \n  o dual simplex solver \n  o interior point solver (experimental) \n\nThe simplex solvers implement the two-phase simplex method. In phase I, the solver tries to \nfind a feasible solution. If no feasible solution is found, the LP is infeasible; otherwise, \nthe solver enters phase II to solve the original LP. The interior point solver implements a \nprimal-dual predictor-corrector interior point algorithm."}},{"Name":"GTESTIT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GTESTIT <PICTURE=1 | 2 | 3>\n  <GOUT=<libref.>output-catalog>; \n  \nThe GTESTIT procedure is a diagnostic tool for testing the installation of SAS/GRAPH \nsoftware and the configuration of your device. Use the GTESTIT procedure when you want to:\n\n  o test a new device\n  o test the settings of a device driver that you are developing\n  o identify the colors and some of the SAS/GRAPH lines and fills for your device\n  o review some of your current settings of device parameters and graphics options\n  o test changes in settings of device parameters and graphics options. \n  \nThe GTESTIT procedure produces three pictures that help you determine the \nconfiguration of your graphics device and graphics options and parameters."}},{"Name":"OPTMODEL","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC PROC OPTMODEL options ; \n\n    Declaration Statements...\n    Programming Statements...\n    parameter = expression ; (Assignment) \n    ...\n\nThe OPTMODEL procedure comprises the powerful OPTMODEL modeling language and state-of-the-art \nsolvers for several classes of mathematical programming problems:\n\n    Linear Programming (LP)\n    Mixed Integer Linear Programming (MILP)\n    Quadratic Programming (QP) (experimental) \n    Nonlinear Programming, Unconstrained (NLPU)\n    General Nonlinear Programming (NLPC) \n    General Nonlinear Programming (SQP) \n    General Nonlinear Programming (IPNLP)"}},{"Name":"CPM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CPM options ; \n    ACTIVITY variable ; \n    ACTUAL / actual options ; \n    ALIGNDATE variable ; \n    ALIGNTYPE variable ; \n    BASELINE / baseline options ; \n    CALID variable ; \n    DURATION / duration options ; \n    HEADNODE variable ; \n    HOLIDAY variable / holiday options ; \n    ID variables ; \n    PROJECT variable / project options ; \n    RESOURCE variables / resource options ; \n    SUCCESSOR variables / lag options ; \n    TAILNODE variable ; \n\nThe CPM procedure can be used for planning, controlling, and monitoring a project. A typical \nproject consists of several activities that may have precedence and time constraints. Some of \nthese activities may already be in progress; some of them may follow different work schedules. \nAll of the activities may compete for scarce resources. PROC CPM enables you to schedule activities \nsubject to all of these constraints."}},{"Name":"PM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PM options ;  \n    ACTIVITY variable ; \n    ACTUAL / actual options ; \n    ALIGNDATE variable ; \n    ALIGNTYPE variable ; \n    BASELINE / baseline options ; \n    CALID variable ; \n    DURATION / duration options ; \n    HOLIDAY variable / holiday options ; \n    ID variables ; \n    PROJECT variable / project options ; \n    RESOURCE variables / resource options ; \n    SUCCESSOR variables / lag options ; \n\nThe PM procedure is an interactive procedure that can be used for planning, controlling, \nand monitoring a project. The syntax and the scheduling features of PROC PM are virtually \nthe same as those of the CPM procedure. However, because the PM procedure is interactive, \nthere are a few extra options that are available and a few other options that have a default \nbehavior that is different from the CPM procedure."}},{"Name":"DTREE","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC DTREE options ; \n    EVALUATE / options ; \n    MODIFY specifications ; \n    MOVE specifications ; \n    QUIT ; \n    RECALL ; \n    RESET options ; \n    SAVE ; \n    SUMMARY / options ; \n    TREEPLOT / options ; \n    VARIABLES / options ; \n    VPC specifications ; \n    VPI specifications ; \n\nThe DTREE procedure in SAS/OR software is an interactive procedure for decision analysis. \nThe procedure interprets a decision problem represented in SAS data sets, finds the optimal \ndecisions, and plots on a line printer or a graphics device the decision tree showing the \noptimal decisions."}},{"Name":"GANTT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GANTT options ; \n    BY variables ; \n    CHART specifications / options ; \n    ID variables ; \n\nThe GANTT procedure produces a Gantt chart that is a graphical scheduling tool for the \nplanning and control of a project. In its most basic form, a Gantt chart is a bar chart \nthat plots the tasks of a project versus time. PROC GANTT displays a Gantt chart corresponding \nto a project schedule such as that produced by the CPM procedure or one that is input directly \nto the procedure, and it offers several options and statements for tailoring the chart to your \nneeds. \n\nUsing PROC GANTT, you can plot the predicted early and late schedules and identify critical, \nsupercritical, and slack activities. In addition, you can visually monitor a project in progress \nwith the actual schedule and compare the actual schedule against a target baseline schedule. You \ncan also graphically view the effects of scheduling a project subject to resource limitations. \nAny combination of these schedules can be viewed simultaneously (provided the relevant data exist) \ntogether with any user-specified variables of interest, such as project deadlines and other important \ndates. PROC GANTT enables you to display the early, late, and actual schedules in a single bar to \nproduce a more meaningful schedule for tracking an activity in progress."}},{"Name":"OPTMILP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTMILP < options > ;\n    DECOMP < options > ;\n    DECOMPMASTER < options > ;\n    DECOMPMASTERIP < options > ;\n    DECOMPSUBPROB < options > ;\n    PERFORMANCE < performance-options > ;\n    TUNER < tuner-options > ; \n\nThe OPTMILP procedure is a solver for general mixed integer linear programs (MILPs). \n\nThe OPTMILP procedure implements an LP-based branch-and-bound algorithm. This divide-and-conquer \napproach attempts to solve the original problem by solving linear programming relaxations of a \nsequence of smaller subproblems. The OPTMILP procedure also implements advanced techniques such \nas presolving, generating cutting planes, and applying primal heuristics to improve the efficiency \nof the overall algorithm."}},{"Name":"NETDRAW","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NETDRAW options ; \n    ACTNET / options ;\n\nThe NETDRAW procedure draws a network diagram of the activities in a project. Boxes (or nodes) are \nused to represent the activities, and lines (or arcs) are used to show the precedence relationships \namong the activities."}},{"Name":"NETFLOW","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NETFLOW options ; \n    CAPACITY variable ; \n    COEF variables ; \n    COLUMN variable ; \n    CONOPT; \n    COST variable ; \n    DEMAND variable ; \n    HEADNODE variable ; \n    ID variables ; \n    LO variable ; \n    NAME variable ; \n    NODE variable ; \n    PIVOT; \n    PRINT options ; \n    QUIT; \n    RESET options ; \n    RHS variables ; \n    ROW variables ; \n    RUN; \n    SAVE options ; \n    SHOW options ; \n    SUPDEM variable ; \n    SUPPLY variable ; \n    TAILNODE variable ; \n    TYPE variable ; \n    VAR variables ; \n\nConstrained network models can be used to describe a wide variety of real-world applications ranging\nfrom production, inventory, and distribution problems to financial applications. These problems can\nbe solved with the NETFLOW procedure."}},{"Name":"ARIMA","Type":"SAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC ARIMA options ; \n    BY variables ; \n    IDENTIFY VAR=variable options ; \n    ESTIMATE options ; \n    OUTLIER options ; \n    FORECAST options ; \n\nThe ARIMA procedure analyzes and forecasts equally spaced univariate time series data, transfer \nfunction data, and intervention data by using the autoregressive integrated moving-average (ARIMA) \nor autoregressive moving-average (ARMA) model. An ARIMA model predicts a value in a response time \nseries as a linear combination of its own past values, past errors (also called shocks or innovations), \nand current and past values of other time series."}},{"Name":"AUTOREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC AUTOREG options ; \n    BY variables ; \n    CLASS variables ; \n    MODEL dependent = regressors / options ; \n    HETERO variables / options ; \n    NLOPTIONS options ; \n    RESTRICT equation , ..., equation ; \n    TEST equation , ..., equation / option ; \n    OUTPUT OUT = SAS data set options ; \n\nThe AUTOREG procedure estimates and forecasts linear regression models for time series \ndata when the errors are autocorrelated or heteroscedastic. The autoregressive error model \nis used to correct for autocorrelation, and the generalized autoregressive conditional \nheteroscedasticity (GARCH) model and its variants are used to model and correct for \nheteroscedasticity."}},{"Name":"COMPUTAB","Type":"SAS_PROCEDURE","#text":"z\n    ","Help":{"#cdata":"Syntax: PROC COMPUTAB options ; \n    BY variables ; \n    COLUMNS names / options ; \n    ROWS names / options ; \n    CELL names / FORMAT= format ; \n    INIT anchor-name locator-name values locator-name values ; \n    programming statements ; \n    SUMBY variables ; \n\nThe COMPUTAB (computing and tabular reporting) procedure produces tabular reports generated \nusing a programmable data table. \n\nThe COMPUTAB procedure is especially useful when you need both the power of a programmable \nspreadsheet and a report generation system, but you want to set up a program to run in a batch \nmode and generate routine reports."}},{"Name":"COUNTREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC COUNTREG <options>; \n    BAYES <options>; \n    BOUNDS bound1 < , bound2 \u2026>; \n    BY variables; \n    CLASS variable <options> \u2026<variable <options>> </global-options>; \n    DISPMODEL dependent-variable <dispersion-related-regressors></option>; \n    FREQ variable; \n    INIT initvalue1 <, initvalue2 \u2026>; \n    MODEL dependent-variable <dispersion-related-regressors></ option>; \n    NLOPTIONS <options>; \n    OUTPUT <OUT=SAS-data-set><output-options>; \n    PERFORMANCE <performance-options>; \n    PRIOR _REGRESSORS |parameter-list ~ distribution ; \n    RESTRICT restriction1 <, restriction2 \u2026>; \n    TEST equation1 <, equation2\u2026> / test-options; \n    SCORE <OUT=SAS-data-set> <output-options>; \n    SHOW options; \n    STORE <OUT=>item-store-name; \n    WEIGHT variable </options>; \n    ZEROMODEL dependent-variable <zero-inflated-regressors> </options>; \n    SPATIALEFFECTS <model-spatial-effect-regressors> </options>; \n    SPATIALDISPEFFECTS <dispersion-spatial-effect-regressors> </options>; \n    SPATIALZEROEFFECTS <zero-inflation-spatial-effect-regressors> </option>; \nSPATIALID variable;  \n\nThe COUNTREG (count regression) procedure analyzes regression models in which the dependent \nvariable takes nonnegative integer or count values. The dependent variable is usually an event \ncount, which refers to the number of times an event occurs."}},{"Name":"DATASOURCE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DATASOURCE options ; \n    KEEP variable-list ; \n    DROP variable-list ; \n    KEEPEVENT event-list ; \n    DROPEVENT event-list ; \n    WHERE where-expression ; \n    RANGE FROM from TO to ; \n    ATTRIBUTE variable-list attribute-list ... ; \n    FORMAT variable-list format ... ; \n    LABEL variable=\"label\" ... ; \n    LENGTH variable-list length ... ; \n    RENAME old-name=new-name ... ; \n\nThe DATASOURCE procedure extracts time series and event data from many different kinds of data files\ndistributed by various data vendors and stores them in a SAS data set. Once stored in a SAS data set,\nthe time series and event variables can be processed by other SAS procedures. \n\nThe DATASOURCE procedure has statements and options to extract only a subset of time series data from \nan input data file. It gives you control over the frequency of data to be extracted, time series variables \nto be selected, cross sections to be included, and time range of data to be output."}},{"Name":"ENTROPY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ENTROPY options ; \n    BOUNDS bound1 < , bound2, ...> ; \n    BY variable < variable ...> ; \n    ID variable < variable ...> ; \n    MODEL variable = variable <variable> ...< / options > ; \n    PRIORS variable < support points > variable < value > ... ; \n    RESTRICT restriction1 < , restriction2 ...> ; \n    TEST < \"name\" > test1 < , test2 ...> </ options > ; \n    WEIGHT variable ; \n\nThe ENTROPY procedure implements a parametric method of linear estimation based \non generalized maximum entropy. The ENTROPY procedure is suitable when there are \noutliers in the data and robustness is required, when the model is ill-posed or \nunder-determined for the observed data, or for regressions that involve small data \nsets."}},{"Name":"ESM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ESM options ; \n    BY variables ; \n    ID variable INTERVAL= interval options ; \n    FORECAST variable-list / options ; \n\nThe ESM procedure generates forecasts by using exponential smoothing models with \noptimized smoothing weights for many time series or transactional data. \n\nFor typical time series, you can use the following smoothing models: \n  o simple \n  o double \n  o linear \n  o damped trend \n  o seasonal \n  o Winters method (additive and multiplicative)"}},{"Name":"EXPAND","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC EXPAND options ; \n    BY variables ; \n    CONVERT variables / options ; \n    ID variable ; \n\nThe EXPAND procedure converts time series from one sampling interval or frequency to another \nand interpolates missing values in time series. A wide array of data transformations is also \nsupported. Using PROC EXPAND, you can collapse time series data from higher frequency intervals \nto lower frequency intervals, or expand data from lower frequency intervals to higher frequency \nintervals. For example, quarterly values can be aggregated to produce an annual series, or \nquarterly estimates can be interpolated from an annual series."}},{"Name":"FORECAST","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FORECAST options ; \n    BY variables ; \n    ID variables ; \n    VAR variables ; \n\nThe FORECAST procedure provides a quick and automatic way to generate forecasts for many \ntime series in one step. The procedure can forecast hundreds of series at a time, with the \nseries organized into separate variables or across BY groups. PROC FORECAST uses extrapolative \nforecasting methods where the forecasts for a series are functions only of time and past values \nof the series, not of other variables."}},{"Name":"LOAN","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LOAN options ; \n    FIXED options ; \n    BALLOON options ; \n    ARM options ; \n    BUYDOWN options ; \n    COMPARE options ; \n\nThe LOAN procedure analyzes and compares fixed rate, adjustable rate, buydown, and balloon\npayment loans. The LOAN procedure computes the loan parameters and outputs the loan summary\ninformation for each loan. \n\nMultiple loan specifications can be processed and compared in terms of economic criteria such \nas after-tax or before-tax present worth of cost and true interest rate, breakeven of periodic \npayment and of interest paid, and outstanding balance at different periods in time. PROC LOAN \nselects the best alternative in terms of the specified economic criterion for each loan \ncomparison period."}},{"Name":"MDC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MDC options ; \n    MDCDATA options ; \n    BOUNDS bound1 < , bound2 ...> ; \n    BY variables ; \n    CLASS options ;\n    ID variable ; \n    MODEL dependent variables = regressors / options ; \n    NEST LEVEL(value) = ((values)@(value),..., (values)@(value)) ; \n    NLOPTIONS options ; \n    OUTPUT options ; \n    RESTRICT restriction1 < , restriction2 ...> ; \n    TEST options ; \n    UTILITY U() = variables, ..., U() = variables ; \n\nThe MDC (multinomial discrete choice) procedure analyzes models in which the choice set consists \nof multiple alternatives. This procedure supports conditional logit, mixed logit, heteroscedastic \nextreme value, nested logit, and multinomial probit models. The MDC procedure uses the maximum \nlikelihood (ML) or simulated maximum likelihood method for model estimation.  The term multinomial \nlogit is often used in the econometrics literature to refer to the conditional logit model of \nMcFadden (1974). Here, the term conditional logit refers to McFadden's conditional logit model, \nand the term multinomial logit refers to a model that differs slightly."}},{"Name":"OLAP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OLAP <option(s)>;  \n    METASVR OLAP_SCHEMA='schema-name' <option(s)>;  \n    DIMENSION dim-name HIERARCHIES=(hier-nam ... hier-nameN) <option(s)>;  \n    LEVEL level-name <option(s)>;  \n    PROPERTY prop-name LEVEL=level-name <option(s)>;  \n    HIERARCHY hier-name LEVELS=(level-name1 <level-name2 ...level-nameN>) <option(s)>;  \n    MEASURE measure-name STAT=statname <option(s)>;  \n    AGGREGATION level-name <level-name2 level-name3 ...level-nameN> / <option(s)>;  \n    DROP_AGGREGATION level-name1 < level-name2 ...level-nameN> / NAME=aggregation-name ;  \n    DEFINE MEMBER | SET'member-or-set-name' AS 'mdx-expression' ;  \n    UNDEFINE MEMBER | SET 'member-or-set-name' ;  \n    USER_DEFINED_TRANSLATIONS locale <locale2 ...localeN> ;  \n    REORGANIZE_LEVEL | REORG_LEVEL ; \n\nThe OLAP procedure is one of the SAS tools that you can use to create, update,\nand delete cubes. This includes adding and deleting cube aggregations."}},{"Name":"PANEL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PANEL options ; \n    BY variables ; \n    CLASS options ; \n    FLATDATA options ; \n    ID cross-section-id time-series-id ; \n    INSTRUMENTS options ; \n    LAG options ; \n    MODEL dependent = regressors < / options > ; \n    RESTRICT equation1 <,equation2...> ; \n    TEST equation1 <,equation2...> ; \n\nThe PANEL procedure analyzes a class of linear econometric models that commonly arise when \ntime series and cross-sectional data are combined. This type of pooled data on time series \ncross-sectional bases is often referred to as panel data. Typical examples of panel data \ninclude observations in time on households, countries, firms, trade, and so on. For example, \nin the case of survey data on household income, the panel is created by repeatedly surveying \nthe same households in different time periods (years)."}},{"Name":"PDLREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PDLREG option ; \n    BY variables ; \n    MODEL dependents = effects / options ; \n    OUTPUT OUT= SAS-data-set keyword = variables ; \n    RESTRICT restrictions ; \n\nThe PDLREG procedure estimates regression models for time series data in which the effects \nof some of the regressor variables are distributed across time. The distributed lag model \nassumes that the effect of an input variable X on an output Y is distributed over time. If \nyou change the value of X at time t, Y will experience some immediate effect at time t, and \nit will also experience a delayed effect at times t+1, t+2, and so on up to time t+p for some \nlimit p."}},{"Name":"QLIM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC QLIM options ; \n    BOUNDS bound1 < , bound2 ...> ; \n    BY variables ; \n    CLASS variables ; \n    ENDOGENOUS variables ~ options ; \n    HETERO dependent variables ~ exogenous variables / options ; \n    INIT initvalue1 < , initvalue2 ...> ; \n    MODEL dependent variables = regressors / options ; \n    NLOPTIONS options ; \n    OUTPUT options ; \n    RESTRICT restriction1 < , restriction2 ...> ; \n    TEST options ; \n    WEIGHT variable ; \n\nThe QLIM (qualitative and limited dependent variable model) procedure analyzes univariate \nand multivariate limited dependent variable models where dependent variables take discrete \nvalues or dependent variables are observed only in a limited range of values. This procedure \nincludes logit, probit, tobit, selection, and multivariate models. The multivariate model can \ncontain discrete choice and limited endogenous variables as well as continuous endogenous \nvariables."}},{"Name":"SIMILARITY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SIMILARITY options ; \n    BY variables ; \n    ID variable INTERVAL= interval options ; \n    FCMPOPT options ; \n    INPUT variable-list / options ; \n    TARGET variable-list / options ; \n    \nThe SIMILARITY procedure computes similarity measures associated with time-stamped data, time series, \nand/or other sequentially ordered numeric data. The procedure computes similarity measures for time-\nstamped transactional data (transactions) with respect to time by accumulating the data into a time\nseries format (time series). The procedure computes similarity measures for sequentially ordered numeric\ndata (sequences) by respecting the ordering of the data. \n\nGiven two ordered numeric sequences (input and target), a similarity measure is a metric that measures \nthe distance between the input and target sequences while taking into account the ordering of the data. \nThe SIMILARITY procedure computes similarity measures between an input sequence and a target sequence, \nas well as similarity measures that \"slide\" the target sequence with respect to the input sequence. The \n\"slides\" can be by observation index (sliding-sequence similarity measures) or by seasonal index (seasonal-\nsliding-sequence similarity measures)."}},{"Name":"SIMLIN","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SIMLIN options ; \n    BY variables ; \n    ENDOGENOUS variables ; \n    EXOGENOUS variables ; \n    ID variables ; \n    LAGGED lag-var endogenous-var number ellipsis ; \n    OUTPUT OUT=SAS-data-set options ;\n\nThe SIMLIN procedure reads the coefficients for a set of linear structural equations, which \nare usually produced by the SYSLIN procedure. PROC SIMLIN then computes the reduced form and, \nif input data are given, uses the reduced form equations to generate predicted values. PROC \nSIMLIN is especially useful when dealing with sets of structural difference equations. The \nSIMLIN procedure can perform simulation or forecasting of the endogenous variables."}},{"Name":"SPECTRA","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SPECTRA options ; \n    BY variables ; \n    VAR variables ; \n    WEIGHTS <weights> <kernel> ; \n    \nThe SPECTRA procedure performs spectral and cross-spectral analysis of time series. You can \nuse spectral analysis techniques to look for periodicities or cyclical patterns in data. \n\nThe SPECTRA procedure produces estimates of the spectral and cross-spectral densities of \na multivariate time series. Estimates of the spectral and cross-spectral densities of a \nmultivariate time series are produced using a finite Fourier transform to obtain periodograms \nand cross-periodograms. The periodogram ordinates are smoothed by a moving average to produce \nestimated spectral and cross-spectral densities. PROC SPECTRA can also test whether or not the \ndata are white noise."}},{"Name":"STATESPACE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC STATESPACE options ; \n    BY variable ... ; \n    FORM variable value ... ; \n    ID variable ; \n    INITIAL F (row,column)=value ...G(row,column)=value ... ; \n    RESTRICT F (row,column)=value ...G (row,column)=value ... ; \n    VAR variable (difference, difference, ...) ... ; \n\nThe STATESPACE procedure uses the state space model to analyze and forecast multivariate \ntime series. The STATESPACE procedure is appropriate for jointly forecasting several related \ntime series that have dynamic interactions. By taking into account the autocorrelations among \nall the variables in a set, the STATESPACE procedure can give better forecasts than methods \nthat model each series separately."}},{"Name":"SYSLIN","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SYSLIN options ; \n    BY variables ; \n    ENDOGENOUS variables ; \n    IDENTITY identities ; \n    INSTRUMENTS variables ; \n    MODEL response = regressors / options ; \n    OUTPUT PREDICTED= variable RESIDUAL= variable ; \n    RESTRICT restrictions ; \n    SRESTRICT restrictions ; \n    STEST equations ; \n    TEST equations ; \n    VAR variables ; \n    WEIGHT variable ;\n\nThe SYSLIN procedure estimates parameters in an interdependent system of linear regression equations. \n\nOrdinary least squares (OLS) estimates are biased and inconsistent when current period endogenous variables\nappear as regressors in other equations in the system. The errors of a set of related regression equations\nare often correlated, and the efficiency of the estimates can be improved by taking these correlations into\naccount. The SYSLIN procedure provides several techniques that produce consistent and asymptotically efficient\nestimates for systems of regression equations."}},{"Name":"TIMESERIES","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TIMESERIES options ; \n    BY variables ; \n    CORR statistics-list / options ; \n    CROSSCORR statistics-list / options ; \n    CROSSVAR variable-list / options ; \n    DECOMP component-list / options ; \n    ID variable INTERVAL= interval-option ; \n    SEASON statistics-list / options ; \n    SPECTRA statistics-list / options ; \n    SSA / options \n    TREND statistics-list / options ; \n    VAR variable-list / options ; \n\nThe TIMESERIES procedure analyzes time-stamped transactional data with respect to time and \naccumulates the data into a time series format. The procedure can perform trend and seasonal \nanalysis on the transactions. After the transactional data are accumulated, time domain and \nfrequency domain analysis can be performed on the accumulated time series."}},{"Name":"TIMEID","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TIMEID options ; \n    BY variables ; \n    ID variable <options> ; \n\nThe TIMEID procedure evaluates a variable in an input data set for its suitability \nas a time ID variable in SAS procedures and solutions that are used for time series \nanalysis. PROC TIMEID assesses how well a time interval specification fits SAS date or  \ndatetime values, or observation numbers used to index a time series. The time interval \nused in this analysis can be either specified explicitly as input to PROC TIMEID or \ninferred by the procedure based on values of the time ID variable. The TIMEID procedure \nproduces diagnostic information in the form of data sets and ODS tabular and plotted \noutput. These diagnostic results summarize characteristics of the time ID variable that \ncan help determine its use as an index in other time series procedures and solutions."}},{"Name":"TSCSREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TSCSREG options ; \n    BY variables ; \n    ID cross-section-id-variable time-series-id-variable ; \n    MODEL dependent = regressor-variables / options ; \n    TEST equation1 <,equation2...> ; \n\nThe TSCSREG (time series cross section regression) procedure analyzes a class \nof linear econometric models that commonly arise when time series and cross-\nsectional data are combined. The TSCSREG procedure deals with panel data sets \nthat consist of time series observations on each of several cross-sectional units."}},{"Name":"UCM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC UCM <options> ; \n    AUTOREG <options> ; \n    BLOCKSEASON options ; \n    BY variables ; \n    CYCLE <options> ; \n    DEPLAG options ; \n    ESTIMATE <options> ; \n    FORECAST <options> ; \n    ID variable options ; \n    IRREGULAR <options> ; \n    LEVEL <options> ; \n    MODEL dependent variable <= regressors> ; \n    NLOPTIONS options ; \n    OUTLIER options ; \n    RANDOMREG regressors </ options> ; \n    SEASON options ; \n    SLOPE <options> ; \n    SPLINEREG regressor <options> ; \n    SPLINESEASON options ; \n\nThe UCM procedure analyzes and forecasts equally spaced univariate time series data by using \nan unobserved components model (UCM). The UCMs are also called structural models in the time \nseries literature. A UCM decomposes the response series into components such as trend, seasonals, \ncycles, and the regression effects due to predictor series. The components in the model are \nsupposed to capture the salient features of the series that are useful in explaining and \npredicting its behavior. Harvey (1989) is a good reference for time series modeling that uses \nthe UCMs. Harvey calls the components in a UCM the \"stylized facts\" about the series under \nconsideration. Traditionally, the ARIMA models and, to some limited extent, the exponential \nsmoothing models have been the main tools in the analysis of this type of time series data. \nIt is fair to say that the UCMs capture the versatility of the ARIMA models while possessing \nthe interpretability of the smoothing models."}},{"Name":"VARMAX","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC VARMAX options ; \n    BY variables ; \n    CAUSAL group1=(variables) group2=(variables) ; \n    COINTEG rank=number <options> ; \n    ID variable interval=value <option> ; \n    MODEL dependent variables <=regressors> <, dependent variables < =regressors> ...> </ options> ; \n    GARCH options ; \n    NLOPTIONS options ; \n    OUTPUT <options> ; \n    RESTRICT restrictions ; \n    TEST restrictions ; \n\nGiven a multivariate time series, the VARMAX procedure estimates the model parameters \nand generates forecasts associated with vector autoregressive moving-average processes \nwith exogenous regressors (VARMAX) models. Often, economic or financial variables are \nnot only contemporaneously correlated to each other, they are also correlated to each \nother's past values. The VARMAX procedure can be used to model these types of time \nrelationships. In many economic and financial applications, the variables of interest \n(dependent, response, or endogenous variables) are influenced by variables external to \nthe system under consideration (independent, input, predictor, regressor, or exogenous \nvariables). The VARMAX procedure enables you to model the dynamic relationship both \nbetween the dependent variables and also between the dependent and independent variables."}},{"Name":"X11","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC X11 options ; \n    ARIMA options ; \n    BY variables ; \n    ID variables ; \n    MACURVES option ; \n    MONTHLY options ; \n    OUTPUT OUT=dataset options ; \n    PDWEIGHTS option ; \n    QUARTERLY options ; \n    SSPAN options ; \n    TABLES tablenames ; \n    VAR variables ;\n\nThe X11 procedure, an adaptation of the U.S. Bureau of the Census X-11 Seasonal Adjustment \nprogram, seasonally adjusts monthly or quarterly time series. The procedure makes additive \nor multiplicative adjustments and creates an output data set containing the adjusted time \nseries and intermediate calculations."}},{"Name":"X12","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC X12 options ; \n    VAR variables ; \n    BY variables ; \n    ID variables ; \n    EVENT variables ; \n    USERDEFINED variables ; \n    TRANSFORM options ; \n    ADJUST options ; \n    IDENTIFY options ; \n    AUTOMDL options ; \n    OUTLIER options ; \n    REGRESSION options ; \n    INPUT variables ; \n    ARIMA options ; \n    ESTIMATE options ; \n    X11 options ; \n    FORECAST options ; \n    OUTPUT options ; \n    TABLES options ;\n\nThe X12 procedure, an adaptation of the U.S. Bureau of the Census X-12-ARIMA Seasonal Adjustment \nprogram (U.S. Bureau of the Census; 2001c), seasonally adjusts monthly or quarterly time series. \nThe procedure makes additive or multiplicative adjustments and creates an output data set that \ncontains the adjusted time series and intermediate calculations."}},{"Name":"TRANSREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TRANSREG <DATA=SAS-data-set>\n    <PLOTS=(plot-requests)> <OUTTEST=SAS-data-set> <a-options> <o-options> ; \n    MODEL <transform(dependents </ t-options>)>\n    <transform(dependents </ t-options>) ...=>\n    transform(independents </ t-options>)\n    <transform(independents </ t-options>) ...> </ a-options> ; \n    OUTPUT <OUT=SAS-data-set> <o-options> ; \n    ID variables ; \n    FREQ variable ; \n    WEIGHT variable ; \n    BY variables ; \n\nThe TRANSREG (transformation regression) procedure fits linear models, optionally with smooth, \nspline, Box-Cox, and other nonlinear transformations of the variables. You can use PROC TRANSREG \nto fit a curve through a scatter plot or fit multiple curves, one for each level of a classification \nvariable. You can also constrain the functions to be parallel or monotone or have the same intercept. \nPROC TRANSREG can be used to code experimental designs and classification variables prior to their use \nin other analyses."}},{"Name":"GKEYMAP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax:  PROC GKEYMAP NAME=map-name \n  data-set-argument \n  <option(s)>; \n  \nThe GKEYMAP procedure creates key maps and device maps that compensate for differences \nbetween the way that characters are encoded internally bySAS/GRAPH software and the way \nthat they are encoded by different operating environments and output devices. \n\nIn addition, the GKEYMAP procedure can create SAS data sets from existing key maps and \ndevice maps, either Institute-supplied or user-generated. This capability is useful when \nyou want to make minor alterations in a large key map or device map and you do not want \nto or cannot re-create the original data set with a DATA step."}},{"Name":"TRANS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TRANS options ; \n  \nTransportation networks are a special type of network, called bipartite networks, that \nhave only supply and demand nodes and arcs directed from supply nodes to demand nodes. \nFor these networks, data can be given most efficiently in a rectangular or matrix form. \nThe TRANS procedure takes cost, capacity, and lower bound data in this form. The observations \nin these data sets correspond to supply nodes, and the variables correspond to demand nodes. \n\nThe TRANS procedure puts the solution in a single output data set. As with the other \noptimization procedures, the TRANS procedure defines a macro variable, named _ORTRANS, \nthat has a character string that describes the solution status."}},{"Name":"HPDECIDE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPDECIDE <option(s)> ; \n    ID variable(s) ; \n    FREQ variable ; \n    PERFORMANCE performance-options ; \n    POSTERIORS variable-list ; \n    PREDICTED variable ; \n    TARGET variable ; \n    DECISION DECDATA=<libref.>SAS-data-set <option(s)> ; \n    CODE <options> ;  \n    \nThe HPDECIDE procedure creates optimal decisions that are based on a decision matrix that you specify, on\nprior probabilities, and on output from a modeling procedure. This output can be either posterior probabilities\nfor a categorical target variable or predicted values for an interval target variable. The HPDECIDE procedure\ncan also adjust the posterior probabilities for changes in the prior probabilities."}},{"Name":"HPIMPUTE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPIMPUTE <option(s)> ; \n    INPUT variable(s) <option(s)> ; \n    IMPUTE variable(s) <option(s)> ; \n    PERFORMANCE performance-options ; \n    ID variable(s) ; \n    FREQ variable ; \n    CODE <option(s)> ; \n    \nThe HPIMPUTE procedure executes high-performance numeric variable imputation, which is a common \nstep in the data preparation stage. You can specify multiple INPUT and IMPUTE statements, as is \nshown in the example. Any class variables that are referenced by the IMPUTE statement are ignored \nsince the HPIMPUTE procedure only takes numeric variables. \n\nThe HPIMPUTE procedure can replace numeric missing values with a given value. It also can replaces \nnumeric missing values with the MEAN, the PSEUDO-MEDIAN, or a RANDOM value between the minimum value \nand the maximum value of the non-missing values. \n\nWhen the MEAN, the PSEUDO-MEDIAN or the RANDOM value is being calculated, the HPIMPUTE procedure \nignores any observation that has a FREQ variable whose value is less than or equal to 0."}},{"Name":"HP4SCORE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HP4SCORE data-options ; \n    ID variables ; \n    SCORE score-options ; \n    PERFORMANCE performance-options ;  \n    \nThe HP4SCORE procedure is a high-performance procedure that scores a data set with a forest predictive\nmodel that was previously trained by the HPFOREST procedure.\n\nThe forest predictive model is an ensemble of hundreds of decision trees that are used to predict a target. The\ntarget can have either an interval or a nominal measurement level. Each decision tree consists of a sequence\nof rules that are applied to the observation to arrive at the prediction. The final prediction is either an average\nof the individual predictions for a target that has an interval measurement level or is derived from the average\nof the individual posterior probabilities for a target that has a nominal measurement level."}},{"Name":"HPBIN","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPBIN DATA=sas-data-set < options > ;\n    CODE FILE=filename ;\n    FREQ variable ;\n    ID id1 id2 . . . idn ;\n    INPUT variables < option > ;\n    PERFORMANCE < performance-options > ;\n    TARGET variable < option(s) > ;  \n    \nBinning is a common step in the data preparation stage of the model building process. One can \nuse binning to classify missing variables, reduce the impact of outliers, or generate multiple \neffects. The generated effects are useful and contain certain nonlinear information of the \noriginal interval variables. \n\nThe HPBIN procedure conducts high-performance binning using either bucket binning, winsorized \nbinning or pseudo-quantile binning. Like other high-performance procedures, the HPBIN procedure \ncan read and write data in distributed form. And it can perform computation in parallel in either \nsymmetric multiprocessing (SMP) or massively parallel processing (MPP) mode."}},{"Name":"HPCDM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPCDM options ;\n    BY variable-list ;\n    DISTBY replication-id-variable ;\n    SEVERITYMODEL severity-model-list ;\n    EXTERNALCOUNTS COUNT=frequency-variable < ID=replication-id-variable > ;\n    OUTPUT OUT=SAS-data-set < variable-name-options > < / out-option > ;\n    OUTSUM OUT=SAS-data-set statistic-keyword< =variable-name > < . . . statistickeyword<\n      =variable-name > > < outsum-options > ;\n    PERFORMANCE options ;\n    Programming statements ;\n    \nIn many loss modeling applications, the loss events are analyzed by modeling the severity (magnitude) of\nloss and the frequency (count) of loss separately. The primary goal of preparing these models is to estimate\nthe aggregate loss\u2014that is, the total loss that occurs over a period of time for which the frequency model is\napplicable. For example, an insurance company might want to assess the expected and worst-case losses for a\nparticular business line, such as automobile insurance, over an entire year given the models for the number of\nlosses in a year and the severity of each loss. A bank might want to assess the value-at-risk (VaR), a measure\nof the worst-case loss, for a portfolio of assets given the frequency and severity models for each asset type."}},{"Name":"HPCORR","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPCORR <options> ; \n    FREQ variable ; \n    VAR variables ; \n    WEIGHT variable ; \n    PERFORMANCE < performance-options > ;\n\nThe HPCORR procedure computes Pearson correlation coefficients and the probabilities \nassociated with these statistics. The correlation statistics include the following: \n\n  o Pearson product-moment correlation \n\nPearson product-moment correlation is a parametric measure of a linear relationship \nbetween two variables."}},{"Name":"HPCOUNTREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPCOUNTREG options ;\n    BOUNDS bound1 [ , bound2 . . . ] ;\n    FREQ freq-variable ;\n    INIT initvalue1 [ , initvalue2 . . . ] ;\n    MODEL dependent variable-variable = regressors / options ;\n    OUTPUT options ;\n    PERFORMANCE options ;\n    RESTRICT restriction1 [, restriction2 . . . ] ;\n    WEIGHT variable ;\n    ZEROMODEL dependent variable ~ zero-inflated regressors / options \n\nThe HPCOUNTREG procedure is a high-performance procedure to fit regression models on the SAS \nappliance in which the dependent variable takes nonnegative integer or count values. \nWith the HPCOUNTREG procedure you can read and write data in distributed form and perform \nanalyses in parallel in SMP or MPP mode."}},{"Name":"HPDMDB","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPDMDB DATA= < libref. >SAS-data-set < option(s) > ;\n    CLASS variable (< order-option >) variable (< order-option >) ... ;\n    FREQ variable ;\n    PERFORMANCE performance-options ;\n    VAR variable(s) ;\n    WEIGHT variable ; \n    \nThe HPDMDB procedure is a high-performance version of the DMDB procedure, which creates summaries\nof the input data source. PROC HPDMDB creates two output data sets: the VAROUT data set, which\ncontains a summary of the numeric variables, and the CLASSOUT data set, which contains a summary of\nthe classification variables."}},{"Name":"HPFOREST","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPFOREST <options>; \n    FREQ variable; \n    INPUT variables <options>; \n    ID variables; \n    PARTITION ROLEVAR=variable <TRAIN='value'> <VALIDATE='value'> ; \n    PERFORMANCE performance-options; \n    SAVE <options>; \n    SCORE <score-options>; \n    TARGET variable <options>; \n    TREATMENT variable <ORDER=order>; \n    \nThe HPFOREST procedure is a high-performance procedure that creates a predictive model called a forest\nthat consists of several decision trees. A predictive model defines a relationship between input variables and\na target variable. The purpose of a predictive model is to predict a target value from inputs. The HPFOREST\nprocedure trains the model; that is, it creates the model, using training data in which the target values are\nknown. The model can then be applied to observations in which the target is unknown. If the predictions\nfit the new data well, the model is said to generalize well. Good generalization is the primary goal for\npredictive tasks. A predictive model might fit the training data well but generalize poorly."}},{"Name":"HPLMIXED","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPLMIXED < options > ;\n    CLASS variables ;\n    MODEL dependent = < fixed-effects > < / options > ;\n    RANDOM random-effects < / options > ;\n    REPEATED < repeated-effect >< / options > ;\n    PARMS (value-list) ... < / options > ;\n    PERFORMANCE < options > ; \n\nThe HPLMIXED procedure fits a variety of mixed linear models to data and enables you \nto use these fitted models to make statistical inferences about the data. A mixed linear \nmodel is a generalization of the standard linear model used in the GLM procedure, the \ngeneralization being that the data are permitted to exhibit correlation and nonconstant \nvariability. The mixed linear model, therefore, provides you with the flexibility of \nmodeling not only the means of your data (as in the standard linear model) but their \nvariances and covariances as well."}},{"Name":"HPLOGISTIC","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPLOGISTIC < options > ;\n    CLASS variable < (options) >... < variable < (options) > > < / global-options > ;\n    MODEL response< (response-options) > = < effects > < / model-options > ;\n    MODEL events/trials< (response-options) > = < effects > < / model-options > ;\n    OUTPUT <OUT=SAS-data-set >\n      < keyword < =name > >...\n      < keyword < =name > > < / options > ;\n    PERFORMANCE performance-options ;\n    SELECTION selection-options ;\n    FREQ variable ;\n    ID variables ;\n    WEIGHT variable ;\n\nThe HPLOGISTIC procedure is a high-performance procedure that fits logistic regression \nmodels for binary, binomial, and multinomial data on the SAS appliance. \n\nThe HPLOGISTIC procedure fits logistic regression models in the broader sense; the procedure \npermits several link functions and can handle ordinal and nominal data with more than two \nresponse categories (multinomial data)."}},{"Name":"HPLSO","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPLSO options ; \n\n  PERFORMANCE options ;  \n    \nThe HPLSO procedure performs general optimization of nonlinear functions that are defined \nby the Base SAS FCMP procedure over both continuous and integer variables. These functions \ncan be nonsmooth, discontinuous, and possibly computationally expensive to evaluate."}},{"Name":"HPNEURAL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPNEURAL <DATA=SAS-data-set > < DISTR=ALL | SPLIT > < NOPRINT > ;\n    PERFORMANCE performance-options ;\n    ARCHITECTURE architecture-option ;\n    ID variables ;\n    INPUT variables < / LEVEL=INT | LEVEL=NOM < MISSING=MAP > > ;\n    WEIGHT variable | _INVERSE_PRIORS_ ;\n    HIDDEN number ;\n    TARGET variables < / LEVEL=INT | LEVEL=NOM > ;\n    PARTITION ROLEVAR=variable( TRAIN=value | VALIDATE=value ) ;\n    PARTITION FRACTION( TRAIN=number | VALIDATE=number ) ;\n    TRAIN < NUMTRIES=number > < MAXITER=number >\n      <VALID=_NONE_ > <OUTMODEL=SAS-data-set > ;\n    SCORE OUT=SAS-data-set <MODEL=SAS-data-set > ;\n    CODE FILE='external-file' | fileref ;\n\nThe HPNEURAL procedure is a high-performance procedure that trains a multilayer perceptron \nneural network. For more information about multilayer perceptron neural networks, see Bishop \n(1995). PROC HPNEURAL can also use the trained network to score the input data set. \n\nPROC HPNEURAL reads and writes data in distributed form and makes full use of multicore \ncomputers and distributed computing environments to perform training and scoring."}},{"Name":"HPNLIN","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax:  PROC HPNLIN < options > ;\n    BOUNDS constraint < , constraint ... > ;\n    ESTIMATE 'label' expression < options > ;\n    MODEL dependent-variable ~ distribution ; \n    PARAMETERS < parameter-specification > < ,... , parameter-specification > < / options >  ;\n    PERFORMANCE < performance-options > ;\n    PREDICT 'label' expression keyword=names < ... keyword=names > < options > ;\n    RESTRICT restriction1 < , restriction2 ... > ;\n    Programming Statements ;\n\nThe HPNLIN procedure is a high-performance procedure that uses either nonlinear least \nsquares or maximum likelihood to fit nonlinear regression models on the SAS appliance. \nPROC HPNLIN enables you to specify the model with SAS programming statements, which gives \nyou greater flexibility in modeling the relationship between the response variable and \nindependent (regressor) variables than SAS procedures that use a more structured MODEL \nstatement."}},{"Name":"HPNLMOD","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax:  PROC HPNLMOD < options > ;\n    BOUNDS inequality < ,. . . ,inequality > ;\n    BY variables ;\n    ESTIMATE 'label' expression < options > ;\n    MODEL model specification ;\n    PARAMETERS < parameter-specification > < ,. . . , parameter-specification > ;\n    PERFORMANCE < performance-options > ;\n    PREDICT 'label' expression keyword=names < . . . keyword=names > < options > ;\n    RESTRICT restriction1 < , restriction2 . . . > ;\n    Programming Statements ;\n\nThe HPNLMOD procedure is a high-performance procedure that uses either nonlinear least squares or\nmaximum likelihood to fit nonlinear regression models on the SAS appliance. PROC HPNLMOD enables\nyou to specify the model with SAS programming statements, which gives you greater flexibility in modeling\nthe relationship between the response variable and independent (regressor) variables than SAS procedures\nthat use a more structured MODEL statement."}},{"Name":"HPREDUCE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPREDUCE < options > ;\n    CLASS variable < (options) >... < variable < (options) > > < / global-options > ;\n    REDUCE UNSUPERVISED effects < / reduce-options > ;\n    REDUCE SUPERVISED response ... < response > = effects < / reduce-options > ;\n    PERFORMANCE performance-options ;\n\nThe HPREDUCE procedure is a high-performance procedure that performs both supervised and unsupervised\nvariable selection on the SAS appliance. With the HPREDUCE procedure you can read data in distributed\nform and perform variable selection in parallel in symmetric multiprocessing (SMP) or massively parallel\nprocessing (MPP) mode. \n\nThe HPREDUCE procedure performs unsupervised variable selection by identifying a set of variables that\njointly explain the maximum amount of data variance. Unlike principal component analysis (PCA), which\nreduces dimensionality by generating a set of new variables (variable extraction), the HPREDUCE procedure\nreduces dimensionality by selecting a subset of the original variables (variable selection). Thus, this technique\npreserves model interpretation."}},{"Name":"HPREG","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPREG < options > ;\n    BY variables ;\n    CODE < options > ;\n    CLASS variable < (options) >... < variable < (options) >> < / global-options > ;\n    MODEL dependent = < effects > < / model-options > ;\n    OUTPUT <OUT=SAS-data-set >\n      < keyword < =name > >...\n      < keyword < =name > > < / options > ;\n    PARTITION < partition-options > ;\n    PERFORMANCE performance-options ;\n    SELECTION selection-options ;\n    FREQ variable ;\n    ID variables ;\n    WEIGHT variable ;\n\nThe HPREG procedure is a high-performance procedure that fits and performs model selection for ordinary\nlinear least squares models. The models supported are standard independently and identically distributed\ngeneral linear models, which can contain main effects that consist of both continuous and classification \nvariables and interaction effects of these variables. The procedure offers extensive capabilities for \ncustomizing the model selection with a wide variety of selection and stopping criteria, from traditional \nand computationally efficient significance-level-based criteria to more computationally intensive \nvalidation-based criteria. PROC HPREG also provides a variety of regression diagnostics that are conditional \non the selected model."}},{"Name":"HPSEVERITY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPSEVERITY options ;\n    LOSS < response-variable > < / censoring-truncation-options > ;\n    WEIGHT weight-variable ;\n    CLASS variable < (options) > . . . < variable < (options) > > < / global-options > ;\n    SCALEMODEL regression-effect-list < / scalemodel-options > ;\n    DIST distribution-name-or-keyword < (distribution-option) < distribution-name-or-keyword\n      < (distribution-option) > > . . . > < / preprocess-options > ;\n    OUTSCORELIB < OUTLIB= > fcmp-library-name options ;\n    NLOPTIONS options ;\n    PERFORMANCE options ;\n    Programming statements ;\n\nThe HPSEVERITY procedure estimates parameters of any arbitrary continuous probability distribution that\nis used to model the magnitude (severity) of a continuous-valued event of interest. Some examples of such\nevents are loss amounts paid by an insurance company and demand of a product as depicted by its sales. \nPROC HPSEVERITY is especially useful when the severity of an event does not follow typical distributions,\nsuch as the normal distribution, that are often assumed by standard statistical methods."}},{"Name":"HPDS2","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: ROC HPDS2 < options > ;\n    PERFORMANCE performance-options ;\n    DATA DS2GTF.out ;\n      DS2 statements\n      METHOD RUN()\n      SET DS2GTF.in\n      END\n    ENDDATA ;\n    RUN ;\n    RUN CANCEL ;\n    QUIT ;\n    \nThe HPDS2 procedure enables you to submit DS2 language statements from a Base SAS session to a SAS\nHigh Performance Analytics grid for parallel execution. PROC HPDS2 verifies the syntactic correctness of\nthe DS2 source on the client machine before submitting it to the grid for execution. The output data created\nby the DS2 DATA statement can be output in either of the following ways: it can be written in parallel\nback to the grid data store or it can be returned to the client machine and directed to any data store that \nis supported by SAS."}},{"Name":"HPSAMPLE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPSAMPLE DATA=< libref. >SAS-data-set OUT=< libref. >SAS-data-set < option(s) > ;\n    VAR variable < variable ... variable > ;\n    CLASS variable < variable ... variable > ; \n    TARGET variable < variable ... variable > ;\n    PERFORMANCE performance-options ;\n\nThe HPSAMPLE procedure is a high-performance procedure that performs either simple random sampling \nor stratified sampling. The HPSAMPLE procedure creates the following: \n\n  \u2022 one output data set, which contains the sample data set\n  \u2022 one performance table, which contains performance information\n  \u2022 one frequency table, which contains the frequency information for the population and sample"}},{"Name":"HPSPLIT","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPSPLIT <options>; \n    CLASS variable... </options>; \n    CODE FILE=filename; \n    GROW criterion </ options>; \n    ID variables; \n    MODEL response <(response-options)> = variable <variable...>; \n    OUTPUT output-options; \n    PARTITION <partition-options>; \n    PERFORMANCE performance-options; \n    PRUNE prune-method <(prune-options)>; \n    RULES FILE=filename; \n\nThe HPSPLIT procedure is a high-performance procedure that builds tree-based statistical models \nfor classification and regression. The procedure produces classification trees, which model a \ncategorical response, and regression trees, which model a continuous response. Both types of \ntrees are referred to as decision trees because the model is expressed as a series of if-then \nstatements."}},{"Name":"HPSUMMARY","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPSUMMARY < option(s) > < statistic-keyword(s) > ;\n    CLASS variable(s) < / option(s) > ;\n    FREQ variable ;\n    OUTPUT <OUT=SAS-data-set > < output-statistic-specification(s) > < / option(s) > ;\n    PERFORMANCE performance-options ;\n    TYPES request(s) ;\n    VAR variable(s) < / WEIGHT=weight-variable > ;\n    WAYS list ;\n    WEIGHT variable ;\n\nThe HPSUMMARY procedure enables you to summarize data on a SAS High Performance Analytics grid\nfor parallel execution. The output data created by PROC HPSUMMARY can then be written in parallel back\nto the grid data store."}},{"Name":"HPQLIM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HPQLIM options ; \n    BOUNDS bound1 < , bound2 \u2026> ; \n    FREQ variable ; \n    ENDOGENOUS variables ~ options ; \n    HETERO dependent variables exogenous variables / options ; \n    INIT initvalue1 < , initvalue2 \u2026> ; \n    MODEL dependent = regressors < / options > ;\n    OUTPUT OUT=SAS-data-set < output-options > ; \n    PERFORMANCE < performance-options > ;\n    RESTRICT restriction1 < , restriction2 \u2026> ; \n    <label:> TEST <string:> equation [,equation...] / options ; \n    WEIGHT variable ;\n\nThe HPQLIM (high-performance qualitative and limited dependent variable model) procedure \nis a high-performance version of the QLIM procedure in SAS/ETS software, which analyzes \nunivariate limited dependent variable models in which dependent variables are observed \nonly in a limited range of values. Unlike the QLIM procedure, which can be run only on \nan individual workstation, the HPQLIM procedure takes advantage of a computing environment \nthat enables it to distribute the optimization task among one or more nodes. In addition, \neach node can use one or more threads to carry out the optimization on its subset of the \ndata. When several nodes are used with each node using several threads to carry out its \npart of the work, the result is a highly parallel computation that provides a dramatic \ngain in performance."}},{"Name":"XSL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC XSL IN=fileref | 'external-file' OUT=fileref | 'external-file' \n    XSL=fileref | 'external-file'; \n  PARAMETER 'parameter'='value';\n\nThe XSL procedure transforms an XML document into another format, such as HTML, text, or another \nXML document type. PROC XSL reads an input XML document, transforms it by using an XSL style sheet, \nand then writes the output. \n\nTo transform the XML document, PROC XSL uses the Saxon-EE version 9.3 software application from \nSaxonica, which is a collection of tools for processing XML documents. The XSLT processor implements \nthe XSLT 2.0 standard."}},{"Name":"ASSESS","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ASSESS < options > ;\n    INPUT variable ;\n    TARGET variables < /options > ;\n    FITSTAT PVAR=variables / PEVENT=\u201cevent-list\u201d <DLM=\u201ccharacter\u201d > ;\n    FREQ variable ;\n    BY variable ;\n\nThe ASSESS procedure assesses and compares supervised learning models. For a supervised learning\nmodel that has a nominal target, the ASSESS procedure produces lift information and receiver operating\ncharacteristic (ROC) information. For a regression model, the ASSESS procedure performs a quantile\nbinning of the predictions and then returns the summary statistics of the response variable for each bin.\nPROC ASSESS also calculates fit statistics such as average square error, mean square logarithmic error, \nmean absolute error, mean consequential error, and multiclass log loss."}},{"Name":"ASTORE","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ASTORE ; \n    SCORE score-options; \n    DESCRIBE describe-options; \n    DOWNLOAD download-options; \n    UPLOAD upload-options; \n    \nThe ASTORE procedure is an interactive procedure in which each statement runs immediately. \nThe ASTORE procedure describes, manages, and scores with an analytic store. The analytic \nstore is the result of a SAVESTATE statement from another analytic procedure; it is a binary \nfile that contains that procedure\u2019s state after it completes the training phase of data analysis. \nSome procedures that support a SAVESTATE statement are the FACTMAC, FOREST, and SVMACHINE \nprocedures. You can use the analytic store at a later time for scoring."}},{"Name":"BINNING","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC BINNING DATA=CAS-libref.data-table < options > ;\n    CODE FILE=filename ;\n    FREQ variable ;\n    INPUT variables < / option > ;\n    OUTPUT OUT=CAS-libref.data-table < option > ;\n    TARGET variable / EVENT=\u201ccategory\u201d ;\n    \nBinning is a common step in the data preparation stage of the model-building process. You can use binning\nto classify missing variables, reduce the impact of outliers, and generate multiple effects. The generated\neffects are useful and contain certain nonlinear information about the original interval variables.\nThe BINNING procedure supports a few binning methods that are described in the following subsections.\nThe BINNING procedure can also calculate the weight of evidence (WOE) and information value (IV) based\non binning results."}},{"Name":"BOOLRULE","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC BOOLRULE <options>; \n    DOCINFO <options>; \n    TERMINFO <options>; \n    OUTPUT <options>; \n    SCORE <options>; \n    \nThe BOOLRULE procedure is a SAS Viya procedure that enables you to extract Boolean rules from large-scale \ntransactional data. \n\nThe BOOLRULE procedure can automatically generate a set of Boolean rules by analyzing a text corpus that \nhas been processed by the TEXTMINE procedure and is represented in a transactional format."}},{"Name":"CARDINALITY","Type":"CAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC CARDINALITY DATA=CAS-libref.data-table OUTCARD=CAS-libref.data-table < options > ;\n    VAR variables < / options > ;\n    FREQ variable ;\n\nThe term cardinality of a variable is an alias to the number of its distinct values. The term limited cardinality\nis the number of distinct values that do not exceed a certain threshold provided by the user. To make a\ndecision about the role of a variable to be included in subsequent SAS analytics (class, interval), it is sufficient\nto aim only for the limited cardinality and not the full cardinality. We tend to make the same decision whether\nwe computed the full or the limited cardinality. The limited cardinality i s computationally less expensive\nthan the full cardinality, especially for big data."}},{"Name":"CAS","Type":"CAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: Syntax: PROC CAS; \n    ...CASL statements... \n    RUN;\n    QUIT; \n\nThe CAS procedure enables you to interact with SAS Cloud Analytic Services (CAS) from the SAS client \nby providing you a programming environment based on the CASL language specification. The programming \nenvironment enables you to run CAS actions and use the results to prepare the parameters for another action. \n\nPROC CAS does not have any required or optional arguments. Once PROC CAS is executed, it will continue \nrunning until it reaches one of the following: \n  o a DATA step \n  o another PROC step \n  o the QUIT statement \n  o an error condition that prevents the progress of the procedure. \n  \nAt that point, you will have to execute PROC CAS again using the syntax above."}},{"Name":"CASUTIL","Type":"CAS_PROCEDURE","Attributes":"InteractivePROC","Help":{"#cdata":"Syntax: PROC CASUTIL <option(s)>;\n  CONTENTS CASDATA=\"table-name\" <INCASLIB=\"caslib\"> <option(s)>;\n  DELETESOURCE CASDATA=\"file-name\" <INCASLIB=\"caslib\"> <QUIET>;\n  DROPTABLE CASDATA=\"table-name\" <INCASLIB=\"caslib\"> <QUIET>;\n  LIST <FILES | TABLES> <options(s)>;\n  LOAD CASDATA=\"file-name\" | DATA=SAS-data-set | FILE=\"SAS-file\" <option(s)>;\n  PROMOTE CASDATA=\"table-name\" <INCASLIB=\"caslib\"> <CASOUT=\"table-name\"> <OUTCASLIB=\"caslib\"> <DROP | KEEP>;\n  SAVE CASDATA=\"table-name \" <INCASLIB=\"caslib\"> <CASOUT=\"file-name\" <OUTCASLIB=\"caslib\">> <option(s)>;\nQUIT;\n\nThe CASUTIL procedure works with tables in SAS Cloud Analytic Services, SAS data sets in SAS libraries, \nand external files. The procedure has three functional areas: \n\n  \u2022 data transfer \n  \u2022 table and file information \n  \u2022 drops tables and deletes files \n\nIn the area of data transfer, you can perform the following operations: \n  \u2022 load a data set from a SAS library into a memory on SAS Cloud Analytic Services.  \n  \u2022 save in-memory tables in a caslib to the data source that is associated with the caslib.  \n  \u2022 load files from the data source that is associated with a caslib into memory on \n    SAS Cloud Analytic Services."}},{"Name":"CORRELATION","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CORRELATION <options>; \n    BY variables; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    FREQ variable; \n    VAR variables; \n    WEIGHT variable; \n    WITH variables; \n    \nThe CORRELATION procedure computes Pearson correlation coefficients and the probabilities associated \nwith these statistics in SAS Viya. \n\nThe Pearson product-moment correlation is a parametric measure of a linear relationship between two \nvariables. When only one set of analysis variables is specified, the default correlation analysis \nincludes descriptive statistics for each analysis variable and pairwise Pearson correlation statistics \nfor these variables. When two sets of analysis variables are specified, the default correlation analysis \nincludes descriptive statistics for each analysis variable and pairwise Pearson correlation statistics \nbetween the two sets of variables. When the relationship between two variables is nonlinear or when \noutliers are present, the correlation coefficient might incorrectly estimate the strength of the \nrelationship."}},{"Name":"FACTMAC","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FACTMAC <options>; \n    CODE FILE=filename; \n    ID variables; \n    INPUT variables <LEVEL=NOMINAL>; \n    OUTPUT OUT=CAS-libref.data-table <options>; \n    SAVESTATE RSTORE=CAS-libref.data-table; \n    TARGET variable <LEVEL=INTERVAL>; \n    AUTOTUNE <options>; \n    \nThe FACTMAC procedure implements the factorization machine model in SAS Viya. The flexible factorization\nmachine model has applications in predictive modeling and recommendation (Rendle 2012).\nFactorization machines generalize matrix factorization, among other techniques. You can use the FACTMAC\nprocedure to read and write data in distributed form, and to perform factorization in parallel by making full\nuse of multicore computers or distributed computing environments."}},{"Name":"FOREST","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FOREST <options>; \n    AUTOTUNE <options>; \n    CODE <options>; \n    CROSSVALIDATION <KFOLD=number>; \n    GROW criterion; \n    ID variables; \n    INPUT variables </ LEVEL=NOMINAL | INTERVAL>; \n    OUTPUT OUT=CAS-libref.data-table <option>; \n    PARTITION partition-option; \n    SAVESTATE RSTORE=CAS-libref.data-table; \n    TARGET variable </ LEVEL=NOMINAL | INTERVAL>; \n    WEIGHT variable; \n\nThe FOREST procedure creates a predictive model called a forest (which consists of several decision trees)\nin SAS Viya. A predictive model defines a relationship between input variables and a target variable. The\npurpose of a predictive model is to predict a target value from inputs. The FOREST procedure trains the\nmodel; that is, it creates the model by using training data in which the target values are known. The model\ncan then be applied to observations in which the target is unknown. If the predictions fit the new data well,\nthe model is said to generalize well. Good generalization is the primary goal for predictive tasks. A predictive\nmodel might fit the training data well but generalize poorly."}},{"Name":"FREQTAB","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FREQTAB <options> ; \n    BY variables; \n    EXACT statistic-options </ computation-options> ; \n    OUTPUT <OUT=SAS-data-set> output-options; \n    TABLES requests </ options> ; \n    TEST options; \n    WEIGHT variable </ option> ; \n\nThe FREQTAB procedure produces one-way to n-way frequency and crosstabulation (contingency) tables \nin SAS Viya. PROC FREQTAB also provides a variety of tests and measures to analyze frequency and \ncrosstabulation tables. \n\nFor one-way frequency tables, PROC FREQTAB provides chi-square goodness-of-fit tests for equal proportions \nand for specified null proportions. It also provides several types of confidence limits for binomial \nproportions and binomial proportion tests (which include noninferiority and equivalence tests).]"}},{"Name":"GAMMOD","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GAMMOD <options>; \n    BY variables; \n    CLASS variable <(options)>\n      <variable <(options)>> </ global-options>; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    FREQ variable; \n    MODEL response <(response-options)> = <PARAM(effects)> <spline-effects> </ model-options>; \n    MODEL events\u00a0/\u00a0trials = <PARAM(effects)> <spline-effects> </ model-options>; \n    OUTPUT OUT=CAS-libref.data-table <keyword <=name>>\u2026<keyword <=name>> </ options>; \n    WEIGHT variable; \n    \nThe GAMMOD procedure fits generalized additive models that are based on low-rank regression splines \n(Wood 2006) in SAS Viya. \n\nGeneralized additive models are extensions of generalized linear models. They relax the generalized \nlinear models\u2019 assumption of linearity by allowing spline terms that characterize nonlinear dependency \nstructures. Each spline term is constructed by the thin-plate regression spline technique (Wood 2003). \nA roughness penalty is applied to each spline term by a smoothing parameter that controls the balance \nbetween goodness of fit and the roughness of the spline curve. PROC GAMMOD fits models for standard \ndistributions in the exponential family, such as the normal, Poisson, gamma and Tweedie distributions.]"}},{"Name":"GENSELECT","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GENSELECT < options > ;\n    BY variables ;\n    CLASS variable < (options) >. . . < variable < (options) > > < / global-options > ;\n    CODE < options > ;\n    DISPLAY < table-list > < / options > ;\n    DISPLAYOUT table-spec-list < / options > ;\n    EFFECT name=effect-type(variables < / options >) ;\n    FREQ variable ;\n    MODEL response< (response-options) > = < effects > < / model-options > ;\n    MODEL events/trials< (response-options) > = < effects > < / model-options > ;\n    OUTPUT OUT=CAS-libref.data-table < keyword < =name > >. . . < keyword < =name > > < options > ;\n    PARTITION < partition-options > ;\n    SELECTION <METHOD=method < (method-options) > >< options > ;\n    WEIGHT variable ;\n\nThe GENSELECT procedure provides model fitting and model building for generalized linear models in\nSAS Viya. It fits models for standard distributions in the exponential family, such as the normal, Poisson, and\nbinomial distributions. In addition, PROC GENSELECT fits models for responses such as those modeled as\nthe beta, generalized Poisson, and negative binomial distributions. For all these models, the GENSELECT\nprocedure provides forward and backward variable selection. It also provides model selection by the LASSO\nmethod."}},{"Name":"GRADBOOST","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GRADBOOST <options>; \n    AUTOTUNE <options>; \n    CODE <options>; \n    CROSSVALIDATION <options>; \n    ID variables; \n    INPUT variables </ options>; \n    OUTPUT OUT=CAS-libref.data-table <option>; \n    PARTITION partition-option; \n    SAVESTATE RSTORE=CAS-libref.data-table; \n    TARGET variable </ LEVEL=NOMINAL | INTERVAL>; \n    TRANSFERLEARN variable </ options>; \n    VIICODE <options>; \n    WEIGHT variable; \n    \nThe GRADBOOST procedure creates a predictive model called a gradient boosting model in SAS Viya.\nA gradient boosting model consists of multiple decision trees. A predictive model defines a relationship\nbetween input variables and a target variable. The purpose of a predictive model is to predict a target value\nfrom inputs. The GRADBOOST procedure creates the model by using training data in which the target\nvalues are known. The model can then be applied to observations in which the target is unknown. If the\npredictions fit the new data well, the model is said to generalize well. Good generalization is the primary\ngoal of predictive tasks. A predictive model might fit the training data well but generalize poorly."}},{"Name":"KCLUS","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC KCLUS DATA=CAS-libref.data-table < options > ;\n    CODE < options > ;\n    DISPLAY < table-list > < /options > ;\n    DISPLAYOUT table-spec-list < /options > ;\n    FREQ variable ;\n    INPUT variables < LEVEL= NOMINAL | INTERVAL> ;\n    SCORE OUT=CAS-libref.data-table < options > ;\n\nThe KCLUS procedure performs clustering (a common step in data exploration) in SAS Viya. You can use\nthe KCLUS procedure to read and write data in distributed form, and to perform clustering and scoring in\nparallel by making full use of multicore computers or distributed computing environments.\n\nThe KCLUS procedure performs a cluster analysis on the basis of distances that are computed from one or\nmore quantitative variables. The observations are divided into clusters such that every observation belongs to\none and only one cluster."}},{"Name":"LOGSELECT","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LOGSELECT < options > ;\n    BY variables ;\n    CLASS variable < (options) >. . . < variable < (options) > > < / global-options > ;\n    CODE < options > ;\n    DISPLAY < table-list > < / options > ;\n    DISPLAYOUT table-spec-list < / options > ;\n    EFFECT name=effect-type(variables < / options >) ;\n    FREQ variable ;\n    MODEL response< (response-options) > = < effects > < / model-options > ;\n    MODEL events/trials< (response-options) > = < effects > < / model-options > ;\n    OUTPUT OUT=CAS-libref.data-table < keyword < =name > >. . . < keyword < =name > > < options > ;\n    PARTITION partition-options ;\n    SELECTION <METHOD=method< (method-options) > >< options > ;\n    WEIGHT variable ;\n\nThe LOGSELECT procedure fits binary and binomial response models in SAS Viya.\n\nLogistic regression analysis is often used to investigate the relationship between discrete responses and a set\nof explanatory variables."}},{"Name":"MWPCA","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MWPCA <options>; \n    ID variable; \n    INPUT variables; \n    RPCA <options>; \n    SVD <options>; \n    OUTPUT OUT=CAS-libref.data-table <options>; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n\nThe MWPCA procedure implements moving windows robust principal component analysis. You can use \nthis procedure to capture changes in principal components over time by using sliding windows. \nAlso, you can choose to perform robust principal component analysis on each window; that is, \nthe outliers and noise would be excluded from each window before the analysis is performed."}},{"Name":"NLMOD","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NLMOD < options > ;\n    BOUNDS constraint < , constraint . . . > ;\n    BY variables ;\n    DISPLAY < table-list >< / options > ;\n    DISPLAYOUT table-spec-list< / options > ;\n    ESTIMATE 'label' expression < options > ;\n    ID variables ;\n    MODEL dependent-variable \u00cf distribution ;\n    PARAMETERS < parameter-specification > < ,. . . , parameter-specification > < / options > ;\n    PREDICT 'label' expression < options > ;\n    RESTRICT restriction1 < , restriction2 . . . > ;\n    Programming statements ;\n\nThe NLMOD procedure uses either nonlinear least squares or maximum likelihood to fit nonlinear regression\nmodels in SAS Viya. PROC NLMOD enables you to specify the model by using SAS programming statements, which \ngive you greater flexibility in modeling the relationship between the response variable and independent \n(regressor) variables than SAS procedures that use a more structured MODEL statement."}},{"Name":"NNET","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NNET < options > ;\n    INPUT variables < / LEVEL=INT | NOM> ;\n    HIDDEN number < /options > ;\n    TARGET variables < /options > ;\n    TRAIN OUTMODEL=CAS-libref.data-table < options > ;\n    ARCHITECTURE architecture-options ;\n    WEIGHT variable ;\n    PARTITION < partition-options > ;\n    OPTIMIZATION < options > ;\n    AUTOTUNE < options > ;\n    CROSSVALIDATION <KFOLD=number > ;\n    SCORE OUT=CAS-libref.data-table < option > ;\n    CODE < options > ; \n  \nThe NNET procedure trains a multilayer perceptron neural network in SAS Viya. For more information\nabout multilayer perceptron neural networks, see Bishop (1995). PROC NNET can also use a previously\ntrained network to score a data table (referred to as stand-alone scoring), or it can generate SAS DATA step\nstatements that can be used to score a data table."}},{"Name":"OUTDESIGN","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OUTDESIGN <options>; \n    BY variables; \n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options>; \n    DISPLAY <table-list> </ options>; \n    EFFECT name=effect-type(variables </ options>); \n    FREQ variable; \n    MODEL dependent = <effects> </ model-options>; \n    OUTPUT OUT=CAS-libref.data-table <keyword <=name>>\u2026<keyword <=name>> </ options>; \n    WEIGHT variable; \n    \nThe OUTDESIGN procedure creates the design matrix associated with a user-specified model statement \nand a user-specified dataset in SAS Viya."}},{"Name":"PARTITION","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PARTITION DATA=CAS-libref.data-table < options > ;\n    BY variable < variable . . . variable > ;\n    OUTPUT OUT=CAS-libref.data-table < options > ;\n    DISPLAY < table-list > < /options > ;\n    \nThe PARTITION procedure performs simple random sampling, stratified sampling, and oversampling to\nproduce a table with a subset of the observations or with observations partitioned.\n\nThe PARTITION procedure creates the following:\n\n o one output data table, which contains the sampled or partitioned data table\n o one summary table, which contains the numbers of observations and variables in the data table\n o one frequency table, which contains the frequency information for the population and sample"}},{"Name":"PCA","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PCA < options > ;\n    BY variables ;\n    CODE < options > ;\n    DISPLAY < table-list > < / options > ;\n    DISPLAYOUT table-spec-list < / options > ;\n    FREQ variable ;\n    OUTPUT OUT=CAS-libref.data-table\n      <COPYVARS=(variables) >\n      < keyword < =prefix > >. . . < keyword < =prefix > > ;\n    PARTIAL variables ;\n    VAR variables ;\n    WEIGHT variable ;\n\nThe PCA procedure performs principal component analysis in SAS Viya. Principal component analysis is\na multivariate technique for examining relationships among several quantitative variables. It provides an\noptimal way to reduce dimensionality by projecting the data onto a lower-dimensional orthogonal subspace\nthat explains as much variation in those variables as possible. The choice between using factor analysis and\nusing principal component analysis depends in part on your research objectives. You should use the PCA\nprocedure if you are interested in summarizing data and detecting linear relationships. You can use principal\ncomponent analysis to reduce the number of variables in regression, clustering, and so on."}},{"Name":"PHSELECT","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PHSELECT <options>; \n    BY variables; \n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options>; \n    CODE <options>; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    EFFECT name=effect-type(variables </ options>); \n    FREQ variable; \n    MODEL response <*censor(list)> = <effects> </ model-options>; \n    OUTPUT OUT=CAS-libref.data-table <options> <keyword <=name>>\u2026<keyword <=name>>; \n    PARTITION partition-options; \n    SELECTION <METHOD=method<(method-options)>><options>; \n    STRATA variable <MISSING>; \n    WEIGHT variable; \n    \nThe PHSELECT procedure fits the Cox proportional hazards regression models for survival data and performs \nvariable selection in SAS Viya. \n\nThe models that PROC PHSELECT supports can contain main effects that consist of both continuous and \nclassification variables and interaction effects of these variables. The models can also include \nconstructed effects such as splines. The procedure offers a number of effect-selection methods, \nincluding stepwise methods and modern LASSO methods."}},{"Name":"PLSMOD","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PLSMOD <options>; \n    BY variables; \n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options>; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    EFFECT name = effect-type (variables </ options>); \n    MODEL response-variables = predictor-effects </ options>; \n    OUTPUT OUT=CAS-libref.data-table\n    <COPYVARS=(variables)>\n    <keyword <=prefix>>\u2026<keyword <=prefix>>; \n    PARTITION partition-options; \n    \nThe PLSMOD procedure fits reduced-rank linear models in SAS Viya by using any one of a number of linear \npredictive methods, including partial least squares (PLS)."}},{"Name":"QTRSELECT","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC QTRSELECT <options>; \n    BY variables; \n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options>; \n    CODE <options>; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    EFFECT name=effect-type(variables </ options>); \n    MODEL dependent = <effects> </ model-options>; \n    OUTPUT OUT=CAS-libref.data-table <keyword <=name>>\u2026<keyword <=name>> </ options>; \n    PARTITION partition-options; \n    SELECTION <METHOD=method <(method-options)>><options>; \n    WEIGHT variable; \n    \nThe QTRSELECT procedure fits and performs model selection for quantile regression models in SAS Viya. \n \nQuantile regression uses a linear function model to fit the quantiles of a response variable conditional \non the explanatory variables. The model does not assume a particular parametric distribution for the \nresponse. The models that PROC QTRSELECT supports can contain main effects that consist of both continuous \nand classification variables and interaction effects of these variables. The models can also include \nconstructed effects such as splines."}},{"Name":"REGSELECT","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC REGSELECT < options > ;\n    BY variables ;\n    CLASS variable < (options) >. . . < variable < (options) > > < / global-options > ;\n    CODE < options > ;\n    DISPLAY < table-list > < / options > ;\n    DISPLAYOUT table-spec-list < / options > ;\n    EFFECT name=effect-type(variables < / options >) ;\n    FREQ variable ;\n    MODEL dependent = < effects > < / model-options > ;\n    OUTPUT OUT=CAS-libref.data-table < keyword < =name > >. . . < keyword < =name > > < / options >  ;\n    PARTITION partition-options ;\n    SELECTION <METHOD=method < (method-options) > >< options > ;\n    WEIGHT variable ;\n\nThe REGSELECT procedure fits and performs model selection for ordinary linear least squares models in\nSAS Viya.\n\nThe models that PROC REGSELECT supports are standard independently and identically distributed general\nlinear models, which can contain main effects that consist of both continuous and classification variables\nand interaction effects of these variables. The procedure offers extensive capabilities for customizing the\nmodel selection with a wide variety of selection and stopping criteria, from traditional and computationally\nefficient significance-level-based criteria to more computationally intensive validation-based criteria. PROC\nREGSELECT also provides a variety of regression diagnostics that are conditional on the selected model."}},{"Name":"RPCA","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC RPCA <options>; \n    ROWID variable; \n    INPUT variables; \n    SVD <options>; \n    OUTDECOMP <options>; \n    CODE FILE=filename; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    \nThe RPCA procedure implements robust principal component analysis (RPCA) in SAS Viya. RPCA can be \nused in many areas, including image processing, latent semantic indexing, ranking, and matrix \ncompletion (Cand\u00e8s et\u00a0al. 2011). \n\nThe RPCA procedure decomposes an input matrix into a sum of two matrices: a low-rank matrix and \na sparse matrix. You can use the low-rank matrix to do feature extraction and use the sparse matrix\nto detect anomalies."}},{"Name":"SPC","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SPC <options>; \n  BY variables; \n  BOXCHART < / options>; \n  CCHART < / options>; \n  IRCHART < / options>; \n  MCHART < / options>; \n  MRCHART < / options>; \n  NPCHART < / options>; \n  PCHART < / options>; \n  RCHART < / options>; \n  SCHART < / options>; \n  UCHART < / options>; \n  XCHART < / options>; \n  XRCHART < / options>; \n  XSCHART < / options>; \n  \nThe SPC procedure performs Shewhart control chart analysis in SAS Viya. \n\nThe Shewhart control chart is a graphical and analytical tool for deciding whether a process is in \na state of statistical control. You can use the SPC procedure to compute many different types of \ncontrol charts, including all commonly used charts for variables and attributes."}},{"Name":"SVDD","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SVDD <options>; \n    CODE FILE=filename; \n    ID variables; \n    INPUT variables / <LEVEL=INTERVAL | NOMINAL>; \n    WEIGHT variable; \n    KERNEL kernel-type / <kernel-parameter>; \n    SOLVER solver-type / <options>; \n    SAVESTATE RSTORE=CAS-libref.data-table; \n    \nThe SVDD procedure implements the support vector data description (SVDD) algorithm (Tax and Duin 2004). \nSVDD is a one-class classification technique that is useful in applications where data that belong to \none class are abundant but data about any other class are scarce or missing. Fraud detection, equipment \nhealth monitoring, and process control are some examples of application areas where the majority of the \ndata belong to one class. You can use SVDD to model such one-class data and subsequently use the model \nto perform outlier detection."}},{"Name":"SVMACHINE","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SVMACHINE <options>; \n    AUTOTUNE <options>; \n    CODE FILE=filename; \n    ID variables; \n    INPUT variables / <LEVEL=INTERVAL | NOMINAL>; \n    KERNEL kernel-type / <kernel-parameter>; \n    OUTPUT OUT=CAS-libref.data-table <option>; \n    PARTITION partition-option; \n    SAVESTATE RSTORE=CAS-libref.data-table; \n    TARGET variable </option>; \n    \nThe SVMACHINE procedure implements the support vector machines (SVM) algorithm in SAS Viya.\nA popular data mining area classification method, the SVM algorithm computes support vector machine\nlearning classifiers for the binary pattern recognition problem; it has been broadly used in the fields such as\nimage classification, handwriting recognition, financial decision, text mining, and so on."}},{"Name":"S3","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC S3 <CONFIG=\"file-path\"> <KEYID=\"aws-key-id\"> <SECRET=\"aws-secret\"> <NOSSL> <REGION=\"aws-region\"> ;\n     COPY \"source-s3-location\" \"destination-s3-location\";\n     CREATE \"bucket-name\";\n     DELETE \"s3-location\";\n     DESTROY \"bucket-name\";\n     GET \"s3-location\" <\"local-path\">;\n     GETDIR \"s3-location\" \"local-path\";\n     INFO \"s3-location\";\n     LIST <_SHORT_> \"s3-location\";\n     MKDIR \"s3-location\";\n     PUT \"local-path\" \"s3-location\";\n     PUTDIR \"local-path\" \"s3-location\";\n     RMDIR \"s3-location\";\n  RUN;\n\nThe S3 procedure is used for managing objects in Amazon Simple Storage Service (Amazon S3). \n\nThe S3 procedure can be used for object management functions. For example, you can create buckets \nand add files to S3 with the procedure. If you want to analyze data that is in S3, then this is not \nthe correct procedure to use. (Hint: You need to use CAS with a caslib that uses S3 as its data source.) \n\nVery important: Before you can use the S3 procedure, you need an AWS key ID and secret.\n\nFor more information about S3, see Amazon's S3 documentation:\nhttp://aws.amazon.com/documentation/s3/"}},{"Name":"TEXTMINE","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TEXTMINE DATA=CAS-libref.data-table < options > ;\n    VARIABLES variable ;\n    TARGET variable ;\n    DOC_ID variable ;\n    PARSE < parse-options > ;\n    SELECT label-list /<GROUP=group-option > KEEP | IGNORE ;\n    SVD < svd-options > ;\n    \nThe TEXTMINE procedure integrates natural language processing and statistical analysis to analyze largescale\ntextual data in SAS Viya. PROC TEXTMINE supports a wide range of fundamental text analysis\nfeatures, which include tokenizing, stemming, part-of-speech tagging, noun group extraction, default or\ncustomized stop lists and start lists, entity parsing, multiword tokens, synonym lists, term weighting, termby-\ndocument matrix creation, and dimension reduction by term filtering and singular value decomposition\n(SVD)."}},{"Name":"TMSCORE","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TMSCORE DATA=CAS-libref.data-table < options > ;\n    VARIABLES variable ;\n    DOC_ID variable ;\n    \nThe TMSCORE procedure scores textual data in SAS Viya. In text mining, scoring is the process of applying\nparsing and singular value decomposition (SVD) projections to new textual data. The TMSCORE procedure\nperforms this scoring of new documents, and its primary outputs are the Outparent data table (which holds\nthe parsing results of the term-by-document matrix) and the Outdocpro data table (which holds the reduced\ndimensional representation of the score collection). PROC TMSCORE uses some of the output data tables of\nthe TEXTMINE procedure as input data to ensure consistency between scoring and training. During scoring,\nthe new textual data must be parsed using the same settings that the training data were parsed with, indexed\nusing only the subset of terms that were used during training, and projected onto the reduced-dimensional\nsubspace of the singular value decomposition that was derived from the training data. To facilitate this\nprocess, you specify the CONFIG=, TERMS=, and SVDU= options in PROC TEXTMINE to create three\ndata tables (Outconfig, Outterms, and Svdu, respectively), and then you specify those three data tables as\ninputs to PROC TMSCORE."}},{"Name":"TREESPLIT","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TREESPLIT < options > ;\n    AUTOTUNE < options > ;\n    CLASS variables;\n    CODE FILE=filename ;\n    FREQ variable ;\n    GROW criterion < options > ;\n    MODEL response = variable. . . ;\n    OUTPUT OUT=CAS-libref.data-table output-options ;\n    PARTITION < partition-options > ;\n    PRUNE prune-method < (prune-options) > ;\n    WEIGHT variable;\n    INPUT variables </ option>;\n    TARGET variable </ options>;\n    \nThe TREESPLIT procedure builds tree-based statistical models for classification and regression in SAS Viya.\nThe procedure produces a classification tree, which models a categorical response, or a regression tree, which\nmodels a continuous response. Both types of trees are referred to as decision trees, because the model is\nexpressed as a series of if-then statements. For each type of tree, you specify a response variable (also called\na target variable), whose values you want PROC TREESPLIT to predict, and one or more input variables\n(called predictor variables), whose values the procedure uses to predict the values of the target variable."}},{"Name":"VARIMPUTE","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC VARIMPUTE DATA=CAS-libref.data-table < options > ;\n    CODE FILE=filename ;\n    FREQ variable ;\n    INPUT variables < /option > ;\n    OUTPUT OUT=CAS-libref.data-table < option > ;\n    \nThe VARIMPUTE procedure executes high-performance numeric variable imputation. Imputation is a\ncommon step in data preparation. The VARIMPUTE procedure takes only numeric variables.\n\nThe VARIMPUTE procedure can replace numeric missing values with a specified value. It can also replace\nnumeric missing values with the mean, median, or some random value between the minimum value and the\nmaximum value of the nonmissing values."}},{"Name":"VARREDUCE","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC VARREDUCE < options > ;\n    CLASS variable < (options) >: : :< variable < (options) > > < / global-options > ;\n    DISPLAY < table-list > < /options > ;\n    DISPLAYOUT table-spec-list < /options > ;\n    REDUCE UNSUPERVISED effects < / reduce-options > ;\n    REDUCE SUPERVISED response : : :< response > = effects < / reduce-options > ;\n    FREQ variable ;\n\nThe VARREDUCE procedure is a high-performance procedure that performs both supervised and unsupervised\nvariable selection on the SAS appliance. You can use the VARREDUCE procedure to read data in\ndistributed form and perform variable selection in parallel in single-machine mode or distributed mode.\n\nThe VARREDUCE procedure performs unsupervised variable selection by identifying a set of variables\nthat jointly explain the maximum amount of data variance. Unlike principal component analysis (PCA),\nwhich reduces dimensionality by generating a set of new variables (variable extraction), the VARREDUCE\nprocedure reduces dimensionality by selecting a subset of the original variables (variable selection). \nThus, this technique preserves model interpretation."}},{"Name":"MDSUMMARY","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MDSUMMARY DATA=libref.table-name <NTHREADS=integer>; \n    VAR <variable-list>; \n    OUTPUT <OUT=table-name>; \n    GROUPBY variable-list </ OUT=table-name>; \n  \nThe MDSUMMARY procedure computes basic descriptive statistics for variables across all observations \nor within groups of observations in parallel for data tables stored in SAS Cloud Analytic Services (CAS). \nThe MDSUMMARY procedure uses CAS tables and capabilities, ensuring full use of parallel processing."}},{"Name":"CCOPULA","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CCOPULA options;\n    BY variables;\n    DEFINE name copula-type <( parameter-value-options \u2026)> ;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    FIT type <NAME=name > <INIT=(parameter-value-options)> / options;\n    SIMULATE < copula-name-list > / options;\n    VAR variables;\n    VIEWSTORE / options ;\n    \nA multivariate distribution for a random vector contains a description of both the marginal distributions \nand their dependence structure. A copula approach to formulating a multivariate distribution provides a \nway to isolate the description of the dependence structure from the marginal distributions. A copula is \na function that combines marginal distributions of variables into a specific multivariate distribution. \nAll of the one-dimensional marginals in the multivariate distribution are the cumulative distribution \nfunctions of the factors. Copulas help perform large-scale multivariate simulation from separate models, \neach of which can be fitted using different, even nonnormal, distributional specifications."}},{"Name":"CCDM","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CCDM options;\n    BY variable-list;\n    SEVERITYMODEL severity-model-list </ definition-option>;\n    EXTERNALCOUNTS COUNT=frequency-variable <ID=replication-id-variable>;\n    OUTPUT OUT=SAS-data-set <variable-name-options> </ out-option>;\n    OUTSUM OUT=SAS-data-set\u2004statistic-keyword<=variable-name>\u2004<\u2026statistic-keyword<=variable-name>>\u2004<outsum-options>;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    Programming statements ;\n    \n In many loss modeling applications, the loss events are analyzed by modeling the severity (magnitude) \n of loss and the frequency (count) of loss separately. The primary goal of preparing these models is to \n estimate the aggregate loss\u2014that is, the total loss that occurs over a period of time for which the \n frequency model is applicable. For example, an insurance company might want to assess the expected \n and worst-case losses for a particular business line, such as automobile insurance, over an entire \n year given the models for the number of losses in a year and the severity of each loss. A bank might \n want to assess the value-at-risk (VaR), a measure of the worst-case loss, for a portfolio of assets \n given the frequency and severity models for each asset type."}},{"Name":"CMDC","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CMDC <options>;\n    BY variables;\n    CLASS variable <(options)> <variable <(options)>> </ global-options>;\n    FREQ variable;\n    WEIGHT variable;\n    ID variables;\n    CHOICEID variables;\n    TIMEID <variables>;\n    MODEL dependent-variable = regressors </ model-options>;\n    MIXED <normal=variables> <uniform=variables> <lognormal=variables>; \n    OUTPUT <OUT=SAS-data-set> <keyword <=name>>\u2026\n      <keyword <=name>> </ options>;\n    INIT initialization1 < , initialization2 \u2026>;\n    BOUNDS bound1 [ , bound2 \u2026];\n    RESTRICT restriction1 [, restriction2 \u2026];\n    \nThe CMDC (Cloud-enabled Multinomial Discrete Choice) procedure is a cloud-enabled procedure that fits \nbinary and multinomial discrete choice models. Discrete choice models, also known as consumer choice \nmodels, qualitative choice models, are econometric models that describe and explain choices over time \namong a finite set of discrete alternatives. The decision makers could be consumers, households, firms \nor other agents. For example, a customer chooses which of several competing products to buy; a firm \ndecides which suppliers to use; a traveler decides which mode of transportations to reach a destination; \na high-school senior decides which colleges to attend."}},{"Name":"CNTSELECT","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CNTSELECT <options>;\n    BOUNDS bound1 [ , bound2 \u2026];\n    BY variables;\n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options>;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    DISPMODEL dependent variable  <dispersion-related regressors>;\n    EFFECT name=effect-type(variables </ options>);\n    FREQ freq-variable;\n    INIT initialization1 < , initialization2 \u2026>;\n    MODEL dependent-variable = regressors </ options>;\n    OUTPUT <output-options>;\n    RESTRICT restriction1 [, restriction2 \u2026];\n    SELECTION <METHOD=method <(method-options)>><options>;\n    TEST equation1 <, equation2\u2026> / <test-options>;\n    VIEWSTORE / options ;\n    WEIGHT variable </ option>;\n    ZEROMODEL dependent-variable  zero-inflated-regressors </ options>;\n    \nThe CNTSELECT (count regression) procedure analyzes regression models in which the dependent variable \ntakes nonnegative integer or count values. The dependent variable is usually an event count, which \nrefers to the number of times an event occurs. For example, an event count might represent the number \nof ship accidents per year for a given fleet."}},{"Name":"CPANEL","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CPANEL <options>;\n    BY variables;\n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options> ;\n    COMPARE <model-list> </ options>;\n    CORRELATED effects;\n    ENDOGENOUS effects </ option>;\n    ID cross-section-id <time-series-id>;\n    INSTRUMENTS effects </ option>;\n    MODEL response = <effects> </ options>;\n    OUTPUT OUT=CAS-libref.data-table <options>;\n    PREDETERMINED effects </ option>;\n    RESTRICT equation1 <, equation2\u2026>;\n    TEST equation1 <, equation2\u2026>;\n    \nThe CPANEL procedure analyzes a class of linear econometric models that arise when time series \nand cross-sectional data are combined. This type of data is called panel data. Typical examples \nof panel data include observations over time on people, households, countries, or firms. For \nexample, in the case of survey data on household income, the panel is created by repeatedly \nsurveying the same households over many years. The individual entities that are followed over \ntime are called cross sections."}},{"Name":"CQLIM","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CQLIM options;\n    BOUNDS bound1 < , bound2 \u2026> ;\n    BY variables;\n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options> ;\n    FREQ variable;\n    ENDOGENOUS variables  options;\n    HETERO dependent-variables  exogenous-variables / options;\n    INIT initvalue1 < , initvalue2 \u2026> ;\n    MODEL dependent-variables = regressors / options;\n    OUTPUT OUT=SAS-data-set <output-options> ;\n    RESTRICT restriction1 < , restriction2 \u2026> ;\n    TEST options;\n    WEIGHT variable </ option>;\n\nThe CQLIM procedure is a version of the QLIM procedure in SAS/ETS software that requires SAS Cloud \nAnalytic Services in order to run. Both procedures analyze univariate limited dependent variable \nmodels in which dependent variables take discrete values or are observed within only a limited \nrange of values. Unlike the QLIM procedure, which can be run only on a single workstation, the \nCQLIM procedure takes advantage of a distributed computing environment that enables it to distribute\nthe optimization task to one or more nodes. In addition, each node can use one or more threads to \nperform the optimization on its subset of the data. When several nodes are used and each node uses \nseveral threads to carry out its part of the work, the result is a highly parallel computation that \ncan provide a dramatic gain in performance."}},{"Name":"CSPATIALREG","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CSPATIALREG <options>; \n    BOUNDS bound1 [ , bound2 \u2026]; \n    BY variables; \n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options>; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    INIT initialization1 < , initialization2 \u2026>; \n    MODEL dependent-variable = regressors </ options>; \n    OUTPUT <output-options>; \n    RESTRICT restriction1 [, restriction2 \u2026]; \n    TEST equation1 <, equation2\u2026> / <test-options>; \n    SPATIALEFFECTS <model-spatial-effect-regressors>; \n    SPATIALID variable; \n    \nThe CSPATIALREG (spatial regression) procedure analyzes a class of spatial linear econometric models \nfor cross-sectional data whose observations are spatially referenced or georeferenced. For example, \nhousing price data that are collected from 48 continental states in the United States fall into the \ncategory of spatially referenced data. Compared to nonspatial regression models, spatial econometric \nmodels are capable of handling spatial interaction and spatial heterogeneity in a regression setting \n(Anselin 2001)."}},{"Name":"HMM","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HMM options; \n    DECODE options; \n    ESTIMATE options; \n    EVALUATE options; \n    FILTER options; \n    FORECAST options; \n    ID TIME= variable <SECTION= variable>; \n    INITIAL equation, \u2026, equation; \n    MODEL dependents < = regressors > < / options > ; \n    OPTIMIZE options; \n    PRIOR equation, \u2026, equation; \n    SCORE options; \n    SMOOTH options; \n    \nThe HMM procedure supports hidden Markov models (HMMs), which have been widely applied in economics, \nfinance, science, and engineering. The HMM has many well-known aliases, such as the general state \nspace model (GSSM), regime-switching model (RSM), Markov-switching model (MSM), and Markov regime-\nswitching model (MRSM). This procedure supports the Gaussian hidden Markov model (Gaussian HMM)."}},{"Name":"SEVSELECT","Type":"ECONOMETRICS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SEVSELECT options; \n    BY variable-list; \n    LOSS <response-variable> </ censoring-truncation-options>; \n    WEIGHT weight-variable; \n    DIST distribution-name-or-keyword <(distribution-option)<distribution-name-or-keyword <(distribution-option)>> \u2026> </ options>; \n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options>; \n    EFFECT name=effect-type(variables </ options>); \n    SCALEMODEL regression-effect-list </ scalemodel-options>; \n    SELECTION <METHOD=method <(method-options)>><options>; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    OUTPUT <OUT=CAS-libref.data-table> output-options; \n    OUTSCORELIB <OUTLIB=> fcmp-library-name options; \n    NLOPTIONS options; \n    Programming statements ; \n    \nThe SEVSELECT procedure estimates parameters of any arbitrary continuous probability distribution that \nis used to model the magnitude (severity) of a continuous-valued event of interest. Examples of such \nevents include loss amounts paid by an insurance company and demand of a product as depicted by its sales. \nPROC SEVSELECT is especially useful when the severity of an event does not follow typical distributions \n(such as the normal distribution) that are often assumed by standard statistical methods."}},{"Name":"TSRECONCILE","Type":"FORECASTING_PROCEDURE","Help":{"#cdata":"Syntax: PROC TSRECONCILE <options> ;\n    BY variables;\n    ID variable </options>;\n    CHILDROLES <options>;\n    PARENTROLES <options>;\n    \nThe TSRECONCILE procedure reconciles forecasts of timestamped data at two different levels of \na hierarchy in a top-down fashion for input data that are contained in CAS tables.\n\nWhen data are organized in a hierarchical fashion, there are often accounting constraints that \nlink the data at different levels of the hierarchy. Typically, for any particular time period, \nthe data in a parent node are either the sum or the average of the data of its child nodes. For \nexample, the total sales of a product by a retail company are the sum of the sales of the same \nproduct in all its stores."}},{"Name":"TSMODEL","Type":"FORECASTING_PROCEDURE","Help":{"#cdata":"Syntax: PROC TSMODEL options;\n    BY variables;\n    ID variable INTERVAL=interval <options>;\n    OUTARRAYS array-name-list;\n    OUTSCALARS scalar-name-list;\n    INSCALARS scalar-name-list;\n    VAR variable-list / options;\n    REQUIRE package-list;\n    PRINT print-options;\n    SUBMIT <FILE= SAS-file-ref | 'File-path'> <submit-options>;\n    Program Statements ;\n    ENDSUBMIT ;\n    \nThe TSMODEL procedure is a SAS Viya procedure that executes user-defined programs on time series data. \nThe TSMODEL procedure analyzes timestamped transactional data with respect to time and accumulates the \ndata into a time series format."}},{"Name":"OPTNETWORK","Type":"OPTIMIZATION_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTNETWORK <options>; \n    BY variables; \n    DISPLAY <table-list> </ options>; \n    DISPLAYOUT table-spec-list </ options>; \n    LINKSVAR <options>; \n    NODESVAR <options>; \n    NODESSUBSETVAR <options>; \n    BICONNECTEDCOMPONENTS ; \n    CLIQUE <options>; \n    CONNECTEDCOMPONENTS <options>; \n    CYCLE <options>; \n    LINEARASSIGNMENT <options>; \n    MINCOSTFLOW <options>; \n    MINCUT <options>; \n    MINSPANTREE <options>; \n    PATH <options>; \n    SHORTESTPATH <options>; \n    SUMMARY <options>; \n    TRANSITIVECLOSURE <options>; \n    TSP < options >;\n    \nThe OPTNETWORK procedure includes a number of graph theory and network optimization algorithms \nthat can augment more generic mathematical optimization approaches. Many practical applications \nof optimization depend on an underlying network. For example, retailers face the problem of \nshipping goods from warehouses to stores in a distribution network to satisfy demand at minimum \ncost. Commuters choose routes in a road network to travel from home to work in the shortest amount \nof time.]"}},{"Name":"OPTNET","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC OPTNET options ;\n    DATA_LINKS_VAR < options >;\n    DATA_MATRIX_VAR <column1,column2,...>;\n    DATA_NODES_VAR < options >;\n    BICONCOMP < option >;\n    CLIQUE < options >;\n    CONCOMP < options >;\n    CYCLE < options >;\n    LINEAR_ASSIGNMENT < options >;\n    MINCOSTFLOW < options >;\n    MINCUT < options >;\n    MINSPANTREE < options >;\n    SHORTPATH < options >;\n    TRANSITIVE_CLOSURE < options >;\n    TSP < options >;\n    PERFORMANCE < options >;\n\nYou can use the OPTNET procedure to analyze relationships between entities. These relationships \nare typically defined by using a graph. A graph G = (N,A) is defined over a set N of nodes and \na set A of arcs. A node is an abstract representation of some entity (or object), and an arc defines \nsome relationship (or connection) between two nodes. The terms node and vertex are often interchanged \nin describing an entity. The term arc is often interchanged with the term edge or link when describing \na connection."}},{"Name":"SGPIE","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SGPIE <option(s)>; \n    DONUT category-variable </option(s)> ; \n    KEYLEGEND </option(s)>; \n    PIE category-variable</option(s)>\n    STYLEATTRS </option(s)>\n    \nThe SGPIE procedure produces pie charts and donut charts. The angles of pie and donut slices \nare used to graphically represent the value of a statistic for a data range. The charts are \nuseful for examining how the values of a variable contribute to the whole and for quickly \ncomparing the values of several variables. \n\nNote: The SGPIE procedure is a preproduction feature in the SAS 9.4M6 release, which means \nthat it has not been fully developed, tested, or documented."}},{"Name":"BNET","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC BNET <options>;\n  AUTOTUNE <options>;\n  CODE FILE=filename;\n  FREQ variable;\n  ID variables;\n  INPUT variables </LEVEL=INTERVAL | NOMINAL > ;\n  OUTPUT OUT=CAS-libref.data-table <option>;\n  PARTITION partition-option;\n  SAVESTATE RSTORE=CAS-libref.data-table;\n  TARGET variable;\n  \nThe BNET procedure learns a Bayesian network from an input data table in SAS Viya. \nA Bayesian network is a directed acyclic graphical model in which nodes represent \nrandom variables and the links between nodes represent conditional dependency of \nthe random variables. Because the Bayesian network provides conditional independence \nstructure and a conditional probability table at each node, the model has been used \nsuccessfully as a predictive model in supervised data mining."}},{"Name":"NETWORK","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC NETWORK <options>;   \n    BY variables;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    LINKSVAR <options>; \n    NODESVAR <options>; \n    NODESSUBSETVAR <options>;\n    BICONNECTEDCOMPONENTS;\n    CENTRALITY < options >;\n    CLIQUE <options>; \n    CONNECTEDCOMPONENTS <options>;\n    CORE < options >;\n    CYCLE <options>; \n    REACH < options >;\n    SHORTESTPATH <options>; \n    SUMMARY <options>; \n    TRANSITIVECLOSURE <options>;\n    \nThe NETWORK procedure includes a number of graph theory and network analysis algorithms that can \naugment data mining and machine learning approaches. In many practical applications of data mining \nand machine learning models, pairwise interaction between the entities of interest in the model often \nplays an important role. For example, when you are modeling churn in a telecommunications network to \nsupport a retention campaign, the influence of individual customers on the other customers\u2014such as \nfriends and acquaintances that they regularly interact with\u2014might contribute to the propensity of other \ncustomers to churn. You could likewise imagine a customer being able to influence the propensity of his \nor her acquaintances to acquire new products. Social networks such as Facebook and Twitter are obvious \nexamples of networks that represent such interactions between individuals."}},{"Name":"FASTKNN","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FASTKNN <options>;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    ID variables;\n    INPUT variables <LEVEL=INTERVAL>;\n    OUTPUT OUT=CAS-libref.data-table <options>;\n    \nThe FASTKNN procedure implements the k-nearest neighbor (k-NN) search algorithm in SAS Viya. \nThe k-NN algorithm has numerous applications, including recommendation systems, image search, \nfingerprint recognition, and clustering. You can use the FASTKNN procedure to read and write \ndata in distributed form, and to perform search in parallel by making full use of multicore \ncomputers or distributed computing environments."}},{"Name":"FISM","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FISM options;\n    CUSTOMER variables;\n    OUTPUT options;\n    TARGET variable;\n    \nThe FISM procedure performs frequent item set mining, which looks for frequent patterns in a large \ndatabase. The FISM procedure finds frequent patterns by using the FP-growth (frequent-pattern growth) \nalgorithm of Han, Pei, and Yin (2000). The FP-growth algorithm uses a special data structure called \nthe frequent-pattern tree (FP-tree), which retains the item set association information. \n\nThe FISM procedure is used by other procedures such as the MBANALYSIS procedure for association rule \nmining."}},{"Name":"GMM","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GMM <options>;\n    DISPLAY <table-list> </options>;\n    DISPLAYOUT <table-spec-list> </options>;\n    INPUT variables;\n    SCORE OUT=CAS-libref.data-table <options>;\n    SAVESTATE RSTORE=CAS-libref.data-table <option>;\n    \nThe GMM procedure performs clustering\u2014a common step in data exploration\u2014on quantitative data in SAS Viya.\n\nYou can use this procedure to read and write data in distributed form, as well as to perform clustering \nand scoring in parallel by making full use of multicore computers or a distributed computing environment.\n\nPROC GMM performs cluster analysis by using the Gaussian mixture model (GMM), which is a probabilistic \nmodel that assumes that all the data points are generated from a mixture of Gaussian distributions. This \nmodel can be regarded as generalizing k-means clustering to incorporate information about the covariance \nstructure of the data as well as the centers of the latent Gaussians."}},{"Name":"MBANALYSIS","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MBANALYSIS options;\n    CUSTOMER variables;\n    HIERARCHY DATA=CAS-libref.data-table <CAS-libref.data-table...>;\n    OUTPUT options;\n    SAVESTATE RSTORE=CAS-libref.data-table;\n    TARGET variable;\n    \nThe MBANALYSIS (market basket analysis) procedure performs association rule mining on a transaction \ndatabase. Association rules are in the form of if A then B, where A and B are items in the transaction \ndatabase. Association rules helps determine association or correlation between various items in a database. \nThese rules are used for finding the latest trends and patterns in data and also help in business decision-\nmaking processes. The MBANALYSIS procedure uses the frequent-pattern growth (FP-growth) algorithm of \nHan, Pei, and Yin (2000) for finding frequent item sets and then generates rules that are based on \nthese frequent item sets."}},{"Name":"GVARCLUS","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC GVARCLUS <options>;\n    DISPLAY <table-list> </options>;\n    DISPLAYOUT table-spec-list </options>;\n    INPUT variables <LEVEL= INTERVAL | NOMINAL>;\n    FREQ variable;\n\nThe GVARCLUS procedure performs variable clustering and graphical modeling in SAS Viya. The procedure \ndivides a set of variables into disjoint clusters and creates tables that contain the edge and vertex \ninformation for defining an undirected graph. Variables in different clusters are conditionally independent \ngiven their own clusters. The procedure also provides the edge and vertex information for an undirected \ngraphical model; this information expresses the relationships among all the variables. A regularization \nparameter is used to control the sparsity of connections among variables. Tuning the regularization \nparameter from low to high increases the number of disconnected components and splits larger clusters \ninto smaller ones. Those divided clusters naturally form a hierarchical structure during this process."}},{"Name":"MTLEARN","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MTLEARN <options>;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    INPUT variables <LEVEL=INTERVAL>;\n    TARGET variables <LEVEL=INTERVAL>;\n    OUTPUT OUT=CAS-libref.data-table <options>;\n    SAVESTATE RSTORE=CAS-libref.data-table <options>;\n    \nThe MTLEARN procedure implements the multitask learning technique for least squares loss with \u1d251 \nand graph structure penalizations. It solves multiple related sparse linear regression problems \nsimultaneously. A graph structure encodes the relationships between the problems. PROC MTLEARN \nshares the data and model parameters among different regression problems and solves the problems \nsimultaneously in order to produce a more robust and accurate predictive model. When used with \nindependent graph tables, PROC MTLEARN also serves as an elastic net regularization solver, which \nis widely used in feature selection."}},{"Name":"SEMISUPLEARN","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SEMISUPLEARN <options>;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    INPUT variables / <LEVEL=INTERVAL>;\n    OUTPUT OUT=CAS-libref.data-table <options>;\n    TARGET variables / <LEVEL=NOMINAL>;\n    \nThe SEMISUPLEARN procedure implements the graph-based semisupervised learning algorithm that relies \non label spreading in a distributed framework in SAS Viya. The semisupervised learning algorithm has \nnumerous applications, including web page classification, image recognition, medical imaging, natural \nlanguage processing, and action recognition.\n\nYou can use the SEMISUPLEARN procedure to read and write data in distributed form and to perform search \nin parallel by making full use of multicore computers or distributed computing environments."}},{"Name":"TSNE","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC TSNE <options>;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    INPUT variables;\n    OUTPUT OUT=CAS-libref.data-table <options>;\n    \nThe TSNE procedure implements the t-distributed stochastic neighbor embedding (t-SNE) dimension \nreduction method in SAS Viya. The t-SNE method is well suited for visualization of high-dimensional \ndata, as well as for feature engineering and preprocessing for subsequent clustering and modeling. \nPROC TSNE computes a low-dimensional representation, also called an embedding, of high-dimensional \ndata into two or three dimensions. Unlike other dimension reduction methods, such as principal \ncomponent analysis, t-SNE is appropriate for nonlinear data and emphasizes existing groupings in \nthe data. The method is named t-SNE because it models the pairwise distances in low dimensions \naccording to Student\u2019s t-distribution."}},{"Name":"ICA","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC ICA <options>;\n    BY variables;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    OUTPUT OUT=CAS-libref.data-table\n      <COPYVARS=(variables)>\n      <keyword <=prefix>>\u2026<keyword <=prefix>>;\n    VAR variables;\n    \nThe ICA procedure performs independent component analysis in SAS Viya.\n\nIndependent component analysis attempts to extract from the observed multivariate data independent \ncomponents (also called factors or latent variables) that are as statistically independent from each \nother as possible. The methods that PROC ICA implements, where statistical independence is defined \nas the maximization of non-Gaussianity, seek linear combinations of the observed random variables \nthat maximize the non-Gaussianity of the estimated independent components."}},{"Name":"MBC","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MBC <options>;\n    BY variables;\n    VAR variables;\n    INIT variables;\n    OUTPUT OUT=CAS-libref.data-table < <=name>>\u2026<keyword <=name>> <options>;\n    DISPLAY <options>;\n    DISPLAYOUT <options>;\n    STORE <options>;\n    \nThe MBC procedure fits mixtures of multivariate Gaussian and uniform distributions to achieve \nunsupervised and semisupervised clustering of data. It treats the cluster memberships as missing \ndata and uses the expectation-maximization (EM) algorithm to maximize the likelihood. The procedure \ncan produce output data tables that contain cluster membership weights and component log likelihoods. \nPROC MBC can also store the fitted model for scoring subsequent input data."}},{"Name":"MODELMATRIX","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC MODELMATRIX <options>;\n    BY variables;\n    CLASS variable <(options)>\u2026<variable <(options)>> </ global-options>;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    EFFECT name = effect-type (variables </ options>);\n    FREQ variable;\n    MODEL dependent = <effects> </ model-options>;\n    OUTPUT OUT= CAS-libref.data-table </ options>;\n    WEIGHT variable;\n    \nThe MODELMATRIX procedure creates a design matrix (matrix of covariates) that is associated \nwith a user-specified MODEL statement and a user-specified data table in SAS Viya.\n\nThe design matrix is the fundamental component of any regression model; it is often expressed \nas the X matrix."}},{"Name":"LMIXED","Type":"CAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LMIXED <options>;\n    CLASS variable <(options )> <variable <(options)>> </ global-options>;\n    BY variables;\n    DISPLAY <table-list> </ options>;\n    DISPLAYOUT table-spec-list </ options>;\n    EFFECT name=effect-type (variables </ options>);\n    MODEL dependent = <fixed-effects> </ options>;\n    RANDOM random-effects </ options>;\n    PARMS <(value-list) \u2026> </ options>;\n    WEIGHT variable;\n    OUTPUT OUT=CAS-libref.data-table<COPYVARS=(variables)><keyword <=name>>\u2026<keyword <=name>>;\n    BLUP OUT=CAS-libref.data-table <options>;\n    OPTIMIZATION <options>;\n    \nThe LMIXED procedure fits a variety of linear mixed models to data and enables you to use these fitted \nmodels to make statistical inferences about the data. A linear mixed model is a generalization of the \nstandard linear model that is used in the GLM procedure in SAS/STAT software; the generalization is that \nthe data are permitted to exhibit correlation and nonconstant variability. Therefore, the linear mixed \nmodel provides you with the flexibility of modeling not only the means of your data (as in the standard \nlinear model) but also their variances and covariances."}},{"Name":"CAUSALMED","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC CAUSALMED <options>; \n    CLASS variables <(options)> \u2026<variable<(options)>> </ global-options>; \n    MODEL outcome=effects </ model-options>; \n    MEDIATOR mediator=treatment; \n    COVAR effects; \n    EVALUATE <'label'> assignment <assignment \u2026> </ options>; \n    BOOTSTRAP <options>; \n    FREQ variable; \n    BY variables; \n    \nThe CAUSALMED procedure estimates causal mediation effects from observational data. In causal \nmediation analysis, there are four main variables of interest: \n\no an outcome variable Y \no a treatment variable T that is hypothesized to have direct and indirect causal effects on the \n  outcome variable Y (in epidemiology, a treatment variable is also known as an exposure, denoted as A) \no a mediator variable M that is hypothesized to be causally affected by the treatment variable T and \n  that itself has a direct effect on the outcome variable Y \no set of pretreatment or background covariates that confound the observed relationships among Y, T, and M"}},{"Name":"DSTODS2","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DSTODS2 IN=datastep-program-filename OUT=ds2-program-filename <OUTDIR=\"output-directory-name\">\n    RUN; \n    <QUIT;>\n    \nThe DSTODS2 procedure enables you to translate a subset of your SAS DATA step code into DS2 code. \nThen you can revise your program to take advantage of DS2 features and submit your program using \nPROC DS2."}},{"Name":"FMTC2ITM","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC FMTC2ITM <options>; \n    <SELECT member-list>; \n    \nThe FMTC2ITM procedure converts one or more format catalogs into a single item store that can be made \navailable to CAS. PROC FMTC2ITM enables you to create an item store that has the following contents: \n\n  o all of the formats from one catalog \n  o a subset of the formats from one catalog \n  o all of the formats from multiple catalogs \n  o a subset of the formats from each of multiple catalogs."}},{"Name":"PRODUCT_STATUS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC PRODUCT_STATUS; \n  RUN;\n  \nPROC PRODUCT_STATUS returns a list of the SAS Foundation products that are installed on your system, \nalong with the version numbers of those products. It provides a quick method to determine whether a \nSAS product is available for your use. The results from PROC PRODUCT_STATUS are returned to the SAS \nlog."}},{"Name":"SCOREACCEL","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SCOREACCEL SESSREF=session-name | SESSUUID=\"session-uuid\"; \n    PUBLISHMODEL required-arguments <publish-model-options>; \n    RUNMODEL required-arguments <run-model-options>; \n    DELETEMODEL required-arguments <delete-model-options>; \n    \nPROC SCOREACCEL provides an interface to the CAS server for DATA step and DS2 model publishing \nand scoring. \n\nModels can be published and executed in CAS, or in an external database: \n  o DATA step and DS2 model code can be published to a CAS table and executed in CAS \n  o Model code can be published from CAS to an external database and then executed there via the \n    SAS Embedded Process (EP). Teradata and Hadoop are supported."}},{"Name":"SQOOP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SQOOP <Sqoop-options>; \n  RUN;\n  \nYou can use Apache Sqoop (pronounced scoop) to transfer data between Hadoop and relational database \nmanagement systems (RDBMSs). You can use the SQOOP procedure to access Apache Sqoop from a SAS session \nto transfer data between a database and HDFS. It lets you submit Sqoop commands from within your SAS \napplication to your Hadoop cluster."}},{"Name":"LUA","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC LUA <INFILE='filename'> <RESTART> <TERMINATE>; \n    <SUBMIT <\"assignment(s);\">;> \n      Lua statements\n    <ENDSUBMIT;>\n    run; \n    \nPROC LUA enables you to perform these tasks: \n  o run Lua code within a SAS session \n  o call most SAS functions within Lua statements \n  o call PROC FCMP functions within Lua statements \n  o submit SAS code from Lua \n  o call CAS actions \n    Note: Support for calling CAS actions was added in SAS 9.4M5. \n  o read VARCHAR data. \n    Note: Support for VARCHAR data was added in SAS Viya 3.3."}},{"Name":"HDMD","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC HDMD <Hadoop-metadata-options>; \n    COLUMN column-specification(s) ; \n    RUN;\n    \nUse PROC HDMD to generate XML-based metadata that describes the contents of files that are stored \nin HDFS. This metadata enables SAS/ACCESS Interface to Hadoop, SAS/ACCESS Interface to Spark, and \nSAS high-performance procedures to read Hadoop data directly without an intermediate metadata \nrepository such as Hive."}},{"Name":"SGMAP","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC SGMAP MAPDATA=map-data-set | PLOTDATA=plot-data-set | MAPRESPDATA=response-data-set\n      </option(s)>; \n    BUBBLE X=variable Y=variable SIZE=numeric-variable </option(s)>;\n    CHOROMAP <response-variable > / </option(s)>; \n    ESRIMAP URL=\u2018map-service\u2019;\n    GRADLEGEND <\"name\"> </option(s)>;\n    KEYLEGEND <\"name\u20131\" ...\"name-n\"> </option(s)>;\n    OPENSTREETMAP;\n    SCATTER X=variable Y=variable </option(s)>;\n    SERIES X=variable Y=variable </option(s)>;\n    TEXT X=variable Y=variable TEXT=variable </option(s)>;\n\nStarting with SAS 9.4M6, Base SAS offers an enhanced SGMAP mapping procedure. The SGMAP procedure \nadds the GRADLEGEND and SERIES statements, and numerous options. The CHOROMAP statement is at production \nlevel. The SGMAP procedure can now render maps with unprojected longitude and latitude coordinates. \nIt can also render maps whose data is prepared by any number of Base SAS mapping procedures such as \nGPROJECT. Prior to SAS 9.4M6, GRPROJECT and other mapping data preparation procedures were provided \nwith SAS/GRAPH, and required a SAS/GRAPH installation to run them. Starting with SAS 9.4M6, the GINSIDE, \nGPROJECT, GREDUCE, and GREMOVE procedures that prepare data for mapping moved from SAS/GRAPH to Base SAS. \nAfter your map data sets are obtained and prepared, use the SGMAP procedure to create maps and then overlay \nplots such as bubble, scatter, series, or text plots. With the enhanced SGMAP procedure, automatic legends \nare now generated, and the option that disables them is provided. Continuous or discrete legends are now \npossible, as well as legend customization, grouping capability, and the ability to customize polygon borders \nand series plot lines."}},{"Name":"DATAMETRICS","Type":"SAS_PROCEDURE","Help":{"#cdata":"Syntax: PROC DATAMETRICS DATA=input-data-set-name OUT=output-data-set\n      <FREQUENCIES =frequencies> <MINMAX=minmax> <THREADS=threads>\n      <MEDIAN> \n      <FORMAT>;\n    IDENTITIES <QKB=qkb> <LOCALE=locale> <DEFINITION=definition> <MULTIIDENTITY>;\n    <VARIABLES=list of variables of profile>;\n    \nPROC DATAMETRICS implements data profile capabilities that help you recognize patterns, \nidentify sparsity in the data, generate frequency distributions, and calculate basic statistics. \nData profiling analysis can be applied to any data set that is accessible to SAS. The following \nanalysis capabilities are included:\n\n  o standard profile metrics\n  o frequency distribution per column, limiting results to top n, bottom n\n  o row and columns counts\n  o pattern analysis\n  o identification analysis"}}],"#comment":[{},{},{},{},{},{},{},{},{},{},{},{},{}]}}