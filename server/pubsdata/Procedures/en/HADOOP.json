{"name":"HADOOP","statements":[{"name":"PROC HADOOP","description":"Controls access to the Hadoop server.","help":"PROC HADOOP  <hadoop-server-options>;\n\tHDFS  <hadoop-server-options> <hdfs-command-options>;\n\tMAPREDUCE  <hadoop-server-options> <mapreduce-options>;\n\tPIG  <hadoop-server-options> <pig-code-options>;\n\tPROPERTIES  <configuration-properties>;","arguments":[{"name":"CFG=","optional":true,"aliases":["OPTIONS="],"description":"identifies the Hadoop configuration file to use in order to connect to the Hadoop server.","help":"CFG=*fileref* | '*external-file*'","type":"choice","arguments":[{"name":"fileref","placeholder":true,"description":"specifies the SAS fileref that is assigned to the Hadoop configuration file. To assign a fileref, use the FILENAME statement.","type":"value","supportSiteTargetFragment":"n066ghoe6l5ae6n1fqedgqbx22te"},{"name":"'external-file'","placeholder":true,"description":"is the physical location of the XML document. Include the complete pathname and the filename. The maximum length is 200 characters.","type":"value","supportSiteTargetFragment":"p0jac6w4bzwa4jn1pzc83dcx1dt8"}],"supportSiteTargetFragment":"p1e96gw5slum51n10rw4qcp7m760"},{"name":"MAXWAIT=","optional":true,"description":"specifies the HTTP status response time when using WebHDFS.","help":"MAXWAIT=*wait-interval*","type":"value","supportSiteTargetFragment":"p0f1n5w08emxofn1tfljsb5jniye"},{"name":"PASSWORD=","optional":true,"aliases":["PASS="],"description":"is the password for the user ID on the Hadoop server.","help":"PASSWORD='*password*'","type":"value","supportSiteTargetFragment":"p0rzmljg3tmybln1d8rdye49568o"},{"name":"USERNAME=","optional":true,"aliases":["USER="],"description":"is an authorized user ID on the Hadoop server.","help":"USERNAME='*ID*'","type":"value","supportSiteTargetFragment":"p0w2hqckfcdvj4n1mq4qfgnzie4q"},{"name":"VERBOSE","optional":true,"description":"enables additional messages that are displayed on the SAS log.","type":"standalone","supportSiteTargetFragment":"n15kt0rxrdyd48n12drjo6p062wi"}],"supportSiteTargetFile":"n02m72os18twk1n17a8o6o885598.htm"},{"name":"HDFS","description":"Submits Hadoop Distributed File System (HDFS) commands.","help":"HDFS  &lt;*hadoop-server-options*&gt; &lt;*hdfs-command-options*&gt;;","arguments":[{"name":"CAT=","optional":true,"description":"displays the contents of the specified file or files.","help":"CAT='*HDFS-file*' &lt;ONLY=*n*&gt; &lt;OUT='*output-location*'&gt; &lt;RECURSE&gt; &lt;SHOW_FILENAME&gt;","type":"value","arguments":[{"name":"'HDFS-file'","placeholder":true,"description":"specifies a pathname or a pathname and a filename. You can use wildcard characters to substitute for any other character or characters in the pathname or the filename. Use * to match one or more characters, or ? to match a single character.","type":"value","supportSiteTargetFragment":"p1k16989bfsfwpn1tjvme3ad86iz"},{"name":"ONLY=","description":"displays only the specified number of lines from the beginning of the file. For example, only=10 displays the first ten lines of a file. This option is helpful to determine the contents of a file.","help":"ONLY=*n*","type":"value","supportSiteTargetFragment":"n0cbawe9lqtai5n11x8s5sxd0k3y"},{"name":"OUT=","description":"specifies the output location for the contents, which can be an external file for your machine or a fileref that is assigned with the FILENAME statement. By default, the output location is the SAS log.","help":"OUT='*output-location*'","type":"value","supportSiteTargetFragment":"p10hfkki1k2p9zn173cg9f3y4h0r"},{"name":"RECURSE","description":"specifies to display the contents for all files in the specified pathname and all files that are in subdirectories. RECURSE has no effect if the specified HDFS file is not a directory.","type":"standalone","supportSiteTargetFragment":"p0kxnexh2nmsdrn13rk4aspexwrb"},{"name":"SHOW_FILENAME","description":"includes the name of the file in the output. For example, hdfs cat='/tmp/*.txt' show_filename only=10 recurse; displays in the SAS log the name of the file and the first ten lines of all .txt files that are found in the /tmp directory and all of its subdirectories.","type":"standalone","supportSiteTargetFragment":"n1ecab4473uzy3n1m9pf9fcj20vl"}],"supportSiteTargetFragment":"p1sjxr2xph010kn1kylwtbdfayt7"},{"name":"CHMOD=","optional":true,"description":"changes file access permissions for one or more HDFS files.","help":"CHMOD='*HDFS-file*' PERMISSION=&lt;'&gt;*value*&lt;'&gt; &lt;RECURSE&gt;","type":"value","arguments":[{"name":"'HDFS-file'","placeholder":true,"description":"specifies a pathname or a pathname and a filename. You can use a wildcard character to substitute for any character or characters in the pathname or filename. Use * to match any number of characters, or ? to match a single character.","type":"value","supportSiteTargetFragment":"n167nodf7ggv08n1p6x7dvdorwop"},{"name":"PERMISSION=","description":"specifies a value that represents three levels of permissions, which are owner, group, and user. All three permission levels are required. You can specify the permissions in read, write, and execute (rwx) symbolic notation or octal notation.\n• For the rwx symbolic notation, use nine characters. The first set of three characters represents what the owner can do, the second set represents what a group can do, and the third set represents what a user can do. For each set of three characters, the first position must be r or - (for read), the second position must be w or - (for write), and the third position must be x or - (for execute). For example,  specifies that the owner has Read, Write, and Execute permission, group members have Read and Execute permission, and users have Read and Execute permission. \n• For octal notation, use three digits. Each digit represents the permissions for owner, group, and user. Each digit must be from 0 to 7. The octal notation represents the same numeric value as the rwx symbolic notation. That is, 4 is r, 2 is w, 1 is x, and 0 is -. For example,  specifies that the owner has Read, Write, and Execute permission, group members have Read and Execute permission, and users have Read and Execute permission.","help":"PERMISSION=*value*","type":"value","supportSiteTargetFragment":"p05ja3rz9568epn1eacfv964af9s"},{"name":"RECURSE","description":"specifies to change the access permissions to all files and directories in the specified pathname and all files and directories that are in subdirectories. RECURSE has no effect if the specified HDFS file is not a directory. For example, hdfs chmod='/tmp' permission=755 recurse; changes the permissions to the specified directory and all files and subdirectories within the directory.","type":"standalone","supportSiteTargetFragment":"n1bg9sv3pc1p9xn1u81mz0y52alz"}],"supportSiteTargetFragment":"p1o04c2x0rkp32n1bcofy83sc090"},{"name":"COPYFROMLOCAL=","optional":true,"description":"copies the specified local file to an HDFS output location.","help":"COPYFROMLOCAL='*local-file*' OUT='*output-location*' &lt;DELETESOURCE&gt; &lt;OVERWRITE&gt; &lt;RECURSE&gt; ","type":"value","arguments":[{"name":"'local-file'","placeholder":true,"description":"specifies the complete pathname and the filename. You can use a wildcard character to substitute for any other character or characters in the pathname or the filename. Use * to match any number of characters, or ? to match a single character.","type":"value","supportSiteTargetFragment":"n11cnoars9urkon1mbrjc26oa7ya"},{"name":"OUT=","description":"specifies the output location for the copied file, which is a complete HDFS pathname and the filename.","help":"OUT='*output-location*'","type":"value","supportSiteTargetFragment":"n0u5dvxnarx6ypn1gqn7pm8j31zj"},{"name":"DELETESOURCE","description":"deletes the input source file after a copy command.","type":"standalone","supportSiteTargetFragment":"n1rhrrrve0fip8n1s2bdvgjzj156"},{"name":"OVERWRITE","description":"specifies to overwrite an existing output location.","type":"standalone","supportSiteTargetFragment":"n08o6k1j22xbkvn1t4k72reyrqtn"},{"name":"RECURSE","description":"specifies to copy all the files in the specified pathname and all files that are in subdirectories. RECURSE has no effect if the specified file is not a directory.","type":"standalone","supportSiteTargetFragment":"p03f1kzgplfx67n1va40fujmvnr5"}],"supportSiteTargetFragment":"p0wpgl6cmkbqy3n1tommoaxcs0di"},{"name":"COPYTOLOCAL=","optional":true,"description":"copies the specified HDFS file to a local output location.","help":"COPYTOLOCAL='*HDFS-file*' OUT='*output-location*' &lt;DELETESOURCE&gt; &lt;KEEPCRC&gt; &lt;OVERWRITE&gt; &lt;RECURSE&gt; ","type":"value","arguments":[{"name":"'HDFS-file'","placeholder":true,"description":"specifies the complete pathname and the filename. You can use a wildcard character to substitute for any other character or characters in the pathname or the filename. Use * to match any number of characters, or ? to match a single character.","type":"value","supportSiteTargetFragment":"p0tui1ccmh5atyn1sqgmbnnlgxry"},{"name":"OUT=","description":"specifies the output location for the copied file, which is an external file for your machine.","help":"OUT='*output-location*'","type":"value","supportSiteTargetFragment":"p1x8qux5dw5zl3n1pwhexowuer5w"},{"name":"DELETESOURCE","description":"deletes the input source file after a copy command.","type":"standalone","supportSiteTargetFragment":"n0ljbtb9ovstnsn13y41vo9spzm9"},{"name":"KEEPCRC","description":"saves the Cyclic Redundancy Check (CRC) file after the copy command to a local output location. The CRC file is saved to the same location that is specified in the OUT= option. The CRC file is used to ensure the correctness of the file being copied. By default, the CRC file is deleted.","type":"standalone","supportSiteTargetFragment":"n0uurb5398hkmhn1gbaunnpw2sey"},{"name":"OVERWRITE","description":"specifies to overwrite an existing output location.","type":"standalone","supportSiteTargetFragment":"n010cyyqdkas26n18t9l5cdt6p9h"},{"name":"RECURSE","description":"specifies to copy all the files in the specified pathname and all files that are in subdirectories. RECURSE has no effect if the specified HDFS file is not a directory.","type":"standalone","supportSiteTargetFragment":"p1ezwb61eo0xn1n1e9s3dg4teqxc"}],"supportSiteTargetFragment":"p0k3s8j31nilqen1rked0wrawsug"},{"name":"DELETE=","optional":true,"description":"deletes the specified HDFS file.","help":"DELETE='*HDFS-file*' &lt;NOWARN&gt; ","type":"value","arguments":[{"name":"HDFS-file","placeholder":true,"description":"specifies a pathname or a pathname and a filename. If you include the filename, then only that file is deleted. If you do not include a filename, then all the files in the specified pathname and all the files that are in subdirectories are deleted. You can use a wildcard character to substitute for any other character or characters in the pathname or the filename. Use * to match any number of characters, or ? to match a single character.","type":"value","supportSiteTargetFragment":"n0nemksgww4dson1ilmecwegmajc"},{"name":"NOWARN","description":"suppresses the warning message when there is an attempt to delete a file that does not exist.","type":"standalone","supportSiteTargetFragment":"p0lf2nl9zpy4hun1up2p13in5rkm"}],"supportSiteTargetFragment":"n0nj9w2t8wjxcwn19fp75ec5c3km"},{"name":"LS=","optional":true,"description":"lists the files in the specified HDFS pathname.","help":"LS='*HDFS-pathname*' &lt;OUT=*output-location*&gt;&lt;RECURSE&gt;","type":"value","arguments":[{"name":"HDFS-pathname","placeholder":true,"description":"specifies a pathname. You can use a wildcard character to substitute for any character or characters in the pathname. Use * to match any number of characters, or ? to match a single character.","type":"value","supportSiteTargetFragment":"n155jp4s7vmhm5n1idwkon0yup5y"},{"name":"OUT=","description":"specifies the output location for the list of files, which can be an external file for your machine or a fileref that is assigned with the FILENAME statement. By default, the output location is the SAS log.","help":"OUT=*output-location*","type":"value","supportSiteTargetFragment":"p1sumujf38lzutn1fa3aub3ug1ae"},{"name":"RECURSE","description":"specifies to list the files in the specified pathname and all files that are in subdirectories. RECURSE has no effect if the specified file is not a directory.","type":"standalone","supportSiteTargetFragment":"p0x370nkkpaurhn1dv6uapvwjnyh"}],"supportSiteTargetFragment":"n0etw8uzgiwz8gn1j5geg08ajt3e"},{"name":"MKDIR=","optional":true,"description":"creates the specified HDFS pathname. Specify the complete HDFS pathname.","help":"MKDIR='*HDFS-pathname*'","type":"value","supportSiteTargetFragment":"n100n4rooihwm4n1o3chpxl67563"},{"name":"RENAME=","optional":true,"description":"renames the specified HDFS file.","help":"RENAME='*HDFS-file*' OUT='*output-location*'","type":"value","arguments":[{"name":"'HDFS-file'","placeholder":true,"description":"specifies the pathname and the filename to rename.","type":"value","supportSiteTargetFragment":"p0i8w7jathvsp8n1w1fu55jzc71n"},{"name":"OUT=","description":"specifies the new HDFS pathname and filename.","help":"OUT='*output-location*'","type":"value","supportSiteTargetFragment":"p1tpd6athdfbfln1i7tswkp9pn0m"}],"supportSiteTargetFragment":"n004n1zt69otv2n1jy3j8i5kwwbz"}],"supportSiteTargetFile":"n0sksf47t7lheen11ay3w7490o5x.htm"},{"name":"MAPREDUCE","description":"Submits MapReduce programs into a Hadoop cluster.","help":"\n\tMAPREDUCE <hadoop-server-options> <mapreduce-options>;","arguments":[{"name":"COMBINE=","optional":true,"description":"specifies the name of the combiner class in dot notation.","help":"COMBINE='*class-name*'","type":"value","supportSiteTargetFragment":"n0xwme3pgk3mifn11gvmrwdlfr7f"},{"name":"DELETERESULTS","optional":true,"description":"specifies to delete the output directory, if it exists, before starting the MapReduce job.","type":"standalone","supportSiteTargetFragment":"p0tlgv9uzj3vtcn19zgrnqtuit76"},{"name":"GROUPCOMPARE=","optional":true,"description":"specifies the name of the grouping comparator (GroupComparator) class in dot notation.","help":"GROUPCOMPARE='*class-name*'","type":"value","supportSiteTargetFragment":"p07zp2g8kpwmoen1mki9uj6m50u5"},{"name":"INPUT=","optional":true,"description":"specifies the HDFS pathname to the MapReduce input file.","help":"INPUT='*HDFS-pathname*'","type":"value","supportSiteTargetFragment":"n0ut0ivp9ryls9n1dstx7jofff6t"},{"name":"INPUTFORMAT=","optional":true,"description":"specifies the name of the input format class in dot notation.","help":"INPUTFORMAT='*class-name*'","type":"value","supportSiteTargetFragment":"p1milvxlze95jzn1qtob6ocmpnjy"},{"name":"JAR=","optional":true,"description":"specifies the locations of the JAR files that contain the MapReduce program and named classes.","help":"JAR='*external-file(s)*'","type":"value","supportSiteTargetFragment":"n0qrd2bznbjw0nn1ec7k3tri6o77"},{"name":"MAP=","optional":true,"description":"specifies the name of the map class in dot notation.","help":"MAP='*class-name*'","type":"value","supportSiteTargetFragment":"p1r6akme5i0issn1leo4xte0ly8l"},{"name":"OUTPUT=","optional":true,"description":"when connecting to the Hadoop server, specifies a new HDFS pathname for the MapReduce output.","help":"OUTPUT='*HDFS-pathname*'","type":"value","supportSiteTargetFragment":"p0chbblr161a4sn1hkmkay7k4goe"},{"name":"OUTPUTFORMAT=","optional":true,"description":"specifies the name of the output format class in dot notation.","help":"OUTPUTFORMAT='*class-name*'","type":"value","supportSiteTargetFragment":"p1e3rbr5f4v0han1ft1ejmotuo4p"},{"name":"OUTPUTKEY=","optional":true,"description":"specifies the name of the output key class in dot notation.","help":"OUTPUTKEY='*class-name*'","type":"value","supportSiteTargetFragment":"n1gz4qx7ohs193n165qe7oel5lzs"},{"name":"OUTPUTVALUE=","optional":true,"description":"is the name of the output value class in dot notation.","help":"OUTPUTVALUE='*class-name*'","type":"value","supportSiteTargetFragment":"n1cbnrbt9c15u9n1weqvhp5ej2sw"},{"name":"PARTITIONER=","optional":true,"description":"specifies the name of the partitioner class in dot notation.","help":"PARTITIONER='*class-name*'","type":"value","supportSiteTargetFragment":"n0hnbt2a5wh9gqn1cfpxcikteic8"},{"name":"REDUCE=","optional":true,"description":"specifies the name of the reducer class in dot notation.","help":"REDUCE='*class-name*'","type":"value","supportSiteTargetFragment":"p08xkviijpxdtdn1k2ulysxf73qi"},{"name":"REDUCETASKS=","optional":true,"description":"specifies the number of reduce tasks.","help":"REDUCETASKS=*integer*","type":"value","supportSiteTargetFragment":"p0835svmcz0n4in1fx5qs8agzhn9"},{"name":"REPLACE","optional":true,"description":"when connecting to Hadoop through the Oozie RESTful API, specifies to delete any existing workflow and JAR file(s) in the Oozie application before copying new files to the working directory.","type":"standalone","supportSiteTargetFragment":"p19gippj9sn565n1kyg338w6a1p4"},{"name":"SORTCOMPARE=","optional":true,"description":"specifies the name of the sort comparator class in dot notation.","help":"SORTCOMPARE='*class-name*'","type":"value","supportSiteTargetFragment":"p06k65uv3ob083n1fhfvri7ayc7a"},{"name":"WORKINGDIR=","optional":true,"description":"specifies the name of the HDFS working directory pathname.","help":"WORKINGDIR='*HDFS-pathname*'","type":"value","supportSiteTargetFragment":"n1qdfva246w08sn1wgix2k45hnbg"}],"supportSiteTargetFile":"n1freeyhq2d05en1qodu0x1p8ziu.htm"},{"name":"PIG","description":"Submits Pig language code into a Hadoop cluster.","help":"\n\tPIG  <hadoop-server-options> <pig-code-options>;","arguments":[{"name":"CODE=","optional":true,"description":"specifies the source that contains the Pig language code to execute.","help":"CODE=*fileref* | '*external-file*'","type":"choice","arguments":[{"name":"fileref","placeholder":true,"description":"is a SAS fileref that is assigned to the source file. To assign a fileref, use the FILENAME statement.","type":"value","supportSiteTargetFragment":"p0pynnnqkc4z4hn13xwubyeyylq7"},{"name":"'external-file'","placeholder":true,"description":"is the physical location of the source file. Specify the complete pathname and the filename.","type":"value","supportSiteTargetFragment":"n0b8zrxlhkxasan1ka68izg992zq"}],"supportSiteTargetFragment":"n1inpphq0fpugmn18070g0mevirb"},{"name":"DELETERESULTS","optional":true,"description":"when connecting to the Hadoop server through the Oozie RESTful API, specifies to delete the existing output location before starting the Oozie job.","type":"standalone","supportSiteTargetFragment":"p1djv52fu87u7jn1syneu1wb2ar3"},{"name":"OUTPUT=","optional":true,"description":"when connecting to the Hadoop server through the Oozie RESTful API, specifies the existing output location to delete before starting the Oozie job.","help":"OUTPUT='*HDFS-pathname*'","type":"value","supportSiteTargetFragment":"p1je76eevhd4cgn1w4cla5be3u4x"},{"name":"PARAMETERS=","optional":true,"description":"specifies the source that contains parameters to be passed as arguments when the Pig code executes.","help":"PARAMETERS=*fileref* | '*external-file*'","type":"choice","arguments":[{"name":"fileref","placeholder":true,"description":"is a SAS fileref that is assigned to the source file. To assign a fileref, use the FILENAME statement.","type":"value","supportSiteTargetFragment":"p0x7l14x6fl0win12kk93wv0d03l"},{"name":"'external-file'","placeholder":true,"description":"is the physical location of the source file. Specify the complete pathname and the filename.","type":"value","supportSiteTargetFragment":"n0zo65oz77ud70n1g35koeldvg7t"}],"supportSiteTargetFragment":"n0sv3axna2ir5gn1tyhraup58lfc"},{"name":"REGISTERJAR=","optional":true,"description":"specifies the locations of the JAR files that contain the Pig scripts to execute.","help":"REGISTERJAR='*external-file(s)*'","type":"value","supportSiteTargetFragment":"p06vej23levd3jn1dkng6nqgojri"},{"name":"REPLACE","optional":true,"description":"when connecting to Hadoop through the Oozie RESTful API, specifies to delete any existing workflow and JAR file(s) in the Oozie application before copying new files to the working directory.","type":"standalone","supportSiteTargetFragment":"n09rfio927sqmyn18d9acd9xtps5"},{"name":"WORKINGDIR=","optional":true,"description":"when connecting to Hadoop through the Oozie RESTful API, specifies the HDFS pathname for the Oozie workflow application directory.","help":"WORKINGDIR='*HDFS-pathname*'","type":"value","supportSiteTargetFragment":"n0xmv9ehbdp6kyn1ckyg047f1lda"}],"supportSiteTargetFile":"p1np380j2eb945n1dycw09yma4ti.htm"},{"name":"PROPERTIES","aliases":["PROP"],"description":"Submits configuration properties to the Hadoop server.","help":"PROPERTIES  '*configuration-property-1*' &lt;'*configuration-property-2*'&gt;  ...;","arguments":[{"name":"configuration-property","placeholder":true,"description":"specifies any property that can be specified in a Hadoop configuration file.","type":"value","supportSiteTargetFragment":"p1ql8qq8loawegn1idiq0jp6or33"}],"supportSiteTargetFile":"p1od05n4qavdfon19r3w6q5993f2.htm"}],"supportSiteInformation":{"docsetId":"proc","docsetVersion":"v_002","docsetTargetFile":"p0esxx8qmpi2p8n1mdmwn1al94a7.htm"}}